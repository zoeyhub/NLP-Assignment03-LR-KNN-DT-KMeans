{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston() #加载数据集\n",
    "x,y=dataset['data'],dataset['target']\n",
    "X_rm = x[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x218d0b82400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_rm,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume that the target funciton is a linear function\n",
    "$$ y = k*rm + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function\n",
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define mean square loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{\\mid y_i - \\hat{y_i}\\mid}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{\\mid y_i - (kx_i + b_i) \\mid}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function \n",
    "def loss(y,y_hat):\n",
    "    s=0\n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        if y_i > y_hat_i:\n",
    "            s += (y_i - y_hat_i)\n",
    "        if y_i < y_hat_i:\n",
    "            s += (y_hat_i - y_i)\n",
    "    return s/len(list(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y > \\hat y $$\n",
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = -\\frac{1}{n}\\sum x_i$$\n",
    "$$ \\frac{\\partial{loss}}{\\partial{b}} = -1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y < \\hat y $$\n",
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = \\frac{1}{n}\\sum x_i$$\n",
    "$$ \\frac{\\partial{loss}}{\\partial{b}} = 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial derivative \n",
    "def partial_derivative_k(x, y, y_hat): \n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        if y_i>y_hat_i:\n",
    "            gradient += x_i\n",
    "        else:\n",
    "            gradient += x_i*(-1)\n",
    "    return -1/n * gradient\n",
    "\n",
    "    \n",
    "def partial_derivative_b(y, y_hat):\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        if y_i>y_hat_i:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, the loss is 169.01749663487325, parameters k is -10.506036348954083 and b is -80.458092997358\n",
      "Iteration 1, the loss is 168.9770000054905, parameters k is -10.499751714566731 and b is -80.45709299735799\n",
      "Iteration 2, the loss is 168.93650337610785, parameters k is -10.493467080179379 and b is -80.45609299735798\n",
      "Iteration 3, the loss is 168.89600674672522, parameters k is -10.487182445792026 and b is -80.45509299735798\n",
      "Iteration 4, the loss is 168.85551011734265, parameters k is -10.480897811404674 and b is -80.45409299735798\n",
      "Iteration 5, the loss is 168.81501348795993, parameters k is -10.474613177017321 and b is -80.45309299735797\n",
      "Iteration 6, the loss is 168.77451685857716, parameters k is -10.468328542629969 and b is -80.45209299735797\n",
      "Iteration 7, the loss is 168.73402022919421, parameters k is -10.462043908242617 and b is -80.45109299735796\n",
      "Iteration 8, the loss is 168.69352359981164, parameters k is -10.455759273855264 and b is -80.45009299735796\n",
      "Iteration 9, the loss is 168.65302697042893, parameters k is -10.449474639467912 and b is -80.44909299735795\n",
      "Iteration 10, the loss is 168.61253034104627, parameters k is -10.44319000508056 and b is -80.44809299735795\n",
      "Iteration 11, the loss is 168.57203371166366, parameters k is -10.436905370693207 and b is -80.44709299735794\n",
      "Iteration 12, the loss is 168.53153708228078, parameters k is -10.430620736305855 and b is -80.44609299735794\n",
      "Iteration 13, the loss is 168.49104045289812, parameters k is -10.424336101918502 and b is -80.44509299735793\n",
      "Iteration 14, the loss is 168.45054382351555, parameters k is -10.41805146753115 and b is -80.44409299735793\n",
      "Iteration 15, the loss is 168.41004719413272, parameters k is -10.411766833143798 and b is -80.44309299735792\n",
      "Iteration 16, the loss is 168.36955056475014, parameters k is -10.405482198756445 and b is -80.44209299735792\n",
      "Iteration 17, the loss is 168.32905393536737, parameters k is -10.399197564369093 and b is -80.44109299735791\n",
      "Iteration 18, the loss is 168.288557305985, parameters k is -10.39291292998174 and b is -80.44009299735791\n",
      "Iteration 19, the loss is 168.2480606766022, parameters k is -10.386628295594388 and b is -80.4390929973579\n",
      "Iteration 20, the loss is 168.20756404721953, parameters k is -10.380343661207036 and b is -80.4380929973579\n",
      "Iteration 21, the loss is 168.16706741783676, parameters k is -10.374059026819683 and b is -80.4370929973579\n",
      "Iteration 22, the loss is 168.126570788454, parameters k is -10.367774392432331 and b is -80.43609299735789\n",
      "Iteration 23, the loss is 168.08607415907122, parameters k is -10.361489758044979 and b is -80.43509299735788\n",
      "Iteration 24, the loss is 168.04557752968861, parameters k is -10.355205123657626 and b is -80.43409299735788\n",
      "Iteration 25, the loss is 168.00508090030584, parameters k is -10.348920489270274 and b is -80.43309299735787\n",
      "Iteration 26, the loss is 167.96458427092307, parameters k is -10.342635854882921 and b is -80.43209299735787\n",
      "Iteration 27, the loss is 167.92408764154032, parameters k is -10.336351220495569 and b is -80.43109299735787\n",
      "Iteration 28, the loss is 167.8835910121578, parameters k is -10.330066586108217 and b is -80.43009299735786\n",
      "Iteration 29, the loss is 167.84309438277518, parameters k is -10.323781951720864 and b is -80.42909299735786\n",
      "Iteration 30, the loss is 167.8025977533924, parameters k is -10.317497317333512 and b is -80.42809299735785\n",
      "Iteration 31, the loss is 167.76210112400972, parameters k is -10.31121268294616 and b is -80.42709299735785\n",
      "Iteration 32, the loss is 167.72160449462714, parameters k is -10.304928048558807 and b is -80.42609299735784\n",
      "Iteration 33, the loss is 167.68110786524437, parameters k is -10.298643414171455 and b is -80.42509299735784\n",
      "Iteration 34, the loss is 167.6406112358617, parameters k is -10.292358779784102 and b is -80.42409299735783\n",
      "Iteration 35, the loss is 167.600114606479, parameters k is -10.28607414539675 and b is -80.42309299735783\n",
      "Iteration 36, the loss is 167.55961797709642, parameters k is -10.279789511009398 and b is -80.42209299735782\n",
      "Iteration 37, the loss is 167.51912134771348, parameters k is -10.273504876622045 and b is -80.42109299735782\n",
      "Iteration 38, the loss is 167.47862471833076, parameters k is -10.267220242234693 and b is -80.42009299735781\n",
      "Iteration 39, the loss is 167.43812808894842, parameters k is -10.26093560784734 and b is -80.41909299735781\n",
      "Iteration 40, the loss is 167.3976314595657, parameters k is -10.254650973459988 and b is -80.4180929973578\n",
      "Iteration 41, the loss is 167.35713483018282, parameters k is -10.248366339072636 and b is -80.4170929973578\n",
      "Iteration 42, the loss is 167.31663820080013, parameters k is -10.242081704685283 and b is -80.4160929973578\n",
      "Iteration 43, the loss is 167.27614157141747, parameters k is -10.23579707029793 and b is -80.41509299735779\n",
      "Iteration 44, the loss is 167.23564494203472, parameters k is -10.229512435910578 and b is -80.41409299735778\n",
      "Iteration 45, the loss is 167.19514831265204, parameters k is -10.223227801523226 and b is -80.41309299735778\n",
      "Iteration 46, the loss is 167.15465168326944, parameters k is -10.216943167135874 and b is -80.41209299735777\n",
      "Iteration 47, the loss is 167.11415505388663, parameters k is -10.210658532748521 and b is -80.41109299735777\n",
      "Iteration 48, the loss is 167.0736584245039, parameters k is -10.204373898361169 and b is -80.41009299735776\n",
      "Iteration 49, the loss is 167.03316179512134, parameters k is -10.198089263973817 and b is -80.40909299735776\n",
      "Iteration 50, the loss is 166.99266516573874, parameters k is -10.191804629586464 and b is -80.40809299735776\n",
      "Iteration 51, the loss is 166.95216853635583, parameters k is -10.185519995199112 and b is -80.40709299735775\n",
      "Iteration 52, the loss is 166.9116719069733, parameters k is -10.17923536081176 and b is -80.40609299735775\n",
      "Iteration 53, the loss is 166.8711752775905, parameters k is -10.172950726424407 and b is -80.40509299735774\n",
      "Iteration 54, the loss is 166.8306786482079, parameters k is -10.166666092037055 and b is -80.40409299735774\n",
      "Iteration 55, the loss is 166.79018201882522, parameters k is -10.160381457649702 and b is -80.40309299735773\n",
      "Iteration 56, the loss is 166.74968538944242, parameters k is -10.15409682326235 and b is -80.40209299735773\n",
      "Iteration 57, the loss is 166.70918876005976, parameters k is -10.147812188874997 and b is -80.40109299735772\n",
      "Iteration 58, the loss is 166.66869213067704, parameters k is -10.141527554487645 and b is -80.40009299735772\n",
      "Iteration 59, the loss is 166.6281955012943, parameters k is -10.135242920100293 and b is -80.39909299735771\n",
      "Iteration 60, the loss is 166.5876988719118, parameters k is -10.12895828571294 and b is -80.39809299735771\n",
      "Iteration 61, the loss is 166.54720224252878, parameters k is -10.122673651325588 and b is -80.3970929973577\n",
      "Iteration 62, the loss is 166.50670561314635, parameters k is -10.116389016938236 and b is -80.3960929973577\n",
      "Iteration 63, the loss is 166.4662089837636, parameters k is -10.110104382550883 and b is -80.3950929973577\n",
      "Iteration 64, the loss is 166.42571235438095, parameters k is -10.10381974816353 and b is -80.39409299735769\n",
      "Iteration 65, the loss is 166.3852157249982, parameters k is -10.097535113776178 and b is -80.39309299735768\n",
      "Iteration 66, the loss is 166.34471909561543, parameters k is -10.091250479388826 and b is -80.39209299735768\n",
      "Iteration 67, the loss is 166.3042224662328, parameters k is -10.084965845001474 and b is -80.39109299735767\n",
      "Iteration 68, the loss is 166.26372583685, parameters k is -10.078681210614121 and b is -80.39009299735767\n",
      "Iteration 69, the loss is 166.22322920746737, parameters k is -10.072396576226769 and b is -80.38909299735766\n",
      "Iteration 70, the loss is 166.1827325780847, parameters k is -10.066111941839416 and b is -80.38809299735766\n",
      "Iteration 71, the loss is 166.14223594870194, parameters k is -10.059827307452064 and b is -80.38709299735766\n",
      "Iteration 72, the loss is 166.10173931931917, parameters k is -10.053542673064712 and b is -80.38609299735765\n",
      "Iteration 73, the loss is 166.06124268993668, parameters k is -10.04725803867736 and b is -80.38509299735765\n",
      "Iteration 74, the loss is 166.02074606055382, parameters k is -10.040973404290007 and b is -80.38409299735764\n",
      "Iteration 75, the loss is 165.98024943117127, parameters k is -10.034688769902655 and b is -80.38309299735764\n",
      "Iteration 76, the loss is 165.9397528017884, parameters k is -10.028404135515302 and b is -80.38209299735763\n",
      "Iteration 77, the loss is 165.89925617240593, parameters k is -10.02211950112795 and b is -80.38109299735763\n",
      "Iteration 78, the loss is 165.85875954302333, parameters k is -10.015834866740597 and b is -80.38009299735762\n",
      "Iteration 79, the loss is 165.8182629136404, parameters k is -10.009550232353245 and b is -80.37909299735762\n",
      "Iteration 80, the loss is 165.77776628425764, parameters k is -10.003265597965893 and b is -80.37809299735761\n",
      "Iteration 81, the loss is 165.73726965487515, parameters k is -9.99698096357854 and b is -80.37709299735761\n",
      "Iteration 82, the loss is 165.6967730254923, parameters k is -9.990696329191188 and b is -80.3760929973576\n",
      "Iteration 83, the loss is 165.65627639610977, parameters k is -9.984411694803836 and b is -80.3750929973576\n",
      "Iteration 84, the loss is 165.61577976672686, parameters k is -9.978127060416483 and b is -80.3740929973576\n",
      "Iteration 85, the loss is 165.57528313734431, parameters k is -9.97184242602913 and b is -80.37309299735759\n",
      "Iteration 86, the loss is 165.53478650796183, parameters k is -9.965557791641778 and b is -80.37209299735758\n",
      "Iteration 87, the loss is 165.49428987857885, parameters k is -9.959273157254426 and b is -80.37109299735758\n",
      "Iteration 88, the loss is 165.453793249196, parameters k is -9.952988522867074 and b is -80.37009299735757\n",
      "Iteration 89, the loss is 165.41329661981337, parameters k is -9.946703888479721 and b is -80.36909299735757\n",
      "Iteration 90, the loss is 165.37279999043082, parameters k is -9.940419254092369 and b is -80.36809299735756\n",
      "Iteration 91, the loss is 165.3323033610481, parameters k is -9.934134619705016 and b is -80.36709299735756\n",
      "Iteration 92, the loss is 165.29180673166545, parameters k is -9.927849985317664 and b is -80.36609299735755\n",
      "Iteration 93, the loss is 165.25131010228299, parameters k is -9.921565350930312 and b is -80.36509299735755\n",
      "Iteration 94, the loss is 165.21081347290007, parameters k is -9.91528071654296 and b is -80.36409299735755\n",
      "Iteration 95, the loss is 165.17031684351727, parameters k is -9.908996082155607 and b is -80.36309299735754\n",
      "Iteration 96, the loss is 165.12982021413464, parameters k is -9.902711447768255 and b is -80.36209299735754\n",
      "Iteration 97, the loss is 165.0893235847519, parameters k is -9.896426813380902 and b is -80.36109299735753\n",
      "Iteration 98, the loss is 165.04882695536932, parameters k is -9.89014217899355 and b is -80.36009299735753\n",
      "Iteration 99, the loss is 165.00833032598663, parameters k is -9.883857544606197 and b is -80.35909299735752\n",
      "Iteration 100, the loss is 164.96783369660398, parameters k is -9.877572910218845 and b is -80.35809299735752\n",
      "Iteration 101, the loss is 164.92733706722123, parameters k is -9.871288275831493 and b is -80.35709299735751\n",
      "Iteration 102, the loss is 164.88684043783834, parameters k is -9.86500364144414 and b is -80.3560929973575\n",
      "Iteration 103, the loss is 164.84634380845577, parameters k is -9.858719007056788 and b is -80.3550929973575\n",
      "Iteration 104, the loss is 164.80584717907328, parameters k is -9.852434372669435 and b is -80.3540929973575\n",
      "Iteration 105, the loss is 164.76535054969048, parameters k is -9.846149738282083 and b is -80.35309299735749\n",
      "Iteration 106, the loss is 164.72485392030757, parameters k is -9.83986510389473 and b is -80.35209299735749\n",
      "Iteration 107, the loss is 164.6843572909251, parameters k is -9.833580469507378 and b is -80.35109299735748\n",
      "Iteration 108, the loss is 164.64386066154242, parameters k is -9.827295835120026 and b is -80.35009299735748\n",
      "Iteration 109, the loss is 164.60336403215956, parameters k is -9.821011200732674 and b is -80.34909299735747\n",
      "Iteration 110, the loss is 164.562867402777, parameters k is -9.814726566345321 and b is -80.34809299735747\n",
      "Iteration 111, the loss is 164.5223707733944, parameters k is -9.808441931957969 and b is -80.34709299735746\n",
      "Iteration 112, the loss is 164.48187414401175, parameters k is -9.802157297570616 and b is -80.34609299735746\n",
      "Iteration 113, the loss is 164.44137751462887, parameters k is -9.795872663183264 and b is -80.34509299735745\n",
      "Iteration 114, the loss is 164.4008808852465, parameters k is -9.789588028795912 and b is -80.34409299735745\n",
      "Iteration 115, the loss is 164.3603842558635, parameters k is -9.78330339440856 and b is -80.34309299735745\n",
      "Iteration 116, the loss is 164.31988762648072, parameters k is -9.777018760021207 and b is -80.34209299735744\n",
      "Iteration 117, the loss is 164.27939099709803, parameters k is -9.770734125633854 and b is -80.34109299735744\n",
      "Iteration 118, the loss is 164.2388943677154, parameters k is -9.764449491246502 and b is -80.34009299735743\n",
      "Iteration 119, the loss is 164.19839773833274, parameters k is -9.75816485685915 and b is -80.33909299735743\n",
      "Iteration 120, the loss is 164.15790110894997, parameters k is -9.751880222471797 and b is -80.33809299735742\n",
      "Iteration 121, the loss is 164.1174044795674, parameters k is -9.745595588084445 and b is -80.33709299735742\n",
      "Iteration 122, the loss is 164.07690785018457, parameters k is -9.739310953697093 and b is -80.33609299735741\n",
      "Iteration 123, the loss is 164.03641122080185, parameters k is -9.73302631930974 and b is -80.3350929973574\n",
      "Iteration 124, the loss is 163.9959145914194, parameters k is -9.726741684922388 and b is -80.3340929973574\n",
      "Iteration 125, the loss is 163.9554179620367, parameters k is -9.720457050535035 and b is -80.3330929973574\n",
      "Iteration 126, the loss is 163.91492133265376, parameters k is -9.714172416147683 and b is -80.33209299735739\n",
      "Iteration 127, the loss is 163.8744247032713, parameters k is -9.70788778176033 and b is -80.33109299735739\n",
      "Iteration 128, the loss is 163.83392807388842, parameters k is -9.701603147372978 and b is -80.33009299735738\n",
      "Iteration 129, the loss is 163.793431444506, parameters k is -9.695318512985626 and b is -80.32909299735738\n",
      "Iteration 130, the loss is 163.75293481512307, parameters k is -9.689033878598273 and b is -80.32809299735737\n",
      "Iteration 131, the loss is 163.7124381857404, parameters k is -9.682749244210921 and b is -80.32709299735737\n",
      "Iteration 132, the loss is 163.6719415563577, parameters k is -9.676464609823569 and b is -80.32609299735736\n",
      "Iteration 133, the loss is 163.63144492697506, parameters k is -9.670179975436216 and b is -80.32509299735736\n",
      "Iteration 134, the loss is 163.5909482975925, parameters k is -9.663895341048864 and b is -80.32409299735735\n",
      "Iteration 135, the loss is 163.55045166820972, parameters k is -9.657610706661512 and b is -80.32309299735735\n",
      "Iteration 136, the loss is 163.5099550388269, parameters k is -9.65132607227416 and b is -80.32209299735734\n",
      "Iteration 137, the loss is 163.46945840944414, parameters k is -9.645041437886807 and b is -80.32109299735734\n",
      "Iteration 138, the loss is 163.42896178006157, parameters k is -9.638756803499454 and b is -80.32009299735734\n",
      "Iteration 139, the loss is 163.3884651506788, parameters k is -9.632472169112102 and b is -80.31909299735733\n",
      "Iteration 140, the loss is 163.34796852129625, parameters k is -9.62618753472475 and b is -80.31809299735733\n",
      "Iteration 141, the loss is 163.30747189191376, parameters k is -9.619902900337397 and b is -80.31709299735732\n",
      "Iteration 142, the loss is 163.2669752625308, parameters k is -9.613618265950045 and b is -80.31609299735732\n",
      "Iteration 143, the loss is 163.2264786331482, parameters k is -9.607333631562692 and b is -80.31509299735731\n",
      "Iteration 144, the loss is 163.1859820037654, parameters k is -9.60104899717534 and b is -80.3140929973573\n",
      "Iteration 145, the loss is 163.1454853743828, parameters k is -9.594764362787988 and b is -80.3130929973573\n",
      "Iteration 146, the loss is 163.1049887450001, parameters k is -9.588479728400635 and b is -80.3120929973573\n",
      "Iteration 147, the loss is 163.0644921156173, parameters k is -9.582195094013283 and b is -80.31109299735729\n",
      "Iteration 148, the loss is 163.02399548623453, parameters k is -9.57591045962593 and b is -80.31009299735729\n",
      "Iteration 149, the loss is 162.98349885685187, parameters k is -9.569625825238578 and b is -80.30909299735728\n",
      "Iteration 150, the loss is 162.94300222746918, parameters k is -9.563341190851226 and b is -80.30809299735728\n",
      "Iteration 151, the loss is 162.90250559808644, parameters k is -9.557056556463873 and b is -80.30709299735727\n",
      "Iteration 152, the loss is 162.86200896870378, parameters k is -9.550771922076521 and b is -80.30609299735727\n",
      "Iteration 153, the loss is 162.82151233932112, parameters k is -9.544487287689169 and b is -80.30509299735726\n",
      "Iteration 154, the loss is 162.78101570993852, parameters k is -9.538202653301816 and b is -80.30409299735726\n",
      "Iteration 155, the loss is 162.74051908055594, parameters k is -9.531918018914464 and b is -80.30309299735725\n",
      "Iteration 156, the loss is 162.70002245117308, parameters k is -9.525633384527112 and b is -80.30209299735725\n",
      "Iteration 157, the loss is 162.65952582179045, parameters k is -9.51934875013976 and b is -80.30109299735724\n",
      "Iteration 158, the loss is 162.61902919240765, parameters k is -9.513064115752407 and b is -80.30009299735724\n",
      "Iteration 159, the loss is 162.57853256302502, parameters k is -9.506779481365054 and b is -80.29909299735723\n",
      "Iteration 160, the loss is 162.53803593364228, parameters k is -9.500494846977702 and b is -80.29809299735723\n",
      "Iteration 161, the loss is 162.49753930425956, parameters k is -9.49421021259035 and b is -80.29709299735723\n",
      "Iteration 162, the loss is 162.457042674877, parameters k is -9.487925578202997 and b is -80.29609299735722\n",
      "Iteration 163, the loss is 162.41654604549427, parameters k is -9.481640943815645 and b is -80.29509299735722\n",
      "Iteration 164, the loss is 162.37604941611156, parameters k is -9.475356309428292 and b is -80.29409299735721\n",
      "Iteration 165, the loss is 162.33555278672907, parameters k is -9.46907167504094 and b is -80.2930929973572\n",
      "Iteration 166, the loss is 162.2950561573459, parameters k is -9.462787040653588 and b is -80.2920929973572\n",
      "Iteration 167, the loss is 162.25455952796355, parameters k is -9.456502406266235 and b is -80.2910929973572\n",
      "Iteration 168, the loss is 162.21406289858075, parameters k is -9.450217771878883 and b is -80.29009299735719\n",
      "Iteration 169, the loss is 162.17356626919812, parameters k is -9.44393313749153 and b is -80.28909299735719\n",
      "Iteration 170, the loss is 162.1330696398154, parameters k is -9.437648503104178 and b is -80.28809299735718\n",
      "Iteration 171, the loss is 162.09257301043277, parameters k is -9.431363868716826 and b is -80.28709299735718\n",
      "Iteration 172, the loss is 162.05207638105, parameters k is -9.425079234329473 and b is -80.28609299735717\n",
      "Iteration 173, the loss is 162.01157975166745, parameters k is -9.418794599942121 and b is -80.28509299735717\n",
      "Iteration 174, the loss is 161.97108312228457, parameters k is -9.412509965554769 and b is -80.28409299735716\n",
      "Iteration 175, the loss is 161.93058649290185, parameters k is -9.406225331167416 and b is -80.28309299735716\n",
      "Iteration 176, the loss is 161.8900898635192, parameters k is -9.399940696780064 and b is -80.28209299735715\n",
      "Iteration 177, the loss is 161.84959323413636, parameters k is -9.393656062392711 and b is -80.28109299735715\n",
      "Iteration 178, the loss is 161.80909660475376, parameters k is -9.387371428005359 and b is -80.28009299735714\n",
      "Iteration 179, the loss is 161.7685999753711, parameters k is -9.381086793618007 and b is -80.27909299735714\n",
      "Iteration 180, the loss is 161.72810334598847, parameters k is -9.374802159230654 and b is -80.27809299735713\n",
      "Iteration 181, the loss is 161.68760671660573, parameters k is -9.368517524843302 and b is -80.27709299735713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 182, the loss is 161.64711008722296, parameters k is -9.36223289045595 and b is -80.27609299735713\n",
      "Iteration 183, the loss is 161.60661345784038, parameters k is -9.355948256068597 and b is -80.27509299735712\n",
      "Iteration 184, the loss is 161.56611682845784, parameters k is -9.349663621681245 and b is -80.27409299735712\n",
      "Iteration 185, the loss is 161.5256201990751, parameters k is -9.343378987293892 and b is -80.27309299735711\n",
      "Iteration 186, the loss is 161.48512356969226, parameters k is -9.33709435290654 and b is -80.2720929973571\n",
      "Iteration 187, the loss is 161.44462694030958, parameters k is -9.330809718519188 and b is -80.2710929973571\n",
      "Iteration 188, the loss is 161.40413031092658, parameters k is -9.324525084131835 and b is -80.2700929973571\n",
      "Iteration 189, the loss is 161.36363368154417, parameters k is -9.318240449744483 and b is -80.26909299735709\n",
      "Iteration 190, the loss is 161.32313705216166, parameters k is -9.31195581535713 and b is -80.26809299735709\n",
      "Iteration 191, the loss is 161.28264042277894, parameters k is -9.305671180969778 and b is -80.26709299735708\n",
      "Iteration 192, the loss is 161.24214379339608, parameters k is -9.299386546582426 and b is -80.26609299735708\n",
      "Iteration 193, the loss is 161.20164716401354, parameters k is -9.293101912195073 and b is -80.26509299735707\n",
      "Iteration 194, the loss is 161.16115053463096, parameters k is -9.286817277807721 and b is -80.26409299735707\n",
      "Iteration 195, the loss is 161.1206539052482, parameters k is -9.280532643420369 and b is -80.26309299735706\n",
      "Iteration 196, the loss is 161.08015727586525, parameters k is -9.274248009033016 and b is -80.26209299735706\n",
      "Iteration 197, the loss is 161.0396606464825, parameters k is -9.267963374645664 and b is -80.26109299735705\n",
      "Iteration 198, the loss is 160.9991640170999, parameters k is -9.261678740258311 and b is -80.26009299735705\n",
      "Iteration 199, the loss is 160.9586673877172, parameters k is -9.255394105870959 and b is -80.25909299735704\n",
      "Iteration 200, the loss is 160.91817075833472, parameters k is -9.249109471483607 and b is -80.25809299735704\n",
      "Iteration 201, the loss is 160.87767412895178, parameters k is -9.242824837096254 and b is -80.25709299735703\n",
      "Iteration 202, the loss is 160.83717749956924, parameters k is -9.236540202708902 and b is -80.25609299735703\n",
      "Iteration 203, the loss is 160.7966808701866, parameters k is -9.23025556832155 and b is -80.25509299735702\n",
      "Iteration 204, the loss is 160.7561842408037, parameters k is -9.223970933934197 and b is -80.25409299735702\n",
      "Iteration 205, the loss is 160.71568761142112, parameters k is -9.217686299546845 and b is -80.25309299735702\n",
      "Iteration 206, the loss is 160.67519098203854, parameters k is -9.211401665159492 and b is -80.25209299735701\n",
      "Iteration 207, the loss is 160.63469435265594, parameters k is -9.20511703077214 and b is -80.251092997357\n",
      "Iteration 208, the loss is 160.59419772327297, parameters k is -9.198832396384788 and b is -80.250092997357\n",
      "Iteration 209, the loss is 160.55370109389048, parameters k is -9.192547761997435 and b is -80.249092997357\n",
      "Iteration 210, the loss is 160.51320446450754, parameters k is -9.186263127610083 and b is -80.24809299735699\n",
      "Iteration 211, the loss is 160.47270783512502, parameters k is -9.17997849322273 and b is -80.24709299735699\n",
      "Iteration 212, the loss is 160.4322112057422, parameters k is -9.173693858835378 and b is -80.24609299735698\n",
      "Iteration 213, the loss is 160.3917145763596, parameters k is -9.167409224448026 and b is -80.24509299735698\n",
      "Iteration 214, the loss is 160.35121794697693, parameters k is -9.161124590060673 and b is -80.24409299735697\n",
      "Iteration 215, the loss is 160.31072131759427, parameters k is -9.15483995567332 and b is -80.24309299735697\n",
      "Iteration 216, the loss is 160.2702246882114, parameters k is -9.148555321285968 and b is -80.24209299735696\n",
      "Iteration 217, the loss is 160.2297280588289, parameters k is -9.142270686898616 and b is -80.24109299735696\n",
      "Iteration 218, the loss is 160.18923142944624, parameters k is -9.135986052511264 and b is -80.24009299735695\n",
      "Iteration 219, the loss is 160.14873480006358, parameters k is -9.129701418123911 and b is -80.23909299735695\n",
      "Iteration 220, the loss is 160.10823817068083, parameters k is -9.123416783736559 and b is -80.23809299735694\n",
      "Iteration 221, the loss is 160.06774154129815, parameters k is -9.117132149349207 and b is -80.23709299735694\n",
      "Iteration 222, the loss is 160.02724491191537, parameters k is -9.110847514961854 and b is -80.23609299735693\n",
      "Iteration 223, the loss is 159.9867482825328, parameters k is -9.104562880574502 and b is -80.23509299735693\n",
      "Iteration 224, the loss is 159.94625165315003, parameters k is -9.09827824618715 and b is -80.23409299735692\n",
      "Iteration 225, the loss is 159.90575502376726, parameters k is -9.091993611799797 and b is -80.23309299735692\n",
      "Iteration 226, the loss is 159.86525839438428, parameters k is -9.085708977412445 and b is -80.23209299735692\n",
      "Iteration 227, the loss is 159.82476176500197, parameters k is -9.079424343025092 and b is -80.23109299735691\n",
      "Iteration 228, the loss is 159.78426513561917, parameters k is -9.07313970863774 and b is -80.2300929973569\n",
      "Iteration 229, the loss is 159.7437685062367, parameters k is -9.066855074250388 and b is -80.2290929973569\n",
      "Iteration 230, the loss is 159.7032718768539, parameters k is -9.060570439863035 and b is -80.2280929973569\n",
      "Iteration 231, the loss is 159.66277524747105, parameters k is -9.054285805475683 and b is -80.22709299735689\n",
      "Iteration 232, the loss is 159.6222786180884, parameters k is -9.04800117108833 and b is -80.22609299735689\n",
      "Iteration 233, the loss is 159.58178198870567, parameters k is -9.041716536700978 and b is -80.22509299735688\n",
      "Iteration 234, the loss is 159.5412853593231, parameters k is -9.035431902313626 and b is -80.22409299735688\n",
      "Iteration 235, the loss is 159.50078872994018, parameters k is -9.029147267926273 and b is -80.22309299735687\n",
      "Iteration 236, the loss is 159.46029210055758, parameters k is -9.02286263353892 and b is -80.22209299735687\n",
      "Iteration 237, the loss is 159.41979547117498, parameters k is -9.016577999151568 and b is -80.22109299735686\n",
      "Iteration 238, the loss is 159.37929884179235, parameters k is -9.010293364764216 and b is -80.22009299735686\n",
      "Iteration 239, the loss is 159.33880221240938, parameters k is -9.004008730376864 and b is -80.21909299735685\n",
      "Iteration 240, the loss is 159.29830558302675, parameters k is -8.997724095989511 and b is -80.21809299735685\n",
      "Iteration 241, the loss is 159.25780895364406, parameters k is -8.991439461602159 and b is -80.21709299735684\n",
      "Iteration 242, the loss is 159.2173123242614, parameters k is -8.985154827214807 and b is -80.21609299735684\n",
      "Iteration 243, the loss is 159.1768156948789, parameters k is -8.978870192827454 and b is -80.21509299735683\n",
      "Iteration 244, the loss is 159.1363190654961, parameters k is -8.972585558440102 and b is -80.21409299735683\n",
      "Iteration 245, the loss is 159.09582243611345, parameters k is -8.96630092405275 and b is -80.21309299735682\n",
      "Iteration 246, the loss is 159.05532580673062, parameters k is -8.960016289665397 and b is -80.21209299735682\n",
      "Iteration 247, the loss is 159.014829177348, parameters k is -8.953731655278045 and b is -80.21109299735681\n",
      "Iteration 248, the loss is 158.97433254796542, parameters k is -8.947447020890692 and b is -80.21009299735681\n",
      "Iteration 249, the loss is 158.93383591858276, parameters k is -8.94116238650334 and b is -80.2090929973568\n",
      "Iteration 250, the loss is 158.89333928920004, parameters k is -8.934877752115987 and b is -80.2080929973568\n",
      "Iteration 251, the loss is 158.85284265981738, parameters k is -8.928593117728635 and b is -80.2070929973568\n",
      "Iteration 252, the loss is 158.81234603043464, parameters k is -8.922308483341283 and b is -80.20609299735679\n",
      "Iteration 253, the loss is 158.77184940105192, parameters k is -8.91602384895393 and b is -80.20509299735679\n",
      "Iteration 254, the loss is 158.7313527716692, parameters k is -8.909739214566578 and b is -80.20409299735678\n",
      "Iteration 255, the loss is 158.69085614228655, parameters k is -8.903454580179226 and b is -80.20309299735678\n",
      "Iteration 256, the loss is 158.65035951290378, parameters k is -8.897169945791873 and b is -80.20209299735677\n",
      "Iteration 257, the loss is 158.6098628835212, parameters k is -8.89088531140452 and b is -80.20109299735677\n",
      "Iteration 258, the loss is 158.5693662541386, parameters k is -8.884600677017168 and b is -80.20009299735676\n",
      "Iteration 259, the loss is 158.52886962475577, parameters k is -8.878316042629816 and b is -80.19909299735676\n",
      "Iteration 260, the loss is 158.48837299537306, parameters k is -8.872031408242464 and b is -80.19809299735675\n",
      "Iteration 261, the loss is 158.44787636599023, parameters k is -8.865746773855111 and b is -80.19709299735675\n",
      "Iteration 262, the loss is 158.4073797366076, parameters k is -8.859462139467759 and b is -80.19609299735674\n",
      "Iteration 263, the loss is 158.36688310722505, parameters k is -8.853177505080406 and b is -80.19509299735674\n",
      "Iteration 264, the loss is 158.32638647784233, parameters k is -8.846892870693054 and b is -80.19409299735673\n",
      "Iteration 265, the loss is 158.2858898484596, parameters k is -8.840608236305702 and b is -80.19309299735673\n",
      "Iteration 266, the loss is 158.24539321907693, parameters k is -8.83432360191835 and b is -80.19209299735672\n",
      "Iteration 267, the loss is 158.2048965896943, parameters k is -8.828038967530997 and b is -80.19109299735672\n",
      "Iteration 268, the loss is 158.16439996031158, parameters k is -8.821754333143645 and b is -80.19009299735671\n",
      "Iteration 269, the loss is 158.12390333092875, parameters k is -8.815469698756292 and b is -80.18909299735671\n",
      "Iteration 270, the loss is 158.08340670154607, parameters k is -8.80918506436894 and b is -80.1880929973567\n",
      "Iteration 271, the loss is 158.04291007216338, parameters k is -8.802900429981587 and b is -80.1870929973567\n",
      "Iteration 272, the loss is 158.0024134427806, parameters k is -8.796615795594235 and b is -80.1860929973567\n",
      "Iteration 273, the loss is 157.961916813398, parameters k is -8.790331161206883 and b is -80.18509299735669\n",
      "Iteration 274, the loss is 157.92142018401526, parameters k is -8.78404652681953 and b is -80.18409299735669\n",
      "Iteration 275, the loss is 157.8809235546325, parameters k is -8.777761892432178 and b is -80.18309299735668\n",
      "Iteration 276, the loss is 157.84042692524983, parameters k is -8.771477258044825 and b is -80.18209299735668\n",
      "Iteration 277, the loss is 157.79993029586723, parameters k is -8.765192623657473 and b is -80.18109299735667\n",
      "Iteration 278, the loss is 157.7594336664846, parameters k is -8.75890798927012 and b is -80.18009299735667\n",
      "Iteration 279, the loss is 157.71893703710182, parameters k is -8.752623354882768 and b is -80.17909299735666\n",
      "Iteration 280, the loss is 157.6784404077192, parameters k is -8.746338720495416 and b is -80.17809299735666\n",
      "Iteration 281, the loss is 157.63794377833653, parameters k is -8.740054086108064 and b is -80.17709299735665\n",
      "Iteration 282, the loss is 157.59744714895348, parameters k is -8.733769451720711 and b is -80.17609299735665\n",
      "Iteration 283, the loss is 157.55695051957116, parameters k is -8.727484817333359 and b is -80.17509299735664\n",
      "Iteration 284, the loss is 157.51645389018836, parameters k is -8.721200182946006 and b is -80.17409299735664\n",
      "Iteration 285, the loss is 157.47595726080573, parameters k is -8.714915548558654 and b is -80.17309299735663\n",
      "Iteration 286, the loss is 157.43546063142293, parameters k is -8.708630914171302 and b is -80.17209299735663\n",
      "Iteration 287, the loss is 157.39496400204027, parameters k is -8.70234627978395 and b is -80.17109299735662\n",
      "Iteration 288, the loss is 157.35446737265744, parameters k is -8.696061645396597 and b is -80.17009299735662\n",
      "Iteration 289, the loss is 157.31397074327498, parameters k is -8.689777011009244 and b is -80.16909299735661\n",
      "Iteration 290, the loss is 157.2734741138923, parameters k is -8.683492376621892 and b is -80.16809299735661\n",
      "Iteration 291, the loss is 157.23297748450958, parameters k is -8.67720774223454 and b is -80.1670929973566\n",
      "Iteration 292, the loss is 157.19248085512683, parameters k is -8.670923107847187 and b is -80.1660929973566\n",
      "Iteration 293, the loss is 157.1519842257443, parameters k is -8.664638473459835 and b is -80.1650929973566\n",
      "Iteration 294, the loss is 157.1114875963615, parameters k is -8.658353839072483 and b is -80.16409299735659\n",
      "Iteration 295, the loss is 157.07099096697897, parameters k is -8.65206920468513 and b is -80.16309299735659\n",
      "Iteration 296, the loss is 157.030494337596, parameters k is -8.645784570297778 and b is -80.16209299735658\n",
      "Iteration 297, the loss is 156.98999770821337, parameters k is -8.639499935910425 and b is -80.16109299735658\n",
      "Iteration 298, the loss is 156.9495010788306, parameters k is -8.633215301523073 and b is -80.16009299735657\n",
      "Iteration 299, the loss is 156.909004449448, parameters k is -8.62693066713572 and b is -80.15909299735657\n",
      "Iteration 300, the loss is 156.86850782006553, parameters k is -8.620646032748368 and b is -80.15809299735656\n",
      "Iteration 301, the loss is 156.8280111906825, parameters k is -8.614361398361016 and b is -80.15709299735656\n",
      "Iteration 302, the loss is 156.78751456129996, parameters k is -8.608076763973664 and b is -80.15609299735655\n",
      "Iteration 303, the loss is 156.74701793191718, parameters k is -8.601792129586311 and b is -80.15509299735655\n",
      "Iteration 304, the loss is 156.70652130253467, parameters k is -8.595507495198959 and b is -80.15409299735654\n",
      "Iteration 305, the loss is 156.66602467315187, parameters k is -8.589222860811606 and b is -80.15309299735654\n",
      "Iteration 306, the loss is 156.62552804376918, parameters k is -8.582938226424254 and b is -80.15209299735653\n",
      "Iteration 307, the loss is 156.5850314143866, parameters k is -8.576653592036902 and b is -80.15109299735653\n",
      "Iteration 308, the loss is 156.5445347850039, parameters k is -8.57036895764955 and b is -80.15009299735652\n",
      "Iteration 309, the loss is 156.5040381556213, parameters k is -8.564084323262197 and b is -80.14909299735652\n",
      "Iteration 310, the loss is 156.46354152623837, parameters k is -8.557799688874844 and b is -80.14809299735651\n",
      "Iteration 311, the loss is 156.42304489685574, parameters k is -8.551515054487492 and b is -80.14709299735651\n",
      "Iteration 312, the loss is 156.3825482674727, parameters k is -8.54523042010014 and b is -80.1460929973565\n",
      "Iteration 313, the loss is 156.3420516380904, parameters k is -8.538945785712787 and b is -80.1450929973565\n",
      "Iteration 314, the loss is 156.3015550087077, parameters k is -8.532661151325435 and b is -80.1440929973565\n",
      "Iteration 315, the loss is 156.26105837932496, parameters k is -8.526376516938083 and b is -80.14309299735649\n",
      "Iteration 316, the loss is 156.22056174994205, parameters k is -8.52009188255073 and b is -80.14209299735649\n",
      "Iteration 317, the loss is 156.18006512055936, parameters k is -8.513807248163378 and b is -80.14109299735648\n",
      "Iteration 318, the loss is 156.13956849117693, parameters k is -8.507522613776025 and b is -80.14009299735648\n",
      "Iteration 319, the loss is 156.099071861794, parameters k is -8.501237979388673 and b is -80.13909299735647\n",
      "Iteration 320, the loss is 156.05857523241127, parameters k is -8.49495334500132 and b is -80.13809299735647\n",
      "Iteration 321, the loss is 156.01807860302867, parameters k is -8.488668710613968 and b is -80.13709299735646\n",
      "Iteration 322, the loss is 155.97758197364595, parameters k is -8.482384076226616 and b is -80.13609299735646\n",
      "Iteration 323, the loss is 155.93708534426344, parameters k is -8.476099441839263 and b is -80.13509299735645\n",
      "Iteration 324, the loss is 155.89658871488066, parameters k is -8.469814807451911 and b is -80.13409299735645\n",
      "Iteration 325, the loss is 155.85609208549803, parameters k is -8.463530173064559 and b is -80.13309299735644\n",
      "Iteration 326, the loss is 155.81559545611537, parameters k is -8.457245538677206 and b is -80.13209299735644\n",
      "Iteration 327, the loss is 155.77509882673246, parameters k is -8.450960904289854 and b is -80.13109299735643\n",
      "Iteration 328, the loss is 155.7346021973501, parameters k is -8.444676269902502 and b is -80.13009299735643\n",
      "Iteration 329, the loss is 155.69410556796728, parameters k is -8.43839163551515 and b is -80.12909299735642\n",
      "Iteration 330, the loss is 155.65360893858448, parameters k is -8.432107001127797 and b is -80.12809299735642\n",
      "Iteration 331, the loss is 155.61311230920185, parameters k is -8.425822366740444 and b is -80.12709299735641\n",
      "Iteration 332, the loss is 155.5726156798189, parameters k is -8.419537732353092 and b is -80.12609299735641\n",
      "Iteration 333, the loss is 155.53211905043665, parameters k is -8.41325309796574 and b is -80.1250929973564\n",
      "Iteration 334, the loss is 155.49162242105382, parameters k is -8.406968463578387 and b is -80.1240929973564\n",
      "Iteration 335, the loss is 155.4511257916709, parameters k is -8.400683829191035 and b is -80.1230929973564\n",
      "Iteration 336, the loss is 155.4106291622883, parameters k is -8.394399194803682 and b is -80.12209299735639\n",
      "Iteration 337, the loss is 155.37013253290573, parameters k is -8.38811456041633 and b is -80.12109299735639\n",
      "Iteration 338, the loss is 155.32963590352298, parameters k is -8.381829926028978 and b is -80.12009299735638\n",
      "Iteration 339, the loss is 155.28913927414013, parameters k is -8.375545291641625 and b is -80.11909299735638\n",
      "Iteration 340, the loss is 155.24864264475752, parameters k is -8.369260657254273 and b is -80.11809299735637\n",
      "Iteration 341, the loss is 155.20814601537498, parameters k is -8.36297602286692 and b is -80.11709299735637\n",
      "Iteration 342, the loss is 155.16764938599223, parameters k is -8.356691388479568 and b is -80.11609299735636\n",
      "Iteration 343, the loss is 155.1271527566093, parameters k is -8.350406754092216 and b is -80.11509299735636\n",
      "Iteration 344, the loss is 155.08665612722697, parameters k is -8.344122119704863 and b is -80.11409299735635\n",
      "Iteration 345, the loss is 155.04615949784412, parameters k is -8.337837485317511 and b is -80.11309299735635\n",
      "Iteration 346, the loss is 155.0056628684614, parameters k is -8.331552850930159 and b is -80.11209299735634\n",
      "Iteration 347, the loss is 154.9651662390787, parameters k is -8.325268216542806 and b is -80.11109299735634\n",
      "Iteration 348, the loss is 154.92466960969594, parameters k is -8.318983582155454 and b is -80.11009299735633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 349, the loss is 154.88417298031322, parameters k is -8.312698947768101 and b is -80.10909299735633\n",
      "Iteration 350, the loss is 154.84367635093065, parameters k is -8.306414313380749 and b is -80.10809299735632\n",
      "Iteration 351, the loss is 154.8031797215479, parameters k is -8.300129678993397 and b is -80.10709299735632\n",
      "Iteration 352, the loss is 154.7626830921652, parameters k is -8.293845044606044 and b is -80.10609299735631\n",
      "Iteration 353, the loss is 154.7221864627828, parameters k is -8.287560410218692 and b is -80.10509299735631\n",
      "Iteration 354, the loss is 154.68168983340001, parameters k is -8.28127577583134 and b is -80.1040929973563\n",
      "Iteration 355, the loss is 154.64119320401713, parameters k is -8.274991141443987 and b is -80.1030929973563\n",
      "Iteration 356, the loss is 154.6006965746345, parameters k is -8.268706507056635 and b is -80.1020929973563\n",
      "Iteration 357, the loss is 154.5601999452519, parameters k is -8.262421872669282 and b is -80.10109299735629\n",
      "Iteration 358, the loss is 154.51970331586924, parameters k is -8.25613723828193 and b is -80.10009299735628\n",
      "Iteration 359, the loss is 154.4792066864864, parameters k is -8.249852603894578 and b is -80.09909299735628\n",
      "Iteration 360, the loss is 154.43871005710375, parameters k is -8.243567969507225 and b is -80.09809299735628\n",
      "Iteration 361, the loss is 154.39821342772086, parameters k is -8.237283335119873 and b is -80.09709299735627\n",
      "Iteration 362, the loss is 154.3577167983384, parameters k is -8.23099870073252 and b is -80.09609299735627\n",
      "Iteration 363, the loss is 154.31722016895569, parameters k is -8.224714066345168 and b is -80.09509299735626\n",
      "Iteration 364, the loss is 154.276723539573, parameters k is -8.218429431957816 and b is -80.09409299735626\n",
      "Iteration 365, the loss is 154.2362269101902, parameters k is -8.212144797570463 and b is -80.09309299735625\n",
      "Iteration 366, the loss is 154.19573028080757, parameters k is -8.205860163183111 and b is -80.09209299735625\n",
      "Iteration 367, the loss is 154.15523365142482, parameters k is -8.199575528795759 and b is -80.09109299735624\n",
      "Iteration 368, the loss is 154.11473702204222, parameters k is -8.193290894408406 and b is -80.09009299735624\n",
      "Iteration 369, the loss is 154.0742403926596, parameters k is -8.187006260021054 and b is -80.08909299735623\n",
      "Iteration 370, the loss is 154.03374376327668, parameters k is -8.180721625633701 and b is -80.08809299735623\n",
      "Iteration 371, the loss is 153.99324713389404, parameters k is -8.174436991246349 and b is -80.08709299735622\n",
      "Iteration 372, the loss is 153.9527505045114, parameters k is -8.168152356858997 and b is -80.08609299735622\n",
      "Iteration 373, the loss is 153.91225387512878, parameters k is -8.161867722471644 and b is -80.08509299735621\n",
      "Iteration 374, the loss is 153.87175724574593, parameters k is -8.155583088084292 and b is -80.08409299735621\n",
      "Iteration 375, the loss is 153.83126061636332, parameters k is -8.14929845369694 and b is -80.0830929973562\n",
      "Iteration 376, the loss is 153.7907639869805, parameters k is -8.143013819309587 and b is -80.0820929973562\n",
      "Iteration 377, the loss is 153.75026735759764, parameters k is -8.136729184922235 and b is -80.0810929973562\n",
      "Iteration 378, the loss is 153.70977072821532, parameters k is -8.130444550534882 and b is -80.08009299735619\n",
      "Iteration 379, the loss is 153.6692740988325, parameters k is -8.12415991614753 and b is -80.07909299735618\n",
      "Iteration 380, the loss is 153.62877746944986, parameters k is -8.117875281760178 and b is -80.07809299735618\n",
      "Iteration 381, the loss is 153.58828084006717, parameters k is -8.111590647372825 and b is -80.07709299735617\n",
      "Iteration 382, the loss is 153.54778421068445, parameters k is -8.105306012985473 and b is -80.07609299735617\n",
      "Iteration 383, the loss is 153.5072875813017, parameters k is -8.09902137859812 and b is -80.07509299735617\n",
      "Iteration 384, the loss is 153.46679095191905, parameters k is -8.092736744210768 and b is -80.07409299735616\n",
      "Iteration 385, the loss is 153.42629432253636, parameters k is -8.086452109823416 and b is -80.07309299735616\n",
      "Iteration 386, the loss is 153.38579769315365, parameters k is -8.080167475436063 and b is -80.07209299735615\n",
      "Iteration 387, the loss is 153.34530106377105, parameters k is -8.073882841048711 and b is -80.07109299735615\n",
      "Iteration 388, the loss is 153.30480443438836, parameters k is -8.067598206661359 and b is -80.07009299735614\n",
      "Iteration 389, the loss is 153.26430780500553, parameters k is -8.061313572274006 and b is -80.06909299735614\n",
      "Iteration 390, the loss is 153.223811175623, parameters k is -8.055028937886654 and b is -80.06809299735613\n",
      "Iteration 391, the loss is 153.18331454624044, parameters k is -8.048744303499301 and b is -80.06709299735613\n",
      "Iteration 392, the loss is 153.14281791685747, parameters k is -8.042459669111949 and b is -80.06609299735612\n",
      "Iteration 393, the loss is 153.1023212874749, parameters k is -8.036175034724597 and b is -80.06509299735612\n",
      "Iteration 394, the loss is 153.06182465809212, parameters k is -8.029890400337244 and b is -80.06409299735611\n",
      "Iteration 395, the loss is 153.02132802870952, parameters k is -8.023605765949892 and b is -80.06309299735611\n",
      "Iteration 396, the loss is 152.98083139932663, parameters k is -8.01732113156254 and b is -80.0620929973561\n",
      "Iteration 397, the loss is 152.940334769944, parameters k is -8.011036497175187 and b is -80.0610929973561\n",
      "Iteration 398, the loss is 152.89983814056146, parameters k is -8.004751862787835 and b is -80.0600929973561\n",
      "Iteration 399, the loss is 152.85934151117866, parameters k is -7.998467228400483 and b is -80.05909299735609\n",
      "Iteration 400, the loss is 152.8188448817962, parameters k is -7.992182594013132 and b is -80.05809299735608\n",
      "Iteration 401, the loss is 152.77834825241337, parameters k is -7.98589795962578 and b is -80.05709299735608\n",
      "Iteration 402, the loss is 152.73785162303056, parameters k is -7.979613325238429 and b is -80.05609299735607\n",
      "Iteration 403, the loss is 152.697354993648, parameters k is -7.973328690851077 and b is -80.05509299735607\n",
      "Iteration 404, the loss is 152.65685836426528, parameters k is -7.967044056463726 and b is -80.05409299735607\n",
      "Iteration 405, the loss is 152.61636173488267, parameters k is -7.960759422076374 and b is -80.05309299735606\n",
      "Iteration 406, the loss is 152.57586510549987, parameters k is -7.954474787689023 and b is -80.05209299735606\n",
      "Iteration 407, the loss is 152.53536847611718, parameters k is -7.948190153301671 and b is -80.05109299735605\n",
      "Iteration 408, the loss is 152.49487184673444, parameters k is -7.94190551891432 and b is -80.05009299735605\n",
      "Iteration 409, the loss is 152.45437521735187, parameters k is -7.935620884526968 and b is -80.04909299735604\n",
      "Iteration 410, the loss is 152.41387858796915, parameters k is -7.929336250139617 and b is -80.04809299735604\n",
      "Iteration 411, the loss is 152.37338195858632, parameters k is -7.923051615752265 and b is -80.04709299735603\n",
      "Iteration 412, the loss is 152.33288532920372, parameters k is -7.916766981364914 and b is -80.04609299735603\n",
      "Iteration 413, the loss is 152.29238869982103, parameters k is -7.910482346977562 and b is -80.04509299735602\n",
      "Iteration 414, the loss is 152.2518920704382, parameters k is -7.904197712590211 and b is -80.04409299735602\n",
      "Iteration 415, the loss is 152.21139544105569, parameters k is -7.897913078202859 and b is -80.04309299735601\n",
      "Iteration 416, the loss is 152.1708988116731, parameters k is -7.891628443815508 and b is -80.04209299735601\n",
      "Iteration 417, the loss is 152.1304021822904, parameters k is -7.885343809428156 and b is -80.041092997356\n",
      "Iteration 418, the loss is 152.08990555290748, parameters k is -7.879059175040805 and b is -80.040092997356\n",
      "Iteration 419, the loss is 152.04940892352505, parameters k is -7.872774540653453 and b is -80.039092997356\n",
      "Iteration 420, the loss is 152.00891229414222, parameters k is -7.866489906266102 and b is -80.03809299735599\n",
      "Iteration 421, the loss is 151.96841566475948, parameters k is -7.86020527187875 and b is -80.03709299735598\n",
      "Iteration 422, the loss is 151.92791903537687, parameters k is -7.853920637491399 and b is -80.03609299735598\n",
      "Iteration 423, the loss is 151.88742240599416, parameters k is -7.847636003104047 and b is -80.03509299735597\n",
      "Iteration 424, the loss is 151.8469257766116, parameters k is -7.841351368716696 and b is -80.03409299735597\n",
      "Iteration 425, the loss is 151.80642914722884, parameters k is -7.835066734329344 and b is -80.03309299735596\n",
      "Iteration 426, the loss is 151.76593251784612, parameters k is -7.828782099941993 and b is -80.03209299735596\n",
      "Iteration 427, the loss is 151.7254358884634, parameters k is -7.822497465554641 and b is -80.03109299735596\n",
      "Iteration 428, the loss is 151.6849392590811, parameters k is -7.81621283116729 and b is -80.03009299735595\n",
      "Iteration 429, the loss is 151.6444426296981, parameters k is -7.809928196779938 and b is -80.02909299735595\n",
      "Iteration 430, the loss is 151.60394600031526, parameters k is -7.803643562392587 and b is -80.02809299735594\n",
      "Iteration 431, the loss is 151.56344937093272, parameters k is -7.797358928005235 and b is -80.02709299735594\n",
      "Iteration 432, the loss is 151.52295274154986, parameters k is -7.791074293617884 and b is -80.02609299735593\n",
      "Iteration 433, the loss is 151.4824561121675, parameters k is -7.784789659230532 and b is -80.02509299735593\n",
      "Iteration 434, the loss is 151.4419594827848, parameters k is -7.778505024843181 and b is -80.02409299735592\n",
      "Iteration 435, the loss is 151.40146285340197, parameters k is -7.772220390455829 and b is -80.02309299735592\n",
      "Iteration 436, the loss is 151.36096622401934, parameters k is -7.765935756068478 and b is -80.02209299735591\n",
      "Iteration 437, the loss is 151.3204695946365, parameters k is -7.759651121681126 and b is -80.02109299735591\n",
      "Iteration 438, the loss is 151.2799729652538, parameters k is -7.753366487293775 and b is -80.0200929973559\n",
      "Iteration 439, the loss is 151.23947633587125, parameters k is -7.747081852906423 and b is -80.0190929973559\n",
      "Iteration 440, the loss is 151.19897970648844, parameters k is -7.740797218519072 and b is -80.0180929973559\n",
      "Iteration 441, the loss is 151.1584830771057, parameters k is -7.73451258413172 and b is -80.01709299735589\n",
      "Iteration 442, the loss is 151.1179864477231, parameters k is -7.728227949744369 and b is -80.01609299735588\n",
      "Iteration 443, the loss is 151.07748981834033, parameters k is -7.721943315357017 and b is -80.01509299735588\n",
      "Iteration 444, the loss is 151.0369931889577, parameters k is -7.715658680969666 and b is -80.01409299735587\n",
      "Iteration 445, the loss is 150.9964965595751, parameters k is -7.709374046582314 and b is -80.01309299735587\n",
      "Iteration 446, the loss is 150.9559999301924, parameters k is -7.703089412194963 and b is -80.01209299735586\n",
      "Iteration 447, the loss is 150.91550330080977, parameters k is -7.696804777807611 and b is -80.01109299735586\n",
      "Iteration 448, the loss is 150.8750066714271, parameters k is -7.69052014342026 and b is -80.01009299735586\n",
      "Iteration 449, the loss is 150.83451004204431, parameters k is -7.684235509032908 and b is -80.00909299735585\n",
      "Iteration 450, the loss is 150.7940134126617, parameters k is -7.677950874645557 and b is -80.00809299735585\n",
      "Iteration 451, the loss is 150.7535167832791, parameters k is -7.671666240258205 and b is -80.00709299735584\n",
      "Iteration 452, the loss is 150.71302015389628, parameters k is -7.665381605870854 and b is -80.00609299735584\n",
      "Iteration 453, the loss is 150.67252352451368, parameters k is -7.659096971483502 and b is -80.00509299735583\n",
      "Iteration 454, the loss is 150.63202689513096, parameters k is -7.652812337096151 and b is -80.00409299735583\n",
      "Iteration 455, the loss is 150.5915302657483, parameters k is -7.6465277027087994 and b is -80.00309299735582\n",
      "Iteration 456, the loss is 150.55103363636553, parameters k is -7.640243068321448 and b is -80.00209299735582\n",
      "Iteration 457, the loss is 150.51053700698282, parameters k is -7.6339584339340965 and b is -80.00109299735581\n",
      "Iteration 458, the loss is 150.47004037760007, parameters k is -7.627673799546745 and b is -80.00009299735581\n",
      "Iteration 459, the loss is 150.4295437482174, parameters k is -7.6213891651593935 and b is -79.9990929973558\n",
      "Iteration 460, the loss is 150.38904711883478, parameters k is -7.615104530772042 and b is -79.9980929973558\n",
      "Iteration 461, the loss is 150.34855048945215, parameters k is -7.6088198963846905 and b is -79.9970929973558\n",
      "Iteration 462, the loss is 150.30805386006924, parameters k is -7.602535261997339 and b is -79.99609299735579\n",
      "Iteration 463, the loss is 150.2675572306866, parameters k is -7.5962506276099875 and b is -79.99509299735578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 464, the loss is 150.2270606013041, parameters k is -7.589965993222636 and b is -79.99409299735578\n",
      "Iteration 465, the loss is 150.18656397192123, parameters k is -7.5836813588352845 and b is -79.99309299735577\n",
      "Iteration 466, the loss is 150.1460673425385, parameters k is -7.577396724447933 and b is -79.99209299735577\n",
      "Iteration 467, the loss is 150.10557071315594, parameters k is -7.5711120900605815 and b is -79.99109299735576\n",
      "Iteration 468, the loss is 150.0650740837732, parameters k is -7.56482745567323 and b is -79.99009299735576\n",
      "Iteration 469, the loss is 150.02457745439057, parameters k is -7.5585428212858785 and b is -79.98909299735575\n",
      "Iteration 470, the loss is 149.98408082500782, parameters k is -7.552258186898527 and b is -79.98809299735575\n",
      "Iteration 471, the loss is 149.9435841956251, parameters k is -7.5459735525111755 and b is -79.98709299735575\n",
      "Iteration 472, the loss is 149.90308756624273, parameters k is -7.539688918123824 and b is -79.98609299735574\n",
      "Iteration 473, the loss is 149.86259093685985, parameters k is -7.5334042837364725 and b is -79.98509299735574\n",
      "Iteration 474, the loss is 149.8220943074771, parameters k is -7.527119649349121 and b is -79.98409299735573\n",
      "Iteration 475, the loss is 149.78159767809447, parameters k is -7.5208350149617695 and b is -79.98309299735573\n",
      "Iteration 476, the loss is 149.7411010487117, parameters k is -7.514550380574418 and b is -79.98209299735572\n",
      "Iteration 477, the loss is 149.7006044193291, parameters k is -7.5082657461870665 and b is -79.98109299735572\n",
      "Iteration 478, the loss is 149.66010778994635, parameters k is -7.501981111799715 and b is -79.98009299735571\n",
      "Iteration 479, the loss is 149.61961116056378, parameters k is -7.495696477412364 and b is -79.9790929973557\n",
      "Iteration 480, the loss is 149.57911453118103, parameters k is -7.489411843025012 and b is -79.9780929973557\n",
      "Iteration 481, the loss is 149.53861790179835, parameters k is -7.483127208637661 and b is -79.9770929973557\n",
      "Iteration 482, the loss is 149.4981212724157, parameters k is -7.476842574250309 and b is -79.97609299735569\n",
      "Iteration 483, the loss is 149.45762464303294, parameters k is -7.470557939862958 and b is -79.97509299735569\n",
      "Iteration 484, the loss is 149.4171280136503, parameters k is -7.464273305475606 and b is -79.97409299735568\n",
      "Iteration 485, the loss is 149.3766313842676, parameters k is -7.457988671088255 and b is -79.97309299735568\n",
      "Iteration 486, the loss is 149.33613475488488, parameters k is -7.451704036700903 and b is -79.97209299735567\n",
      "Iteration 487, the loss is 149.295638125502, parameters k is -7.445419402313552 and b is -79.97109299735567\n",
      "Iteration 488, the loss is 149.25514149611953, parameters k is -7.4391347679262 and b is -79.97009299735566\n",
      "Iteration 489, the loss is 149.21464486673696, parameters k is -7.432850133538849 and b is -79.96909299735566\n",
      "Iteration 490, the loss is 149.1741482373541, parameters k is -7.426565499151497 and b is -79.96809299735565\n",
      "Iteration 491, the loss is 149.13365160797147, parameters k is -7.420280864764146 and b is -79.96709299735565\n",
      "Iteration 492, the loss is 149.09315497858867, parameters k is -7.413996230376794 and b is -79.96609299735564\n",
      "Iteration 493, the loss is 149.0526583492058, parameters k is -7.407711595989443 and b is -79.96509299735564\n",
      "Iteration 494, the loss is 149.01216171982358, parameters k is -7.401426961602091 and b is -79.96409299735564\n",
      "Iteration 495, the loss is 148.9716650904406, parameters k is -7.39514232721474 and b is -79.96309299735563\n",
      "Iteration 496, the loss is 148.9311684610582, parameters k is -7.388857692827388 and b is -79.96209299735563\n",
      "Iteration 497, the loss is 148.89067183167532, parameters k is -7.382573058440037 and b is -79.96109299735562\n",
      "Iteration 498, the loss is 148.85017520229272, parameters k is -7.376288424052685 and b is -79.96009299735562\n",
      "Iteration 499, the loss is 148.80967857291, parameters k is -7.370003789665334 and b is -79.95909299735561\n",
      "Iteration 500, the loss is 148.7691819435273, parameters k is -7.363719155277982 and b is -79.9580929973556\n",
      "Iteration 501, the loss is 148.7286853141446, parameters k is -7.357434520890631 and b is -79.9570929973556\n",
      "Iteration 502, the loss is 148.68818868476185, parameters k is -7.351149886503279 and b is -79.9560929973556\n",
      "Iteration 503, the loss is 148.6476920553791, parameters k is -7.344865252115928 and b is -79.95509299735559\n",
      "Iteration 504, the loss is 148.6071954259966, parameters k is -7.338580617728576 and b is -79.95409299735559\n",
      "Iteration 505, the loss is 148.5666987966138, parameters k is -7.332295983341225 and b is -79.95309299735558\n",
      "Iteration 506, the loss is 148.52620216723102, parameters k is -7.326011348953873 and b is -79.95209299735558\n",
      "Iteration 507, the loss is 148.48570553784847, parameters k is -7.319726714566522 and b is -79.95109299735557\n",
      "Iteration 508, the loss is 148.44520890846584, parameters k is -7.31344208017917 and b is -79.95009299735557\n",
      "Iteration 509, the loss is 148.40471227908307, parameters k is -7.307157445791819 and b is -79.94909299735556\n",
      "Iteration 510, the loss is 148.36421564970047, parameters k is -7.300872811404467 and b is -79.94809299735556\n",
      "Iteration 511, the loss is 148.32371902031764, parameters k is -7.294588177017116 and b is -79.94709299735555\n",
      "Iteration 512, the loss is 148.28322239093484, parameters k is -7.288303542629764 and b is -79.94609299735555\n",
      "Iteration 513, the loss is 148.24272576155226, parameters k is -7.282018908242413 and b is -79.94509299735554\n",
      "Iteration 514, the loss is 148.20222913216963, parameters k is -7.275734273855061 and b is -79.94409299735554\n",
      "Iteration 515, the loss is 148.16173250278678, parameters k is -7.26944963946771 and b is -79.94309299735554\n",
      "Iteration 516, the loss is 148.12123587340432, parameters k is -7.263165005080358 and b is -79.94209299735553\n",
      "Iteration 517, the loss is 148.08073924402171, parameters k is -7.256880370693007 and b is -79.94109299735553\n",
      "Iteration 518, the loss is 148.04024261463897, parameters k is -7.250595736305655 and b is -79.94009299735552\n",
      "Iteration 519, the loss is 147.99974598525623, parameters k is -7.244311101918304 and b is -79.93909299735552\n",
      "Iteration 520, the loss is 147.9592493558736, parameters k is -7.238026467530952 and b is -79.93809299735551\n",
      "Iteration 521, the loss is 147.91875272649062, parameters k is -7.231741833143601 and b is -79.9370929973555\n",
      "Iteration 522, the loss is 147.87825609710828, parameters k is -7.225457198756249 and b is -79.9360929973555\n",
      "Iteration 523, the loss is 147.83775946772562, parameters k is -7.219172564368898 and b is -79.9350929973555\n",
      "Iteration 524, the loss is 147.79726283834268, parameters k is -7.212887929981546 and b is -79.93409299735549\n",
      "Iteration 525, the loss is 147.75676620895996, parameters k is -7.206603295594195 and b is -79.93309299735549\n",
      "Iteration 526, the loss is 147.7162695795774, parameters k is -7.200318661206843 and b is -79.93209299735548\n",
      "Iteration 527, the loss is 147.6757729501947, parameters k is -7.194034026819492 and b is -79.93109299735548\n",
      "Iteration 528, the loss is 147.63527632081193, parameters k is -7.18774939243214 and b is -79.93009299735547\n",
      "Iteration 529, the loss is 147.5947796914294, parameters k is -7.181464758044789 and b is -79.92909299735547\n",
      "Iteration 530, the loss is 147.55428306204675, parameters k is -7.175180123657437 and b is -79.92809299735546\n",
      "Iteration 531, the loss is 147.5137864326639, parameters k is -7.168895489270086 and b is -79.92709299735546\n",
      "Iteration 532, the loss is 147.47328980328135, parameters k is -7.162610854882734 and b is -79.92609299735545\n",
      "Iteration 533, the loss is 147.4327931738986, parameters k is -7.156326220495383 and b is -79.92509299735545\n",
      "Iteration 534, the loss is 147.3922965445158, parameters k is -7.150041586108031 and b is -79.92409299735544\n",
      "Iteration 535, the loss is 147.35179991513334, parameters k is -7.14375695172068 and b is -79.92309299735544\n",
      "Iteration 536, the loss is 147.31130328575054, parameters k is -7.137472317333328 and b is -79.92209299735543\n",
      "Iteration 537, the loss is 147.2708066563676, parameters k is -7.131187682945977 and b is -79.92109299735543\n",
      "Iteration 538, the loss is 147.23031002698508, parameters k is -7.124903048558625 and b is -79.92009299735543\n",
      "Iteration 539, the loss is 147.1898133976025, parameters k is -7.118618414171274 and b is -79.91909299735542\n",
      "Iteration 540, the loss is 147.14931676821976, parameters k is -7.112333779783922 and b is -79.91809299735542\n",
      "Iteration 541, the loss is 147.10882013883716, parameters k is -7.106049145396571 and b is -79.91709299735541\n",
      "Iteration 542, the loss is 147.06832350945447, parameters k is -7.099764511009219 and b is -79.9160929973554\n",
      "Iteration 543, the loss is 147.02782688007176, parameters k is -7.093479876621868 and b is -79.9150929973554\n",
      "Iteration 544, the loss is 146.98733025068904, parameters k is -7.087195242234516 and b is -79.9140929973554\n",
      "Iteration 545, the loss is 146.9468336213063, parameters k is -7.080910607847165 and b is -79.91309299735539\n",
      "Iteration 546, the loss is 146.90633699192364, parameters k is -7.074625973459813 and b is -79.91209299735539\n",
      "Iteration 547, the loss is 146.86584036254092, parameters k is -7.068341339072462 and b is -79.91109299735538\n",
      "Iteration 548, the loss is 146.82534373315815, parameters k is -7.06205670468511 and b is -79.91009299735538\n",
      "Iteration 549, the loss is 146.7848471037755, parameters k is -7.055772070297759 and b is -79.90909299735537\n",
      "Iteration 550, the loss is 146.74435047439277, parameters k is -7.049487435910407 and b is -79.90809299735537\n",
      "Iteration 551, the loss is 146.70385384501017, parameters k is -7.043202801523056 and b is -79.90709299735536\n",
      "Iteration 552, the loss is 146.66335721562757, parameters k is -7.036918167135704 and b is -79.90609299735536\n",
      "Iteration 553, the loss is 146.6228605862448, parameters k is -7.030633532748353 and b is -79.90509299735535\n",
      "Iteration 554, the loss is 146.58236395686214, parameters k is -7.024348898361001 and b is -79.90409299735535\n",
      "Iteration 555, the loss is 146.54186732747948, parameters k is -7.01806426397365 and b is -79.90309299735534\n",
      "Iteration 556, the loss is 146.50137069809685, parameters k is -7.011779629586298 and b is -79.90209299735534\n",
      "Iteration 557, the loss is 146.460874068714, parameters k is -7.005494995198947 and b is -79.90109299735533\n",
      "Iteration 558, the loss is 146.42037743933145, parameters k is -6.999210360811595 and b is -79.90009299735533\n",
      "Iteration 559, the loss is 146.3798808099486, parameters k is -6.992925726424244 and b is -79.89909299735532\n",
      "Iteration 560, the loss is 146.3393841805659, parameters k is -6.986641092036892 and b is -79.89809299735532\n",
      "Iteration 561, the loss is 146.2988875511834, parameters k is -6.980356457649541 and b is -79.89709299735532\n",
      "Iteration 562, the loss is 146.25839092180072, parameters k is -6.974071823262189 and b is -79.89609299735531\n",
      "Iteration 563, the loss is 146.21789429241812, parameters k is -6.967787188874838 and b is -79.8950929973553\n",
      "Iteration 564, the loss is 146.17739766303532, parameters k is -6.9615025544874864 and b is -79.8940929973553\n",
      "Iteration 565, the loss is 146.13690103365244, parameters k is -6.955217920100135 and b is -79.8930929973553\n",
      "Iteration 566, the loss is 146.09640440426998, parameters k is -6.9489332857127835 and b is -79.89209299735529\n",
      "Iteration 567, the loss is 146.0559077748873, parameters k is -6.942648651325432 and b is -79.89109299735529\n",
      "Iteration 568, the loss is 146.0154111455044, parameters k is -6.9363640169380805 and b is -79.89009299735528\n",
      "Iteration 569, the loss is 145.97491451612174, parameters k is -6.930079382550729 and b is -79.88909299735528\n",
      "Iteration 570, the loss is 145.93441788673917, parameters k is -6.9237947481633775 and b is -79.88809299735527\n",
      "Iteration 571, the loss is 145.8939212573566, parameters k is -6.917510113776026 and b is -79.88709299735527\n",
      "Iteration 572, the loss is 145.8534246279739, parameters k is -6.9112254793886745 and b is -79.88609299735526\n",
      "Iteration 573, the loss is 145.81292799859114, parameters k is -6.904940845001323 and b is -79.88509299735526\n",
      "Iteration 574, the loss is 145.7724313692084, parameters k is -6.8986562106139715 and b is -79.88409299735525\n",
      "Iteration 575, the loss is 145.7319347398258, parameters k is -6.89237157622662 and b is -79.88309299735525\n",
      "Iteration 576, the loss is 145.69143811044304, parameters k is -6.8860869418392685 and b is -79.88209299735524\n",
      "Iteration 577, the loss is 145.65094148106027, parameters k is -6.879802307451917 and b is -79.88109299735524\n",
      "Iteration 578, the loss is 145.61044485167756, parameters k is -6.8735176730645655 and b is -79.88009299735523\n",
      "Iteration 579, the loss is 145.5699482222949, parameters k is -6.867233038677214 and b is -79.87909299735523\n",
      "Iteration 580, the loss is 145.5294515929124, parameters k is -6.8609484042898625 and b is -79.87809299735522\n",
      "Iteration 581, the loss is 145.48895496352966, parameters k is -6.854663769902511 and b is -79.87709299735522\n",
      "Iteration 582, the loss is 145.44845833414686, parameters k is -6.8483791355151595 and b is -79.87609299735522\n",
      "Iteration 583, the loss is 145.40796170476415, parameters k is -6.842094501127808 and b is -79.87509299735521\n",
      "Iteration 584, the loss is 145.36746507538172, parameters k is -6.8358098667404565 and b is -79.8740929973552\n",
      "Iteration 585, the loss is 145.32696844599883, parameters k is -6.829525232353105 and b is -79.8730929973552\n",
      "Iteration 586, the loss is 145.2864718166161, parameters k is -6.8232405979657536 and b is -79.8720929973552\n",
      "Iteration 587, the loss is 145.2459751872333, parameters k is -6.816955963578402 and b is -79.87109299735519\n",
      "Iteration 588, the loss is 145.2054785578507, parameters k is -6.810671329191051 and b is -79.87009299735519\n",
      "Iteration 589, the loss is 145.1649819284682, parameters k is -6.804386694803699 and b is -79.86909299735518\n",
      "Iteration 590, the loss is 145.1244852990854, parameters k is -6.798102060416348 and b is -79.86809299735518\n",
      "Iteration 591, the loss is 145.08398866970293, parameters k is -6.791817426028996 and b is -79.86709299735517\n",
      "Iteration 592, the loss is 145.0434920403202, parameters k is -6.785532791641645 and b is -79.86609299735517\n",
      "Iteration 593, the loss is 145.0029954109374, parameters k is -6.779248157254293 and b is -79.86509299735516\n",
      "Iteration 594, the loss is 144.96249878155456, parameters k is -6.772963522866942 and b is -79.86409299735516\n",
      "Iteration 595, the loss is 144.92200215217204, parameters k is -6.76667888847959 and b is -79.86309299735515\n",
      "Iteration 596, the loss is 144.8815055227894, parameters k is -6.760394254092239 and b is -79.86209299735515\n",
      "Iteration 597, the loss is 144.84100889340652, parameters k is -6.754109619704887 and b is -79.86109299735514\n",
      "Iteration 598, the loss is 144.8005122640238, parameters k is -6.747824985317536 and b is -79.86009299735514\n",
      "Iteration 599, the loss is 144.76001563464118, parameters k is -6.741540350930184 and b is -79.85909299735513\n",
      "Iteration 600, the loss is 144.7195190052586, parameters k is -6.735255716542833 and b is -79.85809299735513\n",
      "Iteration 601, the loss is 144.67902237587566, parameters k is -6.728971082155481 and b is -79.85709299735512\n",
      "Iteration 602, the loss is 144.63852574649326, parameters k is -6.72268644776813 and b is -79.85609299735512\n",
      "Iteration 603, the loss is 144.5980291171105, parameters k is -6.716401813380778 and b is -79.85509299735511\n",
      "Iteration 604, the loss is 144.55753248772783, parameters k is -6.710117178993427 and b is -79.85409299735511\n",
      "Iteration 605, the loss is 144.51703585834508, parameters k is -6.703832544606075 and b is -79.8530929973551\n",
      "Iteration 606, the loss is 144.47653922896248, parameters k is -6.697547910218724 and b is -79.8520929973551\n",
      "Iteration 607, the loss is 144.4360425995798, parameters k is -6.691263275831372 and b is -79.8510929973551\n",
      "Iteration 608, the loss is 144.39554597019713, parameters k is -6.684978641444021 and b is -79.85009299735509\n",
      "Iteration 609, the loss is 144.3550493408143, parameters k is -6.678694007056669 and b is -79.84909299735509\n",
      "Iteration 610, the loss is 144.31455271143182, parameters k is -6.672409372669318 and b is -79.84809299735508\n",
      "Iteration 611, the loss is 144.27405608204896, parameters k is -6.666124738281966 and b is -79.84709299735508\n",
      "Iteration 612, the loss is 144.2335594526662, parameters k is -6.659840103894615 and b is -79.84609299735507\n",
      "Iteration 613, the loss is 144.19306282328364, parameters k is -6.653555469507263 and b is -79.84509299735507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 614, the loss is 144.15256619390095, parameters k is -6.647270835119912 and b is -79.84409299735506\n",
      "Iteration 615, the loss is 144.11206956451824, parameters k is -6.64098620073256 and b is -79.84309299735506\n",
      "Iteration 616, the loss is 144.07157293513546, parameters k is -6.634701566345209 and b is -79.84209299735505\n",
      "Iteration 617, the loss is 144.03107630575292, parameters k is -6.628416931957857 and b is -79.84109299735505\n",
      "Iteration 618, the loss is 143.99057967637023, parameters k is -6.622132297570506 and b is -79.84009299735504\n",
      "Iteration 619, the loss is 143.95008304698732, parameters k is -6.615847663183154 and b is -79.83909299735504\n",
      "Iteration 620, the loss is 143.90958641760474, parameters k is -6.609563028795803 and b is -79.83809299735503\n",
      "Iteration 621, the loss is 143.86908978822208, parameters k is -6.603278394408451 and b is -79.83709299735503\n",
      "Iteration 622, the loss is 143.82859315883925, parameters k is -6.5969937600211 and b is -79.83609299735502\n",
      "Iteration 623, the loss is 143.78809652945645, parameters k is -6.590709125633748 and b is -79.83509299735502\n",
      "Iteration 624, the loss is 143.74759990007414, parameters k is -6.584424491246397 and b is -79.83409299735501\n",
      "Iteration 625, the loss is 143.70710327069122, parameters k is -6.578139856859045 and b is -79.83309299735501\n",
      "Iteration 626, the loss is 143.66660664130862, parameters k is -6.571855222471694 and b is -79.832092997355\n",
      "Iteration 627, the loss is 143.62611001192585, parameters k is -6.565570588084342 and b is -79.831092997355\n",
      "Iteration 628, the loss is 143.58561338254333, parameters k is -6.559285953696991 and b is -79.830092997355\n",
      "Iteration 629, the loss is 143.54511675316039, parameters k is -6.553001319309639 and b is -79.82909299735499\n",
      "Iteration 630, the loss is 143.50462012377784, parameters k is -6.546716684922288 and b is -79.82809299735499\n",
      "Iteration 631, the loss is 143.4641234943953, parameters k is -6.540432050534936 and b is -79.82709299735498\n",
      "Iteration 632, the loss is 143.42362686501255, parameters k is -6.534147416147585 and b is -79.82609299735498\n",
      "Iteration 633, the loss is 143.38313023562972, parameters k is -6.527862781760233 and b is -79.82509299735497\n",
      "Iteration 634, the loss is 143.34263360624715, parameters k is -6.521578147372882 and b is -79.82409299735497\n",
      "Iteration 635, the loss is 143.3021369768644, parameters k is -6.51529351298553 and b is -79.82309299735496\n",
      "Iteration 636, the loss is 143.2616403474819, parameters k is -6.509008878598179 and b is -79.82209299735496\n",
      "Iteration 637, the loss is 143.22114371809914, parameters k is -6.502724244210827 and b is -79.82109299735495\n",
      "Iteration 638, the loss is 143.18064708871626, parameters k is -6.496439609823476 and b is -79.82009299735495\n",
      "Iteration 639, the loss is 143.14015045933394, parameters k is -6.490154975436124 and b is -79.81909299735494\n",
      "Iteration 640, the loss is 143.09965382995097, parameters k is -6.483870341048773 and b is -79.81809299735494\n",
      "Iteration 641, the loss is 143.05915720056834, parameters k is -6.477585706661421 and b is -79.81709299735493\n",
      "Iteration 642, the loss is 143.01866057118568, parameters k is -6.47130107227407 and b is -79.81609299735493\n",
      "Iteration 643, the loss is 142.97816394180293, parameters k is -6.465016437886718 and b is -79.81509299735492\n",
      "Iteration 644, the loss is 142.93766731242027, parameters k is -6.458731803499367 and b is -79.81409299735492\n",
      "Iteration 645, the loss is 142.89717068303753, parameters k is -6.452447169112015 and b is -79.81309299735491\n",
      "Iteration 646, the loss is 142.856674053655, parameters k is -6.446162534724664 and b is -79.81209299735491\n",
      "Iteration 647, the loss is 142.8161774242722, parameters k is -6.439877900337312 and b is -79.8110929973549\n",
      "Iteration 648, the loss is 142.7756807948895, parameters k is -6.433593265949961 and b is -79.8100929973549\n",
      "Iteration 649, the loss is 142.73518416550672, parameters k is -6.427308631562609 and b is -79.8090929973549\n",
      "Iteration 650, the loss is 142.6946875361242, parameters k is -6.421023997175258 and b is -79.80809299735489\n",
      "Iteration 651, the loss is 142.6541909067416, parameters k is -6.414739362787906 and b is -79.80709299735489\n",
      "Iteration 652, the loss is 142.61369427735875, parameters k is -6.408454728400555 and b is -79.80609299735488\n",
      "Iteration 653, the loss is 142.5731976479763, parameters k is -6.402170094013203 and b is -79.80509299735488\n",
      "Iteration 654, the loss is 142.53270101859331, parameters k is -6.395885459625852 and b is -79.80409299735487\n",
      "Iteration 655, the loss is 142.4922043892108, parameters k is -6.3896008252385 and b is -79.80309299735487\n",
      "Iteration 656, the loss is 142.45170775982808, parameters k is -6.383316190851149 and b is -79.80209299735486\n",
      "Iteration 657, the loss is 142.4112111304453, parameters k is -6.377031556463797 and b is -79.80109299735486\n",
      "Iteration 658, the loss is 142.37071450106274, parameters k is -6.370746922076446 and b is -79.80009299735485\n",
      "Iteration 659, the loss is 142.33021787167993, parameters k is -6.364462287689094 and b is -79.79909299735485\n",
      "Iteration 660, the loss is 142.28972124229733, parameters k is -6.358177653301743 and b is -79.79809299735484\n",
      "Iteration 661, the loss is 142.24922461291456, parameters k is -6.351893018914391 and b is -79.79709299735484\n",
      "Iteration 662, the loss is 142.2087279835321, parameters k is -6.34560838452704 and b is -79.79609299735483\n",
      "Iteration 663, the loss is 142.16823135414927, parameters k is -6.339323750139688 and b is -79.79509299735483\n",
      "Iteration 664, the loss is 142.12773472476655, parameters k is -6.333039115752337 and b is -79.79409299735482\n",
      "Iteration 665, the loss is 142.08723809538364, parameters k is -6.326754481364985 and b is -79.79309299735482\n",
      "Iteration 666, the loss is 142.04674146600115, parameters k is -6.320469846977634 and b is -79.79209299735481\n",
      "Iteration 667, the loss is 142.00624483661846, parameters k is -6.314185212590282 and b is -79.79109299735481\n",
      "Iteration 668, the loss is 141.9657482072358, parameters k is -6.307900578202931 and b is -79.7900929973548\n",
      "Iteration 669, the loss is 141.9252515778532, parameters k is -6.301615943815579 and b is -79.7890929973548\n",
      "Iteration 670, the loss is 141.88475494847037, parameters k is -6.295331309428228 and b is -79.7880929973548\n",
      "Iteration 671, the loss is 141.8442583190878, parameters k is -6.289046675040876 and b is -79.78709299735479\n",
      "Iteration 672, the loss is 141.8037616897049, parameters k is -6.282762040653525 and b is -79.78609299735479\n",
      "Iteration 673, the loss is 141.76326506032234, parameters k is -6.2764774062661735 and b is -79.78509299735478\n",
      "Iteration 674, the loss is 141.72276843093965, parameters k is -6.270192771878822 and b is -79.78409299735478\n",
      "Iteration 675, the loss is 141.6822718015571, parameters k is -6.2639081374914705 and b is -79.78309299735477\n",
      "Iteration 676, the loss is 141.64177517217416, parameters k is -6.257623503104119 and b is -79.78209299735477\n",
      "Iteration 677, the loss is 141.6012785427916, parameters k is -6.2513388687167675 and b is -79.78109299735476\n",
      "Iteration 678, the loss is 141.5607819134089, parameters k is -6.245054234329416 and b is -79.78009299735476\n",
      "Iteration 679, the loss is 141.52028528402622, parameters k is -6.2387695999420645 and b is -79.77909299735475\n",
      "Iteration 680, the loss is 141.4797886546435, parameters k is -6.232484965554713 and b is -79.77809299735475\n",
      "Iteration 681, the loss is 141.43929202526076, parameters k is -6.2262003311673615 and b is -79.77709299735474\n",
      "Iteration 682, the loss is 141.39879539587804, parameters k is -6.21991569678001 and b is -79.77609299735474\n",
      "Iteration 683, the loss is 141.35829876649555, parameters k is -6.2136310623926585 and b is -79.77509299735473\n",
      "Iteration 684, the loss is 141.31780213711275, parameters k is -6.207346428005307 and b is -79.77409299735473\n",
      "Iteration 685, the loss is 141.27730550773, parameters k is -6.2010617936179555 and b is -79.77309299735472\n",
      "Iteration 686, the loss is 141.23680887834738, parameters k is -6.194777159230604 and b is -79.77209299735472\n",
      "Iteration 687, the loss is 141.19631224896455, parameters k is -6.1884925248432525 and b is -79.77109299735471\n",
      "Iteration 688, the loss is 141.15581561958209, parameters k is -6.182207890455901 and b is -79.77009299735471\n",
      "Iteration 689, the loss is 141.11531899019943, parameters k is -6.1759232560685495 and b is -79.7690929973547\n",
      "Iteration 690, the loss is 141.07482236081668, parameters k is -6.169638621681198 and b is -79.7680929973547\n",
      "Iteration 691, the loss is 141.0343257314339, parameters k is -6.1633539872938465 and b is -79.7670929973547\n",
      "Iteration 692, the loss is 140.99382910205117, parameters k is -6.157069352906495 and b is -79.76609299735469\n",
      "Iteration 693, the loss is 140.95333247266865, parameters k is -6.1507847185191435 and b is -79.76509299735469\n",
      "Iteration 694, the loss is 140.91283584328588, parameters k is -6.144500084131792 and b is -79.76409299735468\n",
      "Iteration 695, the loss is 140.8723392139031, parameters k is -6.1382154497444406 and b is -79.76309299735468\n",
      "Iteration 696, the loss is 140.83184258452064, parameters k is -6.131930815357089 and b is -79.76209299735467\n",
      "Iteration 697, the loss is 140.79134595513787, parameters k is -6.125646180969738 and b is -79.76109299735467\n",
      "Iteration 698, the loss is 140.75084932575513, parameters k is -6.119361546582386 and b is -79.76009299735466\n",
      "Iteration 699, the loss is 140.71035269637252, parameters k is -6.113076912195035 and b is -79.75909299735466\n",
      "Iteration 700, the loss is 140.6698560669897, parameters k is -6.106792277807683 and b is -79.75809299735465\n",
      "Iteration 701, the loss is 140.62935943760706, parameters k is -6.100507643420332 and b is -79.75709299735465\n",
      "Iteration 702, the loss is 140.58886280822443, parameters k is -6.09422300903298 and b is -79.75609299735464\n",
      "Iteration 703, the loss is 140.54836617884175, parameters k is -6.087938374645629 and b is -79.75509299735464\n",
      "Iteration 704, the loss is 140.50786954945895, parameters k is -6.081653740258277 and b is -79.75409299735463\n",
      "Iteration 705, the loss is 140.46737292007634, parameters k is -6.075369105870926 and b is -79.75309299735463\n",
      "Iteration 706, the loss is 140.42687629069366, parameters k is -6.069084471483574 and b is -79.75209299735462\n",
      "Iteration 707, the loss is 140.38637966131094, parameters k is -6.062799837096223 and b is -79.75109299735462\n",
      "Iteration 708, the loss is 140.34588303192825, parameters k is -6.056515202708871 and b is -79.75009299735461\n",
      "Iteration 709, the loss is 140.3053864025455, parameters k is -6.05023056832152 and b is -79.74909299735461\n",
      "Iteration 710, the loss is 140.26488977316288, parameters k is -6.043945933934168 and b is -79.7480929973546\n",
      "Iteration 711, the loss is 140.22439314378016, parameters k is -6.037661299546817 and b is -79.7470929973546\n",
      "Iteration 712, the loss is 140.1838965143975, parameters k is -6.031376665159465 and b is -79.7460929973546\n",
      "Iteration 713, the loss is 140.14339988501496, parameters k is -6.025092030772114 and b is -79.74509299735459\n",
      "Iteration 714, the loss is 140.1029032556322, parameters k is -6.018807396384762 and b is -79.74409299735458\n",
      "Iteration 715, the loss is 140.06240662624938, parameters k is -6.012522761997411 and b is -79.74309299735458\n",
      "Iteration 716, the loss is 140.02190999686692, parameters k is -6.006238127610059 and b is -79.74209299735458\n",
      "Iteration 717, the loss is 139.98141336748412, parameters k is -5.999953493222708 and b is -79.74109299735457\n",
      "Iteration 718, the loss is 139.94091673810146, parameters k is -5.993668858835356 and b is -79.74009299735457\n",
      "Iteration 719, the loss is 139.90042010871875, parameters k is -5.987384224448005 and b is -79.73909299735456\n",
      "Iteration 720, the loss is 139.859923479336, parameters k is -5.981099590060653 and b is -79.73809299735456\n",
      "Iteration 721, the loss is 139.81942684995326, parameters k is -5.974814955673302 and b is -79.73709299735455\n",
      "Iteration 722, the loss is 139.7789302205708, parameters k is -5.96853032128595 and b is -79.73609299735455\n",
      "Iteration 723, the loss is 139.73843359118797, parameters k is -5.962245686898599 and b is -79.73509299735454\n",
      "Iteration 724, the loss is 139.69793696180528, parameters k is -5.955961052511247 and b is -79.73409299735454\n",
      "Iteration 725, the loss is 139.65744033242268, parameters k is -5.949676418123896 and b is -79.73309299735453\n",
      "Iteration 726, the loss is 139.61694370304002, parameters k is -5.943391783736544 and b is -79.73209299735453\n",
      "Iteration 727, the loss is 139.57644707365725, parameters k is -5.937107149349193 and b is -79.73109299735452\n",
      "Iteration 728, the loss is 139.5359504442745, parameters k is -5.930822514961841 and b is -79.73009299735452\n",
      "Iteration 729, the loss is 139.49545381489193, parameters k is -5.92453788057449 and b is -79.72909299735451\n",
      "Iteration 730, the loss is 139.45495718550913, parameters k is -5.918253246187138 and b is -79.72809299735451\n",
      "Iteration 731, the loss is 139.4144605561266, parameters k is -5.911968611799787 and b is -79.7270929973545\n",
      "Iteration 732, the loss is 139.37396392674376, parameters k is -5.905683977412435 and b is -79.7260929973545\n",
      "Iteration 733, the loss is 139.3334672973611, parameters k is -5.899399343025084 and b is -79.7250929973545\n",
      "Iteration 734, the loss is 139.29297066797844, parameters k is -5.893114708637732 and b is -79.72409299735449\n",
      "Iteration 735, the loss is 139.25247403859566, parameters k is -5.886830074250381 and b is -79.72309299735448\n",
      "Iteration 736, the loss is 139.21197740921306, parameters k is -5.880545439863029 and b is -79.72209299735448\n",
      "Iteration 737, the loss is 139.17148077983026, parameters k is -5.874260805475678 and b is -79.72109299735448\n",
      "Iteration 738, the loss is 139.1309841504477, parameters k is -5.867976171088326 and b is -79.72009299735447\n",
      "Iteration 739, the loss is 139.09048752106494, parameters k is -5.861691536700975 and b is -79.71909299735447\n",
      "Iteration 740, the loss is 139.0499908916824, parameters k is -5.855406902313623 and b is -79.71809299735446\n",
      "Iteration 741, the loss is 139.00949426229963, parameters k is -5.849122267926272 and b is -79.71709299735446\n",
      "Iteration 742, the loss is 138.9689976329168, parameters k is -5.84283763353892 and b is -79.71609299735445\n",
      "Iteration 743, the loss is 138.9285010035342, parameters k is -5.836552999151569 and b is -79.71509299735445\n",
      "Iteration 744, the loss is 138.8880043741515, parameters k is -5.830268364764217 and b is -79.71409299735444\n",
      "Iteration 745, the loss is 138.84750774476876, parameters k is -5.823983730376866 and b is -79.71309299735444\n",
      "Iteration 746, the loss is 138.80701111538616, parameters k is -5.817699095989514 and b is -79.71209299735443\n",
      "Iteration 747, the loss is 138.76651448600362, parameters k is -5.811414461602163 and b is -79.71109299735443\n",
      "Iteration 748, the loss is 138.7260178566207, parameters k is -5.805129827214811 and b is -79.71009299735442\n",
      "Iteration 749, the loss is 138.68552122723804, parameters k is -5.79884519282746 and b is -79.70909299735442\n",
      "Iteration 750, the loss is 138.6450245978555, parameters k is -5.792560558440108 and b is -79.70809299735441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 751, the loss is 138.6045279684726, parameters k is -5.786275924052757 and b is -79.70709299735441\n",
      "Iteration 752, the loss is 138.5640313390902, parameters k is -5.779991289665405 and b is -79.7060929973544\n",
      "Iteration 753, the loss is 138.52353470970712, parameters k is -5.773706655278054 and b is -79.7050929973544\n",
      "Iteration 754, the loss is 138.48303808032472, parameters k is -5.767422020890702 and b is -79.7040929973544\n",
      "Iteration 755, the loss is 138.4425414509419, parameters k is -5.761137386503351 and b is -79.70309299735439\n",
      "Iteration 756, the loss is 138.40204482155949, parameters k is -5.754852752115999 and b is -79.70209299735438\n",
      "Iteration 757, the loss is 138.3615481921765, parameters k is -5.748568117728648 and b is -79.70109299735438\n",
      "Iteration 758, the loss is 138.32105156279388, parameters k is -5.742283483341296 and b is -79.70009299735437\n",
      "Iteration 759, the loss is 138.28055493341125, parameters k is -5.735998848953945 and b is -79.69909299735437\n",
      "Iteration 760, the loss is 138.2400583040285, parameters k is -5.729714214566593 and b is -79.69809299735437\n",
      "Iteration 761, the loss is 138.19956167464596, parameters k is -5.723429580179242 and b is -79.69709299735436\n",
      "Iteration 762, the loss is 138.15906504526305, parameters k is -5.71714494579189 and b is -79.69609299735436\n",
      "Iteration 763, the loss is 138.11856841588045, parameters k is -5.710860311404539 and b is -79.69509299735435\n",
      "Iteration 764, the loss is 138.07807178649784, parameters k is -5.704575677017187 and b is -79.69409299735435\n",
      "Iteration 765, the loss is 138.03757515711513, parameters k is -5.698291042629836 and b is -79.69309299735434\n",
      "Iteration 766, the loss is 137.99707852773238, parameters k is -5.692006408242484 and b is -79.69209299735434\n",
      "Iteration 767, the loss is 137.95658189834964, parameters k is -5.685721773855133 and b is -79.69109299735433\n",
      "Iteration 768, the loss is 137.91608526896698, parameters k is -5.679437139467781 and b is -79.69009299735433\n",
      "Iteration 769, the loss is 137.87558863958435, parameters k is -5.67315250508043 and b is -79.68909299735432\n",
      "Iteration 770, the loss is 137.83509201020172, parameters k is -5.666867870693078 and b is -79.68809299735432\n",
      "Iteration 771, the loss is 137.79459538081892, parameters k is -5.660583236305727 and b is -79.68709299735431\n",
      "Iteration 772, the loss is 137.7540987514365, parameters k is -5.654298601918375 and b is -79.68609299735431\n",
      "Iteration 773, the loss is 137.71360212205354, parameters k is -5.648013967531024 and b is -79.6850929973543\n",
      "Iteration 774, the loss is 137.67310549267077, parameters k is -5.641729333143672 and b is -79.6840929973543\n",
      "Iteration 775, the loss is 137.6326088632883, parameters k is -5.635444698756321 and b is -79.6830929973543\n",
      "Iteration 776, the loss is 137.59211223390548, parameters k is -5.629160064368969 and b is -79.68209299735429\n",
      "Iteration 777, the loss is 137.55161560452277, parameters k is -5.622875429981618 and b is -79.68109299735428\n",
      "Iteration 778, the loss is 137.51111897514025, parameters k is -5.616590795594266 and b is -79.68009299735428\n",
      "Iteration 779, the loss is 137.4706223457574, parameters k is -5.610306161206915 and b is -79.67909299735427\n",
      "Iteration 780, the loss is 137.43012571637493, parameters k is -5.6040215268195634 and b is -79.67809299735427\n",
      "Iteration 781, the loss is 137.38962908699207, parameters k is -5.597736892432212 and b is -79.67709299735426\n",
      "Iteration 782, the loss is 137.34913245760944, parameters k is -5.5914522580448605 and b is -79.67609299735426\n",
      "Iteration 783, the loss is 137.3086358282269, parameters k is -5.585167623657509 and b is -79.67509299735426\n",
      "Iteration 784, the loss is 137.26813919884404, parameters k is -5.5788829892701575 and b is -79.67409299735425\n",
      "Iteration 785, the loss is 137.2276425694612, parameters k is -5.572598354882806 and b is -79.67309299735425\n",
      "Iteration 786, the loss is 137.18714594007878, parameters k is -5.5663137204954545 and b is -79.67209299735424\n",
      "Iteration 787, the loss is 137.14664931069592, parameters k is -5.560029086108103 and b is -79.67109299735424\n",
      "Iteration 788, the loss is 137.10615268131315, parameters k is -5.5537444517207515 and b is -79.67009299735423\n",
      "Iteration 789, the loss is 137.06565605193057, parameters k is -5.5474598173334 and b is -79.66909299735423\n",
      "Iteration 790, the loss is 137.025159422548, parameters k is -5.5411751829460485 and b is -79.66809299735422\n",
      "Iteration 791, the loss is 136.98466279316534, parameters k is -5.534890548558697 and b is -79.66709299735422\n",
      "Iteration 792, the loss is 136.94416616378257, parameters k is -5.5286059141713455 and b is -79.66609299735421\n",
      "Iteration 793, the loss is 136.9036695343998, parameters k is -5.522321279783994 and b is -79.66509299735421\n",
      "Iteration 794, the loss is 136.86317290501717, parameters k is -5.5160366453966425 and b is -79.6640929973542\n",
      "Iteration 795, the loss is 136.82267627563434, parameters k is -5.509752011009291 and b is -79.6630929973542\n",
      "Iteration 796, the loss is 136.78217964625165, parameters k is -5.5034673766219395 and b is -79.6620929973542\n",
      "Iteration 797, the loss is 136.74168301686905, parameters k is -5.497182742234588 and b is -79.66109299735419\n",
      "Iteration 798, the loss is 136.70118638748633, parameters k is -5.4908981078472365 and b is -79.66009299735418\n",
      "Iteration 799, the loss is 136.66068975810379, parameters k is -5.484613473459885 and b is -79.65909299735418\n",
      "Iteration 800, the loss is 136.62019312872098, parameters k is -5.4783288390725335 and b is -79.65809299735417\n",
      "Iteration 801, the loss is 136.5796964993384, parameters k is -5.472044204685182 and b is -79.65709299735417\n",
      "Iteration 802, the loss is 136.53919986995567, parameters k is -5.4657595702978305 and b is -79.65609299735416\n",
      "Iteration 803, the loss is 136.49870324057292, parameters k is -5.459474935910479 and b is -79.65509299735416\n",
      "Iteration 804, the loss is 136.45820661119026, parameters k is -5.453190301523128 and b is -79.65409299735416\n",
      "Iteration 805, the loss is 136.41770998180758, parameters k is -5.446905667135776 and b is -79.65309299735415\n",
      "Iteration 806, the loss is 136.37721335242486, parameters k is -5.440621032748425 and b is -79.65209299735415\n",
      "Iteration 807, the loss is 136.3367167230422, parameters k is -5.434336398361073 and b is -79.65109299735414\n",
      "Iteration 808, the loss is 136.2962200936596, parameters k is -5.428051763973722 and b is -79.65009299735414\n",
      "Iteration 809, the loss is 136.25572346427683, parameters k is -5.42176712958637 and b is -79.64909299735413\n",
      "Iteration 810, the loss is 136.2152268348941, parameters k is -5.415482495199019 and b is -79.64809299735413\n",
      "Iteration 811, the loss is 136.17473020551134, parameters k is -5.409197860811667 and b is -79.64709299735412\n",
      "Iteration 812, the loss is 136.13423357612882, parameters k is -5.402913226424316 and b is -79.64609299735412\n",
      "Iteration 813, the loss is 136.09373694674608, parameters k is -5.396628592036964 and b is -79.64509299735411\n",
      "Iteration 814, the loss is 136.05324031736345, parameters k is -5.390343957649613 and b is -79.64409299735411\n",
      "Iteration 815, the loss is 136.01274368798062, parameters k is -5.384059323262261 and b is -79.6430929973541\n",
      "Iteration 816, the loss is 135.972247058598, parameters k is -5.37777468887491 and b is -79.6420929973541\n",
      "Iteration 817, the loss is 135.93175042921527, parameters k is -5.371490054487558 and b is -79.6410929973541\n",
      "Iteration 818, the loss is 135.89125379983267, parameters k is -5.365205420100207 and b is -79.64009299735409\n",
      "Iteration 819, the loss is 135.85075717045, parameters k is -5.358920785712855 and b is -79.63909299735408\n",
      "Iteration 820, the loss is 135.81026054106715, parameters k is -5.352636151325504 and b is -79.63809299735408\n",
      "Iteration 821, the loss is 135.76976391168455, parameters k is -5.346351516938152 and b is -79.63709299735407\n",
      "Iteration 822, the loss is 135.729267282302, parameters k is -5.340066882550801 and b is -79.63609299735407\n",
      "Iteration 823, the loss is 135.68877065291923, parameters k is -5.333782248163449 and b is -79.63509299735406\n",
      "Iteration 824, the loss is 135.64827402353654, parameters k is -5.327497613776098 and b is -79.63409299735406\n",
      "Iteration 825, the loss is 135.60777739415389, parameters k is -5.321212979388746 and b is -79.63309299735405\n",
      "Iteration 826, the loss is 135.56728076477108, parameters k is -5.314928345001395 and b is -79.63209299735405\n",
      "Iteration 827, the loss is 135.52678413538845, parameters k is -5.308643710614043 and b is -79.63109299735405\n",
      "Iteration 828, the loss is 135.4862875060058, parameters k is -5.302359076226692 and b is -79.63009299735404\n",
      "Iteration 829, the loss is 135.4457908766232, parameters k is -5.29607444183934 and b is -79.62909299735404\n",
      "Iteration 830, the loss is 135.40529424724045, parameters k is -5.289789807451989 and b is -79.62809299735403\n",
      "Iteration 831, the loss is 135.3647976178578, parameters k is -5.283505173064637 and b is -79.62709299735403\n",
      "Iteration 832, the loss is 135.32430098847507, parameters k is -5.277220538677286 and b is -79.62609299735402\n",
      "Iteration 833, the loss is 135.2838043590925, parameters k is -5.270935904289934 and b is -79.62509299735402\n",
      "Iteration 834, the loss is 135.2433077297097, parameters k is -5.264651269902583 and b is -79.62409299735401\n",
      "Iteration 835, the loss is 135.202811100327, parameters k is -5.258366635515231 and b is -79.62309299735401\n",
      "Iteration 836, the loss is 135.16231447094432, parameters k is -5.25208200112788 and b is -79.622092997354\n",
      "Iteration 837, the loss is 135.1218178415616, parameters k is -5.245797366740528 and b is -79.621092997354\n",
      "Iteration 838, the loss is 135.08132121217898, parameters k is -5.239512732353177 and b is -79.62009299735399\n",
      "Iteration 839, the loss is 135.04082458279615, parameters k is -5.233228097965825 and b is -79.61909299735399\n",
      "Iteration 840, the loss is 135.0003279534136, parameters k is -5.226943463578474 and b is -79.61809299735398\n",
      "Iteration 841, the loss is 134.9598313240307, parameters k is -5.220658829191122 and b is -79.61709299735398\n",
      "Iteration 842, the loss is 134.91933469464817, parameters k is -5.214374194803771 and b is -79.61609299735397\n",
      "Iteration 843, the loss is 134.87883806526554, parameters k is -5.208089560416419 and b is -79.61509299735397\n",
      "Iteration 844, the loss is 134.83834143588282, parameters k is -5.201804926029068 and b is -79.61409299735396\n",
      "Iteration 845, the loss is 134.79784480649994, parameters k is -5.195520291641716 and b is -79.61309299735396\n",
      "Iteration 846, the loss is 134.75734817711754, parameters k is -5.189235657254365 and b is -79.61209299735395\n",
      "Iteration 847, the loss is 134.71685154773465, parameters k is -5.182951022867013 and b is -79.61109299735395\n",
      "Iteration 848, the loss is 134.67635491835213, parameters k is -5.176666388479662 and b is -79.61009299735395\n",
      "Iteration 849, the loss is 134.63585828896944, parameters k is -5.17038175409231 and b is -79.60909299735394\n",
      "Iteration 850, the loss is 134.59536165958662, parameters k is -5.164097119704959 and b is -79.60809299735394\n",
      "Iteration 851, the loss is 134.55486503020393, parameters k is -5.157812485317607 and b is -79.60709299735393\n",
      "Iteration 852, the loss is 134.5143684008211, parameters k is -5.151527850930256 and b is -79.60609299735393\n",
      "Iteration 853, the loss is 134.47387177143867, parameters k is -5.145243216542904 and b is -79.60509299735392\n",
      "Iteration 854, the loss is 134.4333751420558, parameters k is -5.138958582155553 and b is -79.60409299735392\n",
      "Iteration 855, the loss is 134.3928785126732, parameters k is -5.132673947768201 and b is -79.60309299735391\n",
      "Iteration 856, the loss is 134.35238188329055, parameters k is -5.12638931338085 and b is -79.6020929973539\n",
      "Iteration 857, the loss is 134.3118852539079, parameters k is -5.120104678993498 and b is -79.6010929973539\n",
      "Iteration 858, the loss is 134.27138862452512, parameters k is -5.113820044606147 and b is -79.6000929973539\n",
      "Iteration 859, the loss is 134.23089199514231, parameters k is -5.107535410218795 and b is -79.59909299735389\n",
      "Iteration 860, the loss is 134.19039536575988, parameters k is -5.101250775831444 and b is -79.59809299735389\n",
      "Iteration 861, the loss is 134.14989873637705, parameters k is -5.094966141444092 and b is -79.59709299735388\n",
      "Iteration 862, the loss is 134.1094021069944, parameters k is -5.088681507056741 and b is -79.59609299735388\n",
      "Iteration 863, the loss is 134.0689054776117, parameters k is -5.082396872669389 and b is -79.59509299735387\n",
      "Iteration 864, the loss is 134.0284088482291, parameters k is -5.076112238282038 and b is -79.59409299735387\n",
      "Iteration 865, the loss is 133.9879122188464, parameters k is -5.069827603894686 and b is -79.59309299735386\n",
      "Iteration 866, the loss is 133.94741558946362, parameters k is -5.063542969507335 and b is -79.59209299735386\n",
      "Iteration 867, the loss is 133.90691896008093, parameters k is -5.057258335119983 and b is -79.59109299735385\n",
      "Iteration 868, the loss is 133.86642233069844, parameters k is -5.050973700732632 and b is -79.59009299735385\n",
      "Iteration 869, the loss is 133.8259257013155, parameters k is -5.04468906634528 and b is -79.58909299735384\n",
      "Iteration 870, the loss is 133.78542907193298, parameters k is -5.038404431957929 and b is -79.58809299735384\n",
      "Iteration 871, the loss is 133.74493244255024, parameters k is -5.032119797570577 and b is -79.58709299735384\n",
      "Iteration 872, the loss is 133.7044358131677, parameters k is -5.025835163183226 and b is -79.58609299735383\n",
      "Iteration 873, the loss is 133.66393918378486, parameters k is -5.019550528795874 and b is -79.58509299735383\n",
      "Iteration 874, the loss is 133.62344255440226, parameters k is -5.013265894408523 and b is -79.58409299735382\n",
      "Iteration 875, the loss is 133.5829459250194, parameters k is -5.006981260021171 and b is -79.58309299735382\n",
      "Iteration 876, the loss is 133.54244929563686, parameters k is -5.00069662563382 and b is -79.58209299735381\n",
      "Iteration 877, the loss is 133.50195266625408, parameters k is -4.994411991246468 and b is -79.5810929973538\n",
      "Iteration 878, the loss is 133.4614560368715, parameters k is -4.988127356859117 and b is -79.5800929973538\n",
      "Iteration 879, the loss is 133.42095940748868, parameters k is -4.981842722471765 and b is -79.5790929973538\n",
      "Iteration 880, the loss is 133.3804627781059, parameters k is -4.975558088084414 and b is -79.57809299735379\n",
      "Iteration 881, the loss is 133.33996614872333, parameters k is -4.969273453697062 and b is -79.57709299735379\n",
      "Iteration 882, the loss is 133.2994695193407, parameters k is -4.962988819309711 and b is -79.57609299735378\n",
      "Iteration 883, the loss is 133.25897288995787, parameters k is -4.956704184922359 and b is -79.57509299735378\n",
      "Iteration 884, the loss is 133.2184762605753, parameters k is -4.950419550535008 and b is -79.57409299735377\n",
      "Iteration 885, the loss is 133.17797963119258, parameters k is -4.944134916147656 and b is -79.57309299735377\n",
      "Iteration 886, the loss is 133.1374830018098, parameters k is -4.937850281760305 and b is -79.57209299735376\n",
      "Iteration 887, the loss is 133.09698637242712, parameters k is -4.931565647372953 and b is -79.57109299735376\n",
      "Iteration 888, the loss is 133.05648974304452, parameters k is -4.925281012985602 and b is -79.57009299735375\n",
      "Iteration 889, the loss is 133.01599311366178, parameters k is -4.9189963785982505 and b is -79.56909299735375\n",
      "Iteration 890, the loss is 132.97549648427926, parameters k is -4.912711744210899 and b is -79.56809299735374\n",
      "Iteration 891, the loss is 132.9349998548964, parameters k is -4.9064271098235475 and b is -79.56709299735374\n",
      "Iteration 892, the loss is 132.89450322551386, parameters k is -4.900142475436196 and b is -79.56609299735373\n",
      "Iteration 893, the loss is 132.854006596131, parameters k is -4.8938578410488445 and b is -79.56509299735373\n",
      "Iteration 894, the loss is 132.8135099667485, parameters k is -4.887573206661493 and b is -79.56409299735373\n",
      "Iteration 895, the loss is 132.77301333736565, parameters k is -4.8812885722741415 and b is -79.56309299735372\n",
      "Iteration 896, the loss is 132.73251670798305, parameters k is -4.87500393788679 and b is -79.56209299735372\n",
      "Iteration 897, the loss is 132.69202007860036, parameters k is -4.8687193034994385 and b is -79.56109299735371\n",
      "Iteration 898, the loss is 132.65152344921762, parameters k is -4.862434669112087 and b is -79.5600929973537\n",
      "Iteration 899, the loss is 132.61102681983502, parameters k is -4.8561500347247355 and b is -79.5590929973537\n",
      "Iteration 900, the loss is 132.57053019045216, parameters k is -4.849865400337384 and b is -79.5580929973537\n",
      "Iteration 901, the loss is 132.5300335610697, parameters k is -4.8435807659500325 and b is -79.55709299735369\n",
      "Iteration 902, the loss is 132.4895369316869, parameters k is -4.837296131562681 and b is -79.55609299735369\n",
      "Iteration 903, the loss is 132.4490403023042, parameters k is -4.8310114971753295 and b is -79.55509299735368\n",
      "Iteration 904, the loss is 132.40854367292155, parameters k is -4.824726862787978 and b is -79.55409299735368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 905, the loss is 132.36804704353872, parameters k is -4.8184422284006265 and b is -79.55309299735367\n",
      "Iteration 906, the loss is 132.3275504141562, parameters k is -4.812157594013275 and b is -79.55209299735367\n",
      "Iteration 907, the loss is 132.2870537847734, parameters k is -4.8058729596259235 and b is -79.55109299735366\n",
      "Iteration 908, the loss is 132.24655715539092, parameters k is -4.799588325238572 and b is -79.55009299735366\n",
      "Iteration 909, the loss is 132.2060605260079, parameters k is -4.7933036908512205 and b is -79.54909299735365\n",
      "Iteration 910, the loss is 132.16556389662549, parameters k is -4.787019056463869 and b is -79.54809299735365\n",
      "Iteration 911, the loss is 132.12506726724266, parameters k is -4.7807344220765176 and b is -79.54709299735364\n",
      "Iteration 912, the loss is 132.08457063786017, parameters k is -4.774449787689166 and b is -79.54609299735364\n",
      "Iteration 913, the loss is 132.04407400847745, parameters k is -4.768165153301815 and b is -79.54509299735363\n",
      "Iteration 914, the loss is 132.0035773790946, parameters k is -4.761880518914463 and b is -79.54409299735363\n",
      "Iteration 915, the loss is 131.9630807497119, parameters k is -4.755595884527112 and b is -79.54309299735363\n",
      "Iteration 916, the loss is 131.92258412032925, parameters k is -4.74931125013976 and b is -79.54209299735362\n",
      "Iteration 917, the loss is 131.88208749094665, parameters k is -4.743026615752409 and b is -79.54109299735362\n",
      "Iteration 918, the loss is 131.8415908615641, parameters k is -4.736741981365057 and b is -79.54009299735361\n",
      "Iteration 919, the loss is 131.80109423218113, parameters k is -4.730457346977706 and b is -79.5390929973536\n",
      "Iteration 920, the loss is 131.7605976027986, parameters k is -4.724172712590354 and b is -79.5380929973536\n",
      "Iteration 921, the loss is 131.7201009734158, parameters k is -4.717888078203003 and b is -79.5370929973536\n",
      "Iteration 922, the loss is 131.67960434403318, parameters k is -4.711603443815651 and b is -79.53609299735359\n",
      "Iteration 923, the loss is 131.63910771465052, parameters k is -4.7053188094283 and b is -79.53509299735359\n",
      "Iteration 924, the loss is 131.5986110852679, parameters k is -4.699034175040948 and b is -79.53409299735358\n",
      "Iteration 925, the loss is 131.5581144558851, parameters k is -4.692749540653597 and b is -79.53309299735358\n",
      "Iteration 926, the loss is 131.51761782650237, parameters k is -4.686464906266245 and b is -79.53209299735357\n",
      "Iteration 927, the loss is 131.47712119711966, parameters k is -4.680180271878894 and b is -79.53109299735357\n",
      "Iteration 928, the loss is 131.43662456773697, parameters k is -4.673895637491542 and b is -79.53009299735356\n",
      "Iteration 929, the loss is 131.39612793835437, parameters k is -4.667611003104191 and b is -79.52909299735356\n",
      "Iteration 930, the loss is 131.35563130897165, parameters k is -4.661326368716839 and b is -79.52809299735355\n",
      "Iteration 931, the loss is 131.315134679589, parameters k is -4.655041734329488 and b is -79.52709299735355\n",
      "Iteration 932, the loss is 131.27463805020636, parameters k is -4.648757099942136 and b is -79.52609299735354\n",
      "Iteration 933, the loss is 131.23414142082353, parameters k is -4.642472465554785 and b is -79.52509299735354\n",
      "Iteration 934, the loss is 131.19364479144096, parameters k is -4.636187831167433 and b is -79.52409299735353\n",
      "Iteration 935, the loss is 131.15314816205827, parameters k is -4.629903196780082 and b is -79.52309299735353\n",
      "Iteration 936, the loss is 131.11265153267556, parameters k is -4.62361856239273 and b is -79.52209299735352\n",
      "Iteration 937, the loss is 131.07215490329287, parameters k is -4.617333928005379 and b is -79.52109299735352\n",
      "Iteration 938, the loss is 131.0316582739101, parameters k is -4.611049293618027 and b is -79.52009299735352\n",
      "Iteration 939, the loss is 130.99116164452747, parameters k is -4.604764659230676 and b is -79.51909299735351\n",
      "Iteration 940, the loss is 130.9506650151449, parameters k is -4.598480024843324 and b is -79.5180929973535\n",
      "Iteration 941, the loss is 130.9101683857621, parameters k is -4.592195390455973 and b is -79.5170929973535\n",
      "Iteration 942, the loss is 130.86967175637946, parameters k is -4.585910756068621 and b is -79.5160929973535\n",
      "Iteration 943, the loss is 130.82917512699666, parameters k is -4.57962612168127 and b is -79.51509299735349\n",
      "Iteration 944, the loss is 130.7886784976141, parameters k is -4.573341487293918 and b is -79.51409299735349\n",
      "Iteration 945, the loss is 130.7481818682313, parameters k is -4.567056852906567 and b is -79.51309299735348\n",
      "Iteration 946, the loss is 130.70768523884865, parameters k is -4.560772218519215 and b is -79.51209299735348\n",
      "Iteration 947, the loss is 130.6671886094659, parameters k is -4.554487584131864 and b is -79.51109299735347\n",
      "Iteration 948, the loss is 130.6266919800834, parameters k is -4.548202949744512 and b is -79.51009299735347\n",
      "Iteration 949, the loss is 130.5861953507005, parameters k is -4.541918315357161 and b is -79.50909299735346\n",
      "Iteration 950, the loss is 130.5456987213179, parameters k is -4.535633680969809 and b is -79.50809299735346\n",
      "Iteration 951, the loss is 130.5052020919353, parameters k is -4.529349046582458 and b is -79.50709299735345\n",
      "Iteration 952, the loss is 130.46470546255267, parameters k is -4.523064412195106 and b is -79.50609299735345\n",
      "Iteration 953, the loss is 130.42420883317, parameters k is -4.516779777807755 and b is -79.50509299735344\n",
      "Iteration 954, the loss is 130.38371220378724, parameters k is -4.510495143420403 and b is -79.50409299735344\n",
      "Iteration 955, the loss is 130.34321557440433, parameters k is -4.504210509033052 and b is -79.50309299735343\n",
      "Iteration 956, the loss is 130.30271894502175, parameters k is -4.4979258746457 and b is -79.50209299735343\n",
      "Iteration 957, the loss is 130.2622223156391, parameters k is -4.491641240258349 and b is -79.50109299735342\n",
      "Iteration 958, the loss is 130.2217256862563, parameters k is -4.485356605870997 and b is -79.50009299735342\n",
      "Iteration 959, the loss is 130.18122905687366, parameters k is -4.479071971483646 and b is -79.49909299735342\n",
      "Iteration 960, the loss is 130.14073242749112, parameters k is -4.472787337096294 and b is -79.49809299735341\n",
      "Iteration 961, the loss is 130.10023579810837, parameters k is -4.466502702708943 and b is -79.4970929973534\n",
      "Iteration 962, the loss is 130.05973916872583, parameters k is -4.460218068321591 and b is -79.4960929973534\n",
      "Iteration 963, the loss is 130.01924253934305, parameters k is -4.45393343393424 and b is -79.4950929973534\n",
      "Iteration 964, the loss is 129.9787459099603, parameters k is -4.447648799546888 and b is -79.49409299735339\n",
      "Iteration 965, the loss is 129.93824928057757, parameters k is -4.441364165159537 and b is -79.49309299735339\n",
      "Iteration 966, the loss is 129.8977526511949, parameters k is -4.435079530772185 and b is -79.49209299735338\n",
      "Iteration 967, the loss is 129.85725602181225, parameters k is -4.428794896384834 and b is -79.49109299735338\n",
      "Iteration 968, the loss is 129.81675939242956, parameters k is -4.422510261997482 and b is -79.49009299735337\n",
      "Iteration 969, the loss is 129.77626276304673, parameters k is -4.416225627610131 and b is -79.48909299735337\n",
      "Iteration 970, the loss is 129.73576613366416, parameters k is -4.409940993222779 and b is -79.48809299735336\n",
      "Iteration 971, the loss is 129.6952695042815, parameters k is -4.403656358835428 and b is -79.48709299735336\n",
      "Iteration 972, the loss is 129.65477287489898, parameters k is -4.397371724448076 and b is -79.48609299735335\n",
      "Iteration 973, the loss is 129.61427624551612, parameters k is -4.391087090060725 and b is -79.48509299735335\n",
      "Iteration 974, the loss is 129.57377961613344, parameters k is -4.384802455673373 and b is -79.48409299735334\n",
      "Iteration 975, the loss is 129.53328298675063, parameters k is -4.378517821286022 and b is -79.48309299735334\n",
      "Iteration 976, the loss is 129.49278635736806, parameters k is -4.37223318689867 and b is -79.48209299735333\n",
      "Iteration 977, the loss is 129.45228972798537, parameters k is -4.365948552511319 and b is -79.48109299735333\n",
      "Iteration 978, the loss is 129.41179309860274, parameters k is -4.359663918123967 and b is -79.48009299735332\n",
      "Iteration 979, the loss is 129.3712964692199, parameters k is -4.353379283736616 and b is -79.47909299735332\n",
      "Iteration 980, the loss is 129.3307998398373, parameters k is -4.347094649349264 and b is -79.47809299735331\n",
      "Iteration 981, the loss is 129.29030321045457, parameters k is -4.340810014961913 and b is -79.47709299735331\n",
      "Iteration 982, the loss is 129.24980658107202, parameters k is -4.334525380574561 and b is -79.4760929973533\n",
      "Iteration 983, the loss is 129.2093099516892, parameters k is -4.32824074618721 and b is -79.4750929973533\n",
      "Iteration 984, the loss is 129.16881332230656, parameters k is -4.321956111799858 and b is -79.4740929973533\n",
      "Iteration 985, the loss is 129.12831669292387, parameters k is -4.315671477412507 and b is -79.47309299735329\n",
      "Iteration 986, the loss is 129.08782006354105, parameters k is -4.309386843025155 and b is -79.47209299735329\n",
      "Iteration 987, the loss is 129.04732343415856, parameters k is -4.303102208637804 and b is -79.47109299735328\n",
      "Iteration 988, the loss is 129.0068268047757, parameters k is -4.296817574250452 and b is -79.47009299735328\n",
      "Iteration 989, the loss is 128.96633017539307, parameters k is -4.290532939863101 and b is -79.46909299735327\n",
      "Iteration 990, the loss is 128.92583354601038, parameters k is -4.284248305475749 and b is -79.46809299735327\n",
      "Iteration 991, the loss is 128.8853369166278, parameters k is -4.277963671088398 and b is -79.46709299735326\n",
      "Iteration 992, the loss is 128.8448402872449, parameters k is -4.271679036701046 and b is -79.46609299735326\n",
      "Iteration 993, the loss is 128.8043436578623, parameters k is -4.265394402313695 and b is -79.46509299735325\n",
      "Iteration 994, the loss is 128.7638470284796, parameters k is -4.259109767926343 and b is -79.46409299735325\n",
      "Iteration 995, the loss is 128.72335039909692, parameters k is -4.252825133538992 and b is -79.46309299735324\n",
      "Iteration 996, the loss is 128.68285376971417, parameters k is -4.2465404991516404 and b is -79.46209299735324\n",
      "Iteration 997, the loss is 128.64235714033154, parameters k is -4.240255864764289 and b is -79.46109299735323\n",
      "Iteration 998, the loss is 128.60186051094888, parameters k is -4.2339712303769375 and b is -79.46009299735323\n",
      "Iteration 999, the loss is 128.56136388156634, parameters k is -4.227686595989586 and b is -79.45909299735322\n",
      "Iteration 1000, the loss is 128.52086725218348, parameters k is -4.2214019616022345 and b is -79.45809299735322\n",
      "Iteration 1001, the loss is 128.48037062280085, parameters k is -4.215117327214883 and b is -79.45709299735321\n",
      "Iteration 1002, the loss is 128.43987399341813, parameters k is -4.2088326928275315 and b is -79.45609299735321\n",
      "Iteration 1003, the loss is 128.39937736403542, parameters k is -4.20254805844018 and b is -79.4550929973532\n",
      "Iteration 1004, the loss is 128.35888073465281, parameters k is -4.1962634240528285 and b is -79.4540929973532\n",
      "Iteration 1005, the loss is 128.3183841052702, parameters k is -4.189978789665477 and b is -79.4530929973532\n",
      "Iteration 1006, the loss is 128.27788747588758, parameters k is -4.1836941552781255 and b is -79.45209299735319\n",
      "Iteration 1007, the loss is 128.23739084650472, parameters k is -4.177409520890774 and b is -79.45109299735319\n",
      "Iteration 1008, the loss is 128.19689421712206, parameters k is -4.1711248865034225 and b is -79.45009299735318\n",
      "Iteration 1009, the loss is 128.1563975877394, parameters k is -4.164840252116071 and b is -79.44909299735318\n",
      "Iteration 1010, the loss is 128.11590095835678, parameters k is -4.1585556177287195 and b is -79.44809299735317\n",
      "Iteration 1011, the loss is 128.07540432897397, parameters k is -4.152270983341368 and b is -79.44709299735317\n",
      "Iteration 1012, the loss is 128.03490769959132, parameters k is -4.1459863489540165 and b is -79.44609299735316\n",
      "Iteration 1013, the loss is 127.9944110702086, parameters k is -4.139701714566665 and b is -79.44509299735316\n",
      "Iteration 1014, the loss is 127.95391444082594, parameters k is -4.1334170801793135 and b is -79.44409299735315\n",
      "Iteration 1015, the loss is 127.9134178114433, parameters k is -4.127132445791962 and b is -79.44309299735315\n",
      "Iteration 1016, the loss is 127.87292118206057, parameters k is -4.1208478114046105 and b is -79.44209299735314\n",
      "Iteration 1017, the loss is 127.83242455267782, parameters k is -4.114563177017259 and b is -79.44109299735314\n",
      "Iteration 1018, the loss is 127.79192792329519, parameters k is -4.1082785426299075 and b is -79.44009299735313\n",
      "Iteration 1019, the loss is 127.75143129391243, parameters k is -4.101993908242556 and b is -79.43909299735313\n",
      "Iteration 1020, the loss is 127.71093466452979, parameters k is -4.095709273855205 and b is -79.43809299735312\n",
      "Iteration 1021, the loss is 127.67043803514717, parameters k is -4.089424639467853 and b is -79.43709299735312\n",
      "Iteration 1022, the loss is 127.62994140576438, parameters k is -4.083140005080502 and b is -79.43609299735311\n",
      "Iteration 1023, the loss is 127.58944477638187, parameters k is -4.07685537069315 and b is -79.43509299735311\n",
      "Iteration 1024, the loss is 127.54894814699898, parameters k is -4.070570736305799 and b is -79.4340929973531\n",
      "Iteration 1025, the loss is 127.50845151761632, parameters k is -4.064286101918447 and b is -79.4330929973531\n",
      "Iteration 1026, the loss is 127.46795488823373, parameters k is -4.058001467531096 and b is -79.4320929973531\n",
      "Iteration 1027, the loss is 127.42745825885089, parameters k is -4.051716833143744 and b is -79.43109299735309\n",
      "Iteration 1028, the loss is 127.38696162946837, parameters k is -4.045432198756393 and b is -79.43009299735309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1029, the loss is 127.34646500008559, parameters k is -4.039147564369041 and b is -79.42909299735308\n",
      "Iteration 1030, the loss is 127.30596837070298, parameters k is -4.03286292998169 and b is -79.42809299735308\n",
      "Iteration 1031, the loss is 127.26547174132023, parameters k is -4.026578295594338 and b is -79.42709299735307\n",
      "Iteration 1032, the loss is 127.22497511193757, parameters k is -4.020293661206987 and b is -79.42609299735307\n",
      "Iteration 1033, the loss is 127.18447848255492, parameters k is -4.014009026819635 and b is -79.42509299735306\n",
      "Iteration 1034, the loss is 127.14398185317226, parameters k is -4.007724392432284 and b is -79.42409299735306\n",
      "Iteration 1035, the loss is 127.10348522378955, parameters k is -4.001439758044932 and b is -79.42309299735305\n",
      "Iteration 1036, the loss is 127.06298859440668, parameters k is -3.99515512365758 and b is -79.42209299735305\n",
      "Iteration 1037, the loss is 127.02249196502403, parameters k is -3.9888704892702282 and b is -79.42109299735304\n",
      "Iteration 1038, the loss is 126.98199533564143, parameters k is -3.9825858548828763 and b is -79.42009299735304\n",
      "Iteration 1039, the loss is 126.94149870625878, parameters k is -3.9763012204955244 and b is -79.41909299735303\n",
      "Iteration 1040, the loss is 126.90100207687594, parameters k is -3.9700165861081724 and b is -79.41809299735303\n",
      "Iteration 1041, the loss is 126.86050544749325, parameters k is -3.9637319517208205 and b is -79.41709299735302\n",
      "Iteration 1042, the loss is 126.82000881811071, parameters k is -3.9574473173334686 and b is -79.41609299735302\n",
      "Iteration 1043, the loss is 126.77951218872799, parameters k is -3.9511626829461166 and b is -79.41509299735301\n",
      "Iteration 1044, the loss is 126.73901555934532, parameters k is -3.9448780485587647 and b is -79.41409299735301\n",
      "Iteration 1045, the loss is 126.69851892996262, parameters k is -3.9385934141714127 and b is -79.413092997353\n",
      "Iteration 1046, the loss is 126.65802230057993, parameters k is -3.932308779784061 and b is -79.412092997353\n",
      "Iteration 1047, the loss is 126.61752567119711, parameters k is -3.926024145396709 and b is -79.411092997353\n",
      "Iteration 1048, the loss is 126.57702904181441, parameters k is -3.919739511009357 and b is -79.41009299735299\n",
      "Iteration 1049, the loss is 126.53653241243191, parameters k is -3.913454876622005 and b is -79.40909299735299\n",
      "Iteration 1050, the loss is 126.4960357830491, parameters k is -3.907170242234653 and b is -79.40809299735298\n",
      "Iteration 1051, the loss is 126.45553915366655, parameters k is -3.900885607847301 and b is -79.40709299735298\n",
      "Iteration 1052, the loss is 126.4150425242838, parameters k is -3.894600973459949 and b is -79.40609299735297\n",
      "Iteration 1053, the loss is 126.37454589490108, parameters k is -3.888316339072597 and b is -79.40509299735297\n",
      "Iteration 1054, the loss is 126.3340492655184, parameters k is -3.8820317046852453 and b is -79.40409299735296\n",
      "Iteration 1055, the loss is 126.29355263613576, parameters k is -3.8757470702978933 and b is -79.40309299735296\n",
      "Iteration 1056, the loss is 126.2530560067529, parameters k is -3.8694624359105414 and b is -79.40209299735295\n",
      "Iteration 1057, the loss is 126.21255937737011, parameters k is -3.8631778015231895 and b is -79.40109299735295\n",
      "Iteration 1058, the loss is 126.17206274798754, parameters k is -3.8568931671358375 and b is -79.40009299735294\n",
      "Iteration 1059, the loss is 126.13156611860502, parameters k is -3.8506085327484856 and b is -79.39909299735294\n",
      "Iteration 1060, the loss is 126.09106948922226, parameters k is -3.8443238983611336 and b is -79.39809299735293\n",
      "Iteration 1061, the loss is 126.05057285983953, parameters k is -3.8380392639737817 and b is -79.39709299735293\n",
      "Iteration 1062, the loss is 126.01007623045686, parameters k is -3.8317546295864298 and b is -79.39609299735292\n",
      "Iteration 1063, the loss is 125.96957960107412, parameters k is -3.825469995199078 and b is -79.39509299735292\n",
      "Iteration 1064, the loss is 125.92908297169151, parameters k is -3.819185360811726 and b is -79.39409299735291\n",
      "Iteration 1065, the loss is 125.88858634230863, parameters k is -3.812900726424374 and b is -79.39309299735291\n",
      "Iteration 1066, the loss is 125.84808971292593, parameters k is -3.806616092037022 and b is -79.3920929973529\n",
      "Iteration 1067, the loss is 125.80759308354327, parameters k is -3.80033145764967 and b is -79.3910929973529\n",
      "Iteration 1068, the loss is 125.76709645416067, parameters k is -3.794046823262318 and b is -79.3900929973529\n",
      "Iteration 1069, the loss is 125.72659982477805, parameters k is -3.787762188874966 and b is -79.38909299735289\n",
      "Iteration 1070, the loss is 125.68610319539526, parameters k is -3.7814775544876142 and b is -79.38809299735289\n",
      "Iteration 1071, the loss is 125.64560656601265, parameters k is -3.7751929201002623 and b is -79.38709299735288\n",
      "Iteration 1072, the loss is 125.60510993663, parameters k is -3.7689082857129104 and b is -79.38609299735288\n",
      "Iteration 1073, the loss is 125.56461330724727, parameters k is -3.7626236513255584 and b is -79.38509299735287\n",
      "Iteration 1074, the loss is 125.5241166778646, parameters k is -3.7563390169382065 and b is -79.38409299735287\n",
      "Iteration 1075, the loss is 125.48362004848188, parameters k is -3.7500543825508545 and b is -79.38309299735286\n",
      "Iteration 1076, the loss is 125.44312341909927, parameters k is -3.7437697481635026 and b is -79.38209299735286\n",
      "Iteration 1077, the loss is 125.40262678971656, parameters k is -3.7374851137761507 and b is -79.38109299735285\n",
      "Iteration 1078, the loss is 125.36213016033393, parameters k is -3.7312004793887987 and b is -79.38009299735285\n",
      "Iteration 1079, the loss is 125.32163353095116, parameters k is -3.724915845001447 and b is -79.37909299735284\n",
      "Iteration 1080, the loss is 125.28113690156853, parameters k is -3.718631210614095 and b is -79.37809299735284\n",
      "Iteration 1081, the loss is 125.24064027218573, parameters k is -3.712346576226743 and b is -79.37709299735283\n",
      "Iteration 1082, the loss is 125.20014364280304, parameters k is -3.706061941839391 and b is -79.37609299735283\n",
      "Iteration 1083, the loss is 125.15964701342031, parameters k is -3.699777307452039 and b is -79.37509299735282\n",
      "Iteration 1084, the loss is 125.11915038403752, parameters k is -3.693492673064687 and b is -79.37409299735282\n",
      "Iteration 1085, the loss is 125.078653754655, parameters k is -3.687208038677335 and b is -79.37309299735281\n",
      "Iteration 1086, the loss is 125.03815712527215, parameters k is -3.680923404289983 and b is -79.37209299735281\n",
      "Iteration 1087, the loss is 124.99766049588959, parameters k is -3.6746387699026313 and b is -79.3710929973528\n",
      "Iteration 1088, the loss is 124.95716386650695, parameters k is -3.6683541355152793 and b is -79.3700929973528\n",
      "Iteration 1089, the loss is 124.91666723712416, parameters k is -3.6620695011279274 and b is -79.3690929973528\n",
      "Iteration 1090, the loss is 124.8761706077414, parameters k is -3.6557848667405755 and b is -79.36809299735279\n",
      "Iteration 1091, the loss is 124.83567397835881, parameters k is -3.6495002323532235 and b is -79.36709299735278\n",
      "Iteration 1092, the loss is 124.7951773489761, parameters k is -3.6432155979658716 and b is -79.36609299735278\n",
      "Iteration 1093, the loss is 124.75468071959338, parameters k is -3.6369309635785196 and b is -79.36509299735278\n",
      "Iteration 1094, the loss is 124.71418409021067, parameters k is -3.6306463291911677 and b is -79.36409299735277\n",
      "Iteration 1095, the loss is 124.67368746082803, parameters k is -3.6243616948038158 and b is -79.36309299735277\n",
      "Iteration 1096, the loss is 124.63319083144539, parameters k is -3.618077060416464 and b is -79.36209299735276\n",
      "Iteration 1097, the loss is 124.59269420206279, parameters k is -3.611792426029112 and b is -79.36109299735276\n",
      "Iteration 1098, the loss is 124.55219757267993, parameters k is -3.60550779164176 and b is -79.36009299735275\n",
      "Iteration 1099, the loss is 124.51170094329724, parameters k is -3.599223157254408 and b is -79.35909299735275\n",
      "Iteration 1100, the loss is 124.47120431391473, parameters k is -3.592938522867056 and b is -79.35809299735274\n",
      "Iteration 1101, the loss is 124.43070768453185, parameters k is -3.586653888479704 and b is -79.35709299735274\n",
      "Iteration 1102, the loss is 124.3902110551493, parameters k is -3.580369254092352 and b is -79.35609299735273\n",
      "Iteration 1103, the loss is 124.34971442576649, parameters k is -3.5740846197050002 and b is -79.35509299735273\n",
      "Iteration 1104, the loss is 124.30921779638379, parameters k is -3.5677999853176483 and b is -79.35409299735272\n",
      "Iteration 1105, the loss is 124.2687211670012, parameters k is -3.5615153509302964 and b is -79.35309299735272\n",
      "Iteration 1106, the loss is 124.22822453761853, parameters k is -3.5552307165429444 and b is -79.35209299735271\n",
      "Iteration 1107, the loss is 124.18772790823577, parameters k is -3.5489460821555925 and b is -79.35109299735271\n",
      "Iteration 1108, the loss is 124.14723127885313, parameters k is -3.5426614477682405 and b is -79.3500929973527\n",
      "Iteration 1109, the loss is 124.10673464947045, parameters k is -3.5363768133808886 and b is -79.3490929973527\n",
      "Iteration 1110, the loss is 124.06623802008757, parameters k is -3.5300921789935367 and b is -79.3480929973527\n",
      "Iteration 1111, the loss is 124.02574139070494, parameters k is -3.5238075446061847 and b is -79.34709299735269\n",
      "Iteration 1112, the loss is 123.98524476132233, parameters k is -3.517522910218833 and b is -79.34609299735268\n",
      "Iteration 1113, the loss is 123.94474813193965, parameters k is -3.511238275831481 and b is -79.34509299735268\n",
      "Iteration 1114, the loss is 123.90425150255693, parameters k is -3.504953641444129 and b is -79.34409299735267\n",
      "Iteration 1115, the loss is 123.86375487317429, parameters k is -3.498669007056777 and b is -79.34309299735267\n",
      "Iteration 1116, the loss is 123.82325824379149, parameters k is -3.492384372669425 and b is -79.34209299735267\n",
      "Iteration 1117, the loss is 123.7827616144089, parameters k is -3.486099738282073 and b is -79.34109299735266\n",
      "Iteration 1118, the loss is 123.74226498502614, parameters k is -3.479815103894721 and b is -79.34009299735266\n",
      "Iteration 1119, the loss is 123.70176835564354, parameters k is -3.473530469507369 and b is -79.33909299735265\n",
      "Iteration 1120, the loss is 123.66127172626074, parameters k is -3.4672458351200173 and b is -79.33809299735265\n",
      "Iteration 1121, the loss is 123.62077509687822, parameters k is -3.4609612007326653 and b is -79.33709299735264\n",
      "Iteration 1122, the loss is 123.58027846749548, parameters k is -3.4546765663453134 and b is -79.33609299735264\n",
      "Iteration 1123, the loss is 123.53978183811277, parameters k is -3.4483919319579615 and b is -79.33509299735263\n",
      "Iteration 1124, the loss is 123.49928520873004, parameters k is -3.4421072975706095 and b is -79.33409299735263\n",
      "Iteration 1125, the loss is 123.45878857934729, parameters k is -3.4358226631832576 and b is -79.33309299735262\n",
      "Iteration 1126, the loss is 123.41829194996463, parameters k is -3.4295380287959056 and b is -79.33209299735262\n",
      "Iteration 1127, the loss is 123.37779532058195, parameters k is -3.4232533944085537 and b is -79.33109299735261\n",
      "Iteration 1128, the loss is 123.33729869119927, parameters k is -3.4169687600212018 and b is -79.33009299735261\n",
      "Iteration 1129, the loss is 123.2968020618166, parameters k is -3.41068412563385 and b is -79.3290929973526\n",
      "Iteration 1130, the loss is 123.25630543243386, parameters k is -3.404399491246498 and b is -79.3280929973526\n",
      "Iteration 1131, the loss is 123.21580880305098, parameters k is -3.398114856859146 and b is -79.3270929973526\n",
      "Iteration 1132, the loss is 123.17531217366846, parameters k is -3.391830222471794 and b is -79.32609299735259\n",
      "Iteration 1133, the loss is 123.13481554428586, parameters k is -3.385545588084442 and b is -79.32509299735258\n",
      "Iteration 1134, the loss is 123.09431891490314, parameters k is -3.37926095369709 and b is -79.32409299735258\n",
      "Iteration 1135, the loss is 123.0538222855204, parameters k is -3.372976319309738 and b is -79.32309299735257\n",
      "Iteration 1136, the loss is 123.01332565613775, parameters k is -3.3666916849223862 and b is -79.32209299735257\n",
      "Iteration 1137, the loss is 122.97282902675511, parameters k is -3.3604070505350343 and b is -79.32109299735257\n",
      "Iteration 1138, the loss is 122.93233239737235, parameters k is -3.3541224161476824 and b is -79.32009299735256\n",
      "Iteration 1139, the loss is 122.89183576798975, parameters k is -3.3478377817603304 and b is -79.31909299735256\n",
      "Iteration 1140, the loss is 122.85133913860696, parameters k is -3.3415531473729785 and b is -79.31809299735255\n",
      "Iteration 1141, the loss is 122.81084250922436, parameters k is -3.3352685129856265 and b is -79.31709299735255\n",
      "Iteration 1142, the loss is 122.77034587984161, parameters k is -3.3289838785982746 and b is -79.31609299735254\n",
      "Iteration 1143, the loss is 122.72984925045891, parameters k is -3.3226992442109227 and b is -79.31509299735254\n",
      "Iteration 1144, the loss is 122.68935262107631, parameters k is -3.3164146098235707 and b is -79.31409299735253\n",
      "Iteration 1145, the loss is 122.64885599169357, parameters k is -3.310129975436219 and b is -79.31309299735253\n",
      "Iteration 1146, the loss is 122.60835936231086, parameters k is -3.303845341048867 and b is -79.31209299735252\n",
      "Iteration 1147, the loss is 122.56786273292812, parameters k is -3.297560706661515 and b is -79.31109299735252\n",
      "Iteration 1148, the loss is 122.52736610354543, parameters k is -3.291276072274163 and b is -79.31009299735251\n",
      "Iteration 1149, the loss is 122.4868694741628, parameters k is -3.284991437886811 and b is -79.30909299735251\n",
      "Iteration 1150, the loss is 122.44637284477999, parameters k is -3.278706803499459 and b is -79.3080929973525\n",
      "Iteration 1151, the loss is 122.40587621539738, parameters k is -3.272422169112107 and b is -79.3070929973525\n",
      "Iteration 1152, the loss is 122.36537958601474, parameters k is -3.266137534724755 and b is -79.3060929973525\n",
      "Iteration 1153, the loss is 122.32488295663208, parameters k is -3.2598529003374033 and b is -79.30509299735249\n",
      "Iteration 1154, the loss is 122.28438632724931, parameters k is -3.2535682659500513 and b is -79.30409299735248\n",
      "Iteration 1155, the loss is 122.24388969786659, parameters k is -3.2472836315626994 and b is -79.30309299735248\n",
      "Iteration 1156, the loss is 122.2033930684839, parameters k is -3.2409989971753475 and b is -79.30209299735247\n",
      "Iteration 1157, the loss is 122.1628964391013, parameters k is -3.2347143627879955 and b is -79.30109299735247\n",
      "Iteration 1158, the loss is 122.12239980971853, parameters k is -3.2284297284006436 and b is -79.30009299735246\n",
      "Iteration 1159, the loss is 122.08190318033594, parameters k is -3.2221450940132916 and b is -79.29909299735246\n",
      "Iteration 1160, the loss is 122.04140655095314, parameters k is -3.2158604596259397 and b is -79.29809299735246\n",
      "Iteration 1161, the loss is 122.00090992157048, parameters k is -3.2095758252385878 and b is -79.29709299735245\n",
      "Iteration 1162, the loss is 121.96041329218772, parameters k is -3.203291190851236 and b is -79.29609299735245\n",
      "Iteration 1163, the loss is 121.9199166628051, parameters k is -3.197006556463884 and b is -79.29509299735244\n",
      "Iteration 1164, the loss is 121.8794200334225, parameters k is -3.190721922076532 and b is -79.29409299735244\n",
      "Iteration 1165, the loss is 121.83892340403982, parameters k is -3.18443728768918 and b is -79.29309299735243\n",
      "Iteration 1166, the loss is 121.798426774657, parameters k is -3.178152653301828 and b is -79.29209299735243\n",
      "Iteration 1167, the loss is 121.75793014527436, parameters k is -3.171868018914476 and b is -79.29109299735242\n",
      "Iteration 1168, the loss is 121.71743351589168, parameters k is -3.165583384527124 and b is -79.29009299735242\n",
      "Iteration 1169, the loss is 121.67693688650907, parameters k is -3.1592987501397722 and b is -79.28909299735241\n",
      "Iteration 1170, the loss is 121.6364402571263, parameters k is -3.1530141157524203 and b is -79.28809299735241\n",
      "Iteration 1171, the loss is 121.59594362774342, parameters k is -3.1467294813650684 and b is -79.2870929973524\n",
      "Iteration 1172, the loss is 121.55544699836086, parameters k is -3.1404448469777164 and b is -79.2860929973524\n",
      "Iteration 1173, the loss is 121.51495036897818, parameters k is -3.1341602125903645 and b is -79.2850929973524\n",
      "Iteration 1174, the loss is 121.47445373959556, parameters k is -3.1278755782030125 and b is -79.28409299735239\n",
      "Iteration 1175, the loss is 121.43395711021283, parameters k is -3.1215909438156606 and b is -79.28309299735238\n",
      "Iteration 1176, the loss is 121.39346048083009, parameters k is -3.1153063094283087 and b is -79.28209299735238\n",
      "Iteration 1177, the loss is 121.35296385144743, parameters k is -3.1090216750409567 and b is -79.28109299735237\n",
      "Iteration 1178, the loss is 121.31246722206474, parameters k is -3.102737040653605 and b is -79.28009299735237\n",
      "Iteration 1179, the loss is 121.27197059268208, parameters k is -3.096452406266253 and b is -79.27909299735236\n",
      "Iteration 1180, the loss is 121.23147396329942, parameters k is -3.090167771878901 and b is -79.27809299735236\n",
      "Iteration 1181, the loss is 121.19097733391672, parameters k is -3.083883137491549 and b is -79.27709299735236\n",
      "Iteration 1182, the loss is 121.15048070453398, parameters k is -3.077598503104197 and b is -79.27609299735235\n",
      "Iteration 1183, the loss is 121.10998407515139, parameters k is -3.071313868716845 and b is -79.27509299735235\n",
      "Iteration 1184, the loss is 121.06948744576867, parameters k is -3.065029234329493 and b is -79.27409299735234\n",
      "Iteration 1185, the loss is 121.02899081638583, parameters k is -3.058744599942141 and b is -79.27309299735234\n",
      "Iteration 1186, the loss is 120.98849418700316, parameters k is -3.0524599655547893 and b is -79.27209299735233\n",
      "Iteration 1187, the loss is 120.94799755762062, parameters k is -3.0461753311674373 and b is -79.27109299735233\n",
      "Iteration 1188, the loss is 120.90750092823787, parameters k is -3.0398906967800854 and b is -79.27009299735232\n",
      "Iteration 1189, the loss is 120.86700429885529, parameters k is -3.0336060623927334 and b is -79.26909299735232\n",
      "Iteration 1190, the loss is 120.82650766947235, parameters k is -3.0273214280053815 and b is -79.26809299735231\n",
      "Iteration 1191, the loss is 120.78601104008979, parameters k is -3.0210367936180296 and b is -79.26709299735231\n",
      "Iteration 1192, the loss is 120.74551441070706, parameters k is -3.0147521592306776 and b is -79.2660929973523\n",
      "Iteration 1193, the loss is 120.70501778132453, parameters k is -3.0084675248433257 and b is -79.2650929973523\n",
      "Iteration 1194, the loss is 120.6645211519417, parameters k is -3.0021828904559738 and b is -79.2640929973523\n",
      "Iteration 1195, the loss is 120.62402452255898, parameters k is -2.995898256068622 and b is -79.26309299735229\n",
      "Iteration 1196, the loss is 120.58352789317634, parameters k is -2.98961362168127 and b is -79.26209299735228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1197, the loss is 120.54303126379354, parameters k is -2.983328987293918 and b is -79.26109299735228\n",
      "Iteration 1198, the loss is 120.50253463441105, parameters k is -2.977044352906566 and b is -79.26009299735227\n",
      "Iteration 1199, the loss is 120.46203800502829, parameters k is -2.970759718519214 and b is -79.25909299735227\n",
      "Iteration 1200, the loss is 120.42154137564546, parameters k is -2.964475084131862 and b is -79.25809299735226\n",
      "Iteration 1201, the loss is 120.38104474626276, parameters k is -2.95819044974451 and b is -79.25709299735226\n",
      "Iteration 1202, the loss is 120.34054811688016, parameters k is -2.9519058153571582 and b is -79.25609299735225\n",
      "Iteration 1203, the loss is 120.30005148749757, parameters k is -2.9456211809698063 and b is -79.25509299735225\n",
      "Iteration 1204, the loss is 120.25955485811487, parameters k is -2.9393365465824544 and b is -79.25409299735225\n",
      "Iteration 1205, the loss is 120.2190582287322, parameters k is -2.9330519121951024 and b is -79.25309299735224\n",
      "Iteration 1206, the loss is 120.17856159934948, parameters k is -2.9267672778077505 and b is -79.25209299735224\n",
      "Iteration 1207, the loss is 120.13806496996666, parameters k is -2.9204826434203985 and b is -79.25109299735223\n",
      "Iteration 1208, the loss is 120.09756834058403, parameters k is -2.9141980090330466 and b is -79.25009299735223\n",
      "Iteration 1209, the loss is 120.05707171120133, parameters k is -2.9079133746456947 and b is -79.24909299735222\n",
      "Iteration 1210, the loss is 120.01657508181859, parameters k is -2.9016287402583427 and b is -79.24809299735222\n",
      "Iteration 1211, the loss is 119.97607845243604, parameters k is -2.895344105870991 and b is -79.24709299735221\n",
      "Iteration 1212, the loss is 119.93558182305324, parameters k is -2.889059471483639 and b is -79.2460929973522\n",
      "Iteration 1213, the loss is 119.89508519367058, parameters k is -2.882774837096287 and b is -79.2450929973522\n",
      "Iteration 1214, the loss is 119.85458856428788, parameters k is -2.876490202708935 and b is -79.2440929973522\n",
      "Iteration 1215, the loss is 119.81409193490528, parameters k is -2.870205568321583 and b is -79.24309299735219\n",
      "Iteration 1216, the loss is 119.77359530552252, parameters k is -2.863920933934231 and b is -79.24209299735219\n",
      "Iteration 1217, the loss is 119.73309867613993, parameters k is -2.857636299546879 and b is -79.24109299735218\n",
      "Iteration 1218, the loss is 119.69260204675719, parameters k is -2.851351665159527 and b is -79.24009299735218\n",
      "Iteration 1219, the loss is 119.6521054173745, parameters k is -2.8450670307721753 and b is -79.23909299735217\n",
      "Iteration 1220, the loss is 119.61160878799186, parameters k is -2.8387823963848233 and b is -79.23809299735217\n",
      "Iteration 1221, the loss is 119.57111215860907, parameters k is -2.8324977619974714 and b is -79.23709299735216\n",
      "Iteration 1222, the loss is 119.53061552922645, parameters k is -2.8262131276101194 and b is -79.23609299735216\n",
      "Iteration 1223, the loss is 119.49011889984367, parameters k is -2.8199284932227675 and b is -79.23509299735215\n",
      "Iteration 1224, the loss is 119.44962227046095, parameters k is -2.8136438588354156 and b is -79.23409299735215\n",
      "Iteration 1225, the loss is 119.40912564107832, parameters k is -2.8073592244480636 and b is -79.23309299735214\n",
      "Iteration 1226, the loss is 119.3686290116956, parameters k is -2.8010745900607117 and b is -79.23209299735214\n",
      "Iteration 1227, the loss is 119.32813238231303, parameters k is -2.7947899556733597 and b is -79.23109299735214\n",
      "Iteration 1228, the loss is 119.28763575293023, parameters k is -2.788505321286008 and b is -79.23009299735213\n",
      "Iteration 1229, the loss is 119.24713912354757, parameters k is -2.782220686898656 and b is -79.22909299735213\n",
      "Iteration 1230, the loss is 119.20664249416481, parameters k is -2.775936052511304 and b is -79.22809299735212\n",
      "Iteration 1231, the loss is 119.16614586478228, parameters k is -2.769651418123952 and b is -79.22709299735212\n",
      "Iteration 1232, the loss is 119.12564923539951, parameters k is -2.7633667837366 and b is -79.22609299735211\n",
      "Iteration 1233, the loss is 119.08515260601663, parameters k is -2.757082149349248 and b is -79.2250929973521\n",
      "Iteration 1234, the loss is 119.04465597663415, parameters k is -2.750797514961896 and b is -79.2240929973521\n",
      "Iteration 1235, the loss is 119.00415934725137, parameters k is -2.7445128805745442 and b is -79.2230929973521\n",
      "Iteration 1236, the loss is 118.96366271786874, parameters k is -2.7382282461871923 and b is -79.22209299735209\n",
      "Iteration 1237, the loss is 118.92316608848607, parameters k is -2.7319436117998404 and b is -79.22109299735209\n",
      "Iteration 1238, the loss is 118.88266945910345, parameters k is -2.7256589774124884 and b is -79.22009299735208\n",
      "Iteration 1239, the loss is 118.8421728297208, parameters k is -2.7193743430251365 and b is -79.21909299735208\n",
      "Iteration 1240, the loss is 118.801676200338, parameters k is -2.7130897086377845 and b is -79.21809299735207\n",
      "Iteration 1241, the loss is 118.76117957095525, parameters k is -2.7068050742504326 and b is -79.21709299735207\n",
      "Iteration 1242, the loss is 118.7206829415725, parameters k is -2.7005204398630807 and b is -79.21609299735206\n",
      "Iteration 1243, the loss is 118.68018631218999, parameters k is -2.6942358054757287 and b is -79.21509299735206\n",
      "Iteration 1244, the loss is 118.63968968280724, parameters k is -2.687951171088377 and b is -79.21409299735205\n",
      "Iteration 1245, the loss is 118.59919305342434, parameters k is -2.681666536701025 and b is -79.21309299735205\n",
      "Iteration 1246, the loss is 118.55869642404178, parameters k is -2.675381902313673 and b is -79.21209299735204\n",
      "Iteration 1247, the loss is 118.51819979465913, parameters k is -2.669097267926321 and b is -79.21109299735204\n",
      "Iteration 1248, the loss is 118.47770316527644, parameters k is -2.662812633538969 and b is -79.21009299735204\n",
      "Iteration 1249, the loss is 118.43720653589394, parameters k is -2.656527999151617 and b is -79.20909299735203\n",
      "Iteration 1250, the loss is 118.39670990651116, parameters k is -2.650243364764265 and b is -79.20809299735203\n",
      "Iteration 1251, the loss is 118.3562132771284, parameters k is -2.643958730376913 and b is -79.20709299735202\n",
      "Iteration 1252, the loss is 118.31571664774575, parameters k is -2.6376740959895613 and b is -79.20609299735202\n",
      "Iteration 1253, the loss is 118.27522001836296, parameters k is -2.6313894616022093 and b is -79.20509299735201\n",
      "Iteration 1254, the loss is 118.23472338898033, parameters k is -2.6251048272148574 and b is -79.204092997352\n",
      "Iteration 1255, the loss is 118.19422675959764, parameters k is -2.6188201928275054 and b is -79.203092997352\n",
      "Iteration 1256, the loss is 118.15373013021498, parameters k is -2.6125355584401535 and b is -79.202092997352\n",
      "Iteration 1257, the loss is 118.11323350083225, parameters k is -2.6062509240528016 and b is -79.20109299735199\n",
      "Iteration 1258, the loss is 118.07273687144956, parameters k is -2.5999662896654496 and b is -79.20009299735199\n",
      "Iteration 1259, the loss is 118.03224024206689, parameters k is -2.5936816552780977 and b is -79.19909299735198\n",
      "Iteration 1260, the loss is 117.99174361268415, parameters k is -2.5873970208907457 and b is -79.19809299735198\n",
      "Iteration 1261, the loss is 117.95124698330152, parameters k is -2.581112386503394 and b is -79.19709299735197\n",
      "Iteration 1262, the loss is 117.91075035391879, parameters k is -2.574827752116042 and b is -79.19609299735197\n",
      "Iteration 1263, the loss is 117.87025372453594, parameters k is -2.56854311772869 and b is -79.19509299735196\n",
      "Iteration 1264, the loss is 117.8297570951535, parameters k is -2.562258483341338 and b is -79.19409299735196\n",
      "Iteration 1265, the loss is 117.78926046577067, parameters k is -2.555973848953986 and b is -79.19309299735195\n",
      "Iteration 1266, the loss is 117.74876383638808, parameters k is -2.549689214566634 and b is -79.19209299735195\n",
      "Iteration 1267, the loss is 117.70826720700535, parameters k is -2.543404580179282 and b is -79.19109299735194\n",
      "Iteration 1268, the loss is 117.6677705776227, parameters k is -2.5371199457919302 and b is -79.19009299735194\n",
      "Iteration 1269, the loss is 117.62727394823996, parameters k is -2.5308353114045783 and b is -79.18909299735193\n",
      "Iteration 1270, the loss is 117.58677731885729, parameters k is -2.5245506770172264 and b is -79.18809299735193\n",
      "Iteration 1271, the loss is 117.5462806894745, parameters k is -2.5182660426298744 and b is -79.18709299735193\n",
      "Iteration 1272, the loss is 117.505784060092, parameters k is -2.5119814082425225 and b is -79.18609299735192\n",
      "Iteration 1273, the loss is 117.46528743070922, parameters k is -2.5056967738551705 and b is -79.18509299735192\n",
      "Iteration 1274, the loss is 117.42479080132651, parameters k is -2.4994121394678186 and b is -79.18409299735191\n",
      "Iteration 1275, the loss is 117.38429417194376, parameters k is -2.4931275050804667 and b is -79.1830929973519\n",
      "Iteration 1276, the loss is 117.34379754256108, parameters k is -2.4868428706931147 and b is -79.1820929973519\n",
      "Iteration 1277, the loss is 117.30330091317849, parameters k is -2.4805582363057628 and b is -79.1810929973519\n",
      "Iteration 1278, the loss is 117.26280428379577, parameters k is -2.474273601918411 and b is -79.18009299735189\n",
      "Iteration 1279, the loss is 117.22230765441307, parameters k is -2.467988967531059 and b is -79.17909299735189\n",
      "Iteration 1280, the loss is 117.18181102503037, parameters k is -2.461704333143707 and b is -79.17809299735188\n",
      "Iteration 1281, the loss is 117.14131439564774, parameters k is -2.455419698756355 and b is -79.17709299735188\n",
      "Iteration 1282, the loss is 117.1008177662649, parameters k is -2.449135064369003 and b is -79.17609299735187\n",
      "Iteration 1283, the loss is 117.06032113688224, parameters k is -2.442850429981651 and b is -79.17509299735187\n",
      "Iteration 1284, the loss is 117.01982450749962, parameters k is -2.436565795594299 and b is -79.17409299735186\n",
      "Iteration 1285, the loss is 116.97932787811683, parameters k is -2.4302811612069473 and b is -79.17309299735186\n",
      "Iteration 1286, the loss is 116.93883124873423, parameters k is -2.4239965268195953 and b is -79.17209299735185\n",
      "Iteration 1287, the loss is 116.8983346193516, parameters k is -2.4177118924322434 and b is -79.17109299735185\n",
      "Iteration 1288, the loss is 116.8578379899689, parameters k is -2.4114272580448914 and b is -79.17009299735184\n",
      "Iteration 1289, the loss is 116.8173413605862, parameters k is -2.4051426236575395 and b is -79.16909299735184\n",
      "Iteration 1290, the loss is 116.77684473120345, parameters k is -2.3988579892701876 and b is -79.16809299735183\n",
      "Iteration 1291, the loss is 116.73634810182068, parameters k is -2.3925733548828356 and b is -79.16709299735183\n",
      "Iteration 1292, the loss is 116.69585147243816, parameters k is -2.3862887204954837 and b is -79.16609299735183\n",
      "Iteration 1293, the loss is 116.65535484305535, parameters k is -2.3800040861081317 and b is -79.16509299735182\n",
      "Iteration 1294, the loss is 116.6148582136728, parameters k is -2.37371945172078 and b is -79.16409299735182\n",
      "Iteration 1295, the loss is 116.57436158429012, parameters k is -2.367434817333428 and b is -79.16309299735181\n",
      "Iteration 1296, the loss is 116.53386495490724, parameters k is -2.361150182946076 and b is -79.1620929973518\n",
      "Iteration 1297, the loss is 116.4933683255247, parameters k is -2.354865548558724 and b is -79.1610929973518\n",
      "Iteration 1298, the loss is 116.45287169614197, parameters k is -2.348580914171372 and b is -79.1600929973518\n",
      "Iteration 1299, the loss is 116.4123750667593, parameters k is -2.34229627978402 and b is -79.15909299735179\n",
      "Iteration 1300, the loss is 116.37187843737664, parameters k is -2.336011645396668 and b is -79.15809299735179\n",
      "Iteration 1301, the loss is 116.33138180799381, parameters k is -2.3297270110093162 and b is -79.15709299735178\n",
      "Iteration 1302, the loss is 116.2908851786113, parameters k is -2.3234423766219643 and b is -79.15609299735178\n",
      "Iteration 1303, the loss is 116.25038854922856, parameters k is -2.3171577422346123 and b is -79.15509299735177\n",
      "Iteration 1304, the loss is 116.20989191984584, parameters k is -2.3108731078472604 and b is -79.15409299735177\n",
      "Iteration 1305, the loss is 116.16939529046304, parameters k is -2.3045884734599085 and b is -79.15309299735176\n",
      "Iteration 1306, the loss is 116.12889866108053, parameters k is -2.2983038390725565 and b is -79.15209299735176\n",
      "Iteration 1307, the loss is 116.0884020316977, parameters k is -2.2920192046852046 and b is -79.15109299735175\n",
      "Iteration 1308, the loss is 116.04790540231508, parameters k is -2.2857345702978527 and b is -79.15009299735175\n",
      "Iteration 1309, the loss is 116.0074087729323, parameters k is -2.2794499359105007 and b is -79.14909299735174\n",
      "Iteration 1310, the loss is 115.9669121435497, parameters k is -2.2731653015231488 and b is -79.14809299735174\n",
      "Iteration 1311, the loss is 115.92641551416699, parameters k is -2.266880667135797 and b is -79.14709299735173\n",
      "Iteration 1312, the loss is 115.88591888478439, parameters k is -2.260596032748445 and b is -79.14609299735173\n",
      "Iteration 1313, the loss is 115.84542225540179, parameters k is -2.254311398361093 and b is -79.14509299735172\n",
      "Iteration 1314, the loss is 115.80492562601893, parameters k is -2.248026763973741 and b is -79.14409299735172\n",
      "Iteration 1315, the loss is 115.76442899663614, parameters k is -2.241742129586389 and b is -79.14309299735172\n",
      "Iteration 1316, the loss is 115.72393236725347, parameters k is -2.235457495199037 and b is -79.14209299735171\n",
      "Iteration 1317, the loss is 115.68343573787078, parameters k is -2.229172860811685 and b is -79.1410929973517\n",
      "Iteration 1318, the loss is 115.64293910848822, parameters k is -2.2228882264243333 and b is -79.1400929973517\n",
      "Iteration 1319, the loss is 115.60244247910548, parameters k is -2.2166035920369813 and b is -79.1390929973517\n",
      "Iteration 1320, the loss is 115.56194584972275, parameters k is -2.2103189576496294 and b is -79.13809299735169\n",
      "Iteration 1321, the loss is 115.52144922034016, parameters k is -2.2040343232622774 and b is -79.13709299735169\n",
      "Iteration 1322, the loss is 115.48095259095739, parameters k is -2.1977496888749255 and b is -79.13609299735168\n",
      "Iteration 1323, the loss is 115.44045596157467, parameters k is -2.1914650544875736 and b is -79.13509299735168\n",
      "Iteration 1324, the loss is 115.39995933219188, parameters k is -2.1851804201002216 and b is -79.13409299735167\n",
      "Iteration 1325, the loss is 115.35946270280922, parameters k is -2.1788957857128697 and b is -79.13309299735167\n",
      "Iteration 1326, the loss is 115.31896607342678, parameters k is -2.1726111513255177 and b is -79.13209299735166\n",
      "Iteration 1327, the loss is 115.2784694440439, parameters k is -2.166326516938166 and b is -79.13109299735166\n",
      "Iteration 1328, the loss is 115.2379728146612, parameters k is -2.160041882550814 and b is -79.13009299735165\n",
      "Iteration 1329, the loss is 115.19747618527857, parameters k is -2.153757248163462 and b is -79.12909299735165\n",
      "Iteration 1330, the loss is 115.15697955589596, parameters k is -2.14747261377611 and b is -79.12809299735164\n",
      "Iteration 1331, the loss is 115.11648292651329, parameters k is -2.141187979388758 and b is -79.12709299735164\n",
      "Iteration 1332, the loss is 115.07598629713056, parameters k is -2.134903345001406 and b is -79.12609299735163\n",
      "Iteration 1333, the loss is 115.03548966774783, parameters k is -2.128618710614054 and b is -79.12509299735163\n",
      "Iteration 1334, the loss is 114.9949930383651, parameters k is -2.1223340762267022 and b is -79.12409299735162\n",
      "Iteration 1335, the loss is 114.95449640898232, parameters k is -2.1160494418393503 and b is -79.12309299735162\n",
      "Iteration 1336, the loss is 114.91399977959982, parameters k is -2.1097648074519983 and b is -79.12209299735161\n",
      "Iteration 1337, the loss is 114.87350315021706, parameters k is -2.1034801730646464 and b is -79.12109299735161\n",
      "Iteration 1338, the loss is 114.83300652083432, parameters k is -2.0971955386772945 and b is -79.1200929973516\n",
      "Iteration 1339, the loss is 114.79250989145176, parameters k is -2.0909109042899425 and b is -79.1190929973516\n",
      "Iteration 1340, the loss is 114.75201326206893, parameters k is -2.0846262699025906 and b is -79.1180929973516\n",
      "Iteration 1341, the loss is 114.71151663268624, parameters k is -2.0783416355152387 and b is -79.11709299735159\n",
      "Iteration 1342, the loss is 114.67102000330365, parameters k is -2.0720570011278867 and b is -79.11609299735159\n",
      "Iteration 1343, the loss is 114.63052337392101, parameters k is -2.0657723667405348 and b is -79.11509299735158\n",
      "Iteration 1344, the loss is 114.5900267445382, parameters k is -2.059487732353183 and b is -79.11409299735158\n",
      "Iteration 1345, the loss is 114.54953011515552, parameters k is -2.053203097965831 and b is -79.11309299735157\n",
      "Iteration 1346, the loss is 114.50903348577279, parameters k is -2.046918463578479 and b is -79.11209299735157\n",
      "Iteration 1347, the loss is 114.4685368563901, parameters k is -2.040633829191127 and b is -79.11109299735156\n",
      "Iteration 1348, the loss is 114.4280402270076, parameters k is -2.034349194803775 and b is -79.11009299735156\n",
      "Iteration 1349, the loss is 114.38754359762473, parameters k is -2.028064560416423 and b is -79.10909299735155\n",
      "Iteration 1350, the loss is 114.34704696824201, parameters k is -2.021779926029071 and b is -79.10809299735155\n",
      "Iteration 1351, the loss is 114.30655033885944, parameters k is -2.0154952916417193 and b is -79.10709299735154\n",
      "Iteration 1352, the loss is 114.26605370947662, parameters k is -2.0092106572543673 and b is -79.10609299735154\n",
      "Iteration 1353, the loss is 114.22555708009398, parameters k is -2.0029260228670154 and b is -79.10509299735153\n",
      "Iteration 1354, the loss is 114.18506045071136, parameters k is -1.9966413884796637 and b is -79.10409299735153\n",
      "Iteration 1355, the loss is 114.14456382132863, parameters k is -1.990356754092312 and b is -79.10309299735152\n",
      "Iteration 1356, the loss is 114.10406719194594, parameters k is -1.9840721197049602 and b is -79.10209299735152\n",
      "Iteration 1357, the loss is 114.06357056256323, parameters k is -1.9777874853176085 and b is -79.10109299735151\n",
      "Iteration 1358, the loss is 114.02307393318048, parameters k is -1.9715028509302568 and b is -79.10009299735151\n",
      "Iteration 1359, the loss is 113.98257730379794, parameters k is -1.965218216542905 and b is -79.0990929973515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1360, the loss is 113.94208067441512, parameters k is -1.9589335821555534 and b is -79.0980929973515\n",
      "Iteration 1361, the loss is 113.90158404503244, parameters k is -1.9526489477682016 and b is -79.0970929973515\n",
      "Iteration 1362, the loss is 113.86108741564975, parameters k is -1.94636431338085 and b is -79.09609299735149\n",
      "Iteration 1363, the loss is 113.82059078626712, parameters k is -1.9400796789934982 and b is -79.09509299735149\n",
      "Iteration 1364, the loss is 113.78009415688435, parameters k is -1.9337950446061465 and b is -79.09409299735148\n",
      "Iteration 1365, the loss is 113.73959752750164, parameters k is -1.9275104102187948 and b is -79.09309299735148\n",
      "Iteration 1366, the loss is 113.69910089811911, parameters k is -1.921225775831443 and b is -79.09209299735147\n",
      "Iteration 1367, the loss is 113.65860426873631, parameters k is -1.9149411414440913 and b is -79.09109299735147\n",
      "Iteration 1368, the loss is 113.61810763935362, parameters k is -1.9086565070567396 and b is -79.09009299735146\n",
      "Iteration 1369, the loss is 113.57761100997092, parameters k is -1.902371872669388 and b is -79.08909299735146\n",
      "Iteration 1370, the loss is 113.5371143805883, parameters k is -1.8960872382820362 and b is -79.08809299735145\n",
      "Iteration 1371, the loss is 113.49661775120559, parameters k is -1.8898026038946845 and b is -79.08709299735145\n",
      "Iteration 1372, the loss is 113.45612112182293, parameters k is -1.8835179695073327 and b is -79.08609299735144\n",
      "Iteration 1373, the loss is 113.41562449244014, parameters k is -1.877233335119981 and b is -79.08509299735144\n",
      "Iteration 1374, the loss is 113.37512786305754, parameters k is -1.8709487007326293 and b is -79.08409299735143\n",
      "Iteration 1375, the loss is 113.33463123367508, parameters k is -1.8646640663452776 and b is -79.08309299735143\n",
      "Iteration 1376, the loss is 113.29413460429228, parameters k is -1.8583794319579259 and b is -79.08209299735142\n",
      "Iteration 1377, the loss is 113.25363797490944, parameters k is -1.8520947975705742 and b is -79.08109299735142\n",
      "Iteration 1378, the loss is 113.21314134552676, parameters k is -1.8458101631832224 and b is -79.08009299735141\n",
      "Iteration 1379, the loss is 113.17264471614408, parameters k is -1.8395255287958707 and b is -79.07909299735141\n",
      "Iteration 1380, the loss is 113.13214808676135, parameters k is -1.833240894408519 and b is -79.0780929973514\n",
      "Iteration 1381, the loss is 113.09165145737867, parameters k is -1.8269562600211673 and b is -79.0770929973514\n",
      "Iteration 1382, the loss is 113.0511548279961, parameters k is -1.8206716256338156 and b is -79.0760929973514\n",
      "Iteration 1383, the loss is 113.01065819861334, parameters k is -1.8143869912464639 and b is -79.07509299735139\n",
      "Iteration 1384, the loss is 112.97016156923075, parameters k is -1.8081023568591121 and b is -79.07409299735139\n",
      "Iteration 1385, the loss is 112.92966493984807, parameters k is -1.8018177224717604 and b is -79.07309299735138\n",
      "Iteration 1386, the loss is 112.88916831046524, parameters k is -1.7955330880844087 and b is -79.07209299735138\n",
      "Iteration 1387, the loss is 112.84867168108254, parameters k is -1.789248453697057 and b is -79.07109299735137\n",
      "Iteration 1388, the loss is 112.8081750516998, parameters k is -1.7829638193097053 and b is -79.07009299735137\n",
      "Iteration 1389, the loss is 112.76767842231715, parameters k is -1.7766791849223535 and b is -79.06909299735136\n",
      "Iteration 1390, the loss is 112.72718179293454, parameters k is -1.7703945505350018 and b is -79.06809299735136\n",
      "Iteration 1391, the loss is 112.68668516355183, parameters k is -1.7641099161476501 and b is -79.06709299735135\n",
      "Iteration 1392, the loss is 112.64618853416916, parameters k is -1.7578252817602984 and b is -79.06609299735135\n",
      "Iteration 1393, the loss is 112.60569190478637, parameters k is -1.7515406473729467 and b is -79.06509299735134\n",
      "Iteration 1394, the loss is 112.5651952754038, parameters k is -1.745256012985595 and b is -79.06409299735134\n",
      "Iteration 1395, the loss is 112.52469864602102, parameters k is -1.7389713785982432 and b is -79.06309299735133\n",
      "Iteration 1396, the loss is 112.48420201663826, parameters k is -1.7326867442108915 and b is -79.06209299735133\n",
      "Iteration 1397, the loss is 112.44370538725562, parameters k is -1.7264021098235398 and b is -79.06109299735132\n",
      "Iteration 1398, the loss is 112.40320875787296, parameters k is -1.720117475436188 and b is -79.06009299735132\n",
      "Iteration 1399, the loss is 112.36271212849034, parameters k is -1.7138328410488364 and b is -79.05909299735131\n",
      "Iteration 1400, the loss is 112.32221549910768, parameters k is -1.7075482066614847 and b is -79.05809299735131\n",
      "Iteration 1401, the loss is 112.2817188697249, parameters k is -1.701263572274133 and b is -79.0570929973513\n",
      "Iteration 1402, the loss is 112.24122224034232, parameters k is -1.6949789378867812 and b is -79.0560929973513\n",
      "Iteration 1403, the loss is 112.20072561095954, parameters k is -1.6886943034994295 and b is -79.0550929973513\n",
      "Iteration 1404, the loss is 112.16022898157695, parameters k is -1.6824096691120778 and b is -79.05409299735129\n",
      "Iteration 1405, the loss is 112.11973235219415, parameters k is -1.676125034724726 and b is -79.05309299735129\n",
      "Iteration 1406, the loss is 112.0792357228115, parameters k is -1.6698404003373744 and b is -79.05209299735128\n",
      "Iteration 1407, the loss is 112.03873909342877, parameters k is -1.6635557659500226 and b is -79.05109299735128\n",
      "Iteration 1408, the loss is 111.99824246404613, parameters k is -1.657271131562671 and b is -79.05009299735127\n",
      "Iteration 1409, the loss is 111.95774583466334, parameters k is -1.6509864971753192 and b is -79.04909299735127\n",
      "Iteration 1410, the loss is 111.9172492052808, parameters k is -1.6447018627879675 and b is -79.04809299735126\n",
      "Iteration 1411, the loss is 111.87675257589807, parameters k is -1.6384172284006158 and b is -79.04709299735126\n",
      "Iteration 1412, the loss is 111.83625594651535, parameters k is -1.632132594013264 and b is -79.04609299735125\n",
      "Iteration 1413, the loss is 111.79575931713264, parameters k is -1.6258479596259123 and b is -79.04509299735125\n",
      "Iteration 1414, the loss is 111.7552626877499, parameters k is -1.6195633252385606 and b is -79.04409299735124\n",
      "Iteration 1415, the loss is 111.71476605836729, parameters k is -1.613278690851209 and b is -79.04309299735124\n",
      "Iteration 1416, the loss is 111.67426942898459, parameters k is -1.6069940564638572 and b is -79.04209299735123\n",
      "Iteration 1417, the loss is 111.63377279960197, parameters k is -1.6007094220765055 and b is -79.04109299735123\n",
      "Iteration 1418, the loss is 111.59327617021911, parameters k is -1.5944247876891537 and b is -79.04009299735122\n",
      "Iteration 1419, the loss is 111.55277954083654, parameters k is -1.588140153301802 and b is -79.03909299735122\n",
      "Iteration 1420, the loss is 111.51228291145398, parameters k is -1.5818555189144503 and b is -79.03809299735121\n",
      "Iteration 1421, the loss is 111.47178628207116, parameters k is -1.5755708845270986 and b is -79.03709299735121\n",
      "Iteration 1422, the loss is 111.43128965268846, parameters k is -1.5692862501397469 and b is -79.0360929973512\n",
      "Iteration 1423, the loss is 111.39079302330575, parameters k is -1.5630016157523952 and b is -79.0350929973512\n",
      "Iteration 1424, the loss is 111.35029639392316, parameters k is -1.5567169813650434 and b is -79.0340929973512\n",
      "Iteration 1425, the loss is 111.30979976454039, parameters k is -1.5504323469776917 and b is -79.03309299735119\n",
      "Iteration 1426, the loss is 111.26930313515771, parameters k is -1.54414771259034 and b is -79.03209299735119\n",
      "Iteration 1427, the loss is 111.22880650577494, parameters k is -1.5378630782029883 and b is -79.03109299735118\n",
      "Iteration 1428, the loss is 111.18830987639232, parameters k is -1.5315784438156366 and b is -79.03009299735118\n",
      "Iteration 1429, the loss is 111.1478132470096, parameters k is -1.5252938094282849 and b is -79.02909299735117\n",
      "Iteration 1430, the loss is 111.10731661762692, parameters k is -1.5190091750409331 and b is -79.02809299735117\n",
      "Iteration 1431, the loss is 111.06681998824432, parameters k is -1.5127245406535814 and b is -79.02709299735116\n",
      "Iteration 1432, the loss is 111.02632335886157, parameters k is -1.5064399062662297 and b is -79.02609299735116\n",
      "Iteration 1433, the loss is 110.98582672947892, parameters k is -1.500155271878878 and b is -79.02509299735115\n",
      "Iteration 1434, the loss is 110.94533010009626, parameters k is -1.4938706374915263 and b is -79.02409299735115\n",
      "Iteration 1435, the loss is 110.9048334707134, parameters k is -1.4875860031041745 and b is -79.02309299735114\n",
      "Iteration 1436, the loss is 110.86433684133073, parameters k is -1.4813013687168228 and b is -79.02209299735114\n",
      "Iteration 1437, the loss is 110.82384021194812, parameters k is -1.4750167343294711 and b is -79.02109299735113\n",
      "Iteration 1438, the loss is 110.78334358256541, parameters k is -1.4687320999421194 and b is -79.02009299735113\n",
      "Iteration 1439, the loss is 110.74284695318268, parameters k is -1.4624474655547677 and b is -79.01909299735112\n",
      "Iteration 1440, the loss is 110.70235032380008, parameters k is -1.456162831167416 and b is -79.01809299735112\n",
      "Iteration 1441, the loss is 110.66185369441745, parameters k is -1.4498781967800642 and b is -79.01709299735111\n",
      "Iteration 1442, the loss is 110.62135706503472, parameters k is -1.4435935623927125 and b is -79.01609299735111\n",
      "Iteration 1443, the loss is 110.58086043565203, parameters k is -1.4373089280053608 and b is -79.0150929973511\n",
      "Iteration 1444, the loss is 110.54036380626934, parameters k is -1.431024293618009 and b is -79.0140929973511\n",
      "Iteration 1445, the loss is 110.4998671768866, parameters k is -1.4247396592306574 and b is -79.0130929973511\n",
      "Iteration 1446, the loss is 110.45937054750392, parameters k is -1.4184550248433057 and b is -79.01209299735109\n",
      "Iteration 1447, the loss is 110.41887391812121, parameters k is -1.412170390455954 and b is -79.01109299735108\n",
      "Iteration 1448, the loss is 110.37837728873859, parameters k is -1.4058857560686022 and b is -79.01009299735108\n",
      "Iteration 1449, the loss is 110.33788065935587, parameters k is -1.3996011216812505 and b is -79.00909299735108\n",
      "Iteration 1450, the loss is 110.29738402997322, parameters k is -1.3933164872938988 and b is -79.00809299735107\n",
      "Iteration 1451, the loss is 110.25688740059049, parameters k is -1.387031852906547 and b is -79.00709299735107\n",
      "Iteration 1452, the loss is 110.21639077120787, parameters k is -1.3807472185191954 and b is -79.00609299735106\n",
      "Iteration 1453, the loss is 110.17589414182521, parameters k is -1.3744625841318436 and b is -79.00509299735106\n",
      "Iteration 1454, the loss is 110.13539751244238, parameters k is -1.368177949744492 and b is -79.00409299735105\n",
      "Iteration 1455, the loss is 110.09490088305974, parameters k is -1.3618933153571402 and b is -79.00309299735105\n",
      "Iteration 1456, the loss is 110.05440425367708, parameters k is -1.3556086809697885 and b is -79.00209299735104\n",
      "Iteration 1457, the loss is 110.01390762429428, parameters k is -1.3493240465824368 and b is -79.00109299735104\n",
      "Iteration 1458, the loss is 109.97341099491172, parameters k is -1.343039412195085 and b is -79.00009299735103\n",
      "Iteration 1459, the loss is 109.93291436552892, parameters k is -1.3367547778077333 and b is -78.99909299735103\n",
      "Iteration 1460, the loss is 109.89241773614633, parameters k is -1.3304701434203816 and b is -78.99809299735102\n",
      "Iteration 1461, the loss is 109.85192110676351, parameters k is -1.32418550903303 and b is -78.99709299735102\n",
      "Iteration 1462, the loss is 109.81142447738085, parameters k is -1.3179008746456782 and b is -78.99609299735101\n",
      "Iteration 1463, the loss is 109.77092784799821, parameters k is -1.3116162402583265 and b is -78.99509299735101\n",
      "Iteration 1464, the loss is 109.73043121861552, parameters k is -1.3053316058709747 and b is -78.994092997351\n",
      "Iteration 1465, the loss is 109.68993458923279, parameters k is -1.299046971483623 and b is -78.993092997351\n",
      "Iteration 1466, the loss is 109.64943795985008, parameters k is -1.2927623370962713 and b is -78.992092997351\n",
      "Iteration 1467, the loss is 109.60894133046753, parameters k is -1.2864777027089196 and b is -78.99109299735099\n",
      "Iteration 1468, the loss is 109.56844470108466, parameters k is -1.2801930683215679 and b is -78.99009299735098\n",
      "Iteration 1469, the loss is 109.52794807170201, parameters k is -1.2739084339342162 and b is -78.98909299735098\n",
      "Iteration 1470, the loss is 109.48745144231941, parameters k is -1.2676237995468644 and b is -78.98809299735098\n",
      "Iteration 1471, the loss is 109.44695481293675, parameters k is -1.2613391651595127 and b is -78.98709299735097\n",
      "Iteration 1472, the loss is 109.406458183554, parameters k is -1.255054530772161 and b is -78.98609299735097\n",
      "Iteration 1473, the loss is 109.36596155417138, parameters k is -1.2487698963848093 and b is -78.98509299735096\n",
      "Iteration 1474, the loss is 109.32546492478868, parameters k is -1.2424852619974576 and b is -78.98409299735096\n",
      "Iteration 1475, the loss is 109.28496829540599, parameters k is -1.2362006276101059 and b is -78.98309299735095\n",
      "Iteration 1476, the loss is 109.24447166602334, parameters k is -1.2299159932227541 and b is -78.98209299735095\n",
      "Iteration 1477, the loss is 109.2039750366406, parameters k is -1.2236313588354024 and b is -78.98109299735094\n",
      "Iteration 1478, the loss is 109.1634784072579, parameters k is -1.2173467244480507 and b is -78.98009299735094\n",
      "Iteration 1479, the loss is 109.12298177787508, parameters k is -1.211062090060699 and b is -78.97909299735093\n",
      "Iteration 1480, the loss is 109.08248514849248, parameters k is -1.2047774556733473 and b is -78.97809299735093\n",
      "Iteration 1481, the loss is 109.04198851910986, parameters k is -1.1984928212859955 and b is -78.97709299735092\n",
      "Iteration 1482, the loss is 109.00149188972722, parameters k is -1.1922081868986438 and b is -78.97609299735092\n",
      "Iteration 1483, the loss is 108.96099526034443, parameters k is -1.1859235525112921 and b is -78.97509299735091\n",
      "Iteration 1484, the loss is 108.92049863096163, parameters k is -1.1796389181239404 and b is -78.97409299735091\n",
      "Iteration 1485, the loss is 108.88000200157914, parameters k is -1.1733542837365887 and b is -78.9730929973509\n",
      "Iteration 1486, the loss is 108.83950537219637, parameters k is -1.167069649349237 and b is -78.9720929973509\n",
      "Iteration 1487, the loss is 108.79900874281377, parameters k is -1.1607850149618852 and b is -78.9710929973509\n",
      "Iteration 1488, the loss is 108.75851211343101, parameters k is -1.1545003805745335 and b is -78.97009299735089\n",
      "Iteration 1489, the loss is 108.71801548404835, parameters k is -1.1482157461871818 and b is -78.96909299735088\n",
      "Iteration 1490, the loss is 108.67751885466559, parameters k is -1.14193111179983 and b is -78.96809299735088\n",
      "Iteration 1491, the loss is 108.63702222528299, parameters k is -1.1356464774124784 and b is -78.96709299735087\n",
      "Iteration 1492, the loss is 108.59652559590023, parameters k is -1.1293618430251267 and b is -78.96609299735087\n",
      "Iteration 1493, the loss is 108.55602896651756, parameters k is -1.123077208637775 and b is -78.96509299735087\n",
      "Iteration 1494, the loss is 108.51553233713491, parameters k is -1.1167925742504232 and b is -78.96409299735086\n",
      "Iteration 1495, the loss is 108.47503570775218, parameters k is -1.1105079398630715 and b is -78.96309299735086\n",
      "Iteration 1496, the loss is 108.43453907836947, parameters k is -1.1042233054757198 and b is -78.96209299735085\n",
      "Iteration 1497, the loss is 108.39404244898677, parameters k is -1.097938671088368 and b is -78.96109299735085\n",
      "Iteration 1498, the loss is 108.35354581960408, parameters k is -1.0916540367010164 and b is -78.96009299735084\n",
      "Iteration 1499, the loss is 108.31304919022129, parameters k is -1.0853694023136646 and b is -78.95909299735084\n",
      "Iteration 1500, the loss is 108.27255256083872, parameters k is -1.079084767926313 and b is -78.95809299735083\n",
      "Iteration 1501, the loss is 108.23205593145606, parameters k is -1.0728001335389612 and b is -78.95709299735083\n",
      "Iteration 1502, the loss is 108.19155930207341, parameters k is -1.0665154991516095 and b is -78.95609299735082\n",
      "Iteration 1503, the loss is 108.15106267269071, parameters k is -1.0602308647642578 and b is -78.95509299735082\n",
      "Iteration 1504, the loss is 108.11056604330805, parameters k is -1.053946230376906 and b is -78.95409299735081\n",
      "Iteration 1505, the loss is 108.07006941392524, parameters k is -1.0476615959895543 and b is -78.95309299735081\n",
      "Iteration 1506, the loss is 108.02957278454242, parameters k is -1.0413769616022026 and b is -78.9520929973508\n",
      "Iteration 1507, the loss is 107.98907615515988, parameters k is -1.035092327214851 and b is -78.9510929973508\n",
      "Iteration 1508, the loss is 107.94857952577723, parameters k is -1.0288076928274992 and b is -78.9500929973508\n",
      "Iteration 1509, the loss is 107.90808289639475, parameters k is -1.0225230584401475 and b is -78.94909299735079\n",
      "Iteration 1510, the loss is 107.8675862670118, parameters k is -1.0162384240527957 and b is -78.94809299735078\n",
      "Iteration 1511, the loss is 107.82708963762923, parameters k is -1.009953789665444 and b is -78.94709299735078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1512, the loss is 107.78659300824648, parameters k is -1.0036691552780923 and b is -78.94609299735077\n",
      "Iteration 1513, the loss is 107.74609637886381, parameters k is -0.9973845208907405 and b is -78.94509299735077\n",
      "Iteration 1514, the loss is 107.70559974948104, parameters k is -0.9910998865033886 and b is -78.94409299735077\n",
      "Iteration 1515, the loss is 107.66510312009842, parameters k is -0.9848152521160368 and b is -78.94309299735076\n",
      "Iteration 1516, the loss is 107.62460649071568, parameters k is -0.978530617728685 and b is -78.94209299735076\n",
      "Iteration 1517, the loss is 107.58410986133296, parameters k is -0.9722459833413332 and b is -78.94109299735075\n",
      "Iteration 1518, the loss is 107.54361323195023, parameters k is -0.9659613489539813 and b is -78.94009299735075\n",
      "Iteration 1519, the loss is 107.50311660256769, parameters k is -0.9596767145666295 and b is -78.93909299735074\n",
      "Iteration 1520, the loss is 107.46261997318493, parameters k is -0.9533920801792777 and b is -78.93809299735074\n",
      "Iteration 1521, the loss is 107.42212334380238, parameters k is -0.9471074457919259 and b is -78.93709299735073\n",
      "Iteration 1522, the loss is 107.38162671441943, parameters k is -0.940822811404574 and b is -78.93609299735073\n",
      "Iteration 1523, the loss is 107.34113008503691, parameters k is -0.9345381770172222 and b is -78.93509299735072\n",
      "Iteration 1524, the loss is 107.30063345565421, parameters k is -0.9282535426298704 and b is -78.93409299735072\n",
      "Iteration 1525, the loss is 107.26013682627143, parameters k is -0.9219689082425185 and b is -78.93309299735071\n",
      "Iteration 1526, the loss is 107.21964019688868, parameters k is -0.9156842738551667 and b is -78.93209299735071\n",
      "Iteration 1527, the loss is 107.17914356750617, parameters k is -0.9093996394678149 and b is -78.9310929973507\n",
      "Iteration 1528, the loss is 107.1386469381235, parameters k is -0.903115005080463 and b is -78.9300929973507\n",
      "Iteration 1529, the loss is 107.09815030874074, parameters k is -0.8968303706931112 and b is -78.9290929973507\n",
      "Iteration 1530, the loss is 107.05765367935805, parameters k is -0.8905457363057594 and b is -78.92809299735069\n",
      "Iteration 1531, the loss is 107.01715704997538, parameters k is -0.8842611019184076 and b is -78.92709299735068\n",
      "Iteration 1532, the loss is 106.97666042059265, parameters k is -0.8779764675310557 and b is -78.92609299735068\n",
      "Iteration 1533, the loss is 106.93616379120996, parameters k is -0.8716918331437039 and b is -78.92509299735067\n",
      "Iteration 1534, the loss is 106.89566716182719, parameters k is -0.8654071987563521 and b is -78.92409299735067\n",
      "Iteration 1535, the loss is 106.85517053244463, parameters k is -0.8591225643690003 and b is -78.92309299735066\n",
      "Iteration 1536, the loss is 106.8146739030619, parameters k is -0.8528379299816484 and b is -78.92209299735066\n",
      "Iteration 1537, the loss is 106.77417727367931, parameters k is -0.8465532955942966 and b is -78.92109299735066\n",
      "Iteration 1538, the loss is 106.73368064429647, parameters k is -0.8402686612069448 and b is -78.92009299735065\n",
      "Iteration 1539, the loss is 106.6931840149139, parameters k is -0.8339840268195929 and b is -78.91909299735065\n",
      "Iteration 1540, the loss is 106.65268738553124, parameters k is -0.8276993924322411 and b is -78.91809299735064\n",
      "Iteration 1541, the loss is 106.61219075614845, parameters k is -0.8214147580448893 and b is -78.91709299735064\n",
      "Iteration 1542, the loss is 106.57169412676583, parameters k is -0.8151301236575375 and b is -78.91609299735063\n",
      "Iteration 1543, the loss is 106.53119749738306, parameters k is -0.8088454892701856 and b is -78.91509299735063\n",
      "Iteration 1544, the loss is 106.49070086800039, parameters k is -0.8025608548828338 and b is -78.91409299735062\n",
      "Iteration 1545, the loss is 106.45020423861783, parameters k is -0.796276220495482 and b is -78.91309299735062\n",
      "Iteration 1546, the loss is 106.40970760923489, parameters k is -0.7899915861081301 and b is -78.91209299735061\n",
      "Iteration 1547, the loss is 106.36921097985237, parameters k is -0.7837069517207783 and b is -78.91109299735061\n",
      "Iteration 1548, the loss is 106.32871435046974, parameters k is -0.7774223173334265 and b is -78.9100929973506\n",
      "Iteration 1549, the loss is 106.28821772108702, parameters k is -0.7711376829460747 and b is -78.9090929973506\n",
      "Iteration 1550, the loss is 106.24772109170424, parameters k is -0.7648530485587228 and b is -78.9080929973506\n",
      "Iteration 1551, the loss is 106.20722446232152, parameters k is -0.758568414171371 and b is -78.90709299735059\n",
      "Iteration 1552, the loss is 106.16672783293879, parameters k is -0.7522837797840192 and b is -78.90609299735058\n",
      "Iteration 1553, the loss is 106.12623120355616, parameters k is -0.7459991453966673 and b is -78.90509299735058\n",
      "Iteration 1554, the loss is 106.0857345741735, parameters k is -0.7397145110093155 and b is -78.90409299735057\n",
      "Iteration 1555, the loss is 106.04523794479087, parameters k is -0.7334298766219637 and b is -78.90309299735057\n",
      "Iteration 1556, the loss is 106.00474131540793, parameters k is -0.7271452422346119 and b is -78.90209299735056\n",
      "Iteration 1557, the loss is 105.96424468602544, parameters k is -0.72086060784726 and b is -78.90109299735056\n",
      "Iteration 1558, the loss is 105.9237480566427, parameters k is -0.7145759734599082 and b is -78.90009299735055\n",
      "Iteration 1559, the loss is 105.88325142726002, parameters k is -0.7082913390725564 and b is -78.89909299735055\n",
      "Iteration 1560, the loss is 105.84275479787725, parameters k is -0.7020067046852045 and b is -78.89809299735055\n",
      "Iteration 1561, the loss is 105.80225816849476, parameters k is -0.6957220702978527 and b is -78.89709299735054\n",
      "Iteration 1562, the loss is 105.76176153911193, parameters k is -0.6894374359105009 and b is -78.89609299735054\n",
      "Iteration 1563, the loss is 105.72126490972931, parameters k is -0.6831528015231491 and b is -78.89509299735053\n",
      "Iteration 1564, the loss is 105.6807682803467, parameters k is -0.6768681671357972 and b is -78.89409299735053\n",
      "Iteration 1565, the loss is 105.64027165096397, parameters k is -0.6705835327484454 and b is -78.89309299735052\n",
      "Iteration 1566, the loss is 105.59977502158128, parameters k is -0.6642988983610936 and b is -78.89209299735052\n",
      "Iteration 1567, the loss is 105.5592783921985, parameters k is -0.6580142639737417 and b is -78.89109299735051\n",
      "Iteration 1568, the loss is 105.51878176281595, parameters k is -0.6517296295863899 and b is -78.89009299735051\n",
      "Iteration 1569, the loss is 105.47828513343322, parameters k is -0.6454449951990381 and b is -78.8890929973505\n",
      "Iteration 1570, the loss is 105.43778850405043, parameters k is -0.6391603608116863 and b is -78.8880929973505\n",
      "Iteration 1571, the loss is 105.39729187466791, parameters k is -0.6328757264243344 and b is -78.88709299735049\n",
      "Iteration 1572, the loss is 105.356795245285, parameters k is -0.6265910920369826 and b is -78.88609299735049\n",
      "Iteration 1573, the loss is 105.31629861590234, parameters k is -0.6203064576496308 and b is -78.88509299735048\n",
      "Iteration 1574, the loss is 105.27580198651975, parameters k is -0.6140218232622789 and b is -78.88409299735048\n",
      "Iteration 1575, the loss is 105.23530535713704, parameters k is -0.6077371888749271 and b is -78.88309299735047\n",
      "Iteration 1576, the loss is 105.19480872775432, parameters k is -0.6014525544875753 and b is -78.88209299735047\n",
      "Iteration 1577, the loss is 105.15431209837163, parameters k is -0.5951679201002235 and b is -78.88109299735046\n",
      "Iteration 1578, the loss is 105.11381546898895, parameters k is -0.5888832857128716 and b is -78.88009299735046\n",
      "Iteration 1579, the loss is 105.07331883960623, parameters k is -0.5825986513255198 and b is -78.87909299735045\n",
      "Iteration 1580, the loss is 105.03282221022356, parameters k is -0.576314016938168 and b is -78.87809299735045\n",
      "Iteration 1581, the loss is 104.99232558084097, parameters k is -0.5700293825508161 and b is -78.87709299735045\n",
      "Iteration 1582, the loss is 104.95182895145822, parameters k is -0.5637447481634643 and b is -78.87609299735044\n",
      "Iteration 1583, the loss is 104.91133232207542, parameters k is -0.5574601137761125 and b is -78.87509299735044\n",
      "Iteration 1584, the loss is 104.87083569269284, parameters k is -0.5511754793887607 and b is -78.87409299735043\n",
      "Iteration 1585, the loss is 104.83033906331013, parameters k is -0.5448908450014088 and b is -78.87309299735043\n",
      "Iteration 1586, the loss is 104.7898424339274, parameters k is -0.538606210614057 and b is -78.87209299735042\n",
      "Iteration 1587, the loss is 104.74934580454473, parameters k is -0.5323215762267052 and b is -78.87109299735042\n",
      "Iteration 1588, the loss is 104.70884917516203, parameters k is -0.5260369418393533 and b is -78.87009299735041\n",
      "Iteration 1589, the loss is 104.66835254577943, parameters k is -0.5197523074520015 and b is -78.8690929973504\n",
      "Iteration 1590, the loss is 104.62785591639663, parameters k is -0.5134676730646497 and b is -78.8680929973504\n",
      "Iteration 1591, the loss is 104.58735928701388, parameters k is -0.5071830386772979 and b is -78.8670929973504\n",
      "Iteration 1592, the loss is 104.54686265763128, parameters k is -0.500898404289946 and b is -78.86609299735039\n",
      "Iteration 1593, the loss is 104.50636602824851, parameters k is -0.49461376990259426 and b is -78.86509299735039\n",
      "Iteration 1594, the loss is 104.46586939886596, parameters k is -0.4883291355152425 and b is -78.86409299735038\n",
      "Iteration 1595, the loss is 104.42537276948332, parameters k is -0.4820445011278907 and b is -78.86309299735038\n",
      "Iteration 1596, the loss is 104.38487614010045, parameters k is -0.47575986674053894 and b is -78.86209299735037\n",
      "Iteration 1597, the loss is 104.34437951071786, parameters k is -0.46947523235318717 and b is -78.86109299735037\n",
      "Iteration 1598, the loss is 104.30388288133521, parameters k is -0.4631905979658354 and b is -78.86009299735036\n",
      "Iteration 1599, the loss is 104.26338625195251, parameters k is -0.4569059635784836 and b is -78.85909299735036\n",
      "Iteration 1600, the loss is 104.22288962256981, parameters k is -0.45062132919113185 and b is -78.85809299735035\n",
      "Iteration 1601, the loss is 104.18239299318704, parameters k is -0.4443366948037801 and b is -78.85709299735035\n",
      "Iteration 1602, the loss is 104.14189636380445, parameters k is -0.4380520604164283 and b is -78.85609299735034\n",
      "Iteration 1603, the loss is 104.10139973442176, parameters k is -0.43176742602907653 and b is -78.85509299735034\n",
      "Iteration 1604, the loss is 104.06090310503903, parameters k is -0.42548279164172476 and b is -78.85409299735034\n",
      "Iteration 1605, the loss is 104.02040647565639, parameters k is -0.419198157254373 and b is -78.85309299735033\n",
      "Iteration 1606, the loss is 103.97990984627353, parameters k is -0.4129135228670212 and b is -78.85209299735033\n",
      "Iteration 1607, the loss is 103.93941321689103, parameters k is -0.40662888847966944 and b is -78.85109299735032\n",
      "Iteration 1608, the loss is 103.89891658750832, parameters k is -0.40034425409231766 and b is -78.85009299735032\n",
      "Iteration 1609, the loss is 103.85841995812574, parameters k is -0.3940596197049659 and b is -78.84909299735031\n",
      "Iteration 1610, the loss is 103.81792332874285, parameters k is -0.3877749853176141 and b is -78.8480929973503\n",
      "Iteration 1611, the loss is 103.77742669936033, parameters k is -0.38149035093026235 and b is -78.8470929973503\n",
      "Iteration 1612, the loss is 103.73693006997752, parameters k is -0.3752057165429106 and b is -78.8460929973503\n",
      "Iteration 1613, the loss is 103.6964334405949, parameters k is -0.3689210821555588 and b is -78.84509299735029\n",
      "Iteration 1614, the loss is 103.65593681121202, parameters k is -0.362636447768207 and b is -78.84409299735029\n",
      "Iteration 1615, the loss is 103.61544018182963, parameters k is -0.35635181338085525 and b is -78.84309299735028\n",
      "Iteration 1616, the loss is 103.57494355244675, parameters k is -0.3500671789935035 and b is -78.84209299735028\n",
      "Iteration 1617, the loss is 103.53444692306407, parameters k is -0.3437825446061517 and b is -78.84109299735027\n",
      "Iteration 1618, the loss is 103.49395029368138, parameters k is -0.33749791021879993 and b is -78.84009299735027\n",
      "Iteration 1619, the loss is 103.45345366429878, parameters k is -0.33121327583144816 and b is -78.83909299735026\n",
      "Iteration 1620, the loss is 103.41295703491593, parameters k is -0.3249286414440964 and b is -78.83809299735026\n",
      "Iteration 1621, the loss is 103.37246040553326, parameters k is -0.3186440070567446 and b is -78.83709299735025\n",
      "Iteration 1622, the loss is 103.33196377615057, parameters k is -0.31235937266939284 and b is -78.83609299735025\n",
      "Iteration 1623, the loss is 103.29146714676793, parameters k is -0.30607473828204107 and b is -78.83509299735024\n",
      "Iteration 1624, the loss is 103.25097051738517, parameters k is -0.2997901038946893 and b is -78.83409299735024\n",
      "Iteration 1625, the loss is 103.2104738880025, parameters k is -0.2935054695073375 and b is -78.83309299735024\n",
      "Iteration 1626, the loss is 103.16997725861988, parameters k is -0.28722083511998575 and b is -78.83209299735023\n",
      "Iteration 1627, the loss is 103.12948062923721, parameters k is -0.280936200732634 and b is -78.83109299735023\n",
      "Iteration 1628, the loss is 103.08898399985449, parameters k is -0.2746515663452822 and b is -78.83009299735022\n",
      "Iteration 1629, the loss is 103.04848737047182, parameters k is -0.26836693195793043 and b is -78.82909299735022\n",
      "Iteration 1630, the loss is 103.00799074108907, parameters k is -0.26208229757057866 and b is -78.82809299735021\n",
      "Iteration 1631, the loss is 102.96749411170633, parameters k is -0.2557976631832269 and b is -78.8270929973502\n",
      "Iteration 1632, the loss is 102.92699748232369, parameters k is -0.2495130287958751 and b is -78.8260929973502\n",
      "Iteration 1633, the loss is 102.88650085294091, parameters k is -0.24322839440852334 and b is -78.8250929973502\n",
      "Iteration 1634, the loss is 102.84600422355835, parameters k is -0.23694376002117157 and b is -78.82409299735019\n",
      "Iteration 1635, the loss is 102.80550759417572, parameters k is -0.2306591256338198 and b is -78.82309299735019\n",
      "Iteration 1636, the loss is 102.76501096479306, parameters k is -0.22437449124646802 and b is -78.82209299735018\n",
      "Iteration 1637, the loss is 102.7245143354102, parameters k is -0.21808985685911625 and b is -78.82109299735018\n",
      "Iteration 1638, the loss is 102.68401770602757, parameters k is -0.21180522247176448 and b is -78.82009299735017\n",
      "Iteration 1639, the loss is 102.64352107664494, parameters k is -0.2055205880844127 and b is -78.81909299735017\n",
      "Iteration 1640, the loss is 102.60302444726226, parameters k is -0.19923595369706093 and b is -78.81809299735016\n",
      "Iteration 1641, the loss is 102.56252781787963, parameters k is -0.19295131930970916 and b is -78.81709299735016\n",
      "Iteration 1642, the loss is 102.52203118849685, parameters k is -0.18666668492235738 and b is -78.81609299735015\n",
      "Iteration 1643, the loss is 102.48153455911425, parameters k is -0.1803820505350056 and b is -78.81509299735015\n",
      "Iteration 1644, the loss is 102.44103792973144, parameters k is -0.17409741614765384 and b is -78.81409299735014\n",
      "Iteration 1645, the loss is 102.40054130034866, parameters k is -0.16781278176030207 and b is -78.81309299735014\n",
      "Iteration 1646, the loss is 102.36004467096613, parameters k is -0.1615281473729503 and b is -78.81209299735013\n",
      "Iteration 1647, the loss is 102.31954804158343, parameters k is -0.15524351298559852 and b is -78.81109299735013\n",
      "Iteration 1648, the loss is 102.27905141220074, parameters k is -0.14895887859824675 and b is -78.81009299735013\n",
      "Iteration 1649, the loss is 102.238554782818, parameters k is -0.14267424421089497 and b is -78.80909299735012\n",
      "Iteration 1650, the loss is 102.19805815343527, parameters k is -0.1363896098235432 and b is -78.80809299735012\n",
      "Iteration 1651, the loss is 102.1575615240526, parameters k is -0.13010497543619143 and b is -78.80709299735011\n",
      "Iteration 1652, the loss is 102.1170648946699, parameters k is -0.12382034104883964 and b is -78.8060929973501\n",
      "Iteration 1653, the loss is 102.07656826528735, parameters k is -0.11753570666148785 and b is -78.8050929973501\n",
      "Iteration 1654, the loss is 102.03607163590462, parameters k is -0.11125107227413607 and b is -78.8040929973501\n",
      "Iteration 1655, the loss is 101.99557500652193, parameters k is -0.10496643788678428 and b is -78.80309299735009\n",
      "Iteration 1656, the loss is 101.9550783771391, parameters k is -0.0986818034994325 and b is -78.80209299735009\n",
      "Iteration 1657, the loss is 101.91458174775651, parameters k is -0.09239716911208071 and b is -78.80109299735008\n",
      "Iteration 1658, the loss is 101.87408511837391, parameters k is -0.08611253472472892 and b is -78.80009299735008\n",
      "Iteration 1659, the loss is 101.83358848899113, parameters k is -0.07982790033737713 and b is -78.79909299735007\n",
      "Iteration 1660, the loss is 101.79309185960828, parameters k is -0.07354326595002535 and b is -78.79809299735007\n",
      "Iteration 1661, the loss is 101.7525952302257, parameters k is -0.06725863156267356 and b is -78.79709299735006\n",
      "Iteration 1662, the loss is 101.7120986008431, parameters k is -0.06097399717532177 and b is -78.79609299735006\n",
      "Iteration 1663, the loss is 101.67160197146038, parameters k is -0.054689362787969986 and b is -78.79509299735005\n",
      "Iteration 1664, the loss is 101.63110534207762, parameters k is -0.0484047284006182 and b is -78.79409299735005\n",
      "Iteration 1665, the loss is 101.590608712695, parameters k is -0.04212009401326641 and b is -78.79309299735004\n",
      "Iteration 1666, the loss is 101.55011208331236, parameters k is -0.035835459625914626 and b is -78.79209299735004\n",
      "Iteration 1667, the loss is 101.50961545392968, parameters k is -0.02955082523856284 and b is -78.79109299735003\n",
      "Iteration 1668, the loss is 101.4691188245469, parameters k is -0.023266190851211052 and b is -78.79009299735003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1669, the loss is 101.42862219516414, parameters k is -0.016981556463859265 and b is -78.78909299735002\n",
      "Iteration 1670, the loss is 101.38812556578158, parameters k is -0.010696922076507479 and b is -78.78809299735002\n",
      "Iteration 1671, the loss is 101.34762893639893, parameters k is -0.004412287689155692 and b is -78.78709299735002\n",
      "Iteration 1672, the loss is 101.30713230701612, parameters k is 0.0018723466981960951 and b is -78.78609299735001\n",
      "Iteration 1673, the loss is 101.26663567763343, parameters k is 0.008156981085547882 and b is -78.78509299735\n",
      "Iteration 1674, the loss is 101.22613904825077, parameters k is 0.014441615472899669 and b is -78.78409299735\n",
      "Iteration 1675, the loss is 101.185642418868, parameters k is 0.020726249860251456 and b is -78.78309299735\n",
      "Iteration 1676, the loss is 101.14514578948537, parameters k is 0.027010884247603242 and b is -78.78209299734999\n",
      "Iteration 1677, the loss is 101.10464916010257, parameters k is 0.03329551863495503 and b is -78.78109299734999\n",
      "Iteration 1678, the loss is 101.06415253072, parameters k is 0.039580153022306816 and b is -78.78009299734998\n",
      "Iteration 1679, the loss is 101.02365590133732, parameters k is 0.0458647874096586 and b is -78.77909299734998\n",
      "Iteration 1680, the loss is 100.98315927195463, parameters k is 0.05214942179701039 and b is -78.77809299734997\n",
      "Iteration 1681, the loss is 100.94266264257207, parameters k is 0.058434056184362176 and b is -78.77709299734997\n",
      "Iteration 1682, the loss is 100.90216601318926, parameters k is 0.06471869057171396 and b is -78.77609299734996\n",
      "Iteration 1683, the loss is 100.86166938380651, parameters k is 0.07100332495906575 and b is -78.77509299734996\n",
      "Iteration 1684, the loss is 100.82117275442388, parameters k is 0.07728795934641754 and b is -78.77409299734995\n",
      "Iteration 1685, the loss is 100.78067612504115, parameters k is 0.08357259373376932 and b is -78.77309299734995\n",
      "Iteration 1686, the loss is 100.74017949565855, parameters k is 0.08985722812112111 and b is -78.77209299734994\n",
      "Iteration 1687, the loss is 100.69968286627588, parameters k is 0.0961418625084729 and b is -78.77109299734994\n",
      "Iteration 1688, the loss is 100.65918623689308, parameters k is 0.10242649689582468 and b is -78.77009299734993\n",
      "Iteration 1689, the loss is 100.61868960751046, parameters k is 0.10871113128317647 and b is -78.76909299734993\n",
      "Iteration 1690, the loss is 100.57819297812765, parameters k is 0.11499576567052826 and b is -78.76809299734992\n",
      "Iteration 1691, the loss is 100.53769634874504, parameters k is 0.12128040005788004 and b is -78.76709299734992\n",
      "Iteration 1692, the loss is 100.49719971936241, parameters k is 0.12756503444523182 and b is -78.76609299734992\n",
      "Iteration 1693, the loss is 100.4567030899798, parameters k is 0.1338496688325836 and b is -78.76509299734991\n",
      "Iteration 1694, the loss is 100.41620646059688, parameters k is 0.14013430321993536 and b is -78.7640929973499\n",
      "Iteration 1695, the loss is 100.37570983121442, parameters k is 0.14641893760728714 and b is -78.7630929973499\n",
      "Iteration 1696, the loss is 100.33521320183168, parameters k is 0.1527035719946389 and b is -78.7620929973499\n",
      "Iteration 1697, the loss is 100.29471657244893, parameters k is 0.15898820638199068 and b is -78.76109299734989\n",
      "Iteration 1698, the loss is 100.25421994306627, parameters k is 0.16527284076934246 and b is -78.76009299734989\n",
      "Iteration 1699, the loss is 100.21372331368342, parameters k is 0.17155747515669423 and b is -78.75909299734988\n",
      "Iteration 1700, the loss is 100.1732266843008, parameters k is 0.177842109544046 and b is -78.75809299734988\n",
      "Iteration 1701, the loss is 100.13273005491823, parameters k is 0.18412674393139777 and b is -78.75709299734987\n",
      "Iteration 1702, the loss is 100.0922334255355, parameters k is 0.19041137831874955 and b is -78.75609299734987\n",
      "Iteration 1703, the loss is 100.05173679615287, parameters k is 0.19669601270610132 and b is -78.75509299734986\n",
      "Iteration 1704, the loss is 100.01124016677016, parameters k is 0.2029806470934531 and b is -78.75409299734986\n",
      "Iteration 1705, the loss is 99.97074353738749, parameters k is 0.20926528148080487 and b is -78.75309299734985\n",
      "Iteration 1706, the loss is 99.93024690800466, parameters k is 0.21554991586815664 and b is -78.75209299734985\n",
      "Iteration 1707, the loss is 99.88975027862202, parameters k is 0.2218345502555084 and b is -78.75109299734984\n",
      "Iteration 1708, the loss is 99.84925364923936, parameters k is 0.22811918464286018 and b is -78.75009299734984\n",
      "Iteration 1709, the loss is 99.80875701985663, parameters k is 0.23440381903021196 and b is -78.74909299734983\n",
      "Iteration 1710, the loss is 99.76826039047403, parameters k is 0.24068845341756373 and b is -78.74809299734983\n",
      "Iteration 1711, the loss is 99.72776376109123, parameters k is 0.2469730878049155 and b is -78.74709299734982\n",
      "Iteration 1712, the loss is 99.68726713170851, parameters k is 0.2532577221922673 and b is -78.74609299734982\n",
      "Iteration 1713, the loss is 99.64677050232586, parameters k is 0.25954235657961905 and b is -78.74509299734981\n",
      "Iteration 1714, the loss is 99.60627387294325, parameters k is 0.2658269909669708 and b is -78.74409299734981\n",
      "Iteration 1715, the loss is 99.56577724356058, parameters k is 0.2721116253543226 and b is -78.7430929973498\n",
      "Iteration 1716, the loss is 99.52528061417779, parameters k is 0.27839625974167437 and b is -78.7420929973498\n",
      "Iteration 1717, the loss is 99.48478398479511, parameters k is 0.28468089412902614 and b is -78.7410929973498\n",
      "Iteration 1718, the loss is 99.44428735541238, parameters k is 0.2909655285163779 and b is -78.74009299734979\n",
      "Iteration 1719, the loss is 99.4037907260296, parameters k is 0.2972501629037297 and b is -78.73909299734979\n",
      "Iteration 1720, the loss is 99.36329409664708, parameters k is 0.30353479729108146 and b is -78.73809299734978\n",
      "Iteration 1721, the loss is 99.3227974672643, parameters k is 0.30981943167843323 and b is -78.73709299734978\n",
      "Iteration 1722, the loss is 99.28230083788175, parameters k is 0.316104066065785 and b is -78.73609299734977\n",
      "Iteration 1723, the loss is 99.24180420849902, parameters k is 0.3223887004531368 and b is -78.73509299734977\n",
      "Iteration 1724, the loss is 99.20130757911629, parameters k is 0.32867333484048855 and b is -78.73409299734976\n",
      "Iteration 1725, the loss is 99.16081094973369, parameters k is 0.3349579692278403 and b is -78.73309299734976\n",
      "Iteration 1726, the loss is 99.120314320351, parameters k is 0.3412426036151921 and b is -78.73209299734975\n",
      "Iteration 1727, the loss is 99.07981769096821, parameters k is 0.34752723800254387 and b is -78.73109299734975\n",
      "Iteration 1728, the loss is 99.03932106158547, parameters k is 0.35381187238989564 and b is -78.73009299734974\n",
      "Iteration 1729, the loss is 98.99882443220294, parameters k is 0.3600965067772474 and b is -78.72909299734974\n",
      "Iteration 1730, the loss is 98.95832780282005, parameters k is 0.3663811411645992 and b is -78.72809299734973\n",
      "Iteration 1731, the loss is 98.91783117343753, parameters k is 0.37266577555195096 and b is -78.72709299734973\n",
      "Iteration 1732, the loss is 98.8773345440547, parameters k is 0.37895040993930273 and b is -78.72609299734972\n",
      "Iteration 1733, the loss is 98.83683791467212, parameters k is 0.3852350443266545 and b is -78.72509299734972\n",
      "Iteration 1734, the loss is 98.79634128528943, parameters k is 0.3915196787140063 and b is -78.72409299734971\n",
      "Iteration 1735, the loss is 98.75584465590664, parameters k is 0.39780431310135805 and b is -78.72309299734971\n",
      "Iteration 1736, the loss is 98.71534802652411, parameters k is 0.4040889474887098 and b is -78.7220929973497\n",
      "Iteration 1737, the loss is 98.67485139714135, parameters k is 0.4103735818760616 and b is -78.7210929973497\n",
      "Iteration 1738, the loss is 98.63435476775867, parameters k is 0.4166582162634134 and b is -78.7200929973497\n",
      "Iteration 1739, the loss is 98.59385813837598, parameters k is 0.42294285065076515 and b is -78.71909299734969\n",
      "Iteration 1740, the loss is 98.55336150899336, parameters k is 0.4292274850381169 and b is -78.71809299734969\n",
      "Iteration 1741, the loss is 98.51286487961059, parameters k is 0.4355121194254687 and b is -78.71709299734968\n",
      "Iteration 1742, the loss is 98.47236825022794, parameters k is 0.44179675381282046 and b is -78.71609299734968\n",
      "Iteration 1743, the loss is 98.43187162084523, parameters k is 0.44808138820017224 and b is -78.71509299734967\n",
      "Iteration 1744, the loss is 98.39137499146254, parameters k is 0.454366022587524 and b is -78.71409299734967\n",
      "Iteration 1745, the loss is 98.3508783620798, parameters k is 0.4606506569748758 and b is -78.71309299734966\n",
      "Iteration 1746, the loss is 98.31038173269711, parameters k is 0.46693529136222756 and b is -78.71209299734966\n",
      "Iteration 1747, the loss is 98.2698851033144, parameters k is 0.47321992574957933 and b is -78.71109299734965\n",
      "Iteration 1748, the loss is 98.22938847393175, parameters k is 0.4795045601369311 and b is -78.71009299734965\n",
      "Iteration 1749, the loss is 98.18889184454905, parameters k is 0.4857891945242829 and b is -78.70909299734964\n",
      "Iteration 1750, the loss is 98.14839521516637, parameters k is 0.49207382891163465 and b is -78.70809299734964\n",
      "Iteration 1751, the loss is 98.10789858578366, parameters k is 0.4983584632989864 and b is -78.70709299734963\n",
      "Iteration 1752, the loss is 98.06740195640103, parameters k is 0.5046430976863382 and b is -78.70609299734963\n",
      "Iteration 1753, the loss is 98.0269053270184, parameters k is 0.51092773207369 and b is -78.70509299734962\n",
      "Iteration 1754, the loss is 97.98640869763564, parameters k is 0.5172123664610419 and b is -78.70409299734962\n",
      "Iteration 1755, the loss is 97.94591206825281, parameters k is 0.5234970008483937 and b is -78.70309299734961\n",
      "Iteration 1756, the loss is 97.90541543887032, parameters k is 0.5297816352357455 and b is -78.70209299734961\n",
      "Iteration 1757, the loss is 97.86491880948756, parameters k is 0.5360662696230973 and b is -78.7010929973496\n",
      "Iteration 1758, the loss is 97.82442218010488, parameters k is 0.5423509040104492 and b is -78.7000929973496\n",
      "Iteration 1759, the loss is 97.78392555072215, parameters k is 0.548635538397801 and b is -78.6990929973496\n",
      "Iteration 1760, the loss is 97.74342892133953, parameters k is 0.5549201727851528 and b is -78.69809299734959\n",
      "Iteration 1761, the loss is 97.7029322919569, parameters k is 0.5612048071725046 and b is -78.69709299734959\n",
      "Iteration 1762, the loss is 97.66243566257408, parameters k is 0.5674894415598565 and b is -78.69609299734958\n",
      "Iteration 1763, the loss is 97.62193903319138, parameters k is 0.5737740759472083 and b is -78.69509299734958\n",
      "Iteration 1764, the loss is 97.5814424038087, parameters k is 0.5800587103345601 and b is -78.69409299734957\n",
      "Iteration 1765, the loss is 97.540945774426, parameters k is 0.586343344721912 and b is -78.69309299734957\n",
      "Iteration 1766, the loss is 97.50044914504338, parameters k is 0.5926279791092638 and b is -78.69209299734956\n",
      "Iteration 1767, the loss is 97.4599525156606, parameters k is 0.5989126134966156 and b is -78.69109299734956\n",
      "Iteration 1768, the loss is 97.41945588627803, parameters k is 0.6051972478839674 and b is -78.69009299734955\n",
      "Iteration 1769, the loss is 97.37895925689527, parameters k is 0.6114818822713193 and b is -78.68909299734955\n",
      "Iteration 1770, the loss is 97.33846262751263, parameters k is 0.6177665166586711 and b is -78.68809299734954\n",
      "Iteration 1771, the loss is 97.29796599812992, parameters k is 0.6240511510460229 and b is -78.68709299734954\n",
      "Iteration 1772, the loss is 97.25746936874724, parameters k is 0.6303357854333748 and b is -78.68609299734953\n",
      "Iteration 1773, the loss is 97.2169727393645, parameters k is 0.6366204198207266 and b is -78.68509299734953\n",
      "Iteration 1774, the loss is 97.17647610998183, parameters k is 0.6429050542080784 and b is -78.68409299734952\n",
      "Iteration 1775, the loss is 97.13597948059918, parameters k is 0.6491896885954302 and b is -78.68309299734952\n",
      "Iteration 1776, the loss is 97.09548285121649, parameters k is 0.6554743229827821 and b is -78.68209299734951\n",
      "Iteration 1777, the loss is 97.05498622183364, parameters k is 0.6617589573701339 and b is -78.68109299734951\n",
      "Iteration 1778, the loss is 97.01448959245114, parameters k is 0.6680435917574857 and b is -78.6800929973495\n",
      "Iteration 1779, the loss is 96.97399296306837, parameters k is 0.6743282261448376 and b is -78.6790929973495\n",
      "Iteration 1780, the loss is 96.93349633368581, parameters k is 0.6806128605321894 and b is -78.6780929973495\n",
      "Iteration 1781, the loss is 96.89299970430301, parameters k is 0.6868974949195412 and b is -78.67709299734949\n",
      "Iteration 1782, the loss is 96.85250307492022, parameters k is 0.693182129306893 and b is -78.67609299734949\n",
      "Iteration 1783, the loss is 96.8120064455377, parameters k is 0.6994667636942449 and b is -78.67509299734948\n",
      "Iteration 1784, the loss is 96.7715098161549, parameters k is 0.7057513980815967 and b is -78.67409299734948\n",
      "Iteration 1785, the loss is 96.73101318677227, parameters k is 0.7120360324689485 and b is -78.67309299734947\n",
      "Iteration 1786, the loss is 96.69051655738951, parameters k is 0.7183206668563004 and b is -78.67209299734947\n",
      "Iteration 1787, the loss is 96.65001992800686, parameters k is 0.7246053012436522 and b is -78.67109299734946\n",
      "Iteration 1788, the loss is 96.60952329862424, parameters k is 0.730889935631004 and b is -78.67009299734946\n",
      "Iteration 1789, the loss is 96.56902666924148, parameters k is 0.7371745700183558 and b is -78.66909299734945\n",
      "Iteration 1790, the loss is 96.52853003985885, parameters k is 0.7434592044057077 and b is -78.66809299734945\n",
      "Iteration 1791, the loss is 96.48803341047605, parameters k is 0.7497438387930595 and b is -78.66709299734944\n",
      "Iteration 1792, the loss is 96.44753678109349, parameters k is 0.7560284731804113 and b is -78.66609299734944\n",
      "Iteration 1793, the loss is 96.40704015171072, parameters k is 0.7623131075677632 and b is -78.66509299734943\n",
      "Iteration 1794, the loss is 96.36654352232802, parameters k is 0.768597741955115 and b is -78.66409299734943\n",
      "Iteration 1795, the loss is 96.32604689294534, parameters k is 0.7748823763424668 and b is -78.66309299734942\n",
      "Iteration 1796, the loss is 96.28555026356264, parameters k is 0.7811670107298186 and b is -78.66209299734942\n",
      "Iteration 1797, the loss is 96.24505363418004, parameters k is 0.7874516451171705 and b is -78.66109299734941\n",
      "Iteration 1798, the loss is 96.20455700479725, parameters k is 0.7937362795045223 and b is -78.66009299734941\n",
      "Iteration 1799, the loss is 96.16406037541455, parameters k is 0.8000209138918741 and b is -78.6590929973494\n",
      "Iteration 1800, the loss is 96.12356374603195, parameters k is 0.806305548279226 and b is -78.6580929973494\n",
      "Iteration 1801, the loss is 96.08306711664913, parameters k is 0.8125901826665778 and b is -78.6570929973494\n",
      "Iteration 1802, the loss is 96.04257048726653, parameters k is 0.8188748170539296 and b is -78.65609299734939\n",
      "Iteration 1803, the loss is 96.00207385788391, parameters k is 0.8251594514412814 and b is -78.65509299734939\n",
      "Iteration 1804, the loss is 95.96157722850108, parameters k is 0.8314440858286333 and b is -78.65409299734938\n",
      "Iteration 1805, the loss is 95.92108059911837, parameters k is 0.8377287202159851 and b is -78.65309299734938\n",
      "Iteration 1806, the loss is 95.8805839697358, parameters k is 0.8440133546033369 and b is -78.65209299734937\n",
      "Iteration 1807, the loss is 95.84008734035308, parameters k is 0.8502979889906888 and b is -78.65109299734937\n",
      "Iteration 1808, the loss is 95.79959071097046, parameters k is 0.8565826233780406 and b is -78.65009299734936\n",
      "Iteration 1809, the loss is 95.75909408158769, parameters k is 0.8628672577653924 and b is -78.64909299734936\n",
      "Iteration 1810, the loss is 95.71859745220493, parameters k is 0.8691518921527442 and b is -78.64809299734935\n",
      "Iteration 1811, the loss is 95.67810082282236, parameters k is 0.8754365265400961 and b is -78.64709299734935\n",
      "Iteration 1812, the loss is 95.63760419343964, parameters k is 0.8817211609274479 and b is -78.64609299734934\n",
      "Iteration 1813, the loss is 95.59710756405701, parameters k is 0.8880057953147997 and b is -78.64509299734934\n",
      "Iteration 1814, the loss is 95.5566109346743, parameters k is 0.8942904297021516 and b is -78.64409299734933\n",
      "Iteration 1815, the loss is 95.5161143052917, parameters k is 0.9005750640895034 and b is -78.64309299734933\n",
      "Iteration 1816, the loss is 95.47561767590888, parameters k is 0.9068596984768552 and b is -78.64209299734932\n",
      "Iteration 1817, the loss is 95.4351210465262, parameters k is 0.913144332864207 and b is -78.64109299734932\n",
      "Iteration 1818, the loss is 95.3946244171435, parameters k is 0.9194289672515589 and b is -78.64009299734931\n",
      "Iteration 1819, the loss is 95.3541277877608, parameters k is 0.9257136016389107 and b is -78.63909299734931\n",
      "Iteration 1820, the loss is 95.31363115837821, parameters k is 0.9319982360262625 and b is -78.6380929973493\n",
      "Iteration 1821, the loss is 95.27313452899544, parameters k is 0.9382828704136144 and b is -78.6370929973493\n",
      "Iteration 1822, the loss is 95.23263789961275, parameters k is 0.9445675048009662 and b is -78.6360929973493\n",
      "Iteration 1823, the loss is 95.19214127023001, parameters k is 0.950852139188318 and b is -78.63509299734929\n",
      "Iteration 1824, the loss is 95.15164464084738, parameters k is 0.9571367735756698 and b is -78.63409299734928\n",
      "Iteration 1825, the loss is 95.11114801146458, parameters k is 0.9634214079630217 and b is -78.63309299734928\n",
      "Iteration 1826, the loss is 95.07065138208205, parameters k is 0.9697060423503735 and b is -78.63209299734928\n",
      "Iteration 1827, the loss is 95.03015475269936, parameters k is 0.9759906767377253 and b is -78.63109299734927\n",
      "Iteration 1828, the loss is 94.98965812331663, parameters k is 0.9822753111250772 and b is -78.63009299734927\n",
      "Iteration 1829, the loss is 94.94916149393384, parameters k is 0.988559945512429 and b is -78.62909299734926\n",
      "Iteration 1830, the loss is 94.90866486455118, parameters k is 0.9948445798997808 and b is -78.62809299734926\n",
      "Iteration 1831, the loss is 94.86816823516853, parameters k is 1.0011292142871326 and b is -78.62709299734925\n",
      "Iteration 1832, the loss is 94.8276716057858, parameters k is 1.0074138486744844 and b is -78.62609299734925\n",
      "Iteration 1833, the loss is 94.7871749764031, parameters k is 1.013698483061836 and b is -78.62509299734924\n",
      "Iteration 1834, the loss is 94.74667834702045, parameters k is 1.0199831174491878 and b is -78.62409299734924\n",
      "Iteration 1835, the loss is 94.70618171763775, parameters k is 1.0262677518365395 and b is -78.62309299734923\n",
      "Iteration 1836, the loss is 94.66568508825507, parameters k is 1.0325523862238912 and b is -78.62209299734923\n",
      "Iteration 1837, the loss is 94.62518845887237, parameters k is 1.038837020611243 and b is -78.62109299734922\n",
      "Iteration 1838, the loss is 94.58469182948967, parameters k is 1.0451216549985947 and b is -78.62009299734922\n",
      "Iteration 1839, the loss is 94.54419520010697, parameters k is 1.0514062893859464 and b is -78.61909299734921\n",
      "Iteration 1840, the loss is 94.50369857072437, parameters k is 1.057690923773298 and b is -78.61809299734921\n",
      "Iteration 1841, the loss is 94.46320194134164, parameters k is 1.0639755581606498 and b is -78.6170929973492\n",
      "Iteration 1842, the loss is 94.42270531195904, parameters k is 1.0702601925480015 and b is -78.6160929973492\n",
      "Iteration 1843, the loss is 94.38220868257635, parameters k is 1.0765448269353532 and b is -78.6150929973492\n",
      "Iteration 1844, the loss is 94.3417120531937, parameters k is 1.082829461322705 and b is -78.61409299734919\n",
      "Iteration 1845, the loss is 94.30121542381093, parameters k is 1.0891140957100567 and b is -78.61309299734918\n",
      "Iteration 1846, the loss is 94.26071879442813, parameters k is 1.0953987300974084 and b is -78.61209299734918\n",
      "Iteration 1847, the loss is 94.22022216504551, parameters k is 1.1016833644847601 and b is -78.61109299734917\n",
      "Iteration 1848, the loss is 94.17972553566283, parameters k is 1.1079679988721118 and b is -78.61009299734917\n",
      "Iteration 1849, the loss is 94.13922890628015, parameters k is 1.1142526332594636 and b is -78.60909299734917\n",
      "Iteration 1850, the loss is 94.09873227689738, parameters k is 1.1205372676468153 and b is -78.60809299734916\n",
      "Iteration 1851, the loss is 94.05823564751485, parameters k is 1.126821902034167 and b is -78.60709299734916\n",
      "Iteration 1852, the loss is 94.01773901813209, parameters k is 1.1331065364215187 and b is -78.60609299734915\n",
      "Iteration 1853, the loss is 93.97724238874942, parameters k is 1.1393911708088704 and b is -78.60509299734915\n",
      "Iteration 1854, the loss is 93.93674575936663, parameters k is 1.1456758051962221 and b is -78.60409299734914\n",
      "Iteration 1855, the loss is 93.896249129984, parameters k is 1.1519604395835739 and b is -78.60309299734914\n",
      "Iteration 1856, the loss is 93.85575250060138, parameters k is 1.1582450739709256 and b is -78.60209299734913\n",
      "Iteration 1857, the loss is 93.81525587121858, parameters k is 1.1645297083582773 and b is -78.60109299734913\n",
      "Iteration 1858, the loss is 93.77475924183594, parameters k is 1.170814342745629 and b is -78.60009299734912\n",
      "Iteration 1859, the loss is 93.73426261245322, parameters k is 1.1770989771329807 and b is -78.59909299734912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1860, the loss is 93.69376598307058, parameters k is 1.1833836115203324 and b is -78.59809299734911\n",
      "Iteration 1861, the loss is 93.65326935368795, parameters k is 1.1896682459076842 and b is -78.59709299734911\n",
      "Iteration 1862, the loss is 93.61277272430519, parameters k is 1.1959528802950359 and b is -78.5960929973491\n",
      "Iteration 1863, the loss is 93.57227609492254, parameters k is 1.2022375146823876 and b is -78.5950929973491\n",
      "Iteration 1864, the loss is 93.5317794655398, parameters k is 1.2085221490697393 and b is -78.5940929973491\n",
      "Iteration 1865, the loss is 93.49128283615713, parameters k is 1.214806783457091 and b is -78.59309299734909\n",
      "Iteration 1866, the loss is 93.4507862067744, parameters k is 1.2210914178444428 and b is -78.59209299734908\n",
      "Iteration 1867, the loss is 93.41028957739168, parameters k is 1.2273760522317945 and b is -78.59109299734908\n",
      "Iteration 1868, the loss is 93.36979294800896, parameters k is 1.2336606866191462 and b is -78.59009299734907\n",
      "Iteration 1869, the loss is 93.32929631862645, parameters k is 1.239945321006498 and b is -78.58909299734907\n",
      "Iteration 1870, the loss is 93.28879968924376, parameters k is 1.2462299553938496 and b is -78.58809299734907\n",
      "Iteration 1871, the loss is 93.24830305986102, parameters k is 1.2525145897812013 and b is -78.58709299734906\n",
      "Iteration 1872, the loss is 93.20780643047824, parameters k is 1.258799224168553 and b is -78.58609299734906\n",
      "Iteration 1873, the loss is 93.16730980109566, parameters k is 1.2650838585559048 and b is -78.58509299734905\n",
      "Iteration 1874, the loss is 93.12681317171294, parameters k is 1.2713684929432565 and b is -78.58409299734905\n",
      "Iteration 1875, the loss is 93.0863165423302, parameters k is 1.2776531273306082 and b is -78.58309299734904\n",
      "Iteration 1876, the loss is 93.0458199129475, parameters k is 1.28393776171796 and b is -78.58209299734904\n",
      "Iteration 1877, the loss is 93.00532328356485, parameters k is 1.2902223961053116 and b is -78.58109299734903\n",
      "Iteration 1878, the loss is 92.96482665418219, parameters k is 1.2965070304926634 and b is -78.58009299734903\n",
      "Iteration 1879, the loss is 92.9243300247995, parameters k is 1.302791664880015 and b is -78.57909299734902\n",
      "Iteration 1880, the loss is 92.88383339541686, parameters k is 1.3090762992673668 and b is -78.57809299734902\n",
      "Iteration 1881, the loss is 92.84333676603407, parameters k is 1.3153609336547185 and b is -78.57709299734901\n",
      "Iteration 1882, the loss is 92.8028401366514, parameters k is 1.3216455680420702 and b is -78.57609299734901\n",
      "Iteration 1883, the loss is 92.76234350726887, parameters k is 1.327930202429422 and b is -78.575092997349\n",
      "Iteration 1884, the loss is 92.721846877886, parameters k is 1.3342148368167737 and b is -78.574092997349\n",
      "Iteration 1885, the loss is 92.68135024850338, parameters k is 1.3404994712041254 and b is -78.573092997349\n",
      "Iteration 1886, the loss is 92.6408536191207, parameters k is 1.346784105591477 and b is -78.57209299734899\n",
      "Iteration 1887, the loss is 92.60035698973797, parameters k is 1.3530687399788288 and b is -78.57109299734898\n",
      "Iteration 1888, the loss is 92.55986036035523, parameters k is 1.3593533743661805 and b is -78.57009299734898\n",
      "Iteration 1889, the loss is 92.51936373097259, parameters k is 1.3656380087535323 and b is -78.56909299734897\n",
      "Iteration 1890, the loss is 92.47886710159005, parameters k is 1.371922643140884 and b is -78.56809299734897\n",
      "Iteration 1891, the loss is 92.43837047220728, parameters k is 1.3782072775282357 and b is -78.56709299734896\n",
      "Iteration 1892, the loss is 92.39787384282448, parameters k is 1.3844919119155874 and b is -78.56609299734896\n",
      "Iteration 1893, the loss is 92.35737721344175, parameters k is 1.3907765463029391 and b is -78.56509299734896\n",
      "Iteration 1894, the loss is 92.31688058405925, parameters k is 1.3970611806902908 and b is -78.56409299734895\n",
      "Iteration 1895, the loss is 92.27638395467639, parameters k is 1.4033458150776426 and b is -78.56309299734895\n",
      "Iteration 1896, the loss is 92.23588732529376, parameters k is 1.4096304494649943 and b is -78.56209299734894\n",
      "Iteration 1897, the loss is 92.19539069591107, parameters k is 1.415915083852346 and b is -78.56109299734894\n",
      "Iteration 1898, the loss is 92.15489406652841, parameters k is 1.4221997182396977 and b is -78.56009299734893\n",
      "Iteration 1899, the loss is 92.11439743714566, parameters k is 1.4284843526270494 and b is -78.55909299734893\n",
      "Iteration 1900, the loss is 92.07390080776317, parameters k is 1.4347689870144011 and b is -78.55809299734892\n",
      "Iteration 1901, the loss is 92.03340417838042, parameters k is 1.4410536214017529 and b is -78.55709299734892\n",
      "Iteration 1902, the loss is 91.99290754899772, parameters k is 1.4473382557891046 and b is -78.55609299734891\n",
      "Iteration 1903, the loss is 91.95241091961486, parameters k is 1.4536228901764563 and b is -78.55509299734891\n",
      "Iteration 1904, the loss is 91.91191429023215, parameters k is 1.459907524563808 and b is -78.5540929973489\n",
      "Iteration 1905, the loss is 91.87141766084954, parameters k is 1.4661921589511597 and b is -78.5530929973489\n",
      "Iteration 1906, the loss is 91.83092103146689, parameters k is 1.4724767933385114 and b is -78.5520929973489\n",
      "Iteration 1907, the loss is 91.79042440208421, parameters k is 1.4787614277258632 and b is -78.55109299734889\n",
      "Iteration 1908, the loss is 91.74992777270145, parameters k is 1.4850460621132149 and b is -78.55009299734888\n",
      "Iteration 1909, the loss is 91.70943114331871, parameters k is 1.4913306965005666 and b is -78.54909299734888\n",
      "Iteration 1910, the loss is 91.66893451393611, parameters k is 1.4976153308879183 and b is -78.54809299734887\n",
      "Iteration 1911, the loss is 91.62843788455346, parameters k is 1.50389996527527 and b is -78.54709299734887\n",
      "Iteration 1912, the loss is 91.58794125517082, parameters k is 1.5101845996626218 and b is -78.54609299734886\n",
      "Iteration 1913, the loss is 91.54744462578797, parameters k is 1.5164692340499735 and b is -78.54509299734886\n",
      "Iteration 1914, the loss is 91.50694799640544, parameters k is 1.5227538684373252 and b is -78.54409299734886\n",
      "Iteration 1915, the loss is 91.46645136702276, parameters k is 1.529038502824677 and b is -78.54309299734885\n",
      "Iteration 1916, the loss is 91.42595473764011, parameters k is 1.5353231372120286 and b is -78.54209299734885\n",
      "Iteration 1917, the loss is 91.38545810825741, parameters k is 1.5416077715993803 and b is -78.54109299734884\n",
      "Iteration 1918, the loss is 91.3449614788746, parameters k is 1.547892405986732 and b is -78.54009299734884\n",
      "Iteration 1919, the loss is 91.30446484949191, parameters k is 1.5541770403740838 and b is -78.53909299734883\n",
      "Iteration 1920, the loss is 91.26396822010926, parameters k is 1.5604616747614355 and b is -78.53809299734883\n",
      "Iteration 1921, the loss is 91.22347159072659, parameters k is 1.5667463091487872 and b is -78.53709299734882\n",
      "Iteration 1922, the loss is 91.18297496134385, parameters k is 1.573030943536139 and b is -78.53609299734882\n",
      "Iteration 1923, the loss is 91.14247833196117, parameters k is 1.5793155779234906 and b is -78.53509299734881\n",
      "Iteration 1924, the loss is 91.10198170257856, parameters k is 1.5856002123108424 and b is -78.53409299734881\n",
      "Iteration 1925, the loss is 91.06148507319575, parameters k is 1.591884846698194 and b is -78.5330929973488\n",
      "Iteration 1926, the loss is 91.02098844381312, parameters k is 1.5981694810855458 and b is -78.5320929973488\n",
      "Iteration 1927, the loss is 90.98049181443035, parameters k is 1.6044541154728975 and b is -78.5310929973488\n",
      "Iteration 1928, the loss is 90.93999518504766, parameters k is 1.6107387498602492 and b is -78.53009299734879\n",
      "Iteration 1929, the loss is 90.89949855566508, parameters k is 1.617023384247601 and b is -78.52909299734878\n",
      "Iteration 1930, the loss is 90.85900192628239, parameters k is 1.6233080186349527 and b is -78.52809299734878\n",
      "Iteration 1931, the loss is 90.81850529689966, parameters k is 1.6295926530223044 and b is -78.52709299734877\n",
      "Iteration 1932, the loss is 90.77800866751701, parameters k is 1.635877287409656 and b is -78.52609299734877\n",
      "Iteration 1933, the loss is 90.7375120381343, parameters k is 1.6421619217970078 and b is -78.52509299734876\n",
      "Iteration 1934, the loss is 90.69701540875164, parameters k is 1.6484465561843595 and b is -78.52409299734876\n",
      "Iteration 1935, the loss is 90.65651877936892, parameters k is 1.6547311905717113 and b is -78.52309299734875\n",
      "Iteration 1936, the loss is 90.61602214998616, parameters k is 1.661015824959063 and b is -78.52209299734875\n",
      "Iteration 1937, the loss is 90.5755255206036, parameters k is 1.6673004593464147 and b is -78.52109299734875\n",
      "Iteration 1938, the loss is 90.53502889122076, parameters k is 1.6735850937337664 and b is -78.52009299734874\n",
      "Iteration 1939, the loss is 90.4945322618381, parameters k is 1.6798697281211181 and b is -78.51909299734874\n",
      "Iteration 1940, the loss is 90.45403563245536, parameters k is 1.6861543625084698 and b is -78.51809299734873\n",
      "Iteration 1941, the loss is 90.4135390030728, parameters k is 1.6924389968958216 and b is -78.51709299734873\n",
      "Iteration 1942, the loss is 90.37304237369011, parameters k is 1.6987236312831733 and b is -78.51609299734872\n",
      "Iteration 1943, the loss is 90.33254574430742, parameters k is 1.705008265670525 and b is -78.51509299734872\n",
      "Iteration 1944, the loss is 90.29204911492478, parameters k is 1.7112929000578767 and b is -78.51409299734871\n",
      "Iteration 1945, the loss is 90.25155248554209, parameters k is 1.7175775344452284 and b is -78.5130929973487\n",
      "Iteration 1946, the loss is 90.21105585615936, parameters k is 1.7238621688325801 and b is -78.5120929973487\n",
      "Iteration 1947, the loss is 90.1705592267767, parameters k is 1.7301468032199319 and b is -78.5110929973487\n",
      "Iteration 1948, the loss is 90.13006259739387, parameters k is 1.7364314376072836 and b is -78.51009299734869\n",
      "Iteration 1949, the loss is 90.08956596801112, parameters k is 1.7427160719946353 and b is -78.50909299734869\n",
      "Iteration 1950, the loss is 90.04906933862848, parameters k is 1.749000706381987 and b is -78.50809299734868\n",
      "Iteration 1951, the loss is 90.00857270924583, parameters k is 1.7552853407693387 and b is -78.50709299734868\n",
      "Iteration 1952, the loss is 89.96807607986324, parameters k is 1.7615699751566904 and b is -78.50609299734867\n",
      "Iteration 1953, the loss is 89.92757945048051, parameters k is 1.7678546095440422 and b is -78.50509299734867\n",
      "Iteration 1954, the loss is 89.88708282109774, parameters k is 1.7741392439313939 and b is -78.50409299734866\n",
      "Iteration 1955, the loss is 89.84658619171518, parameters k is 1.7804238783187456 and b is -78.50309299734866\n",
      "Iteration 1956, the loss is 89.80608956233246, parameters k is 1.7867085127060973 and b is -78.50209299734865\n",
      "Iteration 1957, the loss is 89.76559293294977, parameters k is 1.792993147093449 and b is -78.50109299734865\n",
      "Iteration 1958, the loss is 89.72509630356703, parameters k is 1.7992777814808008 and b is -78.50009299734864\n",
      "Iteration 1959, the loss is 89.6845996741843, parameters k is 1.8055624158681525 and b is -78.49909299734864\n",
      "Iteration 1960, the loss is 89.64410304480181, parameters k is 1.8118470502555042 and b is -78.49809299734864\n",
      "Iteration 1961, the loss is 89.60360641541911, parameters k is 1.818131684642856 and b is -78.49709299734863\n",
      "Iteration 1962, the loss is 89.56310978603638, parameters k is 1.8244163190302076 and b is -78.49609299734863\n",
      "Iteration 1963, the loss is 89.52261315665372, parameters k is 1.8307009534175593 and b is -78.49509299734862\n",
      "Iteration 1964, the loss is 89.48211652727086, parameters k is 1.836985587804911 and b is -78.49409299734862\n",
      "Iteration 1965, the loss is 89.44161989788822, parameters k is 1.8432702221922628 and b is -78.49309299734861\n",
      "Iteration 1966, the loss is 89.40112326850546, parameters k is 1.8495548565796145 and b is -78.4920929973486\n",
      "Iteration 1967, the loss is 89.36062663912277, parameters k is 1.8558394909669662 and b is -78.4910929973486\n",
      "Iteration 1968, the loss is 89.3201300097402, parameters k is 1.862124125354318 and b is -78.4900929973486\n",
      "Iteration 1969, the loss is 89.27963338035755, parameters k is 1.8684087597416696 and b is -78.48909299734859\n",
      "Iteration 1970, the loss is 89.23913675097485, parameters k is 1.8746933941290214 and b is -78.48809299734859\n",
      "Iteration 1971, the loss is 89.19864012159213, parameters k is 1.880978028516373 and b is -78.48709299734858\n",
      "Iteration 1972, the loss is 89.15814349220936, parameters k is 1.8872626629037248 and b is -78.48609299734858\n",
      "Iteration 1973, the loss is 89.11764686282679, parameters k is 1.8935472972910765 and b is -78.48509299734857\n",
      "Iteration 1974, the loss is 89.077150233444, parameters k is 1.8998319316784282 and b is -78.48409299734857\n",
      "Iteration 1975, the loss is 89.0366536040614, parameters k is 1.90611656606578 and b is -78.48309299734856\n",
      "Iteration 1976, the loss is 88.99615697467871, parameters k is 1.9124012004531317 and b is -78.48209299734856\n",
      "Iteration 1977, the loss is 88.95566034529604, parameters k is 1.9186858348404834 and b is -78.48109299734855\n",
      "Iteration 1978, the loss is 88.91516371591334, parameters k is 1.924970469227835 and b is -78.48009299734855\n",
      "Iteration 1979, the loss is 88.87466708653056, parameters k is 1.9312551036151868 and b is -78.47909299734854\n",
      "Iteration 1980, the loss is 88.83417045714788, parameters k is 1.9375397380025385 and b is -78.47809299734854\n",
      "Iteration 1981, the loss is 88.79367382776512, parameters k is 1.9438243723898903 and b is -78.47709299734854\n",
      "Iteration 1982, the loss is 88.75317719838259, parameters k is 1.950109006777242 and b is -78.47609299734853\n",
      "Iteration 1983, the loss is 88.7126805689999, parameters k is 1.9563936411645937 and b is -78.47509299734853\n",
      "Iteration 1984, the loss is 88.67218393961709, parameters k is 1.9626782755519454 and b is -78.47409299734852\n",
      "Iteration 1985, the loss is 88.63168731023441, parameters k is 1.9689629099392971 and b is -78.47309299734852\n",
      "Iteration 1986, the loss is 88.59119068085177, parameters k is 1.9752475443266488 and b is -78.47209299734851\n",
      "Iteration 1987, the loss is 88.55069405146898, parameters k is 1.9815321787140006 and b is -78.4710929973485\n",
      "Iteration 1988, the loss is 88.51019742208638, parameters k is 1.9878168131013523 and b is -78.4700929973485\n",
      "Iteration 1989, the loss is 88.46970079270376, parameters k is 1.994101447488704 and b is -78.4690929973485\n",
      "Iteration 1990, the loss is 88.42920416332096, parameters k is 2.000386081876056 and b is -78.46809299734849\n",
      "Iteration 1991, the loss is 88.38870753393823, parameters k is 2.006670716263408 and b is -78.46709299734849\n",
      "Iteration 1992, the loss is 88.34821090455561, parameters k is 2.01295535065076 and b is -78.46609299734848\n",
      "Iteration 1993, the loss is 88.3077142751729, parameters k is 2.0192399850381118 and b is -78.46509299734848\n",
      "Iteration 1994, the loss is 88.26721764579035, parameters k is 2.0255246194254637 and b is -78.46409299734847\n",
      "Iteration 1995, the loss is 88.22672101640757, parameters k is 2.0318092538128156 and b is -78.46309299734847\n",
      "Iteration 1996, the loss is 88.18622438702486, parameters k is 2.0380938882001676 and b is -78.46209299734846\n",
      "Iteration 1997, the loss is 88.14572775764223, parameters k is 2.0443785225875195 and b is -78.46109299734846\n",
      "Iteration 1998, the loss is 88.10523112825942, parameters k is 2.0506631569748714 and b is -78.46009299734845\n",
      "Iteration 1999, the loss is 88.06473449887683, parameters k is 2.0569477913622234 and b is -78.45909299734845\n",
      "Iteration 2000, the loss is 88.0242378694942, parameters k is 2.0632324257495753 and b is -78.45809299734844\n",
      "Iteration 2001, the loss is 87.98374124011146, parameters k is 2.0695170601369273 and b is -78.45709299734844\n",
      "Iteration 2002, the loss is 87.94324461072864, parameters k is 2.075801694524279 and b is -78.45609299734843\n",
      "Iteration 2003, the loss is 87.90274798134595, parameters k is 2.082086328911631 and b is -78.45509299734843\n",
      "Iteration 2004, the loss is 87.86225135196338, parameters k is 2.088370963298983 and b is -78.45409299734843\n",
      "Iteration 2005, the loss is 87.82175472258068, parameters k is 2.094655597686335 and b is -78.45309299734842\n",
      "Iteration 2006, the loss is 87.78125809319803, parameters k is 2.100940232073687 and b is -78.45209299734842\n",
      "Iteration 2007, the loss is 87.74076146381529, parameters k is 2.107224866461039 and b is -78.45109299734841\n",
      "Iteration 2008, the loss is 87.70026483443263, parameters k is 2.113509500848391 and b is -78.4500929973484\n",
      "Iteration 2009, the loss is 87.65976820504993, parameters k is 2.119794135235743 and b is -78.4490929973484\n",
      "Iteration 2010, the loss is 87.61927157566721, parameters k is 2.1260787696230947 and b is -78.4480929973484\n",
      "Iteration 2011, the loss is 87.57877494628457, parameters k is 2.1323634040104467 and b is -78.44709299734839\n",
      "Iteration 2012, the loss is 87.53827831690195, parameters k is 2.1386480383977986 and b is -78.44609299734839\n",
      "Iteration 2013, the loss is 87.49778168751915, parameters k is 2.1449326727851505 and b is -78.44509299734838\n",
      "Iteration 2014, the loss is 87.45728505813652, parameters k is 2.1512173071725025 and b is -78.44409299734838\n",
      "Iteration 2015, the loss is 87.41678842875382, parameters k is 2.1575019415598544 and b is -78.44309299734837\n",
      "Iteration 2016, the loss is 87.37629179937109, parameters k is 2.1637865759472064 and b is -78.44209299734837\n",
      "Iteration 2017, the loss is 87.3357951699884, parameters k is 2.1700712103345583 and b is -78.44109299734836\n",
      "Iteration 2018, the loss is 87.29529854060573, parameters k is 2.1763558447219102 and b is -78.44009299734836\n",
      "Iteration 2019, the loss is 87.25480191122291, parameters k is 2.182640479109262 and b is -78.43909299734835\n",
      "Iteration 2020, the loss is 87.21430528184027, parameters k is 2.188925113496614 and b is -78.43809299734835\n",
      "Iteration 2021, the loss is 87.17380865245752, parameters k is 2.195209747883966 and b is -78.43709299734834\n",
      "Iteration 2022, the loss is 87.13331202307494, parameters k is 2.201494382271318 and b is -78.43609299734834\n",
      "Iteration 2023, the loss is 87.09281539369232, parameters k is 2.20777901665867 and b is -78.43509299734833\n",
      "Iteration 2024, the loss is 87.05231876430953, parameters k is 2.214063651046022 and b is -78.43409299734833\n",
      "Iteration 2025, the loss is 87.01182213492687, parameters k is 2.220348285433374 and b is -78.43309299734833\n",
      "Iteration 2026, the loss is 86.9713255055442, parameters k is 2.2266329198207258 and b is -78.43209299734832\n",
      "Iteration 2027, the loss is 86.93082887616153, parameters k is 2.2329175542080777 and b is -78.43109299734832\n",
      "Iteration 2028, the loss is 86.8903322467787, parameters k is 2.2392021885954296 and b is -78.43009299734831\n",
      "Iteration 2029, the loss is 86.84983561739615, parameters k is 2.2454868229827816 and b is -78.4290929973483\n",
      "Iteration 2030, the loss is 86.8093389880135, parameters k is 2.2517714573701335 and b is -78.4280929973483\n",
      "Iteration 2031, the loss is 86.76884235863056, parameters k is 2.2580560917574855 and b is -78.4270929973483\n",
      "Iteration 2032, the loss is 86.72834572924793, parameters k is 2.2643407261448374 and b is -78.42609299734829\n",
      "Iteration 2033, the loss is 86.6878490998653, parameters k is 2.2706253605321893 and b is -78.42509299734829\n",
      "Iteration 2034, the loss is 86.64735247048272, parameters k is 2.2769099949195413 and b is -78.42409299734828\n",
      "Iteration 2035, the loss is 86.60685584109999, parameters k is 2.283194629306893 and b is -78.42309299734828\n",
      "Iteration 2036, the loss is 86.56635921171736, parameters k is 2.289479263694245 and b is -78.42209299734827\n",
      "Iteration 2037, the loss is 86.52586258233461, parameters k is 2.295763898081597 and b is -78.42109299734827\n",
      "Iteration 2038, the loss is 86.48536595295188, parameters k is 2.302048532468949 and b is -78.42009299734826\n",
      "Iteration 2039, the loss is 86.44486932356918, parameters k is 2.308333166856301 and b is -78.41909299734826\n",
      "Iteration 2040, the loss is 86.40437269418646, parameters k is 2.314617801243653 and b is -78.41809299734825\n",
      "Iteration 2041, the loss is 86.3638760648038, parameters k is 2.320902435631005 and b is -78.41709299734825\n",
      "Iteration 2042, the loss is 86.32337943542117, parameters k is 2.327187070018357 and b is -78.41609299734824\n",
      "Iteration 2043, the loss is 86.2828828060384, parameters k is 2.3334717044057087 and b is -78.41509299734824\n",
      "Iteration 2044, the loss is 86.24238617665571, parameters k is 2.3397563387930607 and b is -78.41409299734823\n",
      "Iteration 2045, the loss is 86.2018895472731, parameters k is 2.3460409731804126 and b is -78.41309299734823\n",
      "Iteration 2046, the loss is 86.16139291789031, parameters k is 2.3523256075677645 and b is -78.41209299734822\n",
      "Iteration 2047, the loss is 86.12089628850774, parameters k is 2.3586102419551165 and b is -78.41109299734822\n",
      "Iteration 2048, the loss is 86.08039965912492, parameters k is 2.3648948763424684 and b is -78.41009299734822\n",
      "Iteration 2049, the loss is 86.0399030297423, parameters k is 2.3711795107298204 and b is -78.40909299734821\n",
      "Iteration 2050, the loss is 85.99940640035953, parameters k is 2.3774641451171723 and b is -78.4080929973482\n",
      "Iteration 2051, the loss is 85.95890977097693, parameters k is 2.3837487795045242 and b is -78.4070929973482\n",
      "Iteration 2052, the loss is 85.91841314159419, parameters k is 2.390033413891876 and b is -78.4060929973482\n",
      "Iteration 2053, the loss is 85.87791651221156, parameters k is 2.396318048279228 and b is -78.40509299734819\n",
      "Iteration 2054, the loss is 85.83741988282891, parameters k is 2.40260268266658 and b is -78.40409299734819\n",
      "Iteration 2055, the loss is 85.79692325344618, parameters k is 2.408887317053932 and b is -78.40309299734818\n",
      "Iteration 2056, the loss is 85.7564266240634, parameters k is 2.415171951441284 and b is -78.40209299734818\n",
      "Iteration 2057, the loss is 85.71592999468079, parameters k is 2.421456585828636 and b is -78.40109299734817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2058, the loss is 85.67543336529813, parameters k is 2.427741220215988 and b is -78.40009299734817\n",
      "Iteration 2059, the loss is 85.6349367359154, parameters k is 2.4340258546033398 and b is -78.39909299734816\n",
      "Iteration 2060, the loss is 85.59444010653269, parameters k is 2.4403104889906917 and b is -78.39809299734816\n",
      "Iteration 2061, the loss is 85.55394347714999, parameters k is 2.4465951233780436 and b is -78.39709299734815\n",
      "Iteration 2062, the loss is 85.51344684776731, parameters k is 2.4528797577653956 and b is -78.39609299734815\n",
      "Iteration 2063, the loss is 85.47295021838458, parameters k is 2.4591643921527475 and b is -78.39509299734814\n",
      "Iteration 2064, the loss is 85.4324535890019, parameters k is 2.4654490265400995 and b is -78.39409299734814\n",
      "Iteration 2065, the loss is 85.39195695961916, parameters k is 2.4717336609274514 and b is -78.39309299734813\n",
      "Iteration 2066, the loss is 85.35146033023646, parameters k is 2.4780182953148033 and b is -78.39209299734813\n",
      "Iteration 2067, the loss is 85.31096370085389, parameters k is 2.4843029297021553 and b is -78.39109299734812\n",
      "Iteration 2068, the loss is 85.27046707147119, parameters k is 2.490587564089507 and b is -78.39009299734812\n",
      "Iteration 2069, the loss is 85.22997044208857, parameters k is 2.496872198476859 and b is -78.38909299734811\n",
      "Iteration 2070, the loss is 85.18947381270578, parameters k is 2.503156832864211 and b is -78.38809299734811\n",
      "Iteration 2071, the loss is 85.14897718332314, parameters k is 2.509441467251563 and b is -78.3870929973481\n",
      "Iteration 2072, the loss is 85.1084805539404, parameters k is 2.515726101638915 and b is -78.3860929973481\n",
      "Iteration 2073, the loss is 85.06798392455775, parameters k is 2.522010736026267 and b is -78.3850929973481\n",
      "Iteration 2074, the loss is 85.02748729517506, parameters k is 2.528295370413619 and b is -78.38409299734809\n",
      "Iteration 2075, the loss is 84.98699066579243, parameters k is 2.534580004800971 and b is -78.38309299734809\n",
      "Iteration 2076, the loss is 84.9464940364097, parameters k is 2.5408646391883227 and b is -78.38209299734808\n",
      "Iteration 2077, the loss is 84.90599740702696, parameters k is 2.5471492735756747 and b is -78.38109299734808\n",
      "Iteration 2078, the loss is 84.86550077764433, parameters k is 2.5534339079630266 and b is -78.38009299734807\n",
      "Iteration 2079, the loss is 84.82500414826164, parameters k is 2.5597185423503785 and b is -78.37909299734807\n",
      "Iteration 2080, the loss is 84.78450751887893, parameters k is 2.5660031767377305 and b is -78.37809299734806\n",
      "Iteration 2081, the loss is 84.74401088949618, parameters k is 2.5722878111250824 and b is -78.37709299734806\n",
      "Iteration 2082, the loss is 84.70351426011358, parameters k is 2.5785724455124344 and b is -78.37609299734805\n",
      "Iteration 2083, the loss is 84.66301763073083, parameters k is 2.5848570798997863 and b is -78.37509299734805\n",
      "Iteration 2084, the loss is 84.62252100134826, parameters k is 2.5911417142871382 and b is -78.37409299734804\n",
      "Iteration 2085, the loss is 84.5820243719655, parameters k is 2.59742634867449 and b is -78.37309299734804\n",
      "Iteration 2086, the loss is 84.54152774258279, parameters k is 2.603710983061842 and b is -78.37209299734803\n",
      "Iteration 2087, the loss is 84.50103111320009, parameters k is 2.609995617449194 and b is -78.37109299734803\n",
      "Iteration 2088, the loss is 84.46053448381736, parameters k is 2.616280251836546 and b is -78.37009299734802\n",
      "Iteration 2089, the loss is 84.42003785443478, parameters k is 2.622564886223898 and b is -78.36909299734802\n",
      "Iteration 2090, the loss is 84.37954122505197, parameters k is 2.62884952061125 and b is -78.36809299734801\n",
      "Iteration 2091, the loss is 84.33904459566921, parameters k is 2.635134154998602 and b is -78.36709299734801\n",
      "Iteration 2092, the loss is 84.29854796628656, parameters k is 2.6414187893859538 and b is -78.366092997348\n",
      "Iteration 2093, the loss is 84.25805133690389, parameters k is 2.6477034237733057 and b is -78.365092997348\n",
      "Iteration 2094, the loss is 84.21755470752124, parameters k is 2.6539880581606576 and b is -78.364092997348\n",
      "Iteration 2095, the loss is 84.17705807813864, parameters k is 2.6602726925480096 and b is -78.36309299734799\n",
      "Iteration 2096, the loss is 84.13656144875588, parameters k is 2.6665573269353615 and b is -78.36209299734799\n",
      "Iteration 2097, the loss is 84.09606481937318, parameters k is 2.6728419613227135 and b is -78.36109299734798\n",
      "Iteration 2098, the loss is 84.05556818999052, parameters k is 2.6791265957100654 and b is -78.36009299734798\n",
      "Iteration 2099, the loss is 84.01507156060778, parameters k is 2.6854112300974173 and b is -78.35909299734797\n",
      "Iteration 2100, the loss is 83.97457493122504, parameters k is 2.6916958644847693 and b is -78.35809299734797\n",
      "Iteration 2101, the loss is 83.9340783018423, parameters k is 2.697980498872121 and b is -78.35709299734796\n",
      "Iteration 2102, the loss is 83.89358167245969, parameters k is 2.704265133259473 and b is -78.35609299734796\n",
      "Iteration 2103, the loss is 83.85308504307703, parameters k is 2.710549767646825 and b is -78.35509299734795\n",
      "Iteration 2104, the loss is 83.81258841369436, parameters k is 2.716834402034177 and b is -78.35409299734795\n",
      "Iteration 2105, the loss is 83.77209178431153, parameters k is 2.723119036421529 and b is -78.35309299734794\n",
      "Iteration 2106, the loss is 83.7315951549289, parameters k is 2.729403670808881 and b is -78.35209299734794\n",
      "Iteration 2107, the loss is 83.69109852554621, parameters k is 2.735688305196233 and b is -78.35109299734793\n",
      "Iteration 2108, the loss is 83.65060189616358, parameters k is 2.741972939583585 and b is -78.35009299734793\n",
      "Iteration 2109, the loss is 83.6101052667809, parameters k is 2.7482575739709367 and b is -78.34909299734792\n",
      "Iteration 2110, the loss is 83.56960863739808, parameters k is 2.7545422083582887 and b is -78.34809299734792\n",
      "Iteration 2111, the loss is 83.52911200801553, parameters k is 2.7608268427456406 and b is -78.34709299734791\n",
      "Iteration 2112, the loss is 83.48861537863287, parameters k is 2.7671114771329925 and b is -78.34609299734791\n",
      "Iteration 2113, the loss is 83.4481187492501, parameters k is 2.7733961115203445 and b is -78.3450929973479\n",
      "Iteration 2114, the loss is 83.4076221198674, parameters k is 2.7796807459076964 and b is -78.3440929973479\n",
      "Iteration 2115, the loss is 83.36712549048491, parameters k is 2.7859653802950484 and b is -78.3430929973479\n",
      "Iteration 2116, the loss is 83.32662886110214, parameters k is 2.7922500146824003 and b is -78.34209299734789\n",
      "Iteration 2117, the loss is 83.28613223171938, parameters k is 2.7985346490697522 and b is -78.34109299734789\n",
      "Iteration 2118, the loss is 83.24563560233668, parameters k is 2.804819283457104 and b is -78.34009299734788\n",
      "Iteration 2119, the loss is 83.20513897295396, parameters k is 2.811103917844456 and b is -78.33909299734788\n",
      "Iteration 2120, the loss is 83.16464234357129, parameters k is 2.817388552231808 and b is -78.33809299734787\n",
      "Iteration 2121, the loss is 83.12414571418856, parameters k is 2.82367318661916 and b is -78.33709299734787\n",
      "Iteration 2122, the loss is 83.083649084806, parameters k is 2.829957821006512 and b is -78.33609299734786\n",
      "Iteration 2123, the loss is 83.04315245542321, parameters k is 2.836242455393864 and b is -78.33509299734786\n",
      "Iteration 2124, the loss is 83.0026558260406, parameters k is 2.842527089781216 and b is -78.33409299734785\n",
      "Iteration 2125, the loss is 82.96215919665775, parameters k is 2.8488117241685678 and b is -78.33309299734785\n",
      "Iteration 2126, the loss is 82.92166256727508, parameters k is 2.8550963585559197 and b is -78.33209299734784\n",
      "Iteration 2127, the loss is 82.88116593789242, parameters k is 2.8613809929432716 and b is -78.33109299734784\n",
      "Iteration 2128, the loss is 82.84066930850973, parameters k is 2.8676656273306236 and b is -78.33009299734783\n",
      "Iteration 2129, the loss is 82.80017267912703, parameters k is 2.8739502617179755 and b is -78.32909299734783\n",
      "Iteration 2130, the loss is 82.75967604974439, parameters k is 2.8802348961053275 and b is -78.32809299734782\n",
      "Iteration 2131, the loss is 82.71917942036173, parameters k is 2.8865195304926794 and b is -78.32709299734782\n",
      "Iteration 2132, the loss is 82.67868279097902, parameters k is 2.8928041648800313 and b is -78.32609299734781\n",
      "Iteration 2133, the loss is 82.6381861615963, parameters k is 2.8990887992673833 and b is -78.32509299734781\n",
      "Iteration 2134, the loss is 82.59768953221364, parameters k is 2.905373433654735 and b is -78.3240929973478\n",
      "Iteration 2135, the loss is 82.55719290283088, parameters k is 2.911658068042087 and b is -78.3230929973478\n",
      "Iteration 2136, the loss is 82.51669627344823, parameters k is 2.917942702429439 and b is -78.3220929973478\n",
      "Iteration 2137, the loss is 82.47619964406549, parameters k is 2.924227336816791 and b is -78.32109299734779\n",
      "Iteration 2138, the loss is 82.43570301468283, parameters k is 2.930511971204143 and b is -78.32009299734779\n",
      "Iteration 2139, the loss is 82.39520638530013, parameters k is 2.936796605591495 and b is -78.31909299734778\n",
      "Iteration 2140, the loss is 82.35470975591747, parameters k is 2.943081239978847 and b is -78.31809299734778\n",
      "Iteration 2141, the loss is 82.31421312653478, parameters k is 2.949365874366199 and b is -78.31709299734777\n",
      "Iteration 2142, the loss is 82.27371649715208, parameters k is 2.9556505087535507 and b is -78.31609299734777\n",
      "Iteration 2143, the loss is 82.23321986776944, parameters k is 2.9619351431409027 and b is -78.31509299734776\n",
      "Iteration 2144, the loss is 82.19272323838676, parameters k is 2.9682197775282546 and b is -78.31409299734776\n",
      "Iteration 2145, the loss is 82.152226609004, parameters k is 2.9745044119156065 and b is -78.31309299734775\n",
      "Iteration 2146, the loss is 82.11172997962129, parameters k is 2.9807890463029585 and b is -78.31209299734775\n",
      "Iteration 2147, the loss is 82.07123335023873, parameters k is 2.9870736806903104 and b is -78.31109299734774\n",
      "Iteration 2148, the loss is 82.03073672085594, parameters k is 2.9933583150776624 and b is -78.31009299734774\n",
      "Iteration 2149, the loss is 81.99024009147327, parameters k is 2.9996429494650143 and b is -78.30909299734773\n",
      "Iteration 2150, the loss is 81.94974346209058, parameters k is 3.0059275838523662 and b is -78.30809299734773\n",
      "Iteration 2151, the loss is 81.9092468327079, parameters k is 3.012212218239718 and b is -78.30709299734772\n",
      "Iteration 2152, the loss is 81.86875020332519, parameters k is 3.01849685262707 and b is -78.30609299734772\n",
      "Iteration 2153, the loss is 81.82825357394252, parameters k is 3.024781487014422 and b is -78.30509299734771\n",
      "Iteration 2154, the loss is 81.78775694455986, parameters k is 3.031066121401774 and b is -78.30409299734771\n",
      "Iteration 2155, the loss is 81.74726031517712, parameters k is 3.037350755789126 and b is -78.3030929973477\n",
      "Iteration 2156, the loss is 81.70676368579448, parameters k is 3.043635390176478 and b is -78.3020929973477\n",
      "Iteration 2157, the loss is 81.66626705641171, parameters k is 3.04992002456383 and b is -78.3010929973477\n",
      "Iteration 2158, the loss is 81.62577042702907, parameters k is 3.0562046589511818 and b is -78.30009299734769\n",
      "Iteration 2159, the loss is 81.58527379764635, parameters k is 3.0624892933385337 and b is -78.29909299734769\n",
      "Iteration 2160, the loss is 81.54477716826362, parameters k is 3.0687739277258856 and b is -78.29809299734768\n",
      "Iteration 2161, the loss is 81.50428053888102, parameters k is 3.0750585621132376 and b is -78.29709299734768\n",
      "Iteration 2162, the loss is 81.4637839094983, parameters k is 3.0813431965005895 and b is -78.29609299734767\n",
      "Iteration 2163, the loss is 81.42328728011555, parameters k is 3.0876278308879415 and b is -78.29509299734767\n",
      "Iteration 2164, the loss is 81.38279065073287, parameters k is 3.0939124652752934 and b is -78.29409299734766\n",
      "Iteration 2165, the loss is 81.34229402135021, parameters k is 3.1001970996626453 and b is -78.29309299734766\n",
      "Iteration 2166, the loss is 81.30179739196753, parameters k is 3.1064817340499973 and b is -78.29209299734765\n",
      "Iteration 2167, the loss is 81.26130076258491, parameters k is 3.112766368437349 and b is -78.29109299734765\n",
      "Iteration 2168, the loss is 81.22080413320214, parameters k is 3.119051002824701 and b is -78.29009299734764\n",
      "Iteration 2169, the loss is 81.18030750381953, parameters k is 3.125335637212053 and b is -78.28909299734764\n",
      "Iteration 2170, the loss is 81.13981087443675, parameters k is 3.131620271599405 and b is -78.28809299734763\n",
      "Iteration 2171, the loss is 81.09931424505406, parameters k is 3.137904905986757 and b is -78.28709299734763\n",
      "Iteration 2172, the loss is 81.05881761567143, parameters k is 3.144189540374109 and b is -78.28609299734762\n",
      "Iteration 2173, the loss is 81.01832098628871, parameters k is 3.150474174761461 and b is -78.28509299734762\n",
      "Iteration 2174, the loss is 80.97782435690605, parameters k is 3.156758809148813 and b is -78.28409299734761\n",
      "Iteration 2175, the loss is 80.9373277275232, parameters k is 3.1630434435361647 and b is -78.28309299734761\n",
      "Iteration 2176, the loss is 80.8968310981407, parameters k is 3.1693280779235167 and b is -78.2820929973476\n",
      "Iteration 2177, the loss is 80.85633446875782, parameters k is 3.1756127123108686 and b is -78.2810929973476\n",
      "Iteration 2178, the loss is 80.81583783937525, parameters k is 3.1818973466982206 and b is -78.2800929973476\n",
      "Iteration 2179, the loss is 80.7753412099926, parameters k is 3.1881819810855725 and b is -78.27909299734759\n",
      "Iteration 2180, the loss is 80.73484458060985, parameters k is 3.1944666154729244 and b is -78.27809299734758\n",
      "Iteration 2181, the loss is 80.69434795122719, parameters k is 3.2007512498602764 and b is -78.27709299734758\n",
      "Iteration 2182, the loss is 80.65385132184443, parameters k is 3.2070358842476283 and b is -78.27609299734758\n",
      "Iteration 2183, the loss is 80.61335469246177, parameters k is 3.2133205186349802 and b is -78.27509299734757\n",
      "Iteration 2184, the loss is 80.57285806307905, parameters k is 3.219605153022332 and b is -78.27409299734757\n",
      "Iteration 2185, the loss is 80.53236143369637, parameters k is 3.225889787409684 and b is -78.27309299734756\n",
      "Iteration 2186, the loss is 80.49186480431374, parameters k is 3.232174421797036 and b is -78.27209299734756\n",
      "Iteration 2187, the loss is 80.45136817493113, parameters k is 3.238459056184388 and b is -78.27109299734755\n",
      "Iteration 2188, the loss is 80.41087154554846, parameters k is 3.24474369057174 and b is -78.27009299734755\n",
      "Iteration 2189, the loss is 80.37037491616579, parameters k is 3.251028324959092 and b is -78.26909299734754\n",
      "Iteration 2190, the loss is 80.329878286783, parameters k is 3.257312959346444 and b is -78.26809299734754\n",
      "Iteration 2191, the loss is 80.28938165740033, parameters k is 3.2635975937337958 and b is -78.26709299734753\n",
      "Iteration 2192, the loss is 80.24888502801764, parameters k is 3.2698822281211477 and b is -78.26609299734753\n",
      "Iteration 2193, the loss is 80.20838839863485, parameters k is 3.2761668625084996 and b is -78.26509299734752\n",
      "Iteration 2194, the loss is 80.16789176925214, parameters k is 3.2824514968958516 and b is -78.26409299734752\n",
      "Iteration 2195, the loss is 80.12739513986948, parameters k is 3.2887361312832035 and b is -78.26309299734751\n",
      "Iteration 2196, the loss is 80.0868985104868, parameters k is 3.2950207656705555 and b is -78.26209299734751\n",
      "Iteration 2197, the loss is 80.0464018811041, parameters k is 3.3013054000579074 and b is -78.2610929973475\n",
      "Iteration 2198, the loss is 80.00590525172139, parameters k is 3.3075900344452593 and b is -78.2600929973475\n",
      "Iteration 2199, the loss is 79.96540862233869, parameters k is 3.3138746688326113 and b is -78.2590929973475\n",
      "Iteration 2200, the loss is 79.92491199295597, parameters k is 3.320159303219963 and b is -78.25809299734749\n",
      "Iteration 2201, the loss is 79.88441536357341, parameters k is 3.326443937607315 and b is -78.25709299734748\n",
      "Iteration 2202, the loss is 79.84391873419071, parameters k is 3.332728571994667 and b is -78.25609299734748\n",
      "Iteration 2203, the loss is 79.80342210480799, parameters k is 3.339013206382019 and b is -78.25509299734748\n",
      "Iteration 2204, the loss is 79.76292547542525, parameters k is 3.345297840769371 and b is -78.25409299734747\n",
      "Iteration 2205, the loss is 79.72242884604262, parameters k is 3.351582475156723 and b is -78.25309299734747\n",
      "Iteration 2206, the loss is 79.68193221665985, parameters k is 3.357867109544075 and b is -78.25209299734746\n",
      "Iteration 2207, the loss is 79.64143558727713, parameters k is 3.364151743931427 and b is -78.25109299734746\n",
      "Iteration 2208, the loss is 79.60093895789453, parameters k is 3.3704363783187787 and b is -78.25009299734745\n",
      "Iteration 2209, the loss is 79.56044232851191, parameters k is 3.3767210127061307 and b is -78.24909299734745\n",
      "Iteration 2210, the loss is 79.51994569912925, parameters k is 3.3830056470934826 and b is -78.24809299734744\n",
      "Iteration 2211, the loss is 79.47944906974647, parameters k is 3.3892902814808346 and b is -78.24709299734744\n",
      "Iteration 2212, the loss is 79.43895244036376, parameters k is 3.3955749158681865 and b is -78.24609299734743\n",
      "Iteration 2213, the loss is 79.39845581098105, parameters k is 3.4018595502555384 and b is -78.24509299734743\n",
      "Iteration 2214, the loss is 79.35795918159836, parameters k is 3.4081441846428904 and b is -78.24409299734742\n",
      "Iteration 2215, the loss is 79.31746255221566, parameters k is 3.4144288190302423 and b is -78.24309299734742\n",
      "Iteration 2216, the loss is 79.276965922833, parameters k is 3.4207134534175943 and b is -78.24209299734741\n",
      "Iteration 2217, the loss is 79.23646929345031, parameters k is 3.426998087804946 and b is -78.24109299734741\n",
      "Iteration 2218, the loss is 79.19597266406758, parameters k is 3.433282722192298 and b is -78.2400929973474\n",
      "Iteration 2219, the loss is 79.15547603468498, parameters k is 3.43956735657965 and b is -78.2390929973474\n",
      "Iteration 2220, the loss is 79.11497940530215, parameters k is 3.445851990967002 and b is -78.2380929973474\n",
      "Iteration 2221, the loss is 79.0744827759196, parameters k is 3.452136625354354 and b is -78.23709299734739\n",
      "Iteration 2222, the loss is 79.03398614653688, parameters k is 3.458421259741706 and b is -78.23609299734738\n",
      "Iteration 2223, the loss is 78.99348951715412, parameters k is 3.464705894129058 and b is -78.23509299734738\n",
      "Iteration 2224, the loss is 78.95299288777154, parameters k is 3.4709905285164098 and b is -78.23409299734737\n",
      "Iteration 2225, the loss is 78.91249625838873, parameters k is 3.4772751629037617 and b is -78.23309299734737\n",
      "Iteration 2226, the loss is 78.87199962900617, parameters k is 3.4835597972911136 and b is -78.23209299734737\n",
      "Iteration 2227, the loss is 78.83150299962344, parameters k is 3.4898444316784656 and b is -78.23109299734736\n",
      "Iteration 2228, the loss is 78.79100637024067, parameters k is 3.4961290660658175 and b is -78.23009299734736\n",
      "Iteration 2229, the loss is 78.75050974085806, parameters k is 3.5024137004531695 and b is -78.22909299734735\n",
      "Iteration 2230, the loss is 78.71001311147532, parameters k is 3.5086983348405214 and b is -78.22809299734735\n",
      "Iteration 2231, the loss is 78.6695164820927, parameters k is 3.5149829692278733 and b is -78.22709299734734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2232, the loss is 78.62901985270994, parameters k is 3.5212676036152253 and b is -78.22609299734734\n",
      "Iteration 2233, the loss is 78.58852322332734, parameters k is 3.5275522380025772 and b is -78.22509299734733\n",
      "Iteration 2234, the loss is 78.54802659394467, parameters k is 3.533836872389929 and b is -78.22409299734733\n",
      "Iteration 2235, the loss is 78.50752996456177, parameters k is 3.540121506777281 and b is -78.22309299734732\n",
      "Iteration 2236, the loss is 78.46703333517924, parameters k is 3.546406141164633 and b is -78.22209299734732\n",
      "Iteration 2237, the loss is 78.4265367057965, parameters k is 3.552690775551985 and b is -78.22109299734731\n",
      "Iteration 2238, the loss is 78.3860400764139, parameters k is 3.558975409939337 and b is -78.22009299734731\n",
      "Iteration 2239, the loss is 78.3455434470312, parameters k is 3.565260044326689 and b is -78.2190929973473\n",
      "Iteration 2240, the loss is 78.30504681764835, parameters k is 3.571544678714041 and b is -78.2180929973473\n",
      "Iteration 2241, the loss is 78.26455018826587, parameters k is 3.5778293131013927 and b is -78.2170929973473\n",
      "Iteration 2242, the loss is 78.22405355888307, parameters k is 3.5841139474887447 and b is -78.21609299734729\n",
      "Iteration 2243, the loss is 78.18355692950037, parameters k is 3.5903985818760966 and b is -78.21509299734728\n",
      "Iteration 2244, the loss is 78.14306030011774, parameters k is 3.5966832162634486 and b is -78.21409299734728\n",
      "Iteration 2245, the loss is 78.10256367073497, parameters k is 3.6029678506508005 and b is -78.21309299734727\n",
      "Iteration 2246, the loss is 78.06206704135228, parameters k is 3.6092524850381524 and b is -78.21209299734727\n",
      "Iteration 2247, the loss is 78.02157041196955, parameters k is 3.6155371194255044 and b is -78.21109299734727\n",
      "Iteration 2248, the loss is 77.98107378258699, parameters k is 3.6218217538128563 and b is -78.21009299734726\n",
      "Iteration 2249, the loss is 77.9405771532042, parameters k is 3.6281063882002083 and b is -78.20909299734726\n",
      "Iteration 2250, the loss is 77.90008052382154, parameters k is 3.63439102258756 and b is -78.20809299734725\n",
      "Iteration 2251, the loss is 77.85958389443891, parameters k is 3.640675656974912 and b is -78.20709299734725\n",
      "Iteration 2252, the loss is 77.81908726505617, parameters k is 3.646960291362264 and b is -78.20609299734724\n",
      "Iteration 2253, the loss is 77.7785906356735, parameters k is 3.653244925749616 and b is -78.20509299734724\n",
      "Iteration 2254, the loss is 77.73809400629067, parameters k is 3.659529560136968 and b is -78.20409299734723\n",
      "Iteration 2255, the loss is 77.69759737690806, parameters k is 3.66581419452432 and b is -78.20309299734723\n",
      "Iteration 2256, the loss is 77.6571007475254, parameters k is 3.672098828911672 and b is -78.20209299734722\n",
      "Iteration 2257, the loss is 77.61660411814275, parameters k is 3.6783834632990238 and b is -78.20109299734722\n",
      "Iteration 2258, the loss is 77.5761074887601, parameters k is 3.6846680976863757 and b is -78.20009299734721\n",
      "Iteration 2259, the loss is 77.53561085937729, parameters k is 3.6909527320737276 and b is -78.19909299734721\n",
      "Iteration 2260, the loss is 77.49511422999468, parameters k is 3.6972373664610796 and b is -78.1980929973472\n",
      "Iteration 2261, the loss is 77.45461760061195, parameters k is 3.7035220008484315 and b is -78.1970929973472\n",
      "Iteration 2262, the loss is 77.41412097122931, parameters k is 3.7098066352357835 and b is -78.1960929973472\n",
      "Iteration 2263, the loss is 77.3736243418465, parameters k is 3.7160912696231354 and b is -78.19509299734719\n",
      "Iteration 2264, the loss is 77.33312771246388, parameters k is 3.7223759040104873 and b is -78.19409299734718\n",
      "Iteration 2265, the loss is 77.29263108308123, parameters k is 3.7286605383978393 and b is -78.19309299734718\n",
      "Iteration 2266, the loss is 77.25213445369855, parameters k is 3.7349451727851912 and b is -78.19209299734717\n",
      "Iteration 2267, the loss is 77.21163782431583, parameters k is 3.741229807172543 and b is -78.19109299734717\n",
      "Iteration 2268, the loss is 77.17114119493309, parameters k is 3.747514441559895 and b is -78.19009299734716\n",
      "Iteration 2269, the loss is 77.13064456555044, parameters k is 3.753799075947247 and b is -78.18909299734716\n",
      "Iteration 2270, the loss is 77.09014793616775, parameters k is 3.760083710334599 and b is -78.18809299734716\n",
      "Iteration 2271, the loss is 77.04965130678505, parameters k is 3.766368344721951 and b is -78.18709299734715\n",
      "Iteration 2272, the loss is 77.00915467740235, parameters k is 3.772652979109303 and b is -78.18609299734715\n",
      "Iteration 2273, the loss is 76.96865804801963, parameters k is 3.778937613496655 and b is -78.18509299734714\n",
      "Iteration 2274, the loss is 76.92816141863689, parameters k is 3.7852222478840067 and b is -78.18409299734714\n",
      "Iteration 2275, the loss is 76.88766478925436, parameters k is 3.7915068822713587 and b is -78.18309299734713\n",
      "Iteration 2276, the loss is 76.84716815987154, parameters k is 3.7977915166587106 and b is -78.18209299734713\n",
      "Iteration 2277, the loss is 76.80667153048896, parameters k is 3.8040761510460626 and b is -78.18109299734712\n",
      "Iteration 2278, the loss is 76.7661749011063, parameters k is 3.8103607854334145 and b is -78.18009299734712\n",
      "Iteration 2279, the loss is 76.72567827172351, parameters k is 3.8166454198207664 and b is -78.17909299734711\n",
      "Iteration 2280, the loss is 76.68518164234082, parameters k is 3.8229300542081184 and b is -78.17809299734711\n",
      "Iteration 2281, the loss is 76.6446850129581, parameters k is 3.8292146885954703 and b is -78.1770929973471\n",
      "Iteration 2282, the loss is 76.60418838357549, parameters k is 3.8354993229828223 and b is -78.1760929973471\n",
      "Iteration 2283, the loss is 76.56369175419277, parameters k is 3.841783957370174 and b is -78.1750929973471\n",
      "Iteration 2284, the loss is 76.52319512481003, parameters k is 3.848068591757526 and b is -78.17409299734709\n",
      "Iteration 2285, the loss is 76.48269849542737, parameters k is 3.854353226144878 and b is -78.17309299734708\n",
      "Iteration 2286, the loss is 76.44220186604468, parameters k is 3.86063786053223 and b is -78.17209299734708\n",
      "Iteration 2287, the loss is 76.40170523666208, parameters k is 3.866922494919582 and b is -78.17109299734707\n",
      "Iteration 2288, the loss is 76.36120860727932, parameters k is 3.873207129306934 and b is -78.17009299734707\n",
      "Iteration 2289, the loss is 76.32071197789661, parameters k is 3.879491763694286 and b is -78.16909299734706\n",
      "Iteration 2290, the loss is 76.28021534851389, parameters k is 3.8857763980816378 and b is -78.16809299734706\n",
      "Iteration 2291, the loss is 76.23971871913116, parameters k is 3.8920610324689897 and b is -78.16709299734705\n",
      "Iteration 2292, the loss is 76.19922208974849, parameters k is 3.8983456668563417 and b is -78.16609299734705\n",
      "Iteration 2293, the loss is 76.15872546036584, parameters k is 3.9046303012436936 and b is -78.16509299734705\n",
      "Iteration 2294, the loss is 76.11822883098307, parameters k is 3.9109149356310455 and b is -78.16409299734704\n",
      "Iteration 2295, the loss is 76.0777322016005, parameters k is 3.9171995700183975 and b is -78.16309299734704\n",
      "Iteration 2296, the loss is 76.03723557221784, parameters k is 3.9234842044057494 and b is -78.16209299734703\n",
      "Iteration 2297, the loss is 75.99673894283514, parameters k is 3.9297688387931013 and b is -78.16109299734703\n",
      "Iteration 2298, the loss is 75.95624231345238, parameters k is 3.9360534731804533 and b is -78.16009299734702\n",
      "Iteration 2299, the loss is 75.91574568406972, parameters k is 3.9423381075678052 and b is -78.15909299734702\n",
      "Iteration 2300, the loss is 75.87524905468705, parameters k is 3.948622741955157 and b is -78.15809299734701\n",
      "Iteration 2301, the loss is 75.83475242530434, parameters k is 3.954907376342509 and b is -78.15709299734701\n",
      "Iteration 2302, the loss is 75.79425579592163, parameters k is 3.961192010729861 and b is -78.156092997347\n",
      "Iteration 2303, the loss is 75.753759166539, parameters k is 3.967476645117213 and b is -78.155092997347\n",
      "Iteration 2304, the loss is 75.71326253715627, parameters k is 3.973761279504565 and b is -78.15409299734699\n",
      "Iteration 2305, the loss is 75.67276590777365, parameters k is 3.980045913891917 and b is -78.15309299734699\n",
      "Iteration 2306, the loss is 75.63226927839085, parameters k is 3.986330548279269 and b is -78.15209299734698\n",
      "Iteration 2307, the loss is 75.5917726490081, parameters k is 3.9926151826666207 and b is -78.15109299734698\n",
      "Iteration 2308, the loss is 75.55127601962553, parameters k is 3.9988998170539727 and b is -78.15009299734697\n",
      "Iteration 2309, the loss is 75.51077939024286, parameters k is 4.005184451441324 and b is -78.14909299734697\n",
      "Iteration 2310, the loss is 75.47028276086013, parameters k is 4.011469085828676 and b is -78.14809299734696\n",
      "Iteration 2311, the loss is 75.42978613147746, parameters k is 4.017753720216027 and b is -78.14709299734696\n",
      "Iteration 2312, the loss is 75.38928950209474, parameters k is 4.024038354603379 and b is -78.14609299734695\n",
      "Iteration 2313, the loss is 75.34879287271205, parameters k is 4.03032298899073 and b is -78.14509299734695\n",
      "Iteration 2314, the loss is 75.30829624332938, parameters k is 4.036607623378082 and b is -78.14409299734695\n",
      "Iteration 2315, the loss is 75.26779961394669, parameters k is 4.042892257765433 and b is -78.14309299734694\n",
      "Iteration 2316, the loss is 75.22730298456405, parameters k is 4.049176892152785 and b is -78.14209299734694\n",
      "Iteration 2317, the loss is 75.1868063551813, parameters k is 4.055461526540136 and b is -78.14109299734693\n",
      "Iteration 2318, the loss is 75.14630972579862, parameters k is 4.061746160927488 and b is -78.14009299734693\n",
      "Iteration 2319, the loss is 75.10581309641597, parameters k is 4.068030795314839 and b is -78.13909299734692\n",
      "Iteration 2320, the loss is 75.06531646703327, parameters k is 4.074315429702191 and b is -78.13809299734692\n",
      "Iteration 2321, the loss is 75.02481983765058, parameters k is 4.080600064089542 and b is -78.13709299734691\n",
      "Iteration 2322, the loss is 74.98432320826784, parameters k is 4.086884698476894 and b is -78.1360929973469\n",
      "Iteration 2323, the loss is 74.94382657888517, parameters k is 4.093169332864245 and b is -78.1350929973469\n",
      "Iteration 2324, the loss is 74.9033299495025, parameters k is 4.099453967251597 and b is -78.1340929973469\n",
      "Iteration 2325, the loss is 74.86283332011986, parameters k is 4.105738601638948 and b is -78.13309299734689\n",
      "Iteration 2326, the loss is 74.82233669073717, parameters k is 4.1120232360263 and b is -78.13209299734689\n",
      "Iteration 2327, the loss is 74.78184006135429, parameters k is 4.118307870413651 and b is -78.13109299734688\n",
      "Iteration 2328, the loss is 74.74134343197174, parameters k is 4.124592504801003 and b is -78.13009299734688\n",
      "Iteration 2329, the loss is 74.70084680258911, parameters k is 4.130877139188354 and b is -78.12909299734687\n",
      "Iteration 2330, the loss is 74.66035017320638, parameters k is 4.137161773575706 and b is -78.12809299734687\n",
      "Iteration 2331, the loss is 74.61985354382374, parameters k is 4.143446407963057 and b is -78.12709299734686\n",
      "Iteration 2332, the loss is 74.579356914441, parameters k is 4.149731042350409 and b is -78.12609299734686\n",
      "Iteration 2333, the loss is 74.5388602850583, parameters k is 4.15601567673776 and b is -78.12509299734685\n",
      "Iteration 2334, the loss is 74.49836365567566, parameters k is 4.162300311125112 and b is -78.12409299734685\n",
      "Iteration 2335, the loss is 74.45786702629294, parameters k is 4.168584945512463 and b is -78.12309299734684\n",
      "Iteration 2336, the loss is 74.41737039691017, parameters k is 4.1748695798998146 and b is -78.12209299734684\n",
      "Iteration 2337, the loss is 74.37687376752764, parameters k is 4.181154214287166 and b is -78.12109299734684\n",
      "Iteration 2338, the loss is 74.33637713814477, parameters k is 4.1874388486745175 and b is -78.12009299734683\n",
      "Iteration 2339, the loss is 74.29588050876227, parameters k is 4.193723483061869 and b is -78.11909299734683\n",
      "Iteration 2340, the loss is 74.25538387937947, parameters k is 4.2000081174492205 and b is -78.11809299734682\n",
      "Iteration 2341, the loss is 74.21488724999678, parameters k is 4.206292751836572 and b is -78.11709299734682\n",
      "Iteration 2342, the loss is 74.17439062061416, parameters k is 4.2125773862239235 and b is -78.11609299734681\n",
      "Iteration 2343, the loss is 74.13389399123143, parameters k is 4.218862020611275 and b is -78.1150929973468\n",
      "Iteration 2344, the loss is 74.0933973618488, parameters k is 4.2251466549986265 and b is -78.1140929973468\n",
      "Iteration 2345, the loss is 74.05290073246618, parameters k is 4.231431289385978 and b is -78.1130929973468\n",
      "Iteration 2346, the loss is 74.01240410308336, parameters k is 4.2377159237733295 and b is -78.11209299734679\n",
      "Iteration 2347, the loss is 73.97190747370065, parameters k is 4.244000558160681 and b is -78.11109299734679\n",
      "Iteration 2348, the loss is 73.93141084431801, parameters k is 4.2502851925480325 and b is -78.11009299734678\n",
      "Iteration 2349, the loss is 73.89091421493535, parameters k is 4.256569826935384 and b is -78.10909299734678\n",
      "Iteration 2350, the loss is 73.85041758555266, parameters k is 4.2628544613227355 and b is -78.10809299734677\n",
      "Iteration 2351, the loss is 73.80992095616993, parameters k is 4.269139095710087 and b is -78.10709299734677\n",
      "Iteration 2352, the loss is 73.76942432678729, parameters k is 4.2754237300974385 and b is -78.10609299734676\n",
      "Iteration 2353, the loss is 73.72892769740452, parameters k is 4.28170836448479 and b is -78.10509299734676\n",
      "Iteration 2354, the loss is 73.68843106802181, parameters k is 4.2879929988721415 and b is -78.10409299734675\n",
      "Iteration 2355, the loss is 73.64793443863921, parameters k is 4.294277633259493 and b is -78.10309299734675\n",
      "Iteration 2356, the loss is 73.60743780925642, parameters k is 4.3005622676468445 and b is -78.10209299734674\n",
      "Iteration 2357, the loss is 73.56694117987377, parameters k is 4.306846902034196 and b is -78.10109299734674\n",
      "Iteration 2358, the loss is 73.52644455049114, parameters k is 4.3131315364215475 and b is -78.10009299734674\n",
      "Iteration 2359, the loss is 73.48594792110846, parameters k is 4.319416170808899 and b is -78.09909299734673\n",
      "Iteration 2360, the loss is 73.44545129172575, parameters k is 4.32570080519625 and b is -78.09809299734673\n",
      "Iteration 2361, the loss is 73.40495466234306, parameters k is 4.331985439583602 and b is -78.09709299734672\n",
      "Iteration 2362, the loss is 73.36445803296041, parameters k is 4.338270073970953 and b is -78.09609299734672\n",
      "Iteration 2363, the loss is 73.32396140357763, parameters k is 4.344554708358305 and b is -78.09509299734671\n",
      "Iteration 2364, the loss is 73.28346477419495, parameters k is 4.350839342745656 and b is -78.0940929973467\n",
      "Iteration 2365, the loss is 73.24296814481231, parameters k is 4.357123977133008 and b is -78.0930929973467\n",
      "Iteration 2366, the loss is 73.20247151542964, parameters k is 4.363408611520359 and b is -78.0920929973467\n",
      "Iteration 2367, the loss is 73.16197488604698, parameters k is 4.369693245907711 and b is -78.09109299734669\n",
      "Iteration 2368, the loss is 73.12147825666423, parameters k is 4.375977880295062 and b is -78.09009299734669\n",
      "Iteration 2369, the loss is 73.08098162728153, parameters k is 4.382262514682414 and b is -78.08909299734668\n",
      "Iteration 2370, the loss is 73.04048499789894, parameters k is 4.388547149069765 and b is -78.08809299734668\n",
      "Iteration 2371, the loss is 72.99998836851626, parameters k is 4.394831783457117 and b is -78.08709299734667\n",
      "Iteration 2372, the loss is 72.95949173913347, parameters k is 4.401116417844468 and b is -78.08609299734667\n",
      "Iteration 2373, the loss is 72.91899510975087, parameters k is 4.40740105223182 and b is -78.08509299734666\n",
      "Iteration 2374, the loss is 72.87849848036814, parameters k is 4.413685686619171 and b is -78.08409299734666\n",
      "Iteration 2375, the loss is 72.8380018509855, parameters k is 4.419970321006523 and b is -78.08309299734665\n",
      "Iteration 2376, the loss is 72.7975052216028, parameters k is 4.426254955393874 and b is -78.08209299734665\n",
      "Iteration 2377, the loss is 72.75700859222012, parameters k is 4.432539589781226 and b is -78.08109299734664\n",
      "Iteration 2378, the loss is 72.71651196283747, parameters k is 4.438824224168577 and b is -78.08009299734664\n",
      "Iteration 2379, the loss is 72.67601533345474, parameters k is 4.445108858555929 and b is -78.07909299734663\n",
      "Iteration 2380, the loss is 72.63551870407201, parameters k is 4.45139349294328 and b is -78.07809299734663\n",
      "Iteration 2381, the loss is 72.59502207468925, parameters k is 4.457678127330632 and b is -78.07709299734663\n",
      "Iteration 2382, the loss is 72.55452544530664, parameters k is 4.463962761717983 and b is -78.07609299734662\n",
      "Iteration 2383, the loss is 72.51402881592394, parameters k is 4.470247396105335 and b is -78.07509299734662\n",
      "Iteration 2384, the loss is 72.47353218654132, parameters k is 4.476532030492686 and b is -78.07409299734661\n",
      "Iteration 2385, the loss is 72.43303555715865, parameters k is 4.482816664880038 and b is -78.0730929973466\n",
      "Iteration 2386, the loss is 72.39253892777597, parameters k is 4.489101299267389 and b is -78.0720929973466\n",
      "Iteration 2387, the loss is 72.35204229839324, parameters k is 4.495385933654741 and b is -78.0710929973466\n",
      "Iteration 2388, the loss is 72.31154566901054, parameters k is 4.501670568042092 and b is -78.07009299734659\n",
      "Iteration 2389, the loss is 72.27104903962783, parameters k is 4.507955202429444 and b is -78.06909299734659\n",
      "Iteration 2390, the loss is 72.23055241024522, parameters k is 4.514239836816795 and b is -78.06809299734658\n",
      "Iteration 2391, the loss is 72.19005578086248, parameters k is 4.520524471204147 and b is -78.06709299734658\n",
      "Iteration 2392, the loss is 72.14955915147975, parameters k is 4.526809105591498 and b is -78.06609299734657\n",
      "Iteration 2393, the loss is 72.10906252209702, parameters k is 4.53309373997885 and b is -78.06509299734657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394, the loss is 72.06856589271435, parameters k is 4.539378374366201 and b is -78.06409299734656\n",
      "Iteration 2395, the loss is 72.02806926333179, parameters k is 4.545663008753553 and b is -78.06309299734656\n",
      "Iteration 2396, the loss is 71.98757263394899, parameters k is 4.551947643140904 and b is -78.06209299734655\n",
      "Iteration 2397, the loss is 71.9470760045664, parameters k is 4.558232277528256 and b is -78.06109299734655\n",
      "Iteration 2398, the loss is 71.90657937518361, parameters k is 4.564516911915607 and b is -78.06009299734654\n",
      "Iteration 2399, the loss is 71.86608274580097, parameters k is 4.570801546302959 and b is -78.05909299734654\n",
      "Iteration 2400, the loss is 71.8255861164183, parameters k is 4.57708618069031 and b is -78.05809299734653\n",
      "Iteration 2401, the loss is 71.78508948703553, parameters k is 4.583370815077662 and b is -78.05709299734653\n",
      "Iteration 2402, the loss is 71.74459285765296, parameters k is 4.589655449465013 and b is -78.05609299734652\n",
      "Iteration 2403, the loss is 71.70409622827025, parameters k is 4.595940083852365 and b is -78.05509299734652\n",
      "Iteration 2404, the loss is 71.66359959888749, parameters k is 4.602224718239716 and b is -78.05409299734652\n",
      "Iteration 2405, the loss is 71.62310296950487, parameters k is 4.608509352627068 and b is -78.05309299734651\n",
      "Iteration 2406, the loss is 71.58260634012214, parameters k is 4.614793987014419 and b is -78.0520929973465\n",
      "Iteration 2407, the loss is 71.54210971073948, parameters k is 4.621078621401771 and b is -78.0510929973465\n",
      "Iteration 2408, the loss is 71.50161308135665, parameters k is 4.627363255789122 and b is -78.0500929973465\n",
      "Iteration 2409, the loss is 71.46111645197412, parameters k is 4.633647890176474 and b is -78.04909299734649\n",
      "Iteration 2410, the loss is 71.4206198225913, parameters k is 4.639932524563825 and b is -78.04809299734649\n",
      "Iteration 2411, the loss is 71.38012319320869, parameters k is 4.646217158951177 and b is -78.04709299734648\n",
      "Iteration 2412, the loss is 71.33962656382599, parameters k is 4.652501793338528 and b is -78.04609299734648\n",
      "Iteration 2413, the loss is 71.29912993444329, parameters k is 4.65878642772588 and b is -78.04509299734647\n",
      "Iteration 2414, the loss is 71.25863330506068, parameters k is 4.665071062113231 and b is -78.04409299734647\n",
      "Iteration 2415, the loss is 71.21813667567795, parameters k is 4.671355696500583 and b is -78.04309299734646\n",
      "Iteration 2416, the loss is 71.17764004629534, parameters k is 4.677640330887934 and b is -78.04209299734646\n",
      "Iteration 2417, the loss is 71.13714341691262, parameters k is 4.683924965275286 and b is -78.04109299734645\n",
      "Iteration 2418, the loss is 71.09664678752993, parameters k is 4.690209599662637 and b is -78.04009299734645\n",
      "Iteration 2419, the loss is 71.05615015814716, parameters k is 4.696494234049989 and b is -78.03909299734644\n",
      "Iteration 2420, the loss is 71.01565352876453, parameters k is 4.70277886843734 and b is -78.03809299734644\n",
      "Iteration 2421, the loss is 70.97515689938177, parameters k is 4.709063502824692 and b is -78.03709299734643\n",
      "Iteration 2422, the loss is 70.9346602699991, parameters k is 4.715348137212043 and b is -78.03609299734643\n",
      "Iteration 2423, the loss is 70.89416364061643, parameters k is 4.721632771599395 and b is -78.03509299734642\n",
      "Iteration 2424, the loss is 70.85366701123384, parameters k is 4.727917405986746 and b is -78.03409299734642\n",
      "Iteration 2425, the loss is 70.81317038185111, parameters k is 4.734202040374098 and b is -78.03309299734642\n",
      "Iteration 2426, the loss is 70.77267375246832, parameters k is 4.740486674761449 and b is -78.03209299734641\n",
      "Iteration 2427, the loss is 70.73217712308576, parameters k is 4.746771309148801 and b is -78.0310929973464\n",
      "Iteration 2428, the loss is 70.69168049370303, parameters k is 4.753055943536152 and b is -78.0300929973464\n",
      "Iteration 2429, the loss is 70.65118386432036, parameters k is 4.759340577923504 and b is -78.0290929973464\n",
      "Iteration 2430, the loss is 70.61068723493764, parameters k is 4.765625212310855 and b is -78.02809299734639\n",
      "Iteration 2431, the loss is 70.57019060555503, parameters k is 4.771909846698207 and b is -78.02709299734639\n",
      "Iteration 2432, the loss is 70.52969397617233, parameters k is 4.778194481085558 and b is -78.02609299734638\n",
      "Iteration 2433, the loss is 70.48919734678958, parameters k is 4.78447911547291 and b is -78.02509299734638\n",
      "Iteration 2434, the loss is 70.44870071740682, parameters k is 4.790763749860261 and b is -78.02409299734637\n",
      "Iteration 2435, the loss is 70.40820408802422, parameters k is 4.797048384247613 and b is -78.02309299734637\n",
      "Iteration 2436, the loss is 70.3677074586416, parameters k is 4.803333018634964 and b is -78.02209299734636\n",
      "Iteration 2437, the loss is 70.3272108292588, parameters k is 4.809617653022316 and b is -78.02109299734636\n",
      "Iteration 2438, the loss is 70.28671419987612, parameters k is 4.815902287409667 and b is -78.02009299734635\n",
      "Iteration 2439, the loss is 70.24621757049336, parameters k is 4.822186921797019 and b is -78.01909299734635\n",
      "Iteration 2440, the loss is 70.20572094111074, parameters k is 4.82847155618437 and b is -78.01809299734634\n",
      "Iteration 2441, the loss is 70.16522431172811, parameters k is 4.834756190571722 and b is -78.01709299734634\n",
      "Iteration 2442, the loss is 70.12472768234541, parameters k is 4.841040824959073 and b is -78.01609299734633\n",
      "Iteration 2443, the loss is 70.08423105296272, parameters k is 4.847325459346425 and b is -78.01509299734633\n",
      "Iteration 2444, the loss is 70.04373442358005, parameters k is 4.853610093733776 and b is -78.01409299734632\n",
      "Iteration 2445, the loss is 70.00323779419733, parameters k is 4.8598947281211275 and b is -78.01309299734632\n",
      "Iteration 2446, the loss is 69.96274116481464, parameters k is 4.866179362508479 and b is -78.01209299734631\n",
      "Iteration 2447, the loss is 69.922244535432, parameters k is 4.8724639968958305 and b is -78.01109299734631\n",
      "Iteration 2448, the loss is 69.8817479060493, parameters k is 4.878748631283182 and b is -78.0100929973463\n",
      "Iteration 2449, the loss is 69.84125127666653, parameters k is 4.8850332656705335 and b is -78.0090929973463\n",
      "Iteration 2450, the loss is 69.80075464728394, parameters k is 4.891317900057885 and b is -78.0080929973463\n",
      "Iteration 2451, the loss is 69.7602580179012, parameters k is 4.8976025344452365 and b is -78.00709299734629\n",
      "Iteration 2452, the loss is 69.71976138851858, parameters k is 4.903887168832588 and b is -78.00609299734629\n",
      "Iteration 2453, the loss is 69.67926475913582, parameters k is 4.9101718032199395 and b is -78.00509299734628\n",
      "Iteration 2454, the loss is 69.63876812975312, parameters k is 4.916456437607291 and b is -78.00409299734628\n",
      "Iteration 2455, the loss is 69.59827150037042, parameters k is 4.9227410719946425 and b is -78.00309299734627\n",
      "Iteration 2456, the loss is 69.55777487098777, parameters k is 4.929025706381994 and b is -78.00209299734627\n",
      "Iteration 2457, the loss is 69.51727824160507, parameters k is 4.9353103407693455 and b is -78.00109299734626\n",
      "Iteration 2458, the loss is 69.47678161222241, parameters k is 4.941594975156697 and b is -78.00009299734626\n",
      "Iteration 2459, the loss is 69.43628498283967, parameters k is 4.9478796095440485 and b is -77.99909299734625\n",
      "Iteration 2460, the loss is 69.39578835345705, parameters k is 4.9541642439314 and b is -77.99809299734625\n",
      "Iteration 2461, the loss is 69.35529172407426, parameters k is 4.9604488783187515 and b is -77.99709299734624\n",
      "Iteration 2462, the loss is 69.31479509469155, parameters k is 4.966733512706103 and b is -77.99609299734624\n",
      "Iteration 2463, the loss is 69.27429846530902, parameters k is 4.9730181470934545 and b is -77.99509299734623\n",
      "Iteration 2464, the loss is 69.23380183592619, parameters k is 4.979302781480806 and b is -77.99409299734623\n",
      "Iteration 2465, the loss is 69.19330520654357, parameters k is 4.9855874158681575 and b is -77.99309299734622\n",
      "Iteration 2466, the loss is 69.15280857716095, parameters k is 4.991872050255509 and b is -77.99209299734622\n",
      "Iteration 2467, the loss is 69.11231194777822, parameters k is 4.9981566846428604 and b is -77.99109299734621\n",
      "Iteration 2468, the loss is 69.07181531839548, parameters k is 5.004441319030212 and b is -77.99009299734621\n",
      "Iteration 2469, the loss is 69.0313186890128, parameters k is 5.010725953417563 and b is -77.9890929973462\n",
      "Iteration 2470, the loss is 68.99082205963018, parameters k is 5.017010587804915 and b is -77.9880929973462\n",
      "Iteration 2471, the loss is 68.9503254302474, parameters k is 5.023295222192266 and b is -77.9870929973462\n",
      "Iteration 2472, the loss is 68.90982880086473, parameters k is 5.029579856579618 and b is -77.98609299734619\n",
      "Iteration 2473, the loss is 68.869332171482, parameters k is 5.035864490966969 and b is -77.98509299734619\n",
      "Iteration 2474, the loss is 68.82883554209934, parameters k is 5.042149125354321 and b is -77.98409299734618\n",
      "Iteration 2475, the loss is 68.78833891271671, parameters k is 5.048433759741672 and b is -77.98309299734618\n",
      "Iteration 2476, the loss is 68.74784228333404, parameters k is 5.054718394129024 and b is -77.98209299734617\n",
      "Iteration 2477, the loss is 68.70734565395135, parameters k is 5.061003028516375 and b is -77.98109299734617\n",
      "Iteration 2478, the loss is 68.66684902456873, parameters k is 5.067287662903727 and b is -77.98009299734616\n",
      "Iteration 2479, the loss is 68.62635239518593, parameters k is 5.073572297291078 and b is -77.97909299734616\n",
      "Iteration 2480, the loss is 68.58585576580326, parameters k is 5.07985693167843 and b is -77.97809299734615\n",
      "Iteration 2481, the loss is 68.54535913642064, parameters k is 5.086141566065781 and b is -77.97709299734615\n",
      "Iteration 2482, the loss is 68.50486250703787, parameters k is 5.092426200453133 and b is -77.97609299734614\n",
      "Iteration 2483, the loss is 68.46436587765524, parameters k is 5.098710834840484 and b is -77.97509299734614\n",
      "Iteration 2484, the loss is 68.42386924827254, parameters k is 5.104995469227836 and b is -77.97409299734613\n",
      "Iteration 2485, the loss is 68.38337261888978, parameters k is 5.111280103615187 and b is -77.97309299734613\n",
      "Iteration 2486, the loss is 68.3428759895071, parameters k is 5.117564738002539 and b is -77.97209299734612\n",
      "Iteration 2487, the loss is 68.30237936012446, parameters k is 5.12384937238989 and b is -77.97109299734612\n",
      "Iteration 2488, the loss is 68.26188273074173, parameters k is 5.130134006777242 and b is -77.97009299734611\n",
      "Iteration 2489, the loss is 68.22138610135904, parameters k is 5.136418641164593 and b is -77.96909299734611\n",
      "Iteration 2490, the loss is 68.18088947197637, parameters k is 5.142703275551945 and b is -77.9680929973461\n",
      "Iteration 2491, the loss is 68.14039284259377, parameters k is 5.148987909939296 and b is -77.9670929973461\n",
      "Iteration 2492, the loss is 68.09989621321107, parameters k is 5.155272544326648 and b is -77.9660929973461\n",
      "Iteration 2493, the loss is 68.0593995838283, parameters k is 5.161557178713999 and b is -77.96509299734609\n",
      "Iteration 2494, the loss is 68.01890295444571, parameters k is 5.167841813101351 and b is -77.96409299734609\n",
      "Iteration 2495, the loss is 67.97840632506299, parameters k is 5.174126447488702 and b is -77.96309299734608\n",
      "Iteration 2496, the loss is 67.93790969568029, parameters k is 5.180411081876054 and b is -77.96209299734608\n",
      "Iteration 2497, the loss is 67.89741306629755, parameters k is 5.186695716263405 and b is -77.96109299734607\n",
      "Iteration 2498, the loss is 67.8569164369149, parameters k is 5.192980350650757 and b is -77.96009299734607\n",
      "Iteration 2499, the loss is 67.81641980753216, parameters k is 5.199264985038108 and b is -77.95909299734606\n",
      "Iteration 2500, the loss is 67.77592317814954, parameters k is 5.20554961942546 and b is -77.95809299734606\n",
      "Iteration 2501, the loss is 67.73542654876681, parameters k is 5.211834253812811 and b is -77.95709299734605\n",
      "Iteration 2502, the loss is 67.69492991938412, parameters k is 5.218118888200163 and b is -77.95609299734605\n",
      "Iteration 2503, the loss is 67.65443329000142, parameters k is 5.224403522587514 and b is -77.95509299734604\n",
      "Iteration 2504, the loss is 67.61393666061879, parameters k is 5.230688156974866 and b is -77.95409299734604\n",
      "Iteration 2505, the loss is 67.57344003123609, parameters k is 5.236972791362217 and b is -77.95309299734603\n",
      "Iteration 2506, the loss is 67.53294340185339, parameters k is 5.243257425749569 and b is -77.95209299734603\n",
      "Iteration 2507, the loss is 67.49244677247074, parameters k is 5.24954206013692 and b is -77.95109299734602\n",
      "Iteration 2508, the loss is 67.45195014308804, parameters k is 5.255826694524272 and b is -77.95009299734602\n",
      "Iteration 2509, the loss is 67.41145351370538, parameters k is 5.262111328911623 and b is -77.94909299734601\n",
      "Iteration 2510, the loss is 67.3709568843226, parameters k is 5.268395963298975 and b is -77.94809299734601\n",
      "Iteration 2511, the loss is 67.33046025493994, parameters k is 5.274680597686326 and b is -77.947092997346\n",
      "Iteration 2512, the loss is 67.28996362555732, parameters k is 5.280965232073678 and b is -77.946092997346\n",
      "Iteration 2513, the loss is 67.24946699617466, parameters k is 5.287249866461029 and b is -77.945092997346\n",
      "Iteration 2514, the loss is 67.2089703667919, parameters k is 5.293534500848381 and b is -77.94409299734599\n",
      "Iteration 2515, the loss is 67.16847373740917, parameters k is 5.299819135235732 and b is -77.94309299734599\n",
      "Iteration 2516, the loss is 67.12797710802651, parameters k is 5.306103769623084 and b is -77.94209299734598\n",
      "Iteration 2517, the loss is 67.08748047864381, parameters k is 5.312388404010435 and b is -77.94109299734598\n",
      "Iteration 2518, the loss is 67.04698384926114, parameters k is 5.318673038397787 and b is -77.94009299734597\n",
      "Iteration 2519, the loss is 67.00648721987845, parameters k is 5.324957672785138 and b is -77.93909299734597\n",
      "Iteration 2520, the loss is 66.96599059049586, parameters k is 5.33124230717249 and b is -77.93809299734596\n",
      "Iteration 2521, the loss is 66.92549396111306, parameters k is 5.337526941559841 and b is -77.93709299734596\n",
      "Iteration 2522, the loss is 66.88499733173035, parameters k is 5.343811575947193 and b is -77.93609299734595\n",
      "Iteration 2523, the loss is 66.8445007023477, parameters k is 5.350096210334544 and b is -77.93509299734595\n",
      "Iteration 2524, the loss is 66.80400407296496, parameters k is 5.356380844721896 and b is -77.93409299734594\n",
      "Iteration 2525, the loss is 66.7635074435823, parameters k is 5.362665479109247 and b is -77.93309299734594\n",
      "Iteration 2526, the loss is 66.72301081419965, parameters k is 5.368950113496599 and b is -77.93209299734593\n",
      "Iteration 2527, the loss is 66.682514184817, parameters k is 5.37523474788395 and b is -77.93109299734593\n",
      "Iteration 2528, the loss is 66.64201755543428, parameters k is 5.381519382271302 and b is -77.93009299734592\n",
      "Iteration 2529, the loss is 66.60152092605156, parameters k is 5.387804016658653 and b is -77.92909299734592\n",
      "Iteration 2530, the loss is 66.56102429666895, parameters k is 5.394088651046005 and b is -77.92809299734591\n",
      "Iteration 2531, the loss is 66.5205276672862, parameters k is 5.400373285433356 and b is -77.92709299734591\n",
      "Iteration 2532, the loss is 66.48003103790347, parameters k is 5.406657919820708 and b is -77.9260929973459\n",
      "Iteration 2533, the loss is 66.43953440852081, parameters k is 5.412942554208059 and b is -77.9250929973459\n",
      "Iteration 2534, the loss is 66.39903777913808, parameters k is 5.419227188595411 and b is -77.9240929973459\n",
      "Iteration 2535, the loss is 66.35854114975547, parameters k is 5.425511822982762 and b is -77.92309299734589\n",
      "Iteration 2536, the loss is 66.31804452037277, parameters k is 5.431796457370114 and b is -77.92209299734589\n",
      "Iteration 2537, the loss is 66.27754789099005, parameters k is 5.438081091757465 and b is -77.92109299734588\n",
      "Iteration 2538, the loss is 66.23705126160733, parameters k is 5.444365726144817 and b is -77.92009299734588\n",
      "Iteration 2539, the loss is 66.19655463222466, parameters k is 5.450650360532168 and b is -77.91909299734587\n",
      "Iteration 2540, the loss is 66.15605800284199, parameters k is 5.45693499491952 and b is -77.91809299734587\n",
      "Iteration 2541, the loss is 66.11556137345933, parameters k is 5.463219629306871 and b is -77.91709299734586\n",
      "Iteration 2542, the loss is 66.07506474407666, parameters k is 5.469504263694223 and b is -77.91609299734586\n",
      "Iteration 2543, the loss is 66.03456811469394, parameters k is 5.475788898081574 and b is -77.91509299734585\n",
      "Iteration 2544, the loss is 65.99407148531122, parameters k is 5.482073532468926 and b is -77.91409299734585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2545, the loss is 65.95357485592857, parameters k is 5.488358166856277 and b is -77.91309299734584\n",
      "Iteration 2546, the loss is 65.91307822654589, parameters k is 5.494642801243629 and b is -77.91209299734584\n",
      "Iteration 2547, the loss is 65.87258159716316, parameters k is 5.50092743563098 and b is -77.91109299734583\n",
      "Iteration 2548, the loss is 65.83208496778047, parameters k is 5.507212070018332 and b is -77.91009299734583\n",
      "Iteration 2549, the loss is 65.79158833839779, parameters k is 5.513496704405683 and b is -77.90909299734582\n",
      "Iteration 2550, the loss is 65.7510917090152, parameters k is 5.519781338793035 and b is -77.90809299734582\n",
      "Iteration 2551, the loss is 65.71059507963245, parameters k is 5.526065973180386 and b is -77.90709299734581\n",
      "Iteration 2552, the loss is 65.67009845024977, parameters k is 5.5323506075677376 and b is -77.90609299734581\n",
      "Iteration 2553, the loss is 65.62960182086712, parameters k is 5.538635241955089 and b is -77.9050929973458\n",
      "Iteration 2554, the loss is 65.58910519148444, parameters k is 5.5449198763424405 and b is -77.9040929973458\n",
      "Iteration 2555, the loss is 65.54860856210169, parameters k is 5.551204510729792 and b is -77.9030929973458\n",
      "Iteration 2556, the loss is 65.50811193271906, parameters k is 5.5574891451171435 and b is -77.90209299734579\n",
      "Iteration 2557, the loss is 65.4676153033363, parameters k is 5.563773779504495 and b is -77.90109299734578\n",
      "Iteration 2558, the loss is 65.42711867395366, parameters k is 5.5700584138918465 and b is -77.90009299734578\n",
      "Iteration 2559, the loss is 65.38662204457096, parameters k is 5.576343048279198 and b is -77.89909299734578\n",
      "Iteration 2560, the loss is 65.34612541518823, parameters k is 5.5826276826665495 and b is -77.89809299734577\n",
      "Iteration 2561, the loss is 65.3056287858056, parameters k is 5.588912317053901 and b is -77.89709299734577\n",
      "Iteration 2562, the loss is 65.26513215642288, parameters k is 5.5951969514412525 and b is -77.89609299734576\n",
      "Iteration 2563, the loss is 65.2246355270402, parameters k is 5.601481585828604 and b is -77.89509299734576\n",
      "Iteration 2564, the loss is 65.18413889765756, parameters k is 5.6077662202159555 and b is -77.89409299734575\n",
      "Iteration 2565, the loss is 65.14364226827489, parameters k is 5.614050854603307 and b is -77.89309299734575\n",
      "Iteration 2566, the loss is 65.10314563889204, parameters k is 5.6203354889906585 and b is -77.89209299734574\n",
      "Iteration 2567, the loss is 65.06264900950939, parameters k is 5.62662012337801 and b is -77.89109299734574\n",
      "Iteration 2568, the loss is 65.0221523801268, parameters k is 5.6329047577653615 and b is -77.89009299734573\n",
      "Iteration 2569, the loss is 64.98165575074405, parameters k is 5.639189392152713 and b is -77.88909299734573\n",
      "Iteration 2570, the loss is 64.94115912136137, parameters k is 5.6454740265400645 and b is -77.88809299734572\n",
      "Iteration 2571, the loss is 64.9006624919787, parameters k is 5.651758660927416 and b is -77.88709299734572\n",
      "Iteration 2572, the loss is 64.86016586259602, parameters k is 5.6580432953147675 and b is -77.88609299734571\n",
      "Iteration 2573, the loss is 64.81966923321335, parameters k is 5.664327929702119 and b is -77.88509299734571\n",
      "Iteration 2574, the loss is 64.77917260383065, parameters k is 5.6706125640894705 and b is -77.8840929973457\n",
      "Iteration 2575, the loss is 64.73867597444789, parameters k is 5.676897198476822 and b is -77.8830929973457\n",
      "Iteration 2576, the loss is 64.6981793450653, parameters k is 5.683181832864173 and b is -77.8820929973457\n",
      "Iteration 2577, the loss is 64.65768271568258, parameters k is 5.689466467251525 and b is -77.88109299734569\n",
      "Iteration 2578, the loss is 64.61718608629984, parameters k is 5.695751101638876 and b is -77.88009299734568\n",
      "Iteration 2579, the loss is 64.57668945691718, parameters k is 5.702035736026228 and b is -77.87909299734568\n",
      "Iteration 2580, the loss is 64.53619282753456, parameters k is 5.708320370413579 and b is -77.87809299734568\n",
      "Iteration 2581, the loss is 64.4956961981518, parameters k is 5.714605004800931 and b is -77.87709299734567\n",
      "Iteration 2582, the loss is 64.45519956876919, parameters k is 5.720889639188282 and b is -77.87609299734567\n",
      "Iteration 2583, the loss is 64.41470293938644, parameters k is 5.727174273575634 and b is -77.87509299734566\n",
      "Iteration 2584, the loss is 64.37420631000383, parameters k is 5.733458907962985 and b is -77.87409299734566\n",
      "Iteration 2585, the loss is 64.33370968062107, parameters k is 5.739743542350337 and b is -77.87309299734565\n",
      "Iteration 2586, the loss is 64.29321305123841, parameters k is 5.746028176737688 and b is -77.87209299734565\n",
      "Iteration 2587, the loss is 64.25271642185574, parameters k is 5.75231281112504 and b is -77.87109299734564\n",
      "Iteration 2588, the loss is 64.21221979247302, parameters k is 5.758597445512391 and b is -77.87009299734564\n",
      "Iteration 2589, the loss is 64.17172316309028, parameters k is 5.764882079899743 and b is -77.86909299734563\n",
      "Iteration 2590, the loss is 64.13122653370769, parameters k is 5.771166714287094 and b is -77.86809299734563\n",
      "Iteration 2591, the loss is 64.09072990432496, parameters k is 5.777451348674446 and b is -77.86709299734562\n",
      "Iteration 2592, the loss is 64.05023327494227, parameters k is 5.783735983061797 and b is -77.86609299734562\n",
      "Iteration 2593, the loss is 64.00973664555954, parameters k is 5.790020617449149 and b is -77.86509299734561\n",
      "Iteration 2594, the loss is 63.96924001617691, parameters k is 5.7963052518365 and b is -77.86409299734561\n",
      "Iteration 2595, the loss is 63.928743386794224, parameters k is 5.802589886223852 and b is -77.8630929973456\n",
      "Iteration 2596, the loss is 63.88824675741149, parameters k is 5.808874520611203 and b is -77.8620929973456\n",
      "Iteration 2597, the loss is 63.8477501280288, parameters k is 5.815159154998555 and b is -77.8610929973456\n",
      "Iteration 2598, the loss is 63.80725349864613, parameters k is 5.821443789385906 and b is -77.86009299734559\n",
      "Iteration 2599, the loss is 63.76675686926345, parameters k is 5.827728423773258 and b is -77.85909299734558\n",
      "Iteration 2600, the loss is 63.72626023988075, parameters k is 5.834013058160609 and b is -77.85809299734558\n",
      "Iteration 2601, the loss is 63.68576361049811, parameters k is 5.840297692547961 and b is -77.85709299734557\n",
      "Iteration 2602, the loss is 63.645266981115476, parameters k is 5.846582326935312 and b is -77.85609299734557\n",
      "Iteration 2603, the loss is 63.60477035173268, parameters k is 5.852866961322664 and b is -77.85509299734557\n",
      "Iteration 2604, the loss is 63.56427372234996, parameters k is 5.859151595710015 and b is -77.85409299734556\n",
      "Iteration 2605, the loss is 63.52377709296732, parameters k is 5.865436230097367 and b is -77.85309299734556\n",
      "Iteration 2606, the loss is 63.48328046358463, parameters k is 5.871720864484718 and b is -77.85209299734555\n",
      "Iteration 2607, the loss is 63.44278383420202, parameters k is 5.87800549887207 and b is -77.85109299734555\n",
      "Iteration 2608, the loss is 63.40228720481932, parameters k is 5.884290133259421 and b is -77.85009299734554\n",
      "Iteration 2609, the loss is 63.36179057543661, parameters k is 5.890574767646773 and b is -77.84909299734554\n",
      "Iteration 2610, the loss is 63.32129394605385, parameters k is 5.896859402034124 and b is -77.84809299734553\n",
      "Iteration 2611, the loss is 63.28079731667121, parameters k is 5.903144036421476 and b is -77.84709299734553\n",
      "Iteration 2612, the loss is 63.24030068728849, parameters k is 5.909428670808827 and b is -77.84609299734552\n",
      "Iteration 2613, the loss is 63.19980405790589, parameters k is 5.915713305196179 and b is -77.84509299734552\n",
      "Iteration 2614, the loss is 63.1593074285231, parameters k is 5.92199793958353 and b is -77.84409299734551\n",
      "Iteration 2615, the loss is 63.11881079914043, parameters k is 5.928282573970882 and b is -77.84309299734551\n",
      "Iteration 2616, the loss is 63.07831416975782, parameters k is 5.934567208358233 and b is -77.8420929973455\n",
      "Iteration 2617, the loss is 63.03781754037511, parameters k is 5.940851842745585 and b is -77.8410929973455\n",
      "Iteration 2618, the loss is 62.99732091099241, parameters k is 5.947136477132936 and b is -77.8400929973455\n",
      "Iteration 2619, the loss is 62.95682428160964, parameters k is 5.953421111520288 and b is -77.83909299734549\n",
      "Iteration 2620, the loss is 62.91632765222707, parameters k is 5.959705745907639 and b is -77.83809299734548\n",
      "Iteration 2621, the loss is 62.875831022844295, parameters k is 5.965990380294991 and b is -77.83709299734548\n",
      "Iteration 2622, the loss is 62.83533439346164, parameters k is 5.972275014682342 and b is -77.83609299734547\n",
      "Iteration 2623, the loss is 62.79483776407901, parameters k is 5.978559649069694 and b is -77.83509299734547\n",
      "Iteration 2624, the loss is 62.754341134696226, parameters k is 5.984844283457045 and b is -77.83409299734546\n",
      "Iteration 2625, the loss is 62.71384450531355, parameters k is 5.991128917844397 and b is -77.83309299734546\n",
      "Iteration 2626, the loss is 62.673347875930965, parameters k is 5.997413552231748 and b is -77.83209299734546\n",
      "Iteration 2627, the loss is 62.6328512465482, parameters k is 6.0036981866191 and b is -77.83109299734545\n",
      "Iteration 2628, the loss is 62.59235461716557, parameters k is 6.009982821006451 and b is -77.83009299734545\n",
      "Iteration 2629, the loss is 62.55185798778286, parameters k is 6.016267455393803 and b is -77.82909299734544\n",
      "Iteration 2630, the loss is 62.511361358400144, parameters k is 6.022552089781154 and b is -77.82809299734544\n",
      "Iteration 2631, the loss is 62.47086472901752, parameters k is 6.028836724168506 and b is -77.82709299734543\n",
      "Iteration 2632, the loss is 62.4303680996347, parameters k is 6.035121358555857 and b is -77.82609299734543\n",
      "Iteration 2633, the loss is 62.38987147025205, parameters k is 6.041405992943209 and b is -77.82509299734542\n",
      "Iteration 2634, the loss is 62.349374840869366, parameters k is 6.04769062733056 and b is -77.82409299734542\n",
      "Iteration 2635, the loss is 62.308878211486714, parameters k is 6.053975261717912 and b is -77.82309299734541\n",
      "Iteration 2636, the loss is 62.26838158210398, parameters k is 6.060259896105263 and b is -77.82209299734541\n",
      "Iteration 2637, the loss is 62.22788495272132, parameters k is 6.066544530492615 and b is -77.8210929973454\n",
      "Iteration 2638, the loss is 62.18738832333871, parameters k is 6.072829164879966 and b is -77.8200929973454\n",
      "Iteration 2639, the loss is 62.14689169395599, parameters k is 6.079113799267318 and b is -77.8190929973454\n",
      "Iteration 2640, the loss is 62.1063950645733, parameters k is 6.085398433654669 and b is -77.81809299734539\n",
      "Iteration 2641, the loss is 62.06589843519058, parameters k is 6.091683068042021 and b is -77.81709299734538\n",
      "Iteration 2642, the loss is 62.02540180580787, parameters k is 6.097967702429372 and b is -77.81609299734538\n",
      "Iteration 2643, the loss is 61.984905176425215, parameters k is 6.104252336816724 and b is -77.81509299734537\n",
      "Iteration 2644, the loss is 61.94440854704254, parameters k is 6.110536971204075 and b is -77.81409299734537\n",
      "Iteration 2645, the loss is 61.90391191765982, parameters k is 6.116821605591427 and b is -77.81309299734536\n",
      "Iteration 2646, the loss is 61.863415288277196, parameters k is 6.123106239978778 and b is -77.81209299734536\n",
      "Iteration 2647, the loss is 61.82291865889444, parameters k is 6.12939087436613 and b is -77.81109299734536\n",
      "Iteration 2648, the loss is 61.78242202951177, parameters k is 6.135675508753481 and b is -77.81009299734535\n",
      "Iteration 2649, the loss is 61.74192540012911, parameters k is 6.141960143140833 and b is -77.80909299734535\n",
      "Iteration 2650, the loss is 61.7014287707464, parameters k is 6.148244777528184 and b is -77.80809299734534\n",
      "Iteration 2651, the loss is 61.66093214136373, parameters k is 6.154529411915536 and b is -77.80709299734534\n",
      "Iteration 2652, the loss is 61.62043551198108, parameters k is 6.160814046302887 and b is -77.80609299734533\n",
      "Iteration 2653, the loss is 61.579938882598356, parameters k is 6.167098680690239 and b is -77.80509299734533\n",
      "Iteration 2654, the loss is 61.539442253215675, parameters k is 6.17338331507759 and b is -77.80409299734532\n",
      "Iteration 2655, the loss is 61.49894562383292, parameters k is 6.179667949464942 and b is -77.80309299734532\n",
      "Iteration 2656, the loss is 61.458448994450286, parameters k is 6.185952583852293 and b is -77.80209299734531\n",
      "Iteration 2657, the loss is 61.417952365067634, parameters k is 6.192237218239645 and b is -77.80109299734531\n",
      "Iteration 2658, the loss is 61.37745573568488, parameters k is 6.198521852626996 and b is -77.8000929973453\n",
      "Iteration 2659, the loss is 61.336959106302224, parameters k is 6.204806487014348 and b is -77.7990929973453\n",
      "Iteration 2660, the loss is 61.29646247691956, parameters k is 6.211091121401699 and b is -77.7980929973453\n",
      "Iteration 2661, the loss is 61.25596584753684, parameters k is 6.2173757557890506 and b is -77.79709299734529\n",
      "Iteration 2662, the loss is 61.21546921815411, parameters k is 6.223660390176402 and b is -77.79609299734528\n",
      "Iteration 2663, the loss is 61.17497258877143, parameters k is 6.2299450245637535 and b is -77.79509299734528\n",
      "Iteration 2664, the loss is 61.1344759593888, parameters k is 6.236229658951105 and b is -77.79409299734527\n",
      "Iteration 2665, the loss is 61.09397933000606, parameters k is 6.2425142933384565 and b is -77.79309299734527\n",
      "Iteration 2666, the loss is 61.05348270062341, parameters k is 6.248798927725808 and b is -77.79209299734526\n",
      "Iteration 2667, the loss is 61.012986071240675, parameters k is 6.2550835621131595 and b is -77.79109299734526\n",
      "Iteration 2668, the loss is 60.972489441857974, parameters k is 6.261368196500511 and b is -77.79009299734525\n",
      "Iteration 2669, the loss is 60.93199281247535, parameters k is 6.2676528308878625 and b is -77.78909299734525\n",
      "Iteration 2670, the loss is 60.891496183092606, parameters k is 6.273937465275214 and b is -77.78809299734525\n",
      "Iteration 2671, the loss is 60.85099955370996, parameters k is 6.2802220996625655 and b is -77.78709299734524\n",
      "Iteration 2672, the loss is 60.81050292432731, parameters k is 6.286506734049917 and b is -77.78609299734524\n",
      "Iteration 2673, the loss is 60.77000629494455, parameters k is 6.2927913684372685 and b is -77.78509299734523\n",
      "Iteration 2674, the loss is 60.72950966556195, parameters k is 6.29907600282462 and b is -77.78409299734523\n",
      "Iteration 2675, the loss is 60.68901303617925, parameters k is 6.3053606372119715 and b is -77.78309299734522\n",
      "Iteration 2676, the loss is 60.6485164067965, parameters k is 6.311645271599323 and b is -77.78209299734522\n",
      "Iteration 2677, the loss is 60.608019777413794, parameters k is 6.3179299059866745 and b is -77.78109299734521\n",
      "Iteration 2678, the loss is 60.56752314803112, parameters k is 6.324214540374026 and b is -77.7800929973452\n",
      "Iteration 2679, the loss is 60.52702651864848, parameters k is 6.3304991747613775 and b is -77.7790929973452\n",
      "Iteration 2680, the loss is 60.48652988926583, parameters k is 6.336783809148729 and b is -77.7780929973452\n",
      "Iteration 2681, the loss is 60.446033259883045, parameters k is 6.3430684435360805 and b is -77.77709299734519\n",
      "Iteration 2682, the loss is 60.40553663050037, parameters k is 6.349353077923432 and b is -77.77609299734519\n",
      "Iteration 2683, the loss is 60.36504000111769, parameters k is 6.3556377123107834 and b is -77.77509299734518\n",
      "Iteration 2684, the loss is 60.32454337173502, parameters k is 6.361922346698135 and b is -77.77409299734518\n",
      "Iteration 2685, the loss is 60.2840467423523, parameters k is 6.368206981085486 and b is -77.77309299734517\n",
      "Iteration 2686, the loss is 60.243550112969714, parameters k is 6.374491615472838 and b is -77.77209299734517\n",
      "Iteration 2687, the loss is 60.203053483586984, parameters k is 6.380776249860189 and b is -77.77109299734516\n",
      "Iteration 2688, the loss is 60.16255685420424, parameters k is 6.387060884247541 and b is -77.77009299734516\n",
      "Iteration 2689, the loss is 60.1220602248216, parameters k is 6.393345518634892 and b is -77.76909299734515\n",
      "Iteration 2690, the loss is 60.081563595438915, parameters k is 6.399630153022244 and b is -77.76809299734515\n",
      "Iteration 2691, the loss is 60.04106696605618, parameters k is 6.405914787409595 and b is -77.76709299734515\n",
      "Iteration 2692, the loss is 60.000570336673576, parameters k is 6.412199421796947 and b is -77.76609299734514\n",
      "Iteration 2693, the loss is 59.960073707290796, parameters k is 6.418484056184298 and b is -77.76509299734514\n",
      "Iteration 2694, the loss is 59.919577077908066, parameters k is 6.42476869057165 and b is -77.76409299734513\n",
      "Iteration 2695, the loss is 59.87908044852547, parameters k is 6.431053324959001 and b is -77.76309299734513\n",
      "Iteration 2696, the loss is 59.838583819142734, parameters k is 6.437337959346353 and b is -77.76209299734512\n",
      "Iteration 2697, the loss is 59.79808718976006, parameters k is 6.443622593733704 and b is -77.76109299734512\n",
      "Iteration 2698, the loss is 59.757590560377395, parameters k is 6.449907228121056 and b is -77.76009299734511\n",
      "Iteration 2699, the loss is 59.71709393099478, parameters k is 6.456191862508407 and b is -77.7590929973451\n",
      "Iteration 2700, the loss is 59.67659730161198, parameters k is 6.462476496895759 and b is -77.7580929973451\n",
      "Iteration 2701, the loss is 59.63610067222933, parameters k is 6.46876113128311 and b is -77.7570929973451\n",
      "Iteration 2702, the loss is 59.59560404284664, parameters k is 6.475045765670462 and b is -77.75609299734509\n",
      "Iteration 2703, the loss is 59.55510741346399, parameters k is 6.481330400057813 and b is -77.75509299734509\n",
      "Iteration 2704, the loss is 59.51461078408128, parameters k is 6.487615034445165 and b is -77.75409299734508\n",
      "Iteration 2705, the loss is 59.47411415469856, parameters k is 6.493899668832516 and b is -77.75309299734508\n",
      "Iteration 2706, the loss is 59.43361752531591, parameters k is 6.500184303219868 and b is -77.75209299734507\n",
      "Iteration 2707, the loss is 59.39312089593318, parameters k is 6.506468937607219 and b is -77.75109299734507\n",
      "Iteration 2708, the loss is 59.35262426655055, parameters k is 6.512753571994571 and b is -77.75009299734506\n",
      "Iteration 2709, the loss is 59.31212763716784, parameters k is 6.519038206381922 and b is -77.74909299734506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2710, the loss is 59.27163100778515, parameters k is 6.525322840769274 and b is -77.74809299734505\n",
      "Iteration 2711, the loss is 59.23113437840246, parameters k is 6.531607475156625 and b is -77.74709299734505\n",
      "Iteration 2712, the loss is 59.190637749019785, parameters k is 6.537892109543977 and b is -77.74609299734504\n",
      "Iteration 2713, the loss is 59.15014111963711, parameters k is 6.544176743931328 and b is -77.74509299734504\n",
      "Iteration 2714, the loss is 59.10964449025436, parameters k is 6.55046137831868 and b is -77.74409299734504\n",
      "Iteration 2715, the loss is 59.06914786087169, parameters k is 6.556746012706031 and b is -77.74309299734503\n",
      "Iteration 2716, the loss is 59.02865123148904, parameters k is 6.563030647093383 and b is -77.74209299734503\n",
      "Iteration 2717, the loss is 58.98815460210629, parameters k is 6.569315281480734 and b is -77.74109299734502\n",
      "Iteration 2718, the loss is 58.94765797272365, parameters k is 6.575599915868086 and b is -77.74009299734502\n",
      "Iteration 2719, the loss is 58.90716134334094, parameters k is 6.581884550255437 and b is -77.73909299734501\n",
      "Iteration 2720, the loss is 58.86666471395825, parameters k is 6.588169184642789 and b is -77.738092997345\n",
      "Iteration 2721, the loss is 58.826168084575535, parameters k is 6.59445381903014 and b is -77.737092997345\n",
      "Iteration 2722, the loss is 58.785671455192876, parameters k is 6.600738453417492 and b is -77.736092997345\n",
      "Iteration 2723, the loss is 58.74517482581018, parameters k is 6.607023087804843 and b is -77.73509299734499\n",
      "Iteration 2724, the loss is 58.704678196427544, parameters k is 6.613307722192195 and b is -77.73409299734499\n",
      "Iteration 2725, the loss is 58.66418156704484, parameters k is 6.619592356579546 and b is -77.73309299734498\n",
      "Iteration 2726, the loss is 58.62368493766216, parameters k is 6.625876990966898 and b is -77.73209299734498\n",
      "Iteration 2727, the loss is 58.58318830827946, parameters k is 6.632161625354249 and b is -77.73109299734497\n",
      "Iteration 2728, the loss is 58.542691678896745, parameters k is 6.638446259741601 and b is -77.73009299734497\n",
      "Iteration 2729, the loss is 58.50219504951407, parameters k is 6.644730894128952 and b is -77.72909299734496\n",
      "Iteration 2730, the loss is 58.461698420131405, parameters k is 6.651015528516304 and b is -77.72809299734496\n",
      "Iteration 2731, the loss is 58.421201790748775, parameters k is 6.657300162903655 and b is -77.72709299734495\n",
      "Iteration 2732, the loss is 58.38070516136606, parameters k is 6.663584797291007 and b is -77.72609299734495\n",
      "Iteration 2733, the loss is 58.34020853198331, parameters k is 6.669869431678358 and b is -77.72509299734494\n",
      "Iteration 2734, the loss is 58.29971190260069, parameters k is 6.67615406606571 and b is -77.72409299734494\n",
      "Iteration 2735, the loss is 58.259215273217976, parameters k is 6.682438700453061 and b is -77.72309299734493\n",
      "Iteration 2736, the loss is 58.218718643835274, parameters k is 6.688723334840413 and b is -77.72209299734493\n",
      "Iteration 2737, the loss is 58.17822201445257, parameters k is 6.695007969227764 and b is -77.72109299734493\n",
      "Iteration 2738, the loss is 58.137725385069935, parameters k is 6.701292603615116 and b is -77.72009299734492\n",
      "Iteration 2739, the loss is 58.0972287556872, parameters k is 6.707577238002467 and b is -77.71909299734492\n",
      "Iteration 2740, the loss is 58.05673212630453, parameters k is 6.713861872389819 and b is -77.71809299734491\n",
      "Iteration 2741, the loss is 58.016235496921766, parameters k is 6.72014650677717 and b is -77.7170929973449\n",
      "Iteration 2742, the loss is 57.975738867539164, parameters k is 6.726431141164522 and b is -77.7160929973449\n",
      "Iteration 2743, the loss is 57.93524223815648, parameters k is 6.732715775551873 and b is -77.7150929973449\n",
      "Iteration 2744, the loss is 57.89474560877378, parameters k is 6.739000409939225 and b is -77.71409299734489\n",
      "Iteration 2745, the loss is 57.854248979391066, parameters k is 6.745285044326576 and b is -77.71309299734489\n",
      "Iteration 2746, the loss is 57.8137523500084, parameters k is 6.751569678713928 and b is -77.71209299734488\n",
      "Iteration 2747, the loss is 57.773255720625706, parameters k is 6.757854313101279 and b is -77.71109299734488\n",
      "Iteration 2748, the loss is 57.73275909124303, parameters k is 6.764138947488631 and b is -77.71009299734487\n",
      "Iteration 2749, the loss is 57.692262461860324, parameters k is 6.770423581875982 and b is -77.70909299734487\n",
      "Iteration 2750, the loss is 57.65176583247761, parameters k is 6.776708216263334 and b is -77.70809299734486\n",
      "Iteration 2751, the loss is 57.611269203094935, parameters k is 6.782992850650685 and b is -77.70709299734486\n",
      "Iteration 2752, the loss is 57.570772573712276, parameters k is 6.789277485038037 and b is -77.70609299734485\n",
      "Iteration 2753, the loss is 57.53027594432963, parameters k is 6.795562119425388 and b is -77.70509299734485\n",
      "Iteration 2754, the loss is 57.48977931494684, parameters k is 6.80184675381274 and b is -77.70409299734484\n",
      "Iteration 2755, the loss is 57.44928268556422, parameters k is 6.808131388200091 and b is -77.70309299734484\n",
      "Iteration 2756, the loss is 57.40878605618151, parameters k is 6.814416022587443 and b is -77.70209299734483\n",
      "Iteration 2757, the loss is 57.36828942679887, parameters k is 6.820700656974794 and b is -77.70109299734483\n",
      "Iteration 2758, the loss is 57.32779279741619, parameters k is 6.826985291362146 and b is -77.70009299734483\n",
      "Iteration 2759, the loss is 57.2872961680335, parameters k is 6.833269925749497 and b is -77.69909299734482\n",
      "Iteration 2760, the loss is 57.24679953865079, parameters k is 6.839554560136849 and b is -77.69809299734482\n",
      "Iteration 2761, the loss is 57.206302909268054, parameters k is 6.8458391945242 and b is -77.69709299734481\n",
      "Iteration 2762, the loss is 57.16580627988538, parameters k is 6.852123828911552 and b is -77.6960929973448\n",
      "Iteration 2763, the loss is 57.12530965050268, parameters k is 6.858408463298903 and b is -77.6950929973448\n",
      "Iteration 2764, the loss is 57.08481302112002, parameters k is 6.864693097686255 and b is -77.6940929973448\n",
      "Iteration 2765, the loss is 57.04431639173741, parameters k is 6.870977732073606 and b is -77.69309299734479\n",
      "Iteration 2766, the loss is 57.00381976235462, parameters k is 6.877262366460958 and b is -77.69209299734479\n",
      "Iteration 2767, the loss is 56.963323132971965, parameters k is 6.883547000848309 and b is -77.69109299734478\n",
      "Iteration 2768, the loss is 56.92282650358926, parameters k is 6.889831635235661 and b is -77.69009299734478\n",
      "Iteration 2769, the loss is 56.88232987420662, parameters k is 6.896116269623012 and b is -77.68909299734477\n",
      "Iteration 2770, the loss is 56.84183324482387, parameters k is 6.9024009040103635 and b is -77.68809299734477\n",
      "Iteration 2771, the loss is 56.80133661544113, parameters k is 6.908685538397715 and b is -77.68709299734476\n",
      "Iteration 2772, the loss is 56.76083998605847, parameters k is 6.9149701727850665 and b is -77.68609299734476\n",
      "Iteration 2773, the loss is 56.72034335667585, parameters k is 6.921254807172418 and b is -77.68509299734475\n",
      "Iteration 2774, the loss is 56.679846727293075, parameters k is 6.9275394415597695 and b is -77.68409299734475\n",
      "Iteration 2775, the loss is 56.639350097910466, parameters k is 6.933824075947121 and b is -77.68309299734474\n",
      "Iteration 2776, the loss is 56.59885346852779, parameters k is 6.9401087103344725 and b is -77.68209299734474\n",
      "Iteration 2777, the loss is 56.558356839145056, parameters k is 6.946393344721824 and b is -77.68109299734473\n",
      "Iteration 2778, the loss is 56.51786020976239, parameters k is 6.9526779791091755 and b is -77.68009299734473\n",
      "Iteration 2779, the loss is 56.47736358037969, parameters k is 6.958962613496527 and b is -77.67909299734472\n",
      "Iteration 2780, the loss is 56.43686695099709, parameters k is 6.9652472478838785 and b is -77.67809299734472\n",
      "Iteration 2781, the loss is 56.39637032161434, parameters k is 6.97153188227123 and b is -77.67709299734472\n",
      "Iteration 2782, the loss is 56.35587369223168, parameters k is 6.9778165166585815 and b is -77.67609299734471\n",
      "Iteration 2783, the loss is 56.315377062848995, parameters k is 6.984101151045933 and b is -77.6750929973447\n",
      "Iteration 2784, the loss is 56.27488043346625, parameters k is 6.9903857854332845 and b is -77.6740929973447\n",
      "Iteration 2785, the loss is 56.23438380408359, parameters k is 6.996670419820636 and b is -77.6730929973447\n",
      "Iteration 2786, the loss is 56.19388717470093, parameters k is 7.0029550542079875 and b is -77.67209299734469\n",
      "Iteration 2787, the loss is 56.153390545318196, parameters k is 7.009239688595339 and b is -77.67109299734469\n",
      "Iteration 2788, the loss is 56.112893915935466, parameters k is 7.0155243229826905 and b is -77.67009299734468\n",
      "Iteration 2789, the loss is 56.072397286552864, parameters k is 7.021808957370042 and b is -77.66909299734468\n",
      "Iteration 2790, the loss is 56.031900657170056, parameters k is 7.0280935917573935 and b is -77.66809299734467\n",
      "Iteration 2791, the loss is 55.99140402778745, parameters k is 7.034378226144745 and b is -77.66709299734467\n",
      "Iteration 2792, the loss is 55.95090739840482, parameters k is 7.0406628605320964 and b is -77.66609299734466\n",
      "Iteration 2793, the loss is 55.91041076902206, parameters k is 7.046947494919448 and b is -77.66509299734466\n",
      "Iteration 2794, the loss is 55.86991413963934, parameters k is 7.053232129306799 and b is -77.66409299734465\n",
      "Iteration 2795, the loss is 55.82941751025679, parameters k is 7.059516763694151 and b is -77.66309299734465\n",
      "Iteration 2796, the loss is 55.788920880873995, parameters k is 7.065801398081502 and b is -77.66209299734464\n",
      "Iteration 2797, the loss is 55.74842425149133, parameters k is 7.072086032468854 and b is -77.66109299734464\n",
      "Iteration 2798, the loss is 55.707927622108684, parameters k is 7.078370666856205 and b is -77.66009299734463\n",
      "Iteration 2799, the loss is 55.66743099272598, parameters k is 7.084655301243557 and b is -77.65909299734463\n",
      "Iteration 2800, the loss is 55.626934363343274, parameters k is 7.090939935630908 and b is -77.65809299734462\n",
      "Iteration 2801, the loss is 55.58643773396059, parameters k is 7.09722457001826 and b is -77.65709299734462\n",
      "Iteration 2802, the loss is 55.5459411045779, parameters k is 7.103509204405611 and b is -77.65609299734462\n",
      "Iteration 2803, the loss is 55.50544447519522, parameters k is 7.109793838792963 and b is -77.65509299734461\n",
      "Iteration 2804, the loss is 55.46494784581252, parameters k is 7.116078473180314 and b is -77.6540929973446\n",
      "Iteration 2805, the loss is 55.424451216429915, parameters k is 7.122363107567666 and b is -77.6530929973446\n",
      "Iteration 2806, the loss is 55.383954587047114, parameters k is 7.128647741955017 and b is -77.6520929973446\n",
      "Iteration 2807, the loss is 55.34345795766453, parameters k is 7.134932376342369 and b is -77.65109299734459\n",
      "Iteration 2808, the loss is 55.30296132828176, parameters k is 7.14121701072972 and b is -77.65009299734459\n",
      "Iteration 2809, the loss is 55.26246469889909, parameters k is 7.147501645117072 and b is -77.64909299734458\n",
      "Iteration 2810, the loss is 55.22196806951637, parameters k is 7.153786279504423 and b is -77.64809299734458\n",
      "Iteration 2811, the loss is 55.18147144013367, parameters k is 7.160070913891775 and b is -77.64709299734457\n",
      "Iteration 2812, the loss is 55.140974810751054, parameters k is 7.166355548279126 and b is -77.64609299734457\n",
      "Iteration 2813, the loss is 55.100478181368345, parameters k is 7.172640182666478 and b is -77.64509299734456\n",
      "Iteration 2814, the loss is 55.0599815519857, parameters k is 7.178924817053829 and b is -77.64409299734456\n",
      "Iteration 2815, the loss is 55.01948492260297, parameters k is 7.185209451441181 and b is -77.64309299734455\n",
      "Iteration 2816, the loss is 54.97898829322028, parameters k is 7.191494085828532 and b is -77.64209299734455\n",
      "Iteration 2817, the loss is 54.93849166383757, parameters k is 7.197778720215884 and b is -77.64109299734454\n",
      "Iteration 2818, the loss is 54.8979950344549, parameters k is 7.204063354603235 and b is -77.64009299734454\n",
      "Iteration 2819, the loss is 54.8574984050723, parameters k is 7.210347988990587 and b is -77.63909299734453\n",
      "Iteration 2820, the loss is 54.817001775689526, parameters k is 7.216632623377938 and b is -77.63809299734453\n",
      "Iteration 2821, the loss is 54.77650514630683, parameters k is 7.22291725776529 and b is -77.63709299734452\n",
      "Iteration 2822, the loss is 54.73600851692414, parameters k is 7.229201892152641 and b is -77.63609299734452\n",
      "Iteration 2823, the loss is 54.695511887541436, parameters k is 7.235486526539993 and b is -77.63509299734451\n",
      "Iteration 2824, the loss is 54.65501525815879, parameters k is 7.241771160927344 and b is -77.63409299734451\n",
      "Iteration 2825, the loss is 54.614518628776054, parameters k is 7.248055795314696 and b is -77.6330929973445\n",
      "Iteration 2826, the loss is 54.57402199939344, parameters k is 7.254340429702047 and b is -77.6320929973445\n",
      "Iteration 2827, the loss is 54.53352537001072, parameters k is 7.260625064089399 and b is -77.6310929973445\n",
      "Iteration 2828, the loss is 54.49302874062804, parameters k is 7.26690969847675 and b is -77.63009299734449\n",
      "Iteration 2829, the loss is 54.452532111245354, parameters k is 7.273194332864102 and b is -77.62909299734449\n",
      "Iteration 2830, the loss is 54.412035481862695, parameters k is 7.279478967251453 and b is -77.62809299734448\n",
      "Iteration 2831, the loss is 54.371538852479915, parameters k is 7.285763601638805 and b is -77.62709299734448\n",
      "Iteration 2832, the loss is 54.331042223097285, parameters k is 7.292048236026156 and b is -77.62609299734447\n",
      "Iteration 2833, the loss is 54.29054559371453, parameters k is 7.298332870413508 and b is -77.62509299734447\n",
      "Iteration 2834, the loss is 54.250048964331874, parameters k is 7.304617504800859 and b is -77.62409299734446\n",
      "Iteration 2835, the loss is 54.20955233494923, parameters k is 7.310902139188211 and b is -77.62309299734446\n",
      "Iteration 2836, the loss is 54.16905570556657, parameters k is 7.317186773575562 and b is -77.62209299734445\n",
      "Iteration 2837, the loss is 54.12855907618379, parameters k is 7.323471407962914 and b is -77.62109299734445\n",
      "Iteration 2838, the loss is 54.088062446801125, parameters k is 7.329756042350265 and b is -77.62009299734444\n",
      "Iteration 2839, the loss is 54.047565817418466, parameters k is 7.336040676737617 and b is -77.61909299734444\n",
      "Iteration 2840, the loss is 54.00706918803582, parameters k is 7.342325311124968 and b is -77.61809299734443\n",
      "Iteration 2841, the loss is 53.966572558653105, parameters k is 7.34860994551232 and b is -77.61709299734443\n",
      "Iteration 2842, the loss is 53.926075929270404, parameters k is 7.354894579899671 and b is -77.61609299734442\n",
      "Iteration 2843, the loss is 53.885579299887674, parameters k is 7.361179214287023 and b is -77.61509299734442\n",
      "Iteration 2844, the loss is 53.84508267050509, parameters k is 7.367463848674374 and b is -77.61409299734441\n",
      "Iteration 2845, the loss is 53.80458604112231, parameters k is 7.373748483061726 and b is -77.61309299734441\n",
      "Iteration 2846, the loss is 53.76408941173963, parameters k is 7.380033117449077 and b is -77.6120929973444\n",
      "Iteration 2847, the loss is 53.72359278235695, parameters k is 7.386317751836429 and b is -77.6110929973444\n",
      "Iteration 2848, the loss is 53.68309615297429, parameters k is 7.39260238622378 and b is -77.6100929973444\n",
      "Iteration 2849, the loss is 53.64259952359163, parameters k is 7.398887020611132 and b is -77.60909299734439\n",
      "Iteration 2850, the loss is 53.602102894208905, parameters k is 7.405171654998483 and b is -77.60809299734439\n",
      "Iteration 2851, the loss is 53.561606264826224, parameters k is 7.411456289385835 and b is -77.60709299734438\n",
      "Iteration 2852, the loss is 53.52110963544355, parameters k is 7.417740923773186 and b is -77.60609299734438\n",
      "Iteration 2853, the loss is 53.48061300606087, parameters k is 7.424025558160538 and b is -77.60509299734437\n",
      "Iteration 2854, the loss is 53.44011637667813, parameters k is 7.430310192547889 and b is -77.60409299734437\n",
      "Iteration 2855, the loss is 53.399619747295425, parameters k is 7.436594826935241 and b is -77.60309299734436\n",
      "Iteration 2856, the loss is 53.35912311791274, parameters k is 7.442879461322592 and b is -77.60209299734436\n",
      "Iteration 2857, the loss is 53.318626488530136, parameters k is 7.449164095709944 and b is -77.60109299734435\n",
      "Iteration 2858, the loss is 53.278129859147406, parameters k is 7.455448730097295 and b is -77.60009299734435\n",
      "Iteration 2859, the loss is 53.237633229764754, parameters k is 7.461733364484647 and b is -77.59909299734434\n",
      "Iteration 2860, the loss is 53.197136600382095, parameters k is 7.468017998871998 and b is -77.59809299734434\n",
      "Iteration 2861, the loss is 53.15663997099929, parameters k is 7.47430263325935 and b is -77.59709299734433\n",
      "Iteration 2862, the loss is 53.11614334161666, parameters k is 7.480587267646701 and b is -77.59609299734433\n",
      "Iteration 2863, the loss is 53.07564671223392, parameters k is 7.486871902034053 and b is -77.59509299734432\n",
      "Iteration 2864, the loss is 53.03515008285131, parameters k is 7.493156536421404 and b is -77.59409299734432\n",
      "Iteration 2865, the loss is 52.99465345346861, parameters k is 7.499441170808756 and b is -77.59309299734431\n",
      "Iteration 2866, the loss is 52.95415682408594, parameters k is 7.505725805196107 and b is -77.59209299734431\n",
      "Iteration 2867, the loss is 52.91366019470322, parameters k is 7.512010439583459 and b is -77.5910929973443\n",
      "Iteration 2868, the loss is 52.87316356532057, parameters k is 7.51829507397081 and b is -77.5900929973443\n",
      "Iteration 2869, the loss is 52.8326669359378, parameters k is 7.524579708358162 and b is -77.5890929973443\n",
      "Iteration 2870, the loss is 52.79217030655518, parameters k is 7.530864342745513 and b is -77.58809299734429\n",
      "Iteration 2871, the loss is 52.75167367717248, parameters k is 7.537148977132865 and b is -77.58709299734429\n",
      "Iteration 2872, the loss is 52.71117704778979, parameters k is 7.543433611520216 and b is -77.58609299734428\n",
      "Iteration 2873, the loss is 52.6706804184071, parameters k is 7.549718245907568 and b is -77.58509299734428\n",
      "Iteration 2874, the loss is 52.630183789024414, parameters k is 7.556002880294919 and b is -77.58409299734427\n",
      "Iteration 2875, the loss is 52.5896871596417, parameters k is 7.562287514682271 and b is -77.58309299734427\n",
      "Iteration 2876, the loss is 52.54919053025906, parameters k is 7.568572149069622 and b is -77.58209299734426\n",
      "Iteration 2877, the loss is 52.50869390087637, parameters k is 7.5748567834569736 and b is -77.58109299734426\n",
      "Iteration 2878, the loss is 52.468197271493615, parameters k is 7.581141417844325 and b is -77.58009299734425\n",
      "Iteration 2879, the loss is 52.42770064211094, parameters k is 7.5874260522316765 and b is -77.57909299734425\n",
      "Iteration 2880, the loss is 52.38720401272828, parameters k is 7.593710686619028 and b is -77.57809299734424\n",
      "Iteration 2881, the loss is 52.34670738334558, parameters k is 7.5999953210063795 and b is -77.57709299734424\n",
      "Iteration 2882, the loss is 52.3062107539629, parameters k is 7.606279955393731 and b is -77.57609299734423\n",
      "Iteration 2883, the loss is 52.26571412458015, parameters k is 7.6125645897810825 and b is -77.57509299734423\n",
      "Iteration 2884, the loss is 52.22521749519751, parameters k is 7.618849224168434 and b is -77.57409299734422\n",
      "Iteration 2885, the loss is 52.18472086581483, parameters k is 7.6251338585557855 and b is -77.57309299734422\n",
      "Iteration 2886, the loss is 52.144224236432265, parameters k is 7.631418492943137 and b is -77.57209299734421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2887, the loss is 52.10372760704947, parameters k is 7.6377031273304885 and b is -77.57109299734421\n",
      "Iteration 2888, the loss is 52.0632309776668, parameters k is 7.64398776171784 and b is -77.5700929973442\n",
      "Iteration 2889, the loss is 52.02273434828404, parameters k is 7.6502723961051915 and b is -77.5690929973442\n",
      "Iteration 2890, the loss is 51.98223771890135, parameters k is 7.656557030492543 and b is -77.5680929973442\n",
      "Iteration 2891, the loss is 51.94174108951879, parameters k is 7.6628416648798945 and b is -77.56709299734419\n",
      "Iteration 2892, the loss is 51.90124446013601, parameters k is 7.669126299267246 and b is -77.56609299734419\n",
      "Iteration 2893, the loss is 51.86074783075344, parameters k is 7.6754109336545975 and b is -77.56509299734418\n",
      "Iteration 2894, the loss is 51.82025120137061, parameters k is 7.681695568041949 and b is -77.56409299734418\n",
      "Iteration 2895, the loss is 51.77975457198798, parameters k is 7.6879802024293005 and b is -77.56309299734417\n",
      "Iteration 2896, the loss is 51.73925794260526, parameters k is 7.694264836816652 and b is -77.56209299734417\n",
      "Iteration 2897, the loss is 51.69876131322261, parameters k is 7.7005494712040035 and b is -77.56109299734416\n",
      "Iteration 2898, the loss is 51.65826468383989, parameters k is 7.706834105591355 and b is -77.56009299734416\n",
      "Iteration 2899, the loss is 51.61776805445722, parameters k is 7.7131187399787065 and b is -77.55909299734415\n",
      "Iteration 2900, the loss is 51.57727142507445, parameters k is 7.719403374366058 and b is -77.55809299734415\n",
      "Iteration 2901, the loss is 51.53677479569191, parameters k is 7.725688008753409 and b is -77.55709299734414\n",
      "Iteration 2902, the loss is 51.49627816630914, parameters k is 7.731972643140761 and b is -77.55609299734414\n",
      "Iteration 2903, the loss is 51.45578153692645, parameters k is 7.738257277528112 and b is -77.55509299734413\n",
      "Iteration 2904, the loss is 51.41528490754382, parameters k is 7.744541911915464 and b is -77.55409299734413\n",
      "Iteration 2905, the loss is 51.37478827816107, parameters k is 7.750826546302815 and b is -77.55309299734412\n",
      "Iteration 2906, the loss is 51.33429164877841, parameters k is 7.757111180690167 and b is -77.55209299734412\n",
      "Iteration 2907, the loss is 51.29379501939571, parameters k is 7.763395815077518 and b is -77.55109299734411\n",
      "Iteration 2908, the loss is 51.25329839001306, parameters k is 7.76968044946487 and b is -77.55009299734411\n",
      "Iteration 2909, the loss is 51.212801760630335, parameters k is 7.775965083852221 and b is -77.5490929973441\n",
      "Iteration 2910, the loss is 51.172305131247654, parameters k is 7.782249718239573 and b is -77.5480929973441\n",
      "Iteration 2911, the loss is 51.13180850186499, parameters k is 7.788534352626924 and b is -77.5470929973441\n",
      "Iteration 2912, the loss is 51.09131187248226, parameters k is 7.794818987014276 and b is -77.54609299734409\n",
      "Iteration 2913, the loss is 51.050815243099585, parameters k is 7.801103621401627 and b is -77.54509299734409\n",
      "Iteration 2914, the loss is 51.01031861371687, parameters k is 7.807388255788979 and b is -77.54409299734408\n",
      "Iteration 2915, the loss is 50.96982198433426, parameters k is 7.81367289017633 and b is -77.54309299734408\n",
      "Iteration 2916, the loss is 50.92932535495162, parameters k is 7.819957524563682 and b is -77.54209299734407\n",
      "Iteration 2917, the loss is 50.88882872556883, parameters k is 7.826242158951033 and b is -77.54109299734407\n",
      "Iteration 2918, the loss is 50.84833209618624, parameters k is 7.832526793338385 and b is -77.54009299734406\n",
      "Iteration 2919, the loss is 50.807835466803446, parameters k is 7.838811427725736 and b is -77.53909299734406\n",
      "Iteration 2920, the loss is 50.76733883742083, parameters k is 7.845096062113088 and b is -77.53809299734405\n",
      "Iteration 2921, the loss is 50.72684220803808, parameters k is 7.851380696500439 and b is -77.53709299734405\n",
      "Iteration 2922, the loss is 50.686345578655384, parameters k is 7.857665330887791 and b is -77.53609299734404\n",
      "Iteration 2923, the loss is 50.645848949272754, parameters k is 7.863949965275142 and b is -77.53509299734404\n",
      "Iteration 2924, the loss is 50.60535231989003, parameters k is 7.870234599662494 and b is -77.53409299734403\n",
      "Iteration 2925, the loss is 50.56485569050732, parameters k is 7.876519234049845 and b is -77.53309299734403\n",
      "Iteration 2926, the loss is 50.524359061124656, parameters k is 7.882803868437197 and b is -77.53209299734402\n",
      "Iteration 2927, the loss is 50.483862431742, parameters k is 7.889088502824548 and b is -77.53109299734402\n",
      "Iteration 2928, the loss is 50.443365802359224, parameters k is 7.8953731372119 and b is -77.53009299734401\n",
      "Iteration 2929, the loss is 50.40286917297657, parameters k is 7.901657771599251 and b is -77.52909299734401\n",
      "Iteration 2930, the loss is 50.36237254359392, parameters k is 7.907942405986603 and b is -77.528092997344\n",
      "Iteration 2931, the loss is 50.321875914211205, parameters k is 7.914227040373954 and b is -77.527092997344\n",
      "Iteration 2932, the loss is 50.28137928482856, parameters k is 7.920511674761306 and b is -77.526092997344\n",
      "Iteration 2933, the loss is 50.2408826554459, parameters k is 7.926796309148657 and b is -77.52509299734399\n",
      "Iteration 2934, the loss is 50.200386026063164, parameters k is 7.933080943536009 and b is -77.52409299734398\n",
      "Iteration 2935, the loss is 50.15988939668041, parameters k is 7.93936557792336 and b is -77.52309299734398\n",
      "Iteration 2936, the loss is 50.11939276729772, parameters k is 7.945650212310712 and b is -77.52209299734398\n",
      "Iteration 2937, the loss is 50.07889613791513, parameters k is 7.951934846698063 and b is -77.52109299734397\n",
      "Iteration 2938, the loss is 50.0383995085324, parameters k is 7.958219481085415 and b is -77.52009299734397\n",
      "Iteration 2939, the loss is 49.997902879149684, parameters k is 7.964504115472766 and b is -77.51909299734396\n",
      "Iteration 2940, the loss is 49.957406249767075, parameters k is 7.970788749860118 and b is -77.51809299734396\n",
      "Iteration 2941, the loss is 49.91690962038436, parameters k is 7.977073384247469 and b is -77.51709299734395\n",
      "Iteration 2942, the loss is 49.87641299100164, parameters k is 7.983358018634821 and b is -77.51609299734395\n",
      "Iteration 2943, the loss is 49.83591636161898, parameters k is 7.989642653022172 and b is -77.51509299734394\n",
      "Iteration 2944, the loss is 49.79541973223624, parameters k is 7.995927287409524 and b is -77.51409299734394\n",
      "Iteration 2945, the loss is 49.75492310285359, parameters k is 8.002211921796876 and b is -77.51309299734393\n",
      "Iteration 2946, the loss is 49.7144264734709, parameters k is 8.008496556184229 and b is -77.51209299734393\n",
      "Iteration 2947, the loss is 49.67392984408825, parameters k is 8.014781190571581 and b is -77.51109299734392\n",
      "Iteration 2948, the loss is 49.633433214705484, parameters k is 8.021065824958933 and b is -77.51009299734392\n",
      "Iteration 2949, the loss is 49.59293658532278, parameters k is 8.027350459346286 and b is -77.50909299734391\n",
      "Iteration 2950, the loss is 49.55243995594013, parameters k is 8.033635093733638 and b is -77.50809299734391\n",
      "Iteration 2951, the loss is 49.511943326557414, parameters k is 8.03991972812099 and b is -77.5070929973439\n",
      "Iteration 2952, the loss is 49.47144669717473, parameters k is 8.046204362508343 and b is -77.5060929973439\n",
      "Iteration 2953, the loss is 49.430950067792054, parameters k is 8.052488996895695 and b is -77.5050929973439\n",
      "Iteration 2954, the loss is 49.39045343840939, parameters k is 8.058773631283048 and b is -77.50409299734389\n",
      "Iteration 2955, the loss is 49.34995680902662, parameters k is 8.0650582656704 and b is -77.50309299734388\n",
      "Iteration 2956, the loss is 49.30946017964396, parameters k is 8.071342900057752 and b is -77.50209299734388\n",
      "Iteration 2957, the loss is 49.26896355026123, parameters k is 8.077627534445105 and b is -77.50109299734387\n",
      "Iteration 2958, the loss is 49.228466920878645, parameters k is 8.083912168832457 and b is -77.50009299734387\n",
      "Iteration 2959, the loss is 49.18797029149588, parameters k is 8.09019680321981 and b is -77.49909299734387\n",
      "Iteration 2960, the loss is 49.14747366211321, parameters k is 8.096481437607162 and b is -77.49809299734386\n",
      "Iteration 2961, the loss is 49.106977032730505, parameters k is 8.102766071994514 and b is -77.49709299734386\n",
      "Iteration 2962, the loss is 49.06648040334781, parameters k is 8.109050706381867 and b is -77.49609299734385\n",
      "Iteration 2963, the loss is 49.02598377396511, parameters k is 8.115335340769219 and b is -77.49509299734385\n",
      "Iteration 2964, the loss is 48.98548714458246, parameters k is 8.121619975156571 and b is -77.49409299734384\n",
      "Iteration 2965, the loss is 48.94499051519974, parameters k is 8.127904609543924 and b is -77.49309299734384\n",
      "Iteration 2966, the loss is 48.90449388581696, parameters k is 8.134189243931276 and b is -77.49209299734383\n",
      "Iteration 2967, the loss is 48.863997256434324, parameters k is 8.140473878318629 and b is -77.49109299734383\n",
      "Iteration 2968, the loss is 48.82350062705162, parameters k is 8.146758512705981 and b is -77.49009299734382\n",
      "Iteration 2969, the loss is 48.78300399766896, parameters k is 8.153043147093333 and b is -77.48909299734382\n",
      "Iteration 2970, the loss is 48.742507368286304, parameters k is 8.159327781480686 and b is -77.48809299734381\n",
      "Iteration 2971, the loss is 48.70201073890357, parameters k is 8.165612415868038 and b is -77.48709299734381\n",
      "Iteration 2972, the loss is 48.66151410952086, parameters k is 8.17189705025539 and b is -77.4860929973438\n",
      "Iteration 2973, the loss is 48.62101748013821, parameters k is 8.178181684642743 and b is -77.4850929973438\n",
      "Iteration 2974, the loss is 48.58052085075548, parameters k is 8.184466319030095 and b is -77.4840929973438\n",
      "Iteration 2975, the loss is 48.540024221372775, parameters k is 8.190750953417448 and b is -77.48309299734379\n",
      "Iteration 2976, the loss is 48.49952759199012, parameters k is 8.1970355878048 and b is -77.48209299734378\n",
      "Iteration 2977, the loss is 48.459030962607486, parameters k is 8.203320222192152 and b is -77.48109299734378\n",
      "Iteration 2978, the loss is 48.4185343332247, parameters k is 8.209604856579505 and b is -77.48009299734377\n",
      "Iteration 2979, the loss is 48.37803770384208, parameters k is 8.215889490966857 and b is -77.47909299734377\n",
      "Iteration 2980, the loss is 48.33754107445936, parameters k is 8.22217412535421 and b is -77.47809299734377\n",
      "Iteration 2981, the loss is 48.29704444507664, parameters k is 8.228458759741562 and b is -77.47709299734376\n",
      "Iteration 2982, the loss is 48.25654781569397, parameters k is 8.234743394128914 and b is -77.47609299734376\n",
      "Iteration 2983, the loss is 48.21605118631123, parameters k is 8.241028028516267 and b is -77.47509299734375\n",
      "Iteration 2984, the loss is 48.17555455692852, parameters k is 8.247312662903619 and b is -77.47409299734375\n",
      "Iteration 2985, the loss is 48.13505792754587, parameters k is 8.253597297290971 and b is -77.47309299734374\n",
      "Iteration 2986, the loss is 48.094561298163185, parameters k is 8.259881931678324 and b is -77.47209299734374\n",
      "Iteration 2987, the loss is 48.05406466878045, parameters k is 8.266166566065676 and b is -77.47109299734373\n",
      "Iteration 2988, the loss is 48.01356803939785, parameters k is 8.272451200453029 and b is -77.47009299734373\n",
      "Iteration 2989, the loss is 47.97307141001514, parameters k is 8.278735834840381 and b is -77.46909299734372\n",
      "Iteration 2990, the loss is 47.93257478063241, parameters k is 8.285020469227733 and b is -77.46809299734372\n",
      "Iteration 2991, the loss is 47.89207815124974, parameters k is 8.291305103615086 and b is -77.46709299734371\n",
      "Iteration 2992, the loss is 47.851581521867026, parameters k is 8.297589738002438 and b is -77.46609299734371\n",
      "Iteration 2993, the loss is 47.81108489248433, parameters k is 8.30387437238979 and b is -77.4650929973437\n",
      "Iteration 2994, the loss is 47.770588263101665, parameters k is 8.310159006777143 and b is -77.4640929973437\n",
      "Iteration 2995, the loss is 47.730091633718956, parameters k is 8.316443641164495 and b is -77.4630929973437\n",
      "Iteration 2996, the loss is 47.68959500433625, parameters k is 8.322728275551848 and b is -77.46209299734369\n",
      "Iteration 2997, the loss is 47.649098374953546, parameters k is 8.3290129099392 and b is -77.46109299734368\n",
      "Iteration 2998, the loss is 47.60860174557083, parameters k is 8.335297544326552 and b is -77.46009299734368\n",
      "Iteration 2999, the loss is 47.56810511618818, parameters k is 8.341582178713905 and b is -77.45909299734367\n",
      "Iteration 3000, the loss is 47.52760848680547, parameters k is 8.347866813101257 and b is -77.45809299734367\n",
      "Iteration 3001, the loss is 47.487111857422825, parameters k is 8.35415144748861 and b is -77.45709299734366\n",
      "Iteration 3002, the loss is 47.44661522804011, parameters k is 8.360436081875962 and b is -77.45609299734366\n",
      "Iteration 3003, the loss is 47.406118598657415, parameters k is 8.366720716263314 and b is -77.45509299734366\n",
      "Iteration 3004, the loss is 47.365621969274706, parameters k is 8.373005350650667 and b is -77.45409299734365\n",
      "Iteration 3005, the loss is 47.325125339892026, parameters k is 8.37928998503802 and b is -77.45309299734365\n",
      "Iteration 3006, the loss is 47.284628710509274, parameters k is 8.385574619425372 and b is -77.45209299734364\n",
      "Iteration 3007, the loss is 47.24413208112663, parameters k is 8.391859253812724 and b is -77.45109299734364\n",
      "Iteration 3008, the loss is 47.203635451743914, parameters k is 8.398143888200076 and b is -77.45009299734363\n",
      "Iteration 3009, the loss is 47.16313882236128, parameters k is 8.404428522587429 and b is -77.44909299734363\n",
      "Iteration 3010, the loss is 47.1226421929785, parameters k is 8.410713156974781 and b is -77.44809299734362\n",
      "Iteration 3011, the loss is 47.08214556359583, parameters k is 8.416997791362133 and b is -77.44709299734362\n",
      "Iteration 3012, the loss is 47.04164893421316, parameters k is 8.423282425749486 and b is -77.44609299734361\n",
      "Iteration 3013, the loss is 47.00115230483045, parameters k is 8.429567060136838 and b is -77.44509299734361\n",
      "Iteration 3014, the loss is 46.96065567544779, parameters k is 8.43585169452419 and b is -77.4440929973436\n",
      "Iteration 3015, the loss is 46.92015904606515, parameters k is 8.442136328911543 and b is -77.4430929973436\n",
      "Iteration 3016, the loss is 46.879662416682436, parameters k is 8.448420963298895 and b is -77.4420929973436\n",
      "Iteration 3017, the loss is 46.83916578729968, parameters k is 8.454705597686248 and b is -77.44109299734359\n",
      "Iteration 3018, the loss is 46.798669157917054, parameters k is 8.4609902320736 and b is -77.44009299734358\n",
      "Iteration 3019, the loss is 46.75817252853436, parameters k is 8.467274866460953 and b is -77.43909299734358\n",
      "Iteration 3020, the loss is 46.717675899151686, parameters k is 8.473559500848305 and b is -77.43809299734357\n",
      "Iteration 3021, the loss is 46.6771792697689, parameters k is 8.479844135235657 and b is -77.43709299734357\n",
      "Iteration 3022, the loss is 46.63668264038623, parameters k is 8.48612876962301 and b is -77.43609299734356\n",
      "Iteration 3023, the loss is 46.59618601100352, parameters k is 8.492413404010362 and b is -77.43509299734356\n",
      "Iteration 3024, the loss is 46.55568938162082, parameters k is 8.498698038397714 and b is -77.43409299734355\n",
      "Iteration 3025, the loss is 46.51519275223809, parameters k is 8.504982672785067 and b is -77.43309299734355\n",
      "Iteration 3026, the loss is 46.474696122855505, parameters k is 8.51126730717242 and b is -77.43209299734355\n",
      "Iteration 3027, the loss is 46.43419949347275, parameters k is 8.517551941559772 and b is -77.43109299734354\n",
      "Iteration 3028, the loss is 46.393702864090095, parameters k is 8.523836575947124 and b is -77.43009299734354\n",
      "Iteration 3029, the loss is 46.353206234707365, parameters k is 8.530121210334476 and b is -77.42909299734353\n",
      "Iteration 3030, the loss is 46.312709605324656, parameters k is 8.536405844721829 and b is -77.42809299734353\n",
      "Iteration 3031, the loss is 46.272212975942, parameters k is 8.542690479109181 and b is -77.42709299734352\n",
      "Iteration 3032, the loss is 46.231716346559274, parameters k is 8.548975113496533 and b is -77.42609299734352\n",
      "Iteration 3033, the loss is 46.19121971717659, parameters k is 8.555259747883886 and b is -77.42509299734351\n",
      "Iteration 3034, the loss is 46.15072308779397, parameters k is 8.561544382271238 and b is -77.42409299734351\n",
      "Iteration 3035, the loss is 46.11022645841122, parameters k is 8.56782901665859 and b is -77.4230929973435\n",
      "Iteration 3036, the loss is 46.069729829028574, parameters k is 8.574113651045943 and b is -77.4220929973435\n",
      "Iteration 3037, the loss is 46.02923319964585, parameters k is 8.580398285433295 and b is -77.4210929973435\n",
      "Iteration 3038, the loss is 45.98873657026317, parameters k is 8.586682919820648 and b is -77.42009299734349\n",
      "Iteration 3039, the loss is 45.94823994088048, parameters k is 8.592967554208 and b is -77.41909299734348\n",
      "Iteration 3040, the loss is 45.907743311497754, parameters k is 8.599252188595353 and b is -77.41809299734348\n",
      "Iteration 3041, the loss is 45.867246682115045, parameters k is 8.605536822982705 and b is -77.41709299734347\n",
      "Iteration 3042, the loss is 45.82675005273235, parameters k is 8.611821457370057 and b is -77.41609299734347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3043, the loss is 45.78625342334964, parameters k is 8.61810609175741 and b is -77.41509299734346\n",
      "Iteration 3044, the loss is 45.74575679396697, parameters k is 8.624390726144762 and b is -77.41409299734346\n",
      "Iteration 3045, the loss is 45.705260164584324, parameters k is 8.630675360532114 and b is -77.41309299734345\n",
      "Iteration 3046, the loss is 45.66476353520163, parameters k is 8.636959994919467 and b is -77.41209299734345\n",
      "Iteration 3047, the loss is 45.62426690581889, parameters k is 8.64324462930682 and b is -77.41109299734345\n",
      "Iteration 3048, the loss is 45.58377027643618, parameters k is 8.649529263694172 and b is -77.41009299734344\n",
      "Iteration 3049, the loss is 45.54327364705349, parameters k is 8.655813898081524 and b is -77.40909299734344\n",
      "Iteration 3050, the loss is 45.5027770176709, parameters k is 8.662098532468876 and b is -77.40809299734343\n",
      "Iteration 3051, the loss is 45.462280388288136, parameters k is 8.668383166856229 and b is -77.40709299734343\n",
      "Iteration 3052, the loss is 45.421783758905434, parameters k is 8.674667801243581 and b is -77.40609299734342\n",
      "Iteration 3053, the loss is 45.38128712952275, parameters k is 8.680952435630934 and b is -77.40509299734342\n",
      "Iteration 3054, the loss is 45.34079050014007, parameters k is 8.687237070018286 and b is -77.40409299734341\n",
      "Iteration 3055, the loss is 45.30029387075736, parameters k is 8.693521704405638 and b is -77.4030929973434\n",
      "Iteration 3056, the loss is 45.25979724137465, parameters k is 8.69980633879299 and b is -77.4020929973434\n",
      "Iteration 3057, the loss is 45.21930061199198, parameters k is 8.706090973180343 and b is -77.4010929973434\n",
      "Iteration 3058, the loss is 45.1788039826093, parameters k is 8.712375607567695 and b is -77.40009299734339\n",
      "Iteration 3059, the loss is 45.13830735322657, parameters k is 8.718660241955048 and b is -77.39909299734339\n",
      "Iteration 3060, the loss is 45.09781072384389, parameters k is 8.7249448763424 and b is -77.39809299734338\n",
      "Iteration 3061, the loss is 45.05731409446122, parameters k is 8.731229510729753 and b is -77.39709299734338\n",
      "Iteration 3062, the loss is 45.016817465078525, parameters k is 8.737514145117105 and b is -77.39609299734337\n",
      "Iteration 3063, the loss is 44.97632083569577, parameters k is 8.743798779504457 and b is -77.39509299734337\n",
      "Iteration 3064, the loss is 44.93582420631315, parameters k is 8.75008341389181 and b is -77.39409299734336\n",
      "Iteration 3065, the loss is 44.89532757693041, parameters k is 8.756368048279162 and b is -77.39309299734336\n",
      "Iteration 3066, the loss is 44.85483094754773, parameters k is 8.762652682666515 and b is -77.39209299734335\n",
      "Iteration 3067, the loss is 44.81433431816509, parameters k is 8.768937317053867 and b is -77.39109299734335\n",
      "Iteration 3068, the loss is 44.77383768878238, parameters k is 8.77522195144122 and b is -77.39009299734334\n",
      "Iteration 3069, the loss is 44.73334105939969, parameters k is 8.781506585828572 and b is -77.38909299734334\n",
      "Iteration 3070, the loss is 44.692844430016955, parameters k is 8.787791220215924 and b is -77.38809299734334\n",
      "Iteration 3071, the loss is 44.65234780063432, parameters k is 8.794075854603276 and b is -77.38709299734333\n",
      "Iteration 3072, the loss is 44.61185117125162, parameters k is 8.800360488990629 and b is -77.38609299734333\n",
      "Iteration 3073, the loss is 44.57135454186887, parameters k is 8.806645123377981 and b is -77.38509299734332\n",
      "Iteration 3074, the loss is 44.53085791248625, parameters k is 8.812929757765334 and b is -77.38409299734332\n",
      "Iteration 3075, the loss is 44.490361283103496, parameters k is 8.819214392152686 and b is -77.38309299734331\n",
      "Iteration 3076, the loss is 44.449864653720844, parameters k is 8.825499026540038 and b is -77.3820929973433\n",
      "Iteration 3077, the loss is 44.40936802433811, parameters k is 8.83178366092739 and b is -77.3810929973433\n",
      "Iteration 3078, the loss is 44.36887139495547, parameters k is 8.838068295314743 and b is -77.3800929973433\n",
      "Iteration 3079, the loss is 44.32837476557281, parameters k is 8.844352929702096 and b is -77.37909299734329\n",
      "Iteration 3080, the loss is 44.28787813619005, parameters k is 8.850637564089448 and b is -77.37809299734329\n",
      "Iteration 3081, the loss is 44.24738150680735, parameters k is 8.8569221984768 and b is -77.37709299734328\n",
      "Iteration 3082, the loss is 44.20688487742464, parameters k is 8.863206832864153 and b is -77.37609299734328\n",
      "Iteration 3083, the loss is 44.166388248041926, parameters k is 8.869491467251505 and b is -77.37509299734327\n",
      "Iteration 3084, the loss is 44.12589161865927, parameters k is 8.875776101638857 and b is -77.37409299734327\n",
      "Iteration 3085, the loss is 44.08539498927654, parameters k is 8.88206073602621 and b is -77.37309299734326\n",
      "Iteration 3086, the loss is 44.04489835989385, parameters k is 8.888345370413562 and b is -77.37209299734326\n",
      "Iteration 3087, the loss is 44.00440173051117, parameters k is 8.894630004800915 and b is -77.37109299734325\n",
      "Iteration 3088, the loss is 43.96390510112847, parameters k is 8.900914639188267 and b is -77.37009299734325\n",
      "Iteration 3089, the loss is 43.923408471745816, parameters k is 8.90719927357562 and b is -77.36909299734324\n",
      "Iteration 3090, the loss is 43.88291184236318, parameters k is 8.913483907962972 and b is -77.36809299734324\n",
      "Iteration 3091, the loss is 43.842415212980455, parameters k is 8.919768542350324 and b is -77.36709299734324\n",
      "Iteration 3092, the loss is 43.80191858359767, parameters k is 8.926053176737677 and b is -77.36609299734323\n",
      "Iteration 3093, the loss is 43.76142195421504, parameters k is 8.932337811125029 and b is -77.36509299734323\n",
      "Iteration 3094, the loss is 43.72092532483238, parameters k is 8.938622445512381 and b is -77.36409299734322\n",
      "Iteration 3095, the loss is 43.68042869544964, parameters k is 8.944907079899734 and b is -77.36309299734322\n",
      "Iteration 3096, the loss is 43.63993206606694, parameters k is 8.951191714287086 and b is -77.36209299734321\n",
      "Iteration 3097, the loss is 43.59943543668429, parameters k is 8.957476348674438 and b is -77.3610929973432\n",
      "Iteration 3098, the loss is 43.55893880730158, parameters k is 8.96376098306179 and b is -77.3600929973432\n",
      "Iteration 3099, the loss is 43.51844217791886, parameters k is 8.970045617449143 and b is -77.3590929973432\n",
      "Iteration 3100, the loss is 43.477945548536184, parameters k is 8.976330251836496 and b is -77.35809299734319\n",
      "Iteration 3101, the loss is 43.43744891915348, parameters k is 8.982614886223848 and b is -77.35709299734319\n",
      "Iteration 3102, the loss is 43.39695228977086, parameters k is 8.9888995206112 and b is -77.35609299734318\n",
      "Iteration 3103, the loss is 43.35645566038808, parameters k is 8.995184154998553 and b is -77.35509299734318\n",
      "Iteration 3104, the loss is 43.315959031005406, parameters k is 9.001468789385905 and b is -77.35409299734317\n",
      "Iteration 3105, the loss is 43.2754624016227, parameters k is 9.007753423773257 and b is -77.35309299734317\n",
      "Iteration 3106, the loss is 43.23496577223999, parameters k is 9.01403805816061 and b is -77.35209299734316\n",
      "Iteration 3107, the loss is 43.194469142857365, parameters k is 9.020322692547962 and b is -77.35109299734316\n",
      "Iteration 3108, the loss is 43.15397251347467, parameters k is 9.026607326935315 and b is -77.35009299734315\n",
      "Iteration 3109, the loss is 43.113475884091905, parameters k is 9.032891961322667 and b is -77.34909299734315\n",
      "Iteration 3110, the loss is 43.07297925470925, parameters k is 9.03917659571002 and b is -77.34809299734314\n",
      "Iteration 3111, the loss is 43.03248262532655, parameters k is 9.045461230097372 and b is -77.34709299734314\n",
      "Iteration 3112, the loss is 42.99198599594385, parameters k is 9.051745864484724 and b is -77.34609299734313\n",
      "Iteration 3113, the loss is 42.951489366561134, parameters k is 9.058030498872077 and b is -77.34509299734313\n",
      "Iteration 3114, the loss is 42.91099273717852, parameters k is 9.064315133259429 and b is -77.34409299734313\n",
      "Iteration 3115, the loss is 42.87049610779576, parameters k is 9.070599767646781 and b is -77.34309299734312\n",
      "Iteration 3116, the loss is 42.8299994784131, parameters k is 9.076884402034134 and b is -77.34209299734312\n",
      "Iteration 3117, the loss is 42.78950284903046, parameters k is 9.083169036421486 and b is -77.34109299734311\n",
      "Iteration 3118, the loss is 42.74900621964772, parameters k is 9.089453670808838 and b is -77.3400929973431\n",
      "Iteration 3119, the loss is 42.708509590265024, parameters k is 9.09573830519619 and b is -77.3390929973431\n",
      "Iteration 3120, the loss is 42.66801296088235, parameters k is 9.102022939583543 and b is -77.3380929973431\n",
      "Iteration 3121, the loss is 42.62751633149962, parameters k is 9.108307573970896 and b is -77.33709299734309\n",
      "Iteration 3122, the loss is 42.587019702116976, parameters k is 9.114592208358248 and b is -77.33609299734309\n",
      "Iteration 3123, the loss is 42.54652307273423, parameters k is 9.1208768427456 and b is -77.33509299734308\n",
      "Iteration 3124, the loss is 42.50602644335156, parameters k is 9.127161477132953 and b is -77.33409299734308\n",
      "Iteration 3125, the loss is 42.46552981396886, parameters k is 9.133446111520305 and b is -77.33309299734307\n",
      "Iteration 3126, the loss is 42.425033184586134, parameters k is 9.139730745907658 and b is -77.33209299734307\n",
      "Iteration 3127, the loss is 42.38453655520343, parameters k is 9.14601538029501 and b is -77.33109299734306\n",
      "Iteration 3128, the loss is 42.344039925820766, parameters k is 9.152300014682362 and b is -77.33009299734306\n",
      "Iteration 3129, the loss is 42.30354329643809, parameters k is 9.158584649069715 and b is -77.32909299734305\n",
      "Iteration 3130, the loss is 42.263046667055406, parameters k is 9.164869283457067 and b is -77.32809299734305\n",
      "Iteration 3131, the loss is 42.22255003767273, parameters k is 9.17115391784442 and b is -77.32709299734304\n",
      "Iteration 3132, the loss is 42.182053408289946, parameters k is 9.177438552231772 and b is -77.32609299734304\n",
      "Iteration 3133, the loss is 42.14155677890726, parameters k is 9.183723186619124 and b is -77.32509299734303\n",
      "Iteration 3134, the loss is 42.10106014952459, parameters k is 9.190007821006477 and b is -77.32409299734303\n",
      "Iteration 3135, the loss is 42.06056352014191, parameters k is 9.196292455393829 and b is -77.32309299734302\n",
      "Iteration 3136, the loss is 42.02006689075925, parameters k is 9.202577089781181 and b is -77.32209299734302\n",
      "Iteration 3137, the loss is 41.97957026137657, parameters k is 9.208861724168534 and b is -77.32109299734302\n",
      "Iteration 3138, the loss is 41.93907363199382, parameters k is 9.215146358555886 and b is -77.32009299734301\n",
      "Iteration 3139, the loss is 41.898577002611134, parameters k is 9.221430992943239 and b is -77.319092997343\n",
      "Iteration 3140, the loss is 41.85808037322845, parameters k is 9.227715627330591 and b is -77.318092997343\n",
      "Iteration 3141, the loss is 41.81758374384575, parameters k is 9.234000261717943 and b is -77.317092997343\n",
      "Iteration 3142, the loss is 41.77708711446305, parameters k is 9.240284896105296 and b is -77.31609299734299\n",
      "Iteration 3143, the loss is 41.73659048508039, parameters k is 9.246569530492648 and b is -77.31509299734299\n",
      "Iteration 3144, the loss is 41.6960938556977, parameters k is 9.25285416488 and b is -77.31409299734298\n",
      "Iteration 3145, the loss is 41.65559722631501, parameters k is 9.259138799267353 and b is -77.31309299734298\n",
      "Iteration 3146, the loss is 41.61510059693224, parameters k is 9.265423433654705 and b is -77.31209299734297\n",
      "Iteration 3147, the loss is 41.57460396754965, parameters k is 9.271708068042058 and b is -77.31109299734297\n",
      "Iteration 3148, the loss is 41.53410733816697, parameters k is 9.27799270242941 and b is -77.31009299734296\n",
      "Iteration 3149, the loss is 41.49361070878417, parameters k is 9.284277336816762 and b is -77.30909299734296\n",
      "Iteration 3150, the loss is 41.45311407940151, parameters k is 9.290561971204115 and b is -77.30809299734295\n",
      "Iteration 3151, the loss is 41.41261745001879, parameters k is 9.296846605591467 and b is -77.30709299734295\n",
      "Iteration 3152, the loss is 41.37212082063616, parameters k is 9.30313123997882 and b is -77.30609299734294\n",
      "Iteration 3153, the loss is 41.33162419125346, parameters k is 9.309415874366172 and b is -77.30509299734294\n",
      "Iteration 3154, the loss is 41.29112756187074, parameters k is 9.315700508753524 and b is -77.30409299734293\n",
      "Iteration 3155, the loss is 41.250630932488036, parameters k is 9.321985143140877 and b is -77.30309299734293\n",
      "Iteration 3156, the loss is 41.210134303105356, parameters k is 9.328269777528229 and b is -77.30209299734292\n",
      "Iteration 3157, the loss is 41.16963767372266, parameters k is 9.334554411915581 and b is -77.30109299734292\n",
      "Iteration 3158, the loss is 41.12914104433992, parameters k is 9.340839046302934 and b is -77.30009299734292\n",
      "Iteration 3159, the loss is 41.08864441495728, parameters k is 9.347123680690286 and b is -77.29909299734291\n",
      "Iteration 3160, the loss is 41.04814778557457, parameters k is 9.353408315077639 and b is -77.2980929973429\n",
      "Iteration 3161, the loss is 41.00765115619193, parameters k is 9.359692949464991 and b is -77.2970929973429\n",
      "Iteration 3162, the loss is 40.96715452680919, parameters k is 9.365977583852343 and b is -77.2960929973429\n",
      "Iteration 3163, the loss is 40.92665789742652, parameters k is 9.372262218239696 and b is -77.29509299734289\n",
      "Iteration 3164, the loss is 40.88616126804381, parameters k is 9.378546852627048 and b is -77.29409299734289\n",
      "Iteration 3165, the loss is 40.84566463866113, parameters k is 9.3848314870144 and b is -77.29309299734288\n",
      "Iteration 3166, the loss is 40.80516800927841, parameters k is 9.391116121401753 and b is -77.29209299734288\n",
      "Iteration 3167, the loss is 40.76467137989574, parameters k is 9.397400755789105 and b is -77.29109299734287\n",
      "Iteration 3168, the loss is 40.72417475051306, parameters k is 9.403685390176458 and b is -77.29009299734287\n",
      "Iteration 3169, the loss is 40.683678121130356, parameters k is 9.40997002456381 and b is -77.28909299734286\n",
      "Iteration 3170, the loss is 40.64318149174762, parameters k is 9.416254658951162 and b is -77.28809299734286\n",
      "Iteration 3171, the loss is 40.60268486236496, parameters k is 9.422539293338515 and b is -77.28709299734285\n",
      "Iteration 3172, the loss is 40.56218823298233, parameters k is 9.428823927725867 and b is -77.28609299734285\n",
      "Iteration 3173, the loss is 40.52169160359955, parameters k is 9.43510856211322 and b is -77.28509299734284\n",
      "Iteration 3174, the loss is 40.481194974216855, parameters k is 9.441393196500572 and b is -77.28409299734284\n",
      "Iteration 3175, the loss is 40.44069834483419, parameters k is 9.447677830887924 and b is -77.28309299734283\n",
      "Iteration 3176, the loss is 40.40020171545142, parameters k is 9.453962465275277 and b is -77.28209299734283\n",
      "Iteration 3177, the loss is 40.35970508606877, parameters k is 9.460247099662629 and b is -77.28109299734282\n",
      "Iteration 3178, the loss is 40.31920845668615, parameters k is 9.466531734049981 and b is -77.28009299734282\n",
      "Iteration 3179, the loss is 40.27871182730348, parameters k is 9.472816368437334 and b is -77.27909299734281\n",
      "Iteration 3180, the loss is 40.23821519792071, parameters k is 9.479101002824686 and b is -77.27809299734281\n",
      "Iteration 3181, the loss is 40.197718568537994, parameters k is 9.485385637212039 and b is -77.2770929973428\n",
      "Iteration 3182, the loss is 40.15722193915535, parameters k is 9.491670271599391 and b is -77.2760929973428\n",
      "Iteration 3183, the loss is 40.11672530977264, parameters k is 9.497954905986743 and b is -77.2750929973428\n",
      "Iteration 3184, the loss is 40.07622868038993, parameters k is 9.504239540374096 and b is -77.27409299734279\n",
      "Iteration 3185, the loss is 40.03573205100723, parameters k is 9.510524174761448 and b is -77.27309299734279\n",
      "Iteration 3186, the loss is 39.99523542162455, parameters k is 9.5168088091488 and b is -77.27209299734278\n",
      "Iteration 3187, the loss is 39.95473879224185, parameters k is 9.523093443536153 and b is -77.27109299734278\n",
      "Iteration 3188, the loss is 39.91424216285917, parameters k is 9.529378077923505 and b is -77.27009299734277\n",
      "Iteration 3189, the loss is 39.87374553347648, parameters k is 9.535662712310858 and b is -77.26909299734277\n",
      "Iteration 3190, the loss is 39.833248904093786, parameters k is 9.54194734669821 and b is -77.26809299734276\n",
      "Iteration 3191, the loss is 39.79275227471114, parameters k is 9.548231981085562 and b is -77.26709299734276\n",
      "Iteration 3192, the loss is 39.75225564532843, parameters k is 9.554516615472915 and b is -77.26609299734275\n",
      "Iteration 3193, the loss is 39.711759015945745, parameters k is 9.560801249860267 and b is -77.26509299734275\n",
      "Iteration 3194, the loss is 39.67126238656301, parameters k is 9.56708588424762 and b is -77.26409299734274\n",
      "Iteration 3195, the loss is 39.63076575718029, parameters k is 9.573370518634972 and b is -77.26309299734274\n",
      "Iteration 3196, the loss is 39.59026912779761, parameters k is 9.579655153022324 and b is -77.26209299734273\n",
      "Iteration 3197, the loss is 39.54977249841496, parameters k is 9.585939787409677 and b is -77.26109299734273\n",
      "Iteration 3198, the loss is 39.509275869032315, parameters k is 9.59222442179703 and b is -77.26009299734272\n",
      "Iteration 3199, the loss is 39.46877923964958, parameters k is 9.598509056184382 and b is -77.25909299734272\n",
      "Iteration 3200, the loss is 39.428282610266834, parameters k is 9.604793690571734 and b is -77.25809299734271\n",
      "Iteration 3201, the loss is 39.38778598088418, parameters k is 9.611078324959086 and b is -77.25709299734271\n",
      "Iteration 3202, the loss is 39.347289351501495, parameters k is 9.617362959346439 and b is -77.2560929973427\n",
      "Iteration 3203, the loss is 39.30679272211882, parameters k is 9.623647593733791 and b is -77.2550929973427\n",
      "Iteration 3204, the loss is 39.266296092736155, parameters k is 9.629932228121143 and b is -77.2540929973427\n",
      "Iteration 3205, the loss is 39.22579946335339, parameters k is 9.636216862508496 and b is -77.25309299734269\n",
      "Iteration 3206, the loss is 39.18530283397073, parameters k is 9.642501496895848 and b is -77.25209299734269\n",
      "Iteration 3207, the loss is 39.144806204588, parameters k is 9.6487861312832 and b is -77.25109299734268\n",
      "Iteration 3208, the loss is 39.10430957520532, parameters k is 9.655070765670553 and b is -77.25009299734268\n",
      "Iteration 3209, the loss is 39.06381294582262, parameters k is 9.661355400057905 and b is -77.24909299734267\n",
      "Iteration 3210, the loss is 39.02331631643993, parameters k is 9.667640034445258 and b is -77.24809299734267\n",
      "Iteration 3211, the loss is 38.982819687057244, parameters k is 9.67392466883261 and b is -77.24709299734266\n",
      "Iteration 3212, the loss is 38.942323057674564, parameters k is 9.680209303219963 and b is -77.24609299734266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3213, the loss is 38.901826428291876, parameters k is 9.686493937607315 and b is -77.24509299734265\n",
      "Iteration 3214, the loss is 38.86132979890911, parameters k is 9.692778571994667 and b is -77.24409299734265\n",
      "Iteration 3215, the loss is 38.82083316952647, parameters k is 9.69906320638202 and b is -77.24309299734264\n",
      "Iteration 3216, the loss is 38.78033654014378, parameters k is 9.705347840769372 and b is -77.24209299734264\n",
      "Iteration 3217, the loss is 38.739839910761106, parameters k is 9.711632475156724 and b is -77.24109299734263\n",
      "Iteration 3218, the loss is 38.69934328137841, parameters k is 9.717917109544077 and b is -77.24009299734263\n",
      "Iteration 3219, the loss is 38.658846651995724, parameters k is 9.72420174393143 and b is -77.23909299734262\n",
      "Iteration 3220, the loss is 38.61835002261307, parameters k is 9.730486378318782 and b is -77.23809299734262\n",
      "Iteration 3221, the loss is 38.577853393230285, parameters k is 9.736771012706134 and b is -77.23709299734261\n",
      "Iteration 3222, the loss is 38.53735676384762, parameters k is 9.743055647093486 and b is -77.23609299734261\n",
      "Iteration 3223, the loss is 38.4968601344649, parameters k is 9.749340281480839 and b is -77.2350929973426\n",
      "Iteration 3224, the loss is 38.45636350508225, parameters k is 9.755624915868191 and b is -77.2340929973426\n",
      "Iteration 3225, the loss is 38.41586687569957, parameters k is 9.761909550255544 and b is -77.2330929973426\n",
      "Iteration 3226, the loss is 38.37537024631687, parameters k is 9.768194184642896 and b is -77.23209299734259\n",
      "Iteration 3227, the loss is 38.33487361693418, parameters k is 9.774478819030248 and b is -77.23109299734259\n",
      "Iteration 3228, the loss is 38.294376987551495, parameters k is 9.7807634534176 and b is -77.23009299734258\n",
      "Iteration 3229, the loss is 38.2538803581688, parameters k is 9.787048087804953 and b is -77.22909299734258\n",
      "Iteration 3230, the loss is 38.21338372878611, parameters k is 9.793332722192305 and b is -77.22809299734257\n",
      "Iteration 3231, the loss is 38.17288709940341, parameters k is 9.799617356579658 and b is -77.22709299734257\n",
      "Iteration 3232, the loss is 38.132390470020695, parameters k is 9.80590199096701 and b is -77.22609299734256\n",
      "Iteration 3233, the loss is 38.091893840638, parameters k is 9.812186625354363 and b is -77.22509299734256\n",
      "Iteration 3234, the loss is 38.05139721125531, parameters k is 9.818471259741715 and b is -77.22409299734255\n",
      "Iteration 3235, the loss is 38.01090058187261, parameters k is 9.824755894129067 and b is -77.22309299734255\n",
      "Iteration 3236, the loss is 37.97040395248993, parameters k is 9.83104052851642 and b is -77.22209299734254\n",
      "Iteration 3237, the loss is 37.92990732310724, parameters k is 9.837325162903772 and b is -77.22109299734254\n",
      "Iteration 3238, the loss is 37.88941069372456, parameters k is 9.843609797291125 and b is -77.22009299734253\n",
      "Iteration 3239, the loss is 37.84891406434186, parameters k is 9.849894431678477 and b is -77.21909299734253\n",
      "Iteration 3240, the loss is 37.808417434959125, parameters k is 9.85617906606583 and b is -77.21809299734252\n",
      "Iteration 3241, the loss is 37.76792080557649, parameters k is 9.862463700453182 and b is -77.21709299734252\n",
      "Iteration 3242, the loss is 37.72742417619379, parameters k is 9.868748334840534 and b is -77.21609299734251\n",
      "Iteration 3243, the loss is 37.68692754681108, parameters k is 9.875032969227886 and b is -77.21509299734251\n",
      "Iteration 3244, the loss is 37.64643091742839, parameters k is 9.881317603615239 and b is -77.2140929973425\n",
      "Iteration 3245, the loss is 37.60593428804567, parameters k is 9.887602238002591 and b is -77.2130929973425\n",
      "Iteration 3246, the loss is 37.565437658663015, parameters k is 9.893886872389944 and b is -77.2120929973425\n",
      "Iteration 3247, the loss is 37.52494102928031, parameters k is 9.900171506777296 and b is -77.21109299734249\n",
      "Iteration 3248, the loss is 37.484444399897605, parameters k is 9.906456141164648 and b is -77.21009299734249\n",
      "Iteration 3249, the loss is 37.4439477705149, parameters k is 9.912740775552 and b is -77.20909299734248\n",
      "Iteration 3250, the loss is 37.40345114113223, parameters k is 9.919025409939353 and b is -77.20809299734248\n",
      "Iteration 3251, the loss is 37.36295451174951, parameters k is 9.925310044326705 and b is -77.20709299734247\n",
      "Iteration 3252, the loss is 37.32245788236682, parameters k is 9.931594678714058 and b is -77.20609299734247\n",
      "Iteration 3253, the loss is 37.28196125298416, parameters k is 9.93787931310141 and b is -77.20509299734246\n",
      "Iteration 3254, the loss is 37.241464623601466, parameters k is 9.944163947488763 and b is -77.20409299734246\n",
      "Iteration 3255, the loss is 37.200967994218736, parameters k is 9.950448581876115 and b is -77.20309299734245\n",
      "Iteration 3256, the loss is 37.16047136483607, parameters k is 9.956733216263467 and b is -77.20209299734245\n",
      "Iteration 3257, the loss is 37.119974735453354, parameters k is 9.96301785065082 and b is -77.20109299734244\n",
      "Iteration 3258, the loss is 37.079478106070646, parameters k is 9.969302485038172 and b is -77.20009299734244\n",
      "Iteration 3259, the loss is 37.03898147668799, parameters k is 9.975587119425525 and b is -77.19909299734243\n",
      "Iteration 3260, the loss is 36.998484847305306, parameters k is 9.981871753812877 and b is -77.19809299734243\n",
      "Iteration 3261, the loss is 36.9579882179226, parameters k is 9.98815638820023 and b is -77.19709299734242\n",
      "Iteration 3262, the loss is 36.91749158853987, parameters k is 9.994441022587582 and b is -77.19609299734242\n",
      "Iteration 3263, the loss is 36.876994959157194, parameters k is 10.000725656974934 and b is -77.19509299734241\n",
      "Iteration 3264, the loss is 36.83649832977447, parameters k is 10.007010291362286 and b is -77.19409299734241\n",
      "Iteration 3265, the loss is 36.79600170039185, parameters k is 10.013294925749639 and b is -77.1930929973424\n",
      "Iteration 3266, the loss is 36.75550507100916, parameters k is 10.019579560136991 and b is -77.1920929973424\n",
      "Iteration 3267, the loss is 36.71500844162638, parameters k is 10.025864194524344 and b is -77.1910929973424\n",
      "Iteration 3268, the loss is 36.67451181224375, parameters k is 10.032148828911696 and b is -77.19009299734239\n",
      "Iteration 3269, the loss is 36.634015182861035, parameters k is 10.038433463299048 and b is -77.18909299734239\n",
      "Iteration 3270, the loss is 36.59351855347836, parameters k is 10.0447180976864 and b is -77.18809299734238\n",
      "Iteration 3271, the loss is 36.55302192409568, parameters k is 10.051002732073753 and b is -77.18709299734238\n",
      "Iteration 3272, the loss is 36.512525294712994, parameters k is 10.057287366461106 and b is -77.18609299734237\n",
      "Iteration 3273, the loss is 36.4720286653303, parameters k is 10.063572000848458 and b is -77.18509299734237\n",
      "Iteration 3274, the loss is 36.43153203594758, parameters k is 10.06985663523581 and b is -77.18409299734236\n",
      "Iteration 3275, the loss is 36.39103540656492, parameters k is 10.076141269623163 and b is -77.18309299734236\n",
      "Iteration 3276, the loss is 36.350538777182166, parameters k is 10.082425904010515 and b is -77.18209299734235\n",
      "Iteration 3277, the loss is 36.31004214779949, parameters k is 10.088710538397867 and b is -77.18109299734235\n",
      "Iteration 3278, the loss is 36.26954551841681, parameters k is 10.09499517278522 and b is -77.18009299734234\n",
      "Iteration 3279, the loss is 36.22904888903413, parameters k is 10.101279807172572 and b is -77.17909299734234\n",
      "Iteration 3280, the loss is 36.18855225965142, parameters k is 10.107564441559925 and b is -77.17809299734233\n",
      "Iteration 3281, the loss is 36.148055630268715, parameters k is 10.113849075947277 and b is -77.17709299734233\n",
      "Iteration 3282, the loss is 36.10755900088608, parameters k is 10.12013371033463 and b is -77.17609299734232\n",
      "Iteration 3283, the loss is 36.067062371503326, parameters k is 10.126418344721982 and b is -77.17509299734232\n",
      "Iteration 3284, the loss is 36.026565742120646, parameters k is 10.132702979109334 and b is -77.17409299734231\n",
      "Iteration 3285, the loss is 35.98606911273795, parameters k is 10.138987613496687 and b is -77.17309299734231\n",
      "Iteration 3286, the loss is 35.94557248335526, parameters k is 10.145272247884039 and b is -77.1720929973423\n",
      "Iteration 3287, the loss is 35.9050758539726, parameters k is 10.151556882271391 and b is -77.1710929973423\n",
      "Iteration 3288, the loss is 35.864579224589896, parameters k is 10.157841516658744 and b is -77.1700929973423\n",
      "Iteration 3289, the loss is 35.824082595207194, parameters k is 10.164126151046096 and b is -77.16909299734229\n",
      "Iteration 3290, the loss is 35.7835859658245, parameters k is 10.170410785433448 and b is -77.16809299734228\n",
      "Iteration 3291, the loss is 35.74308933644178, parameters k is 10.1766954198208 and b is -77.16709299734228\n",
      "Iteration 3292, the loss is 35.702592707059104, parameters k is 10.182980054208153 and b is -77.16609299734228\n",
      "Iteration 3293, the loss is 35.66209607767642, parameters k is 10.189264688595506 and b is -77.16509299734227\n",
      "Iteration 3294, the loss is 35.62159944829373, parameters k is 10.195549322982858 and b is -77.16409299734227\n",
      "Iteration 3295, the loss is 35.581102818911006, parameters k is 10.20183395737021 and b is -77.16309299734226\n",
      "Iteration 3296, the loss is 35.54060618952831, parameters k is 10.208118591757563 and b is -77.16209299734226\n",
      "Iteration 3297, the loss is 35.500109560145624, parameters k is 10.214403226144915 and b is -77.16109299734225\n",
      "Iteration 3298, the loss is 35.45961293076292, parameters k is 10.220687860532268 and b is -77.16009299734225\n",
      "Iteration 3299, the loss is 35.41911630138028, parameters k is 10.22697249491962 and b is -77.15909299734224\n",
      "Iteration 3300, the loss is 35.37861967199754, parameters k is 10.233257129306972 and b is -77.15809299734224\n",
      "Iteration 3301, the loss is 35.338123042614896, parameters k is 10.239541763694325 and b is -77.15709299734223\n",
      "Iteration 3302, the loss is 35.297626413232194, parameters k is 10.245826398081677 and b is -77.15609299734223\n",
      "Iteration 3303, the loss is 35.2571297838495, parameters k is 10.25211103246903 and b is -77.15509299734222\n",
      "Iteration 3304, the loss is 35.2166331544668, parameters k is 10.258395666856382 and b is -77.15409299734222\n",
      "Iteration 3305, the loss is 35.17613652508414, parameters k is 10.264680301243734 and b is -77.15309299734221\n",
      "Iteration 3306, the loss is 35.135639895701416, parameters k is 10.270964935631087 and b is -77.15209299734221\n",
      "Iteration 3307, the loss is 35.095143266318736, parameters k is 10.277249570018439 and b is -77.1510929973422\n",
      "Iteration 3308, the loss is 35.054646636936056, parameters k is 10.283534204405791 and b is -77.1500929973422\n",
      "Iteration 3309, the loss is 35.01415000755334, parameters k is 10.289818838793144 and b is -77.1490929973422\n",
      "Iteration 3310, the loss is 34.97365337817061, parameters k is 10.296103473180496 and b is -77.14809299734219\n",
      "Iteration 3311, the loss is 34.933156748787916, parameters k is 10.302388107567849 and b is -77.14709299734218\n",
      "Iteration 3312, the loss is 34.89266011940529, parameters k is 10.308672741955201 and b is -77.14609299734218\n",
      "Iteration 3313, the loss is 34.85216349002253, parameters k is 10.314957376342553 and b is -77.14509299734218\n",
      "Iteration 3314, the loss is 34.811666860639875, parameters k is 10.321242010729906 and b is -77.14409299734217\n",
      "Iteration 3315, the loss is 34.77117023125718, parameters k is 10.327526645117258 and b is -77.14309299734217\n",
      "Iteration 3316, the loss is 34.730673601874486, parameters k is 10.33381127950461 and b is -77.14209299734216\n",
      "Iteration 3317, the loss is 34.69017697249175, parameters k is 10.340095913891963 and b is -77.14109299734216\n",
      "Iteration 3318, the loss is 34.64968034310908, parameters k is 10.346380548279315 and b is -77.14009299734215\n",
      "Iteration 3319, the loss is 34.60918371372645, parameters k is 10.352665182666668 and b is -77.13909299734215\n",
      "Iteration 3320, the loss is 34.56868708434372, parameters k is 10.35894981705402 and b is -77.13809299734214\n",
      "Iteration 3321, the loss is 34.528190454961006, parameters k is 10.365234451441372 and b is -77.13709299734214\n",
      "Iteration 3322, the loss is 34.48769382557834, parameters k is 10.371519085828725 and b is -77.13609299734213\n",
      "Iteration 3323, the loss is 34.44719719619564, parameters k is 10.377803720216077 and b is -77.13509299734213\n",
      "Iteration 3324, the loss is 34.406700566812894, parameters k is 10.38408835460343 and b is -77.13409299734212\n",
      "Iteration 3325, the loss is 34.36620393743023, parameters k is 10.390372988990782 and b is -77.13309299734212\n",
      "Iteration 3326, the loss is 34.325707308047555, parameters k is 10.396657623378134 and b is -77.13209299734211\n",
      "Iteration 3327, the loss is 34.28521067866487, parameters k is 10.402942257765487 and b is -77.13109299734211\n",
      "Iteration 3328, the loss is 34.24471404928213, parameters k is 10.409226892152839 and b is -77.1300929973421\n",
      "Iteration 3329, the loss is 34.20421741989947, parameters k is 10.415511526540191 and b is -77.1290929973421\n",
      "Iteration 3330, the loss is 34.163720790516805, parameters k is 10.421796160927544 and b is -77.1280929973421\n",
      "Iteration 3331, the loss is 34.12322416113409, parameters k is 10.428080795314896 and b is -77.12709299734209\n",
      "Iteration 3332, the loss is 34.0827275317514, parameters k is 10.434365429702249 and b is -77.12609299734208\n",
      "Iteration 3333, the loss is 34.042230902368715, parameters k is 10.440650064089601 and b is -77.12509299734208\n",
      "Iteration 3334, the loss is 34.001734272986006, parameters k is 10.446934698476953 and b is -77.12409299734207\n",
      "Iteration 3335, the loss is 33.96123764360328, parameters k is 10.453219332864306 and b is -77.12309299734207\n",
      "Iteration 3336, the loss is 33.920741014220624, parameters k is 10.459503967251658 and b is -77.12209299734207\n",
      "Iteration 3337, the loss is 33.88024438483793, parameters k is 10.46578860163901 and b is -77.12109299734206\n",
      "Iteration 3338, the loss is 33.83974775545522, parameters k is 10.472073236026363 and b is -77.12009299734206\n",
      "Iteration 3339, the loss is 33.79925112607254, parameters k is 10.478357870413715 and b is -77.11909299734205\n",
      "Iteration 3340, the loss is 33.758754496689875, parameters k is 10.484642504801068 and b is -77.11809299734205\n",
      "Iteration 3341, the loss is 33.71825786730718, parameters k is 10.49092713918842 and b is -77.11709299734204\n",
      "Iteration 3342, the loss is 33.67776123792447, parameters k is 10.497211773575772 and b is -77.11609299734204\n",
      "Iteration 3343, the loss is 33.63726460854172, parameters k is 10.503496407963125 and b is -77.11509299734203\n",
      "Iteration 3344, the loss is 33.59676797915911, parameters k is 10.509781042350477 and b is -77.11409299734203\n",
      "Iteration 3345, the loss is 33.55627134977643, parameters k is 10.51606567673783 and b is -77.11309299734202\n",
      "Iteration 3346, the loss is 33.51577472039369, parameters k is 10.522350311125182 and b is -77.11209299734202\n",
      "Iteration 3347, the loss is 33.475278091011006, parameters k is 10.528634945512534 and b is -77.11109299734201\n",
      "Iteration 3348, the loss is 33.434781461628305, parameters k is 10.534919579899887 and b is -77.11009299734201\n",
      "Iteration 3349, the loss is 33.39428483224562, parameters k is 10.541204214287239 and b is -77.109092997342\n",
      "Iteration 3350, the loss is 33.35378820286294, parameters k is 10.547488848674591 and b is -77.108092997342\n",
      "Iteration 3351, the loss is 33.3132915734802, parameters k is 10.553773483061944 and b is -77.107092997342\n",
      "Iteration 3352, the loss is 33.27279494409752, parameters k is 10.560058117449296 and b is -77.10609299734199\n",
      "Iteration 3353, the loss is 33.23229831471483, parameters k is 10.566342751836649 and b is -77.10509299734198\n",
      "Iteration 3354, the loss is 33.19180168533211, parameters k is 10.572627386224001 and b is -77.10409299734198\n",
      "Iteration 3355, the loss is 33.15130505594939, parameters k is 10.578912020611353 and b is -77.10309299734197\n",
      "Iteration 3356, the loss is 33.11080842656676, parameters k is 10.585196654998706 and b is -77.10209299734197\n",
      "Iteration 3357, the loss is 33.07031179718404, parameters k is 10.591481289386058 and b is -77.10109299734196\n",
      "Iteration 3358, the loss is 33.029815167801374, parameters k is 10.59776592377341 and b is -77.10009299734196\n",
      "Iteration 3359, the loss is 32.9893185384187, parameters k is 10.604050558160763 and b is -77.09909299734196\n",
      "Iteration 3360, the loss is 32.94882190903598, parameters k is 10.610335192548115 and b is -77.09809299734195\n",
      "Iteration 3361, the loss is 32.90832527965334, parameters k is 10.616619826935468 and b is -77.09709299734195\n",
      "Iteration 3362, the loss is 32.86782865027061, parameters k is 10.62290446132282 and b is -77.09609299734194\n",
      "Iteration 3363, the loss is 32.82733202088791, parameters k is 10.629189095710172 and b is -77.09509299734194\n",
      "Iteration 3364, the loss is 32.786835391505186, parameters k is 10.635473730097525 and b is -77.09409299734193\n",
      "Iteration 3365, the loss is 32.74633876212255, parameters k is 10.641758364484877 and b is -77.09309299734193\n",
      "Iteration 3366, the loss is 32.70584213273981, parameters k is 10.64804299887223 and b is -77.09209299734192\n",
      "Iteration 3367, the loss is 32.66534550335714, parameters k is 10.654327633259582 and b is -77.09109299734192\n",
      "Iteration 3368, the loss is 32.62484887397442, parameters k is 10.660612267646934 and b is -77.09009299734191\n",
      "Iteration 3369, the loss is 32.58435224459174, parameters k is 10.666896902034287 and b is -77.08909299734191\n",
      "Iteration 3370, the loss is 32.54385561520904, parameters k is 10.67318153642164 and b is -77.0880929973419\n",
      "Iteration 3371, the loss is 32.50335898582637, parameters k is 10.679466170808992 and b is -77.0870929973419\n",
      "Iteration 3372, the loss is 32.46286235644369, parameters k is 10.685750805196344 and b is -77.0860929973419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3373, the loss is 32.42236572706097, parameters k is 10.692035439583696 and b is -77.08509299734189\n",
      "Iteration 3374, the loss is 32.38186909767827, parameters k is 10.698320073971049 and b is -77.08409299734188\n",
      "Iteration 3375, the loss is 32.341372468295575, parameters k is 10.704604708358401 and b is -77.08309299734188\n",
      "Iteration 3376, the loss is 32.30087583891291, parameters k is 10.710889342745753 and b is -77.08209299734187\n",
      "Iteration 3377, the loss is 32.260379209530214, parameters k is 10.717173977133106 and b is -77.08109299734187\n",
      "Iteration 3378, the loss is 32.21988258014753, parameters k is 10.723458611520458 and b is -77.08009299734186\n",
      "Iteration 3379, the loss is 32.179385950764825, parameters k is 10.72974324590781 and b is -77.07909299734186\n",
      "Iteration 3380, the loss is 32.13888932138214, parameters k is 10.736027880295163 and b is -77.07809299734186\n",
      "Iteration 3381, the loss is 32.09839269199943, parameters k is 10.742312514682515 and b is -77.07709299734185\n",
      "Iteration 3382, the loss is 32.05789606261675, parameters k is 10.748597149069868 and b is -77.07609299734185\n",
      "Iteration 3383, the loss is 32.017399433234075, parameters k is 10.75488178345722 and b is -77.07509299734184\n",
      "Iteration 3384, the loss is 31.976902803851367, parameters k is 10.761166417844573 and b is -77.07409299734184\n",
      "Iteration 3385, the loss is 31.936406174468676, parameters k is 10.767451052231925 and b is -77.07309299734183\n",
      "Iteration 3386, the loss is 31.895909545086027, parameters k is 10.773735686619277 and b is -77.07209299734183\n",
      "Iteration 3387, the loss is 31.855412915703294, parameters k is 10.78002032100663 and b is -77.07109299734182\n",
      "Iteration 3388, the loss is 31.814916286320585, parameters k is 10.786304955393982 and b is -77.07009299734182\n",
      "Iteration 3389, the loss is 31.77441965693789, parameters k is 10.792589589781334 and b is -77.06909299734181\n",
      "Iteration 3390, the loss is 31.733923027555207, parameters k is 10.798874224168687 and b is -77.06809299734181\n",
      "Iteration 3391, the loss is 31.693426398172512, parameters k is 10.80515885855604 and b is -77.0670929973418\n",
      "Iteration 3392, the loss is 31.65292976878979, parameters k is 10.811443492943392 and b is -77.0660929973418\n",
      "Iteration 3393, the loss is 31.612433139407113, parameters k is 10.817728127330744 and b is -77.0650929973418\n",
      "Iteration 3394, the loss is 31.57193651002445, parameters k is 10.824012761718096 and b is -77.06409299734179\n",
      "Iteration 3395, the loss is 31.531439880641734, parameters k is 10.830297396105449 and b is -77.06309299734178\n",
      "Iteration 3396, the loss is 31.49094325125901, parameters k is 10.836582030492801 and b is -77.06209299734178\n",
      "Iteration 3397, the loss is 31.45044662187634, parameters k is 10.842866664880153 and b is -77.06109299734177\n",
      "Iteration 3398, the loss is 31.409949992493647, parameters k is 10.849151299267506 and b is -77.06009299734177\n",
      "Iteration 3399, the loss is 31.36945336311097, parameters k is 10.855435933654858 and b is -77.05909299734176\n",
      "Iteration 3400, the loss is 31.32895673372827, parameters k is 10.86172056804221 and b is -77.05809299734176\n",
      "Iteration 3401, the loss is 31.288460104345575, parameters k is 10.868005202429563 and b is -77.05709299734175\n",
      "Iteration 3402, the loss is 31.24796347496287, parameters k is 10.874289836816915 and b is -77.05609299734175\n",
      "Iteration 3403, the loss is 31.207466845580182, parameters k is 10.880574471204268 and b is -77.05509299734175\n",
      "Iteration 3404, the loss is 31.166970216197512, parameters k is 10.88685910559162 and b is -77.05409299734174\n",
      "Iteration 3405, the loss is 31.126473586814793, parameters k is 10.893143739978973 and b is -77.05309299734174\n",
      "Iteration 3406, the loss is 31.08597695743208, parameters k is 10.899428374366325 and b is -77.05209299734173\n",
      "Iteration 3407, the loss is 31.045480328049386, parameters k is 10.905713008753677 and b is -77.05109299734173\n",
      "Iteration 3408, the loss is 31.004983698666713, parameters k is 10.91199764314103 and b is -77.05009299734172\n",
      "Iteration 3409, the loss is 30.964487069284022, parameters k is 10.918282277528382 and b is -77.04909299734172\n",
      "Iteration 3410, the loss is 30.923990439901313, parameters k is 10.924566911915734 and b is -77.04809299734171\n",
      "Iteration 3411, the loss is 30.883493810518594, parameters k is 10.930851546303087 and b is -77.04709299734171\n",
      "Iteration 3412, the loss is 30.842997181135953, parameters k is 10.93713618069044 and b is -77.0460929973417\n",
      "Iteration 3413, the loss is 30.802500551753248, parameters k is 10.943420815077792 and b is -77.0450929973417\n",
      "Iteration 3414, the loss is 30.762003922370546, parameters k is 10.949705449465144 and b is -77.04409299734169\n",
      "Iteration 3415, the loss is 30.72150729298786, parameters k is 10.955990083852496 and b is -77.04309299734169\n",
      "Iteration 3416, the loss is 30.681010663605164, parameters k is 10.962274718239849 and b is -77.04209299734168\n",
      "Iteration 3417, the loss is 30.64051403422248, parameters k is 10.968559352627201 and b is -77.04109299734168\n",
      "Iteration 3418, the loss is 30.60001740483977, parameters k is 10.974843987014554 and b is -77.04009299734167\n",
      "Iteration 3419, the loss is 30.55952077545707, parameters k is 10.981128621401906 and b is -77.03909299734167\n",
      "Iteration 3420, the loss is 30.51902414607443, parameters k is 10.987413255789258 and b is -77.03809299734166\n",
      "Iteration 3421, the loss is 30.478527516691702, parameters k is 10.99369789017661 and b is -77.03709299734166\n",
      "Iteration 3422, the loss is 30.438030887309008, parameters k is 10.999982524563963 and b is -77.03609299734165\n",
      "Iteration 3423, the loss is 30.397534257926317, parameters k is 11.006267158951315 and b is -77.03509299734165\n",
      "Iteration 3424, the loss is 30.357037628543647, parameters k is 11.012551793338668 and b is -77.03409299734165\n",
      "Iteration 3425, the loss is 30.316540999160903, parameters k is 11.01883642772602 and b is -77.03309299734164\n",
      "Iteration 3426, the loss is 30.27604436977823, parameters k is 11.025121062113373 and b is -77.03209299734164\n",
      "Iteration 3427, the loss is 30.235547740395567, parameters k is 11.031405696500725 and b is -77.03109299734163\n",
      "Iteration 3428, the loss is 30.195051111012866, parameters k is 11.037690330888077 and b is -77.03009299734163\n",
      "Iteration 3429, the loss is 30.154554481630186, parameters k is 11.04397496527543 and b is -77.02909299734162\n",
      "Iteration 3430, the loss is 30.114057852247473, parameters k is 11.050259599662782 and b is -77.02809299734162\n",
      "Iteration 3431, the loss is 30.07356122286479, parameters k is 11.056544234050135 and b is -77.02709299734161\n",
      "Iteration 3432, the loss is 30.033064593482123, parameters k is 11.062828868437487 and b is -77.0260929973416\n",
      "Iteration 3433, the loss is 29.992567964099383, parameters k is 11.06911350282484 and b is -77.0250929973416\n",
      "Iteration 3434, the loss is 29.952071334716713, parameters k is 11.075398137212192 and b is -77.0240929973416\n",
      "Iteration 3435, the loss is 29.91157470533401, parameters k is 11.081682771599544 and b is -77.02309299734159\n",
      "Iteration 3436, the loss is 29.871078075951324, parameters k is 11.087967405986896 and b is -77.02209299734159\n",
      "Iteration 3437, the loss is 29.830581446568615, parameters k is 11.094252040374249 and b is -77.02109299734158\n",
      "Iteration 3438, the loss is 29.790084817185903, parameters k is 11.100536674761601 and b is -77.02009299734158\n",
      "Iteration 3439, the loss is 29.749588187803226, parameters k is 11.106821309148954 and b is -77.01909299734157\n",
      "Iteration 3440, the loss is 29.70909155842054, parameters k is 11.113105943536306 and b is -77.01809299734157\n",
      "Iteration 3441, the loss is 29.668594929037873, parameters k is 11.119390577923658 and b is -77.01709299734156\n",
      "Iteration 3442, the loss is 29.62809829965513, parameters k is 11.12567521231101 and b is -77.01609299734156\n",
      "Iteration 3443, the loss is 29.58760167027242, parameters k is 11.131959846698363 and b is -77.01509299734155\n",
      "Iteration 3444, the loss is 29.54710504088981, parameters k is 11.138244481085716 and b is -77.01409299734155\n",
      "Iteration 3445, the loss is 29.50660841150706, parameters k is 11.144529115473068 and b is -77.01309299734154\n",
      "Iteration 3446, the loss is 29.466111782124376, parameters k is 11.15081374986042 and b is -77.01209299734154\n",
      "Iteration 3447, the loss is 29.425615152741667, parameters k is 11.157098384247773 and b is -77.01109299734154\n",
      "Iteration 3448, the loss is 29.38511852335898, parameters k is 11.163383018635125 and b is -77.01009299734153\n",
      "Iteration 3449, the loss is 29.344621893976274, parameters k is 11.169667653022477 and b is -77.00909299734153\n",
      "Iteration 3450, the loss is 29.30412526459362, parameters k is 11.17595228740983 and b is -77.00809299734152\n",
      "Iteration 3451, the loss is 29.2636286352109, parameters k is 11.182236921797182 and b is -77.00709299734152\n",
      "Iteration 3452, the loss is 29.223132005828194, parameters k is 11.188521556184535 and b is -77.00609299734151\n",
      "Iteration 3453, the loss is 29.18263537644553, parameters k is 11.194806190571887 and b is -77.0050929973415\n",
      "Iteration 3454, the loss is 29.142138747062866, parameters k is 11.20109082495924 and b is -77.0040929973415\n",
      "Iteration 3455, the loss is 29.1016421176801, parameters k is 11.207375459346592 and b is -77.0030929973415\n",
      "Iteration 3456, the loss is 29.061145488297434, parameters k is 11.213660093733944 and b is -77.00209299734149\n",
      "Iteration 3457, the loss is 29.02064885891477, parameters k is 11.219944728121297 and b is -77.00109299734149\n",
      "Iteration 3458, the loss is 28.980152229532045, parameters k is 11.226229362508649 and b is -77.00009299734148\n",
      "Iteration 3459, the loss is 28.939655600149354, parameters k is 11.232513996896001 and b is -76.99909299734148\n",
      "Iteration 3460, the loss is 28.89915897076669, parameters k is 11.238798631283354 and b is -76.99809299734147\n",
      "Iteration 3461, the loss is 28.85866234138398, parameters k is 11.245083265670706 and b is -76.99709299734147\n",
      "Iteration 3462, the loss is 28.818165712001292, parameters k is 11.251367900058058 and b is -76.99609299734146\n",
      "Iteration 3463, the loss is 28.777669082618583, parameters k is 11.25765253444541 and b is -76.99509299734146\n",
      "Iteration 3464, the loss is 28.737185399263602, parameters k is 11.263937168832763 and b is -76.99409299734145\n",
      "Iteration 3465, the loss is 28.697127716452492, parameters k is 11.270187099662802 and b is -76.99309299734145\n",
      "Iteration 3466, the loss is 28.657070033641403, parameters k is 11.276437030492842 and b is -76.99209299734144\n",
      "Iteration 3467, the loss is 28.617012350830297, parameters k is 11.28268696132288 and b is -76.99109299734144\n",
      "Iteration 3468, the loss is 28.57695466801916, parameters k is 11.28893689215292 and b is -76.99009299734143\n",
      "Iteration 3469, the loss is 28.53689698520803, parameters k is 11.29518682298296 and b is -76.98909299734143\n",
      "Iteration 3470, the loss is 28.496839302396957, parameters k is 11.301436753812999 and b is -76.98809299734143\n",
      "Iteration 3471, the loss is 28.456781619585822, parameters k is 11.307686684643038 and b is -76.98709299734142\n",
      "Iteration 3472, the loss is 28.41672393677471, parameters k is 11.313936615473077 and b is -76.98609299734142\n",
      "Iteration 3473, the loss is 28.376666253963656, parameters k is 11.320186546303116 and b is -76.98509299734141\n",
      "Iteration 3474, the loss is 28.336608571152517, parameters k is 11.326436477133155 and b is -76.9840929973414\n",
      "Iteration 3475, the loss is 28.29655088834138, parameters k is 11.332686407963195 and b is -76.9830929973414\n",
      "Iteration 3476, the loss is 28.256493205530273, parameters k is 11.338936338793234 and b is -76.9820929973414\n",
      "Iteration 3477, the loss is 28.21643552271917, parameters k is 11.345186269623273 and b is -76.98109299734139\n",
      "Iteration 3478, the loss is 28.176377839908064, parameters k is 11.351436200453312 and b is -76.98009299734139\n",
      "Iteration 3479, the loss is 28.136320157096964, parameters k is 11.357686131283351 and b is -76.97909299734138\n",
      "Iteration 3480, the loss is 28.096262474285794, parameters k is 11.36393606211339 and b is -76.97809299734138\n",
      "Iteration 3481, the loss is 28.056204791474723, parameters k is 11.37018599294343 and b is -76.97709299734137\n",
      "Iteration 3482, the loss is 28.01614710866361, parameters k is 11.37643592377347 and b is -76.97609299734137\n",
      "Iteration 3483, the loss is 27.976089425852514, parameters k is 11.382685854603508 and b is -76.97509299734136\n",
      "Iteration 3484, the loss is 27.936031743041355, parameters k is 11.388935785433548 and b is -76.97409299734136\n",
      "Iteration 3485, the loss is 27.895974060230273, parameters k is 11.395185716263587 and b is -76.97309299734135\n",
      "Iteration 3486, the loss is 27.855916377419163, parameters k is 11.401435647093626 and b is -76.97209299734135\n",
      "Iteration 3487, the loss is 27.815858694608064, parameters k is 11.407685577923665 and b is -76.97109299734134\n",
      "Iteration 3488, the loss is 27.77580101179695, parameters k is 11.413935508753704 and b is -76.97009299734134\n",
      "Iteration 3489, the loss is 27.735743328985823, parameters k is 11.420185439583744 and b is -76.96909299734133\n",
      "Iteration 3490, the loss is 27.695685646174734, parameters k is 11.426435370413783 and b is -76.96809299734133\n",
      "Iteration 3491, the loss is 27.65562796336359, parameters k is 11.432685301243822 and b is -76.96709299734133\n",
      "Iteration 3492, the loss is 27.615570280552536, parameters k is 11.438935232073861 and b is -76.96609299734132\n",
      "Iteration 3493, the loss is 27.575512597741387, parameters k is 11.4451851629039 and b is -76.96509299734132\n",
      "Iteration 3494, the loss is 27.535454914930273, parameters k is 11.45143509373394 and b is -76.96409299734131\n",
      "Iteration 3495, the loss is 27.49539723211915, parameters k is 11.457685024563979 and b is -76.9630929973413\n",
      "Iteration 3496, the loss is 27.455339549308068, parameters k is 11.463934955394018 and b is -76.9620929973413\n",
      "Iteration 3497, the loss is 27.41528186649694, parameters k is 11.470184886224057 and b is -76.9610929973413\n",
      "Iteration 3498, the loss is 27.375224183685827, parameters k is 11.476434817054097 and b is -76.96009299734129\n",
      "Iteration 3499, the loss is 27.335166500874735, parameters k is 11.482684747884136 and b is -76.95909299734129\n",
      "Iteration 3500, the loss is 27.295108818063614, parameters k is 11.488934678714175 and b is -76.95809299734128\n",
      "Iteration 3501, the loss is 27.25505113525249, parameters k is 11.495184609544214 and b is -76.95709299734128\n",
      "Iteration 3502, the loss is 27.214993452441377, parameters k is 11.501434540374254 and b is -76.95609299734127\n",
      "Iteration 3503, the loss is 27.17493576963026, parameters k is 11.507684471204293 and b is -76.95509299734127\n",
      "Iteration 3504, the loss is 27.13487808681915, parameters k is 11.513934402034332 and b is -76.95409299734126\n",
      "Iteration 3505, the loss is 27.094820404008043, parameters k is 11.520184332864371 and b is -76.95309299734126\n",
      "Iteration 3506, the loss is 27.054762721196948, parameters k is 11.52643426369441 and b is -76.95209299734125\n",
      "Iteration 3507, the loss is 27.01470503838579, parameters k is 11.53268419452445 and b is -76.95109299734125\n",
      "Iteration 3508, the loss is 26.974647355574714, parameters k is 11.538934125354489 and b is -76.95009299734124\n",
      "Iteration 3509, the loss is 26.934589672763618, parameters k is 11.545184056184528 and b is -76.94909299734124\n",
      "Iteration 3510, the loss is 26.894531989952497, parameters k is 11.551433987014567 and b is -76.94809299734123\n",
      "Iteration 3511, the loss is 26.854474307141356, parameters k is 11.557683917844606 and b is -76.94709299734123\n",
      "Iteration 3512, the loss is 26.814416624330256, parameters k is 11.563933848674646 and b is -76.94609299734122\n",
      "Iteration 3513, the loss is 26.77435894151914, parameters k is 11.570183779504685 and b is -76.94509299734122\n",
      "Iteration 3514, the loss is 26.734301258708054, parameters k is 11.576433710334724 and b is -76.94409299734122\n",
      "Iteration 3515, the loss is 26.694243575896905, parameters k is 11.582683641164763 and b is -76.94309299734121\n",
      "Iteration 3516, the loss is 26.65418589308583, parameters k is 11.588933571994803 and b is -76.9420929973412\n",
      "Iteration 3517, the loss is 26.614128210274725, parameters k is 11.595183502824842 and b is -76.9410929973412\n",
      "Iteration 3518, the loss is 26.57407052746359, parameters k is 11.601433433654881 and b is -76.9400929973412\n",
      "Iteration 3519, the loss is 26.53401284465248, parameters k is 11.60768336448492 and b is -76.93909299734119\n",
      "Iteration 3520, the loss is 26.49395516184139, parameters k is 11.61393329531496 and b is -76.93809299734119\n",
      "Iteration 3521, the loss is 26.453897479030296, parameters k is 11.620183226144999 and b is -76.93709299734118\n",
      "Iteration 3522, the loss is 26.41383979621914, parameters k is 11.626433156975038 and b is -76.93609299734118\n",
      "Iteration 3523, the loss is 26.373782113408037, parameters k is 11.632683087805077 and b is -76.93509299734117\n",
      "Iteration 3524, the loss is 26.333724430596906, parameters k is 11.638933018635116 and b is -76.93409299734117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3525, the loss is 26.293666747785792, parameters k is 11.645182949465156 and b is -76.93309299734116\n",
      "Iteration 3526, the loss is 26.253609064974693, parameters k is 11.651432880295195 and b is -76.93209299734116\n",
      "Iteration 3527, the loss is 26.213551382163615, parameters k is 11.657682811125234 and b is -76.93109299734115\n",
      "Iteration 3528, the loss is 26.173493699352463, parameters k is 11.663932741955273 and b is -76.93009299734115\n",
      "Iteration 3529, the loss is 26.133436016541395, parameters k is 11.670182672785312 and b is -76.92909299734114\n",
      "Iteration 3530, the loss is 26.093378333730236, parameters k is 11.676432603615352 and b is -76.92809299734114\n",
      "Iteration 3531, the loss is 26.05332065091919, parameters k is 11.68268253444539 and b is -76.92709299734113\n",
      "Iteration 3532, the loss is 26.01326296810806, parameters k is 11.68893246527543 and b is -76.92609299734113\n",
      "Iteration 3533, the loss is 25.97320528529692, parameters k is 11.69518239610547 and b is -76.92509299734112\n",
      "Iteration 3534, the loss is 25.933147602485782, parameters k is 11.701432326935508 and b is -76.92409299734112\n",
      "Iteration 3535, the loss is 25.89308991967469, parameters k is 11.707682257765548 and b is -76.92309299734112\n",
      "Iteration 3536, the loss is 25.85303223686359, parameters k is 11.713932188595587 and b is -76.92209299734111\n",
      "Iteration 3537, the loss is 25.812974554052463, parameters k is 11.720182119425626 and b is -76.9210929973411\n",
      "Iteration 3538, the loss is 25.77291687124138, parameters k is 11.726432050255665 and b is -76.9200929973411\n",
      "Iteration 3539, the loss is 25.732859188430275, parameters k is 11.732681981085705 and b is -76.9190929973411\n",
      "Iteration 3540, the loss is 25.692801505619165, parameters k is 11.738931911915744 and b is -76.91809299734109\n",
      "Iteration 3541, the loss is 25.652743822808045, parameters k is 11.745181842745783 and b is -76.91709299734109\n",
      "Iteration 3542, the loss is 25.612686139996875, parameters k is 11.751431773575822 and b is -76.91609299734108\n",
      "Iteration 3543, the loss is 25.57262845718578, parameters k is 11.757681704405861 and b is -76.91509299734108\n",
      "Iteration 3544, the loss is 25.53257077437469, parameters k is 11.7639316352359 and b is -76.91409299734107\n",
      "Iteration 3545, the loss is 25.492513091563584, parameters k is 11.77018156606594 and b is -76.91309299734107\n",
      "Iteration 3546, the loss is 25.452455408752492, parameters k is 11.77643149689598 and b is -76.91209299734106\n",
      "Iteration 3547, the loss is 25.412397725941368, parameters k is 11.782681427726018 and b is -76.91109299734106\n",
      "Iteration 3548, the loss is 25.37234004313025, parameters k is 11.788931358556058 and b is -76.91009299734105\n",
      "Iteration 3549, the loss is 25.332282360319137, parameters k is 11.795181289386097 and b is -76.90909299734105\n",
      "Iteration 3550, the loss is 25.29222467750807, parameters k is 11.801431220216136 and b is -76.90809299734104\n",
      "Iteration 3551, the loss is 25.252166994696914, parameters k is 11.807681151046175 and b is -76.90709299734104\n",
      "Iteration 3552, the loss is 25.212109311885808, parameters k is 11.813931081876214 and b is -76.90609299734103\n",
      "Iteration 3553, the loss is 25.172051629074687, parameters k is 11.820181012706254 and b is -76.90509299734103\n",
      "Iteration 3554, the loss is 25.131993946263577, parameters k is 11.826430943536293 and b is -76.90409299734102\n",
      "Iteration 3555, the loss is 25.09193626345248, parameters k is 11.832680874366332 and b is -76.90309299734102\n",
      "Iteration 3556, the loss is 25.05187858064136, parameters k is 11.838930805196371 and b is -76.90209299734101\n",
      "Iteration 3557, the loss is 25.01182089783025, parameters k is 11.84518073602641 and b is -76.90109299734101\n",
      "Iteration 3558, the loss is 24.97176321501916, parameters k is 11.85143066685645 and b is -76.900092997341\n",
      "Iteration 3559, the loss is 24.93170553220802, parameters k is 11.857680597686489 and b is -76.899092997341\n",
      "Iteration 3560, the loss is 24.891647849396914, parameters k is 11.863930528516528 and b is -76.898092997341\n",
      "Iteration 3561, the loss is 24.85159016658579, parameters k is 11.870180459346567 and b is -76.89709299734099\n",
      "Iteration 3562, the loss is 24.81153248377467, parameters k is 11.876430390176607 and b is -76.89609299734099\n",
      "Iteration 3563, the loss is 24.771474800963553, parameters k is 11.882680321006646 and b is -76.89509299734098\n",
      "Iteration 3564, the loss is 24.73141711815248, parameters k is 11.888930251836685 and b is -76.89409299734098\n",
      "Iteration 3565, the loss is 24.69135943534137, parameters k is 11.895180182666724 and b is -76.89309299734097\n",
      "Iteration 3566, the loss is 24.651301752530262, parameters k is 11.901430113496763 and b is -76.89209299734097\n",
      "Iteration 3567, the loss is 24.61124406971914, parameters k is 11.907680044326803 and b is -76.89109299734096\n",
      "Iteration 3568, the loss is 24.57118638690802, parameters k is 11.913929975156842 and b is -76.89009299734096\n",
      "Iteration 3569, the loss is 24.531128704096897, parameters k is 11.920179905986881 and b is -76.88909299734095\n",
      "Iteration 3570, the loss is 24.49107102128579, parameters k is 11.92642983681692 and b is -76.88809299734095\n",
      "Iteration 3571, the loss is 24.451013338474677, parameters k is 11.93267976764696 and b is -76.88709299734094\n",
      "Iteration 3572, the loss is 24.41095565566357, parameters k is 11.938929698476999 and b is -76.88609299734094\n",
      "Iteration 3573, the loss is 24.370897972852458, parameters k is 11.945179629307038 and b is -76.88509299734093\n",
      "Iteration 3574, the loss is 24.33084029004138, parameters k is 11.951429560137077 and b is -76.88409299734093\n",
      "Iteration 3575, the loss is 24.290782607230216, parameters k is 11.957679490967116 and b is -76.88309299734092\n",
      "Iteration 3576, the loss is 24.250724924419153, parameters k is 11.963929421797156 and b is -76.88209299734092\n",
      "Iteration 3577, the loss is 24.21066724160801, parameters k is 11.970179352627195 and b is -76.88109299734091\n",
      "Iteration 3578, the loss is 24.170609558796933, parameters k is 11.976429283457234 and b is -76.88009299734091\n",
      "Iteration 3579, the loss is 24.13055187598581, parameters k is 11.982679214287273 and b is -76.8790929973409\n",
      "Iteration 3580, the loss is 24.090494193174695, parameters k is 11.988929145117313 and b is -76.8780929973409\n",
      "Iteration 3581, the loss is 24.05043651036358, parameters k is 11.995179075947352 and b is -76.8770929973409\n",
      "Iteration 3582, the loss is 24.010378827552476, parameters k is 12.001429006777391 and b is -76.87609299734089\n",
      "Iteration 3583, the loss is 23.970321144741373, parameters k is 12.00767893760743 and b is -76.87509299734089\n",
      "Iteration 3584, the loss is 23.93026346193025, parameters k is 12.01392886843747 and b is -76.87409299734088\n",
      "Iteration 3585, the loss is 23.89020577911913, parameters k is 12.020178799267509 and b is -76.87309299734088\n",
      "Iteration 3586, the loss is 23.850148096308025, parameters k is 12.026428730097548 and b is -76.87209299734087\n",
      "Iteration 3587, the loss is 23.810090413496898, parameters k is 12.032678660927587 and b is -76.87109299734087\n",
      "Iteration 3588, the loss is 23.77003273068578, parameters k is 12.038928591757626 and b is -76.87009299734086\n",
      "Iteration 3589, the loss is 23.729975047874717, parameters k is 12.045178522587666 and b is -76.86909299734086\n",
      "Iteration 3590, the loss is 23.68991736506356, parameters k is 12.051428453417705 and b is -76.86809299734085\n",
      "Iteration 3591, the loss is 23.64985968225245, parameters k is 12.057678384247744 and b is -76.86709299734085\n",
      "Iteration 3592, the loss is 23.609801999441345, parameters k is 12.063928315077783 and b is -76.86609299734084\n",
      "Iteration 3593, the loss is 23.569744316630253, parameters k is 12.070178245907822 and b is -76.86509299734084\n",
      "Iteration 3594, the loss is 23.529686633819132, parameters k is 12.076428176737862 and b is -76.86409299734083\n",
      "Iteration 3595, the loss is 23.489628951008015, parameters k is 12.0826781075679 and b is -76.86309299734083\n",
      "Iteration 3596, the loss is 23.449571268196923, parameters k is 12.08892803839794 and b is -76.86209299734082\n",
      "Iteration 3597, the loss is 23.409513585385792, parameters k is 12.09517796922798 and b is -76.86109299734082\n",
      "Iteration 3598, the loss is 23.36945590257467, parameters k is 12.101427900058018 and b is -76.86009299734081\n",
      "Iteration 3599, the loss is 23.32939821976358, parameters k is 12.107677830888058 and b is -76.85909299734081\n",
      "Iteration 3600, the loss is 23.289340536952455, parameters k is 12.113927761718097 and b is -76.8580929973408\n",
      "Iteration 3601, the loss is 23.249282854141367, parameters k is 12.120177692548136 and b is -76.8570929973408\n",
      "Iteration 3602, the loss is 23.20922517133022, parameters k is 12.126427623378175 and b is -76.8560929973408\n",
      "Iteration 3603, the loss is 23.169167488519122, parameters k is 12.132677554208215 and b is -76.85509299734079\n",
      "Iteration 3604, the loss is 23.12910980570798, parameters k is 12.138927485038254 and b is -76.85409299734079\n",
      "Iteration 3605, the loss is 23.089052122896913, parameters k is 12.145177415868293 and b is -76.85309299734078\n",
      "Iteration 3606, the loss is 23.04899444008582, parameters k is 12.151427346698332 and b is -76.85209299734078\n",
      "Iteration 3607, the loss is 23.00893675727468, parameters k is 12.157677277528371 and b is -76.85109299734077\n",
      "Iteration 3608, the loss is 22.96887907446358, parameters k is 12.16392720835841 and b is -76.85009299734077\n",
      "Iteration 3609, the loss is 22.92882139165248, parameters k is 12.17017713918845 and b is -76.84909299734076\n",
      "Iteration 3610, the loss is 22.888763708841317, parameters k is 12.17642707001849 and b is -76.84809299734076\n",
      "Iteration 3611, the loss is 22.84870602603023, parameters k is 12.182677000848528 and b is -76.84709299734075\n",
      "Iteration 3612, the loss is 22.80864834321912, parameters k is 12.188926931678568 and b is -76.84609299734075\n",
      "Iteration 3613, the loss is 22.768590660407988, parameters k is 12.195176862508607 and b is -76.84509299734074\n",
      "Iteration 3614, the loss is 22.7285329775969, parameters k is 12.201426793338646 and b is -76.84409299734074\n",
      "Iteration 3615, the loss is 22.688475294785786, parameters k is 12.207676724168685 and b is -76.84309299734073\n",
      "Iteration 3616, the loss is 22.648417611974693, parameters k is 12.213926654998724 and b is -76.84209299734073\n",
      "Iteration 3617, the loss is 22.60835992916355, parameters k is 12.220176585828764 and b is -76.84109299734072\n",
      "Iteration 3618, the loss is 22.568302246352413, parameters k is 12.226426516658803 and b is -76.84009299734072\n",
      "Iteration 3619, the loss is 22.528244563541328, parameters k is 12.232676447488842 and b is -76.83909299734071\n",
      "Iteration 3620, the loss is 22.488186880730243, parameters k is 12.238926378318881 and b is -76.83809299734071\n",
      "Iteration 3621, the loss is 22.44812919791911, parameters k is 12.24517630914892 and b is -76.8370929973407\n",
      "Iteration 3622, the loss is 22.408071515107988, parameters k is 12.25142623997896 and b is -76.8360929973407\n",
      "Iteration 3623, the loss is 22.368013832296892, parameters k is 12.257676170808999 and b is -76.8350929973407\n",
      "Iteration 3624, the loss is 22.327956149485818, parameters k is 12.263926101639038 and b is -76.83409299734069\n",
      "Iteration 3625, the loss is 22.287898466674662, parameters k is 12.270176032469077 and b is -76.83309299734069\n",
      "Iteration 3626, the loss is 22.24784078386357, parameters k is 12.276425963299117 and b is -76.83209299734068\n",
      "Iteration 3627, the loss is 22.207783101052456, parameters k is 12.282675894129156 and b is -76.83109299734068\n",
      "Iteration 3628, the loss is 22.167725418241343, parameters k is 12.288925824959195 and b is -76.83009299734067\n",
      "Iteration 3629, the loss is 22.127667735430222, parameters k is 12.295175755789234 and b is -76.82909299734067\n",
      "Iteration 3630, the loss is 22.08761005261912, parameters k is 12.301425686619273 and b is -76.82809299734066\n",
      "Iteration 3631, the loss is 22.047552369808024, parameters k is 12.307675617449313 and b is -76.82709299734066\n",
      "Iteration 3632, the loss is 22.00749468699691, parameters k is 12.313925548279352 and b is -76.82609299734065\n",
      "Iteration 3633, the loss is 21.967437004185786, parameters k is 12.320175479109391 and b is -76.82509299734065\n",
      "Iteration 3634, the loss is 21.927379321374655, parameters k is 12.32642540993943 and b is -76.82409299734064\n",
      "Iteration 3635, the loss is 21.88732163856358, parameters k is 12.33267534076947 and b is -76.82309299734064\n",
      "Iteration 3636, the loss is 21.84726395575246, parameters k is 12.338925271599509 and b is -76.82209299734063\n",
      "Iteration 3637, the loss is 21.80720627294132, parameters k is 12.345175202429548 and b is -76.82109299734063\n",
      "Iteration 3638, the loss is 21.76714859013022, parameters k is 12.351425133259587 and b is -76.82009299734062\n",
      "Iteration 3639, the loss is 21.727090907319116, parameters k is 12.357675064089626 and b is -76.81909299734062\n",
      "Iteration 3640, the loss is 21.687033224508, parameters k is 12.363924994919666 and b is -76.81809299734061\n",
      "Iteration 3641, the loss is 21.64697554169688, parameters k is 12.370174925749705 and b is -76.81709299734061\n",
      "Iteration 3642, the loss is 21.60691785888577, parameters k is 12.376424856579744 and b is -76.8160929973406\n",
      "Iteration 3643, the loss is 21.566860176074655, parameters k is 12.382674787409783 and b is -76.8150929973406\n",
      "Iteration 3644, the loss is 21.526802493263546, parameters k is 12.388924718239823 and b is -76.8140929973406\n",
      "Iteration 3645, the loss is 21.48674481045242, parameters k is 12.395174649069862 and b is -76.81309299734059\n",
      "Iteration 3646, the loss is 21.446687127641333, parameters k is 12.401424579899901 and b is -76.81209299734059\n",
      "Iteration 3647, the loss is 21.40662944483018, parameters k is 12.40767451072994 and b is -76.81109299734058\n",
      "Iteration 3648, the loss is 21.366571762019117, parameters k is 12.41392444155998 and b is -76.81009299734058\n",
      "Iteration 3649, the loss is 21.326514079208003, parameters k is 12.420174372390019 and b is -76.80909299734057\n",
      "Iteration 3650, the loss is 21.286456396396886, parameters k is 12.426424303220058 and b is -76.80809299734057\n",
      "Iteration 3651, the loss is 21.24644339207585, parameters k is 12.432674234050097 and b is -76.80709299734056\n",
      "Iteration 3652, the loss is 21.206724018597857, parameters k is 12.438897358556027 and b is -76.80609299734056\n",
      "Iteration 3653, the loss is 21.167004645119928, parameters k is 12.445120483061956 and b is -76.80509299734055\n",
      "Iteration 3654, the loss is 21.12728527164198, parameters k is 12.451343607567885 and b is -76.80409299734055\n",
      "Iteration 3655, the loss is 21.087565898163994, parameters k is 12.457566732073815 and b is -76.80309299734054\n",
      "Iteration 3656, the loss is 21.04784652468602, parameters k is 12.463789856579744 and b is -76.80209299734054\n",
      "Iteration 3657, the loss is 21.00812715120807, parameters k is 12.470012981085674 and b is -76.80109299734053\n",
      "Iteration 3658, the loss is 20.968407777730125, parameters k is 12.476236105591603 and b is -76.80009299734053\n",
      "Iteration 3659, the loss is 20.928688404252163, parameters k is 12.482459230097533 and b is -76.79909299734052\n",
      "Iteration 3660, the loss is 20.889066561961855, parameters k is 12.488682354603462 and b is -76.79809299734052\n",
      "Iteration 3661, the loss is 20.849686117907066, parameters k is 12.494878506777376 and b is -76.79709299734051\n",
      "Iteration 3662, the loss is 20.81030567385227, parameters k is 12.501074658951289 and b is -76.79609299734051\n",
      "Iteration 3663, the loss is 20.770925229797506, parameters k is 12.507270811125203 and b is -76.7950929973405\n",
      "Iteration 3664, the loss is 20.731544785742702, parameters k is 12.513466963299116 and b is -76.7940929973405\n",
      "Iteration 3665, the loss is 20.692337936910352, parameters k is 12.51966311547303 and b is -76.7930929973405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3666, the loss is 20.65330198956505, parameters k is 12.525831726144967 and b is -76.79209299734049\n",
      "Iteration 3667, the loss is 20.61426604221986, parameters k is 12.532000336816903 and b is -76.79109299734048\n",
      "Iteration 3668, the loss is 20.57523009487458, parameters k is 12.53816894748884 and b is -76.79009299734048\n",
      "Iteration 3669, the loss is 20.536194147529315, parameters k is 12.544337558160777 and b is -76.78909299734048\n",
      "Iteration 3670, the loss is 20.497158200184067, parameters k is 12.550506168832714 and b is -76.78809299734047\n",
      "Iteration 3671, the loss is 20.45827984044822, parameters k is 12.55667477950465 and b is -76.78709299734047\n",
      "Iteration 3672, the loss is 20.419603619254772, parameters k is 12.562814485038247 and b is -76.78609299734046\n",
      "Iteration 3673, the loss is 20.38092739806132, parameters k is 12.568954190571844 and b is -76.78509299734046\n",
      "Iteration 3674, the loss is 20.342251176867897, parameters k is 12.575093896105441 and b is -76.78409299734045\n",
      "Iteration 3675, the loss is 20.303574955674442, parameters k is 12.581233601639038 and b is -76.78309299734045\n",
      "Iteration 3676, the loss is 20.26489873448103, parameters k is 12.587373307172635 and b is -76.78209299734044\n",
      "Iteration 3677, the loss is 20.226222513287585, parameters k is 12.593513012706232 and b is -76.78109299734044\n",
      "Iteration 3678, the loss is 20.187546292094144, parameters k is 12.59965271823983 and b is -76.78009299734043\n",
      "Iteration 3679, the loss is 20.148870070900703, parameters k is 12.605792423773426 and b is -76.77909299734043\n",
      "Iteration 3680, the loss is 20.110193849707315, parameters k is 12.611932129307023 and b is -76.77809299734042\n",
      "Iteration 3681, the loss is 20.07151762851382, parameters k is 12.61807183484062 and b is -76.77709299734042\n",
      "Iteration 3682, the loss is 20.032841407320415, parameters k is 12.624211540374217 and b is -76.77609299734041\n",
      "Iteration 3683, the loss is 19.994165186126956, parameters k is 12.630351245907814 and b is -76.77509299734041\n",
      "Iteration 3684, the loss is 19.955488964933554, parameters k is 12.636490951441411 and b is -76.7740929973404\n",
      "Iteration 3685, the loss is 19.916812743740074, parameters k is 12.642630656975008 and b is -76.7730929973404\n",
      "Iteration 3686, the loss is 19.878136522546665, parameters k is 12.648770362508605 and b is -76.7720929973404\n",
      "Iteration 3687, the loss is 19.83946030135324, parameters k is 12.654910068042202 and b is -76.77109299734039\n",
      "Iteration 3688, the loss is 19.800784080159776, parameters k is 12.6610497735758 and b is -76.77009299734038\n",
      "Iteration 3689, the loss is 19.762107858966367, parameters k is 12.667189479109396 and b is -76.76909299734038\n",
      "Iteration 3690, the loss is 19.723431637772926, parameters k is 12.673329184642993 and b is -76.76809299734037\n",
      "Iteration 3691, the loss is 19.684755416579492, parameters k is 12.67946889017659 and b is -76.76709299734037\n",
      "Iteration 3692, the loss is 19.646079195386037, parameters k is 12.685608595710187 and b is -76.76609299734037\n",
      "Iteration 3693, the loss is 19.6074029741926, parameters k is 12.691748301243784 and b is -76.76509299734036\n",
      "Iteration 3694, the loss is 19.568726752999183, parameters k is 12.697888006777381 and b is -76.76409299734036\n",
      "Iteration 3695, the loss is 19.530050531805752, parameters k is 12.704027712310978 and b is -76.76309299734035\n",
      "Iteration 3696, the loss is 19.4913743106123, parameters k is 12.710167417844575 and b is -76.76209299734035\n",
      "Iteration 3697, the loss is 19.452698089418885, parameters k is 12.716307123378172 and b is -76.76109299734034\n",
      "Iteration 3698, the loss is 19.414021868225444, parameters k is 12.72244682891177 and b is -76.76009299734034\n",
      "Iteration 3699, the loss is 19.375345647032, parameters k is 12.728586534445366 and b is -76.75909299734033\n",
      "Iteration 3700, the loss is 19.336669425838576, parameters k is 12.734726239978963 and b is -76.75809299734033\n",
      "Iteration 3701, the loss is 19.297993204645127, parameters k is 12.74086594551256 and b is -76.75709299734032\n",
      "Iteration 3702, the loss is 19.259316983451686, parameters k is 12.747005651046157 and b is -76.75609299734032\n",
      "Iteration 3703, the loss is 19.220640762258274, parameters k is 12.753145356579754 and b is -76.75509299734031\n",
      "Iteration 3704, the loss is 19.181964541064822, parameters k is 12.759285062113351 and b is -76.75409299734031\n",
      "Iteration 3705, the loss is 19.143288319871374, parameters k is 12.765424767646948 and b is -76.7530929973403\n",
      "Iteration 3706, the loss is 19.104612098677936, parameters k is 12.771564473180545 and b is -76.7520929973403\n",
      "Iteration 3707, the loss is 19.06593587748452, parameters k is 12.777704178714142 and b is -76.7510929973403\n",
      "Iteration 3708, the loss is 19.027259656291076, parameters k is 12.783843884247739 and b is -76.75009299734029\n",
      "Iteration 3709, the loss is 18.98861211368226, parameters k is 12.789983589781336 and b is -76.74909299734028\n",
      "Iteration 3710, the loss is 18.950297812064427, parameters k is 12.796094073971059 and b is -76.74809299734028\n",
      "Iteration 3711, the loss is 18.911983510446596, parameters k is 12.802204558160781 and b is -76.74709299734027\n",
      "Iteration 3712, the loss is 18.87366920882878, parameters k is 12.808315042350504 and b is -76.74609299734027\n",
      "Iteration 3713, the loss is 18.83535490721094, parameters k is 12.814425526540226 and b is -76.74509299734027\n",
      "Iteration 3714, the loss is 18.797040605593082, parameters k is 12.820536010729949 and b is -76.74409299734026\n",
      "Iteration 3715, the loss is 18.758726303975262, parameters k is 12.826646494919672 and b is -76.74309299734026\n",
      "Iteration 3716, the loss is 18.720412002357417, parameters k is 12.832756979109394 and b is -76.74209299734025\n",
      "Iteration 3717, the loss is 18.682097700739565, parameters k is 12.838867463299117 and b is -76.74109299734025\n",
      "Iteration 3718, the loss is 18.643783399121745, parameters k is 12.84497794748884 and b is -76.74009299734024\n",
      "Iteration 3719, the loss is 18.605469097503914, parameters k is 12.851088431678562 and b is -76.73909299734024\n",
      "Iteration 3720, the loss is 18.56715479588603, parameters k is 12.857198915868285 and b is -76.73809299734023\n",
      "Iteration 3721, the loss is 18.528840494268206, parameters k is 12.863309400058007 and b is -76.73709299734023\n",
      "Iteration 3722, the loss is 18.490526192650385, parameters k is 12.86941988424773 and b is -76.73609299734022\n",
      "Iteration 3723, the loss is 18.452211891032533, parameters k is 12.875530368437452 and b is -76.73509299734022\n",
      "Iteration 3724, the loss is 18.41389758941469, parameters k is 12.881640852627175 and b is -76.73409299734021\n",
      "Iteration 3725, the loss is 18.375583287796864, parameters k is 12.887751336816898 and b is -76.73309299734021\n",
      "Iteration 3726, the loss is 18.337268986179012, parameters k is 12.89386182100662 and b is -76.7320929973402\n",
      "Iteration 3727, the loss is 18.29895468456119, parameters k is 12.899972305196343 and b is -76.7310929973402\n",
      "Iteration 3728, the loss is 18.260640382943322, parameters k is 12.906082789386065 and b is -76.7300929973402\n",
      "Iteration 3729, the loss is 18.22232608132549, parameters k is 12.912193273575788 and b is -76.72909299734019\n",
      "Iteration 3730, the loss is 18.184011779707664, parameters k is 12.91830375776551 and b is -76.72809299734018\n",
      "Iteration 3731, the loss is 18.145697478089822, parameters k is 12.924414241955233 and b is -76.72709299734018\n",
      "Iteration 3732, the loss is 18.10738317647198, parameters k is 12.930524726144956 and b is -76.72609299734017\n",
      "Iteration 3733, the loss is 18.069068874854125, parameters k is 12.936635210334678 and b is -76.72509299734017\n",
      "Iteration 3734, the loss is 18.03075457323631, parameters k is 12.942745694524401 and b is -76.72409299734016\n",
      "Iteration 3735, the loss is 17.99244027161848, parameters k is 12.948856178714124 and b is -76.72309299734016\n",
      "Iteration 3736, the loss is 17.95412597000062, parameters k is 12.954966662903846 and b is -76.72209299734016\n",
      "Iteration 3737, the loss is 17.9158116683828, parameters k is 12.961077147093569 and b is -76.72109299734015\n",
      "Iteration 3738, the loss is 17.877497366764945, parameters k is 12.967187631283291 and b is -76.72009299734015\n",
      "Iteration 3739, the loss is 17.83918306514713, parameters k is 12.973298115473014 and b is -76.71909299734014\n",
      "Iteration 3740, the loss is 17.80086876352927, parameters k is 12.979408599662737 and b is -76.71809299734014\n",
      "Iteration 3741, the loss is 17.762554461911442, parameters k is 12.98551908385246 and b is -76.71709299734013\n",
      "Iteration 3742, the loss is 17.724240160293604, parameters k is 12.991629568042182 and b is -76.71609299734013\n",
      "Iteration 3743, the loss is 17.685925858675763, parameters k is 12.997740052231904 and b is -76.71509299734012\n",
      "Iteration 3744, the loss is 17.64761155705793, parameters k is 13.003850536421627 and b is -76.71409299734012\n",
      "Iteration 3745, the loss is 17.60929725544007, parameters k is 13.00996102061135 and b is -76.71309299734011\n",
      "Iteration 3746, the loss is 17.570982953822234, parameters k is 13.016071504801072 and b is -76.71209299734011\n",
      "Iteration 3747, the loss is 17.532668652204407, parameters k is 13.022181988990795 and b is -76.7110929973401\n",
      "Iteration 3748, the loss is 17.494354350586576, parameters k is 13.028292473180517 and b is -76.7100929973401\n",
      "Iteration 3749, the loss is 17.45604004896874, parameters k is 13.03440295737024 and b is -76.7090929973401\n",
      "Iteration 3750, the loss is 17.417725747350907, parameters k is 13.040513441559963 and b is -76.70809299734009\n",
      "Iteration 3751, the loss is 17.37954933245611, parameters k is 13.046623925749685 and b is -76.70709299734008\n",
      "Iteration 3752, the loss is 17.341549126050083, parameters k is 13.052708979109369 and b is -76.70609299734008\n",
      "Iteration 3753, the loss is 17.303548919644065, parameters k is 13.058794032469052 and b is -76.70509299734007\n",
      "Iteration 3754, the loss is 17.265548713238076, parameters k is 13.064879085828736 and b is -76.70409299734007\n",
      "Iteration 3755, the loss is 17.227548506832054, parameters k is 13.070964139188419 and b is -76.70309299734006\n",
      "Iteration 3756, the loss is 17.189548300426043, parameters k is 13.077049192548102 and b is -76.70209299734006\n",
      "Iteration 3757, the loss is 17.151548094020043, parameters k is 13.083134245907786 and b is -76.70109299734006\n",
      "Iteration 3758, the loss is 17.11354788761401, parameters k is 13.08921929926747 and b is -76.70009299734005\n",
      "Iteration 3759, the loss is 17.075547681207997, parameters k is 13.095304352627153 and b is -76.69909299734005\n",
      "Iteration 3760, the loss is 17.037547474801986, parameters k is 13.101389405986836 and b is -76.69809299734004\n",
      "Iteration 3761, the loss is 16.999547268395993, parameters k is 13.10747445934652 and b is -76.69709299734004\n",
      "Iteration 3762, the loss is 16.96154706198996, parameters k is 13.113559512706203 and b is -76.69609299734003\n",
      "Iteration 3763, the loss is 16.92354685558397, parameters k is 13.119644566065887 and b is -76.69509299734003\n",
      "Iteration 3764, the loss is 16.885546649177932, parameters k is 13.12572961942557 and b is -76.69409299734002\n",
      "Iteration 3765, the loss is 16.847546442771947, parameters k is 13.131814672785254 and b is -76.69309299734002\n",
      "Iteration 3766, the loss is 16.809546236365907, parameters k is 13.137899726144937 and b is -76.69209299734001\n",
      "Iteration 3767, the loss is 16.77154602995992, parameters k is 13.14398477950462 and b is -76.69109299734001\n",
      "Iteration 3768, the loss is 16.733545823553897, parameters k is 13.150069832864304 and b is -76.69009299734\n",
      "Iteration 3769, the loss is 16.695545617147907, parameters k is 13.156154886223987 and b is -76.68909299734\n",
      "Iteration 3770, the loss is 16.65754541074188, parameters k is 13.162239939583671 and b is -76.68809299734\n",
      "Iteration 3771, the loss is 16.61954520433585, parameters k is 13.168324992943354 and b is -76.68709299733999\n",
      "Iteration 3772, the loss is 16.58154499792986, parameters k is 13.174410046303038 and b is -76.68609299733998\n",
      "Iteration 3773, the loss is 16.543544791523853, parameters k is 13.180495099662721 and b is -76.68509299733998\n",
      "Iteration 3774, the loss is 16.50554458511781, parameters k is 13.186580153022405 and b is -76.68409299733997\n",
      "Iteration 3775, the loss is 16.467544378711814, parameters k is 13.192665206382088 and b is -76.68309299733997\n",
      "Iteration 3776, the loss is 16.429544172305807, parameters k is 13.198750259741772 and b is -76.68209299733996\n",
      "Iteration 3777, the loss is 16.391543965899785, parameters k is 13.204835313101455 and b is -76.68109299733996\n",
      "Iteration 3778, the loss is 16.353543759493782, parameters k is 13.210920366461139 and b is -76.68009299733995\n",
      "Iteration 3779, the loss is 16.315543553087778, parameters k is 13.217005419820822 and b is -76.67909299733995\n",
      "Iteration 3780, the loss is 16.277543346681746, parameters k is 13.223090473180505 and b is -76.67809299733995\n",
      "Iteration 3781, the loss is 16.239683722756002, parameters k is 13.229175526540189 and b is -76.67709299733994\n",
      "Iteration 3782, the loss is 16.201991958882154, parameters k is 13.235235508753627 and b is -76.67609299733994\n",
      "Iteration 3783, the loss is 16.164300195008323, parameters k is 13.241295490967065 and b is -76.67509299733993\n",
      "Iteration 3784, the loss is 16.126720842547332, parameters k is 13.247355473180503 and b is -76.67409299733993\n",
      "Iteration 3785, the loss is 16.08935777667311, parameters k is 13.253388601639001 and b is -76.67309299733992\n",
      "Iteration 3786, the loss is 16.051994710798912, parameters k is 13.259421730097499 and b is -76.67209299733992\n",
      "Iteration 3787, the loss is 16.014631644924695, parameters k is 13.265454858555996 and b is -76.67109299733991\n",
      "Iteration 3788, the loss is 15.977268579050486, parameters k is 13.271487987014494 and b is -76.6700929973399\n",
      "Iteration 3789, the loss is 15.939905513176257, parameters k is 13.277521115472991 and b is -76.6690929973399\n",
      "Iteration 3790, the loss is 15.902542447302057, parameters k is 13.283554243931489 and b is -76.6680929973399\n",
      "Iteration 3791, the loss is 15.865340083080813, parameters k is 13.289587372389986 and b is -76.66709299733989\n",
      "Iteration 3792, the loss is 15.828306124671013, parameters k is 13.295593492943347 and b is -76.66609299733989\n",
      "Iteration 3793, the loss is 15.79127216626124, parameters k is 13.301599613496707 and b is -76.66509299733988\n",
      "Iteration 3794, the loss is 15.754238207851433, parameters k is 13.307605734050068 and b is -76.66409299733988\n",
      "Iteration 3795, the loss is 15.717204249441624, parameters k is 13.313611854603428 and b is -76.66309299733987\n",
      "Iteration 3796, the loss is 15.680170291031828, parameters k is 13.319617975156788 and b is -76.66209299733987\n",
      "Iteration 3797, the loss is 15.643136332622023, parameters k is 13.325624095710149 and b is -76.66109299733986\n",
      "Iteration 3798, the loss is 15.606102374212236, parameters k is 13.331630216263509 and b is -76.66009299733986\n",
      "Iteration 3799, the loss is 15.569068415802425, parameters k is 13.33763633681687 and b is -76.65909299733985\n",
      "Iteration 3800, the loss is 15.532034457392635, parameters k is 13.34364245737023 and b is -76.65809299733985\n",
      "Iteration 3801, the loss is 15.4951573576985, parameters k is 13.34964857792359 and b is -76.65709299733984\n",
      "Iteration 3802, the loss is 15.458583914056497, parameters k is 13.355628022587622 and b is -76.65609299733984\n",
      "Iteration 3803, the loss is 15.422182334956986, parameters k is 13.361581929702247 and b is -76.65509299733984\n",
      "Iteration 3804, the loss is 15.38578075585741, parameters k is 13.367535836816872 and b is -76.65409299733983\n",
      "Iteration 3805, the loss is 15.349379176757868, parameters k is 13.373489743931497 and b is -76.65309299733983\n",
      "Iteration 3806, the loss is 15.313042284214687, parameters k is 13.379443651046122 and b is -76.65209299733982\n",
      "Iteration 3807, the loss is 15.27695203842671, parameters k is 13.38537168859553 and b is -76.65109299733982\n",
      "Iteration 3808, the loss is 15.240861792638722, parameters k is 13.391299726144938 and b is -76.65009299733981\n",
      "Iteration 3809, the loss is 15.204771546850766, parameters k is 13.397227763694346 and b is -76.6490929973398\n",
      "Iteration 3810, the loss is 15.16868130106277, parameters k is 13.403155801243754 and b is -76.6480929973398\n",
      "Iteration 3811, the loss is 15.132591055274776, parameters k is 13.409083838793162 and b is -76.6470929973398\n",
      "Iteration 3812, the loss is 15.096500809486788, parameters k is 13.41501187634257 and b is -76.64609299733979\n",
      "Iteration 3813, the loss is 15.060410563698818, parameters k is 13.420939913891978 and b is -76.64509299733979\n",
      "Iteration 3814, the loss is 15.024320317910835, parameters k is 13.426867951441386 and b is -76.64409299733978\n",
      "Iteration 3815, the loss is 14.988230072122855, parameters k is 13.432795988990794 and b is -76.64309299733978\n",
      "Iteration 3816, the loss is 14.95213982633488, parameters k is 13.438724026540202 and b is -76.64209299733977\n",
      "Iteration 3817, the loss is 14.91604958054689, parameters k is 13.44465206408961 and b is -76.64109299733977\n",
      "Iteration 3818, the loss is 14.879959334758908, parameters k is 13.450580101639018 and b is -76.64009299733976\n",
      "Iteration 3819, the loss is 14.843869088970942, parameters k is 13.456508139188426 and b is -76.63909299733976\n",
      "Iteration 3820, the loss is 14.80777884318296, parameters k is 13.462436176737834 and b is -76.63809299733975\n",
      "Iteration 3821, the loss is 14.771688597394986, parameters k is 13.468364214287242 and b is -76.63709299733975\n",
      "Iteration 3822, the loss is 14.735598351606997, parameters k is 13.47429225183665 and b is -76.63609299733974\n",
      "Iteration 3823, the loss is 14.699508105818994, parameters k is 13.480220289386057 and b is -76.63509299733974\n",
      "Iteration 3824, the loss is 14.66341786003103, parameters k is 13.486148326935465 and b is -76.63409299733974\n",
      "Iteration 3825, the loss is 14.627327614243029, parameters k is 13.492076364484873 and b is -76.63309299733973\n",
      "Iteration 3826, the loss is 14.591237368455063, parameters k is 13.498004402034281 and b is -76.63209299733973\n",
      "Iteration 3827, the loss is 14.555241968387257, parameters k is 13.50393243958369 and b is -76.63109299733972\n",
      "Iteration 3828, the loss is 14.519454018536747, parameters k is 13.509835259741791 and b is -76.63009299733972\n",
      "Iteration 3829, the loss is 14.483666068686203, parameters k is 13.515738079899894 and b is -76.62909299733971\n",
      "Iteration 3830, the loss is 14.447878118835686, parameters k is 13.521640900057996 and b is -76.6280929973397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3831, the loss is 14.412090168985143, parameters k is 13.527543720216098 and b is -76.6270929973397\n",
      "Iteration 3832, the loss is 14.376302219134637, parameters k is 13.5334465403742 and b is -76.6260929973397\n",
      "Iteration 3833, the loss is 14.340514269284114, parameters k is 13.539349360532302 and b is -76.62509299733969\n",
      "Iteration 3834, the loss is 14.304726319433584, parameters k is 13.545252180690404 and b is -76.62409299733969\n",
      "Iteration 3835, the loss is 14.268938369583042, parameters k is 13.551155000848507 and b is -76.62309299733968\n",
      "Iteration 3836, the loss is 14.233150419732533, parameters k is 13.557057821006609 and b is -76.62209299733968\n",
      "Iteration 3837, the loss is 14.197362469882004, parameters k is 13.562960641164711 and b is -76.62109299733967\n",
      "Iteration 3838, the loss is 14.161574520031483, parameters k is 13.568863461322813 and b is -76.62009299733967\n",
      "Iteration 3839, the loss is 14.125786570180964, parameters k is 13.574766281480915 and b is -76.61909299733966\n",
      "Iteration 3840, the loss is 14.090030883087048, parameters k is 13.580669101639018 and b is -76.61809299733966\n",
      "Iteration 3841, the loss is 14.054555525724162, parameters k is 13.586545720216092 and b is -76.61709299733965\n",
      "Iteration 3842, the loss is 14.019080168361283, parameters k is 13.592422338793167 and b is -76.61609299733965\n",
      "Iteration 3843, the loss is 13.983604810998424, parameters k is 13.598298957370242 and b is -76.61509299733964\n",
      "Iteration 3844, the loss is 13.948187952756614, parameters k is 13.604175575947316 and b is -76.61409299733964\n",
      "Iteration 3845, the loss is 13.913028393269785, parameters k is 13.610025601639016 and b is -76.61309299733963\n",
      "Iteration 3846, the loss is 13.877947347809773, parameters k is 13.615875627330716 and b is -76.61209299733963\n",
      "Iteration 3847, the loss is 13.843098534970055, parameters k is 13.621699372390005 and b is -76.61109299733963\n",
      "Iteration 3848, the loss is 13.808249722130368, parameters k is 13.627523117449293 and b is -76.61009299733962\n",
      "Iteration 3849, the loss is 13.773400909290658, parameters k is 13.633346862508581 and b is -76.60909299733962\n",
      "Iteration 3850, the loss is 13.738552096450967, parameters k is 13.63917060756787 and b is -76.60809299733961\n",
      "Iteration 3851, the loss is 13.703703283611262, parameters k is 13.644994352627158 and b is -76.6070929973396\n",
      "Iteration 3852, the loss is 13.668854470771564, parameters k is 13.650818097686447 and b is -76.6060929973396\n",
      "Iteration 3853, the loss is 13.634005657931857, parameters k is 13.656641842745735 and b is -76.6050929973396\n",
      "Iteration 3854, the loss is 13.599156845092164, parameters k is 13.662465587805023 and b is -76.60409299733959\n",
      "Iteration 3855, the loss is 13.564308032252448, parameters k is 13.668289332864312 and b is -76.60309299733959\n",
      "Iteration 3856, the loss is 13.52945921941275, parameters k is 13.6741130779236 and b is -76.60209299733958\n",
      "Iteration 3857, the loss is 13.494610406573038, parameters k is 13.679936822982889 and b is -76.60109299733958\n",
      "Iteration 3858, the loss is 13.459761593733353, parameters k is 13.685760568042177 and b is -76.60009299733957\n",
      "Iteration 3859, the loss is 13.425050528249306, parameters k is 13.691584313101465 and b is -76.59909299733957\n",
      "Iteration 3860, the loss is 13.390502372495387, parameters k is 13.697382528516485 and b is -76.59809299733956\n",
      "Iteration 3861, the loss is 13.355954216741472, parameters k is 13.703180743931505 and b is -76.59709299733956\n",
      "Iteration 3862, the loss is 13.321406060987561, parameters k is 13.708978959346524 and b is -76.59609299733955\n",
      "Iteration 3863, the loss is 13.286857905233635, parameters k is 13.714777174761544 and b is -76.59509299733955\n",
      "Iteration 3864, the loss is 13.252309749479721, parameters k is 13.720575390176563 and b is -76.59409299733954\n",
      "Iteration 3865, the loss is 13.217761593725792, parameters k is 13.726373605591583 and b is -76.59309299733954\n",
      "Iteration 3866, the loss is 13.183302053367255, parameters k is 13.732171821006602 and b is -76.59209299733953\n",
      "Iteration 3867, the loss is 13.149031708501942, parameters k is 13.737946372390002 and b is -76.59109299733953\n",
      "Iteration 3868, the loss is 13.114761363636676, parameters k is 13.743720923773402 and b is -76.59009299733953\n",
      "Iteration 3869, the loss is 13.080491018771367, parameters k is 13.749495475156802 and b is -76.58909299733952\n",
      "Iteration 3870, the loss is 13.046220673906065, parameters k is 13.755270026540202 and b is -76.58809299733952\n",
      "Iteration 3871, the loss is 13.011950329040758, parameters k is 13.761044577923602 and b is -76.58709299733951\n",
      "Iteration 3872, the loss is 12.977679984175474, parameters k is 13.766819129307002 and b is -76.5860929973395\n",
      "Iteration 3873, the loss is 12.943409639310158, parameters k is 13.772593680690402 and b is -76.5850929973395\n",
      "Iteration 3874, the loss is 12.909139294444866, parameters k is 13.778368232073802 and b is -76.5840929973395\n",
      "Iteration 3875, the loss is 12.874868949579582, parameters k is 13.784142783457202 and b is -76.58309299733949\n",
      "Iteration 3876, the loss is 12.840598604714273, parameters k is 13.789917334840602 and b is -76.58209299733949\n",
      "Iteration 3877, the loss is 12.806443819159194, parameters k is 13.795691886224002 and b is -76.58109299733948\n",
      "Iteration 3878, the loss is 12.772480526560583, parameters k is 13.801440133259575 and b is -76.58009299733948\n",
      "Iteration 3879, the loss is 12.73851723396201, parameters k is 13.807188380295148 and b is -76.57909299733947\n",
      "Iteration 3880, the loss is 12.704553941363434, parameters k is 13.812936627330721 and b is -76.57809299733947\n",
      "Iteration 3881, the loss is 12.670590648764858, parameters k is 13.818684874366294 and b is -76.57709299733946\n",
      "Iteration 3882, the loss is 12.636627356166276, parameters k is 13.824433121401867 and b is -76.57609299733946\n",
      "Iteration 3883, the loss is 12.602664063567703, parameters k is 13.83018136843744 and b is -76.57509299733945\n",
      "Iteration 3884, the loss is 12.568700770969139, parameters k is 13.835929615473013 and b is -76.57409299733945\n",
      "Iteration 3885, the loss is 12.534737478370545, parameters k is 13.841677862508586 and b is -76.57309299733944\n",
      "Iteration 3886, the loss is 12.500801157345782, parameters k is 13.847426109544159 and b is -76.57209299733944\n",
      "Iteration 3887, the loss is 12.467132178772388, parameters k is 13.853149044326768 and b is -76.57109299733943\n",
      "Iteration 3888, the loss is 12.43350536454472, parameters k is 13.858871979109377 and b is -76.57009299733943\n",
      "Iteration 3889, the loss is 12.400234165716178, parameters k is 13.864569336816887 and b is -76.56909299733942\n",
      "Iteration 3890, the loss is 12.367141674923946, parameters k is 13.870242378318864 and b is -76.56809299733942\n",
      "Iteration 3891, the loss is 12.334110117850589, parameters k is 13.87591541982084 and b is -76.56709299733942\n",
      "Iteration 3892, the loss is 12.301321392348521, parameters k is 13.881561975156808 and b is -76.56609299733941\n",
      "Iteration 3893, the loss is 12.268532666846461, parameters k is 13.887208530492776 and b is -76.5650929973394\n",
      "Iteration 3894, the loss is 12.235743941344365, parameters k is 13.892855085828744 and b is -76.5640929973394\n",
      "Iteration 3895, the loss is 12.20305256845597, parameters k is 13.898501641164712 and b is -76.5630929973394\n",
      "Iteration 3896, the loss is 12.170558385499456, parameters k is 13.904122405986847 and b is -76.56209299733939\n",
      "Iteration 3897, the loss is 12.138185989150431, parameters k is 13.909743170808982 and b is -76.56109299733939\n",
      "Iteration 3898, the loss is 12.105979710727848, parameters k is 13.915338619425583 and b is -76.56009299733938\n",
      "Iteration 3899, the loss is 12.073773432305238, parameters k is 13.920934068042184 and b is -76.55909299733938\n",
      "Iteration 3900, the loss is 12.041567153882598, parameters k is 13.926529516658785 and b is -76.55809299733937\n",
      "Iteration 3901, the loss is 12.00936087546001, parameters k is 13.932124965275387 and b is -76.55709299733937\n",
      "Iteration 3902, the loss is 11.977154597037407, parameters k is 13.937720413891988 and b is -76.55609299733936\n",
      "Iteration 3903, the loss is 11.945004293377847, parameters k is 13.94331586250859 and b is -76.55509299733936\n",
      "Iteration 3904, the loss is 11.913076623205688, parameters k is 13.948886714287246 and b is -76.55409299733935\n",
      "Iteration 3905, the loss is 11.881148953033502, parameters k is 13.954457566065903 and b is -76.55309299733935\n",
      "Iteration 3906, the loss is 11.84933752539085, parameters k is 13.96002841784456 and b is -76.55209299733934\n",
      "Iteration 3907, the loss is 11.817695758591295, parameters k is 13.965573905986853 and b is -76.55109299733934\n",
      "Iteration 3908, the loss is 11.786053991791741, parameters k is 13.971119394129145 and b is -76.55009299733933\n",
      "Iteration 3909, the loss is 11.754412224992189, parameters k is 13.976664882271438 and b is -76.54909299733933\n",
      "Iteration 3910, the loss is 11.722770458192644, parameters k is 13.98221037041373 and b is -76.54809299733932\n",
      "Iteration 3911, the loss is 11.691128691393077, parameters k is 13.987755858556023 and b is -76.54709299733932\n",
      "Iteration 3912, the loss is 11.659486924593532, parameters k is 13.993301346698315 and b is -76.54609299733931\n",
      "Iteration 3913, the loss is 11.627845157793976, parameters k is 13.998846834840608 and b is -76.54509299733931\n",
      "Iteration 3914, the loss is 11.596203390994415, parameters k is 14.0043923229829 and b is -76.5440929973393\n",
      "Iteration 3915, the loss is 11.564561624194884, parameters k is 14.009937811125193 and b is -76.5430929973393\n",
      "Iteration 3916, the loss is 11.532919857395322, parameters k is 14.015483299267485 and b is -76.5420929973393\n",
      "Iteration 3917, the loss is 11.50127809059578, parameters k is 14.021028787409778 and b is -76.54109299733929\n",
      "Iteration 3918, the loss is 11.469636323796227, parameters k is 14.02657427555207 and b is -76.54009299733929\n",
      "Iteration 3919, the loss is 11.43799455699667, parameters k is 14.032119763694363 and b is -76.53909299733928\n",
      "Iteration 3920, the loss is 11.406352790197102, parameters k is 14.037665251836655 and b is -76.53809299733928\n",
      "Iteration 3921, the loss is 11.374711023397557, parameters k is 14.043210739978948 and b is -76.53709299733927\n",
      "Iteration 3922, the loss is 11.343069256598007, parameters k is 14.04875622812124 and b is -76.53609299733927\n",
      "Iteration 3923, the loss is 11.31155141055902, parameters k is 14.054301716263533 and b is -76.53509299733926\n",
      "Iteration 3924, the loss is 11.280192645900723, parameters k is 14.059821987014521 and b is -76.53409299733926\n",
      "Iteration 3925, the loss is 11.24883388124243, parameters k is 14.06534225776551 and b is -76.53309299733925\n",
      "Iteration 3926, the loss is 11.217475116584124, parameters k is 14.070862528516498 and b is -76.53209299733925\n",
      "Iteration 3927, the loss is 11.186116351925829, parameters k is 14.076382799267487 and b is -76.53109299733924\n",
      "Iteration 3928, the loss is 11.154809507187602, parameters k is 14.081903070018475 and b is -76.53009299733924\n",
      "Iteration 3929, the loss is 11.12374450428469, parameters k is 14.087397028516499 and b is -76.52909299733923\n",
      "Iteration 3930, the loss is 11.09267950138178, parameters k is 14.092890987014522 and b is -76.52809299733923\n",
      "Iteration 3931, the loss is 11.061658334189264, parameters k is 14.098384945512546 and b is -76.52709299733922\n",
      "Iteration 3932, the loss is 11.030866038900633, parameters k is 14.103854390176577 and b is -76.52609299733922\n",
      "Iteration 3933, the loss is 11.000073743612004, parameters k is 14.109323834840609 and b is -76.52509299733921\n",
      "Iteration 3934, the loss is 10.96935542678008, parameters k is 14.11479327950464 and b is -76.52409299733921\n",
      "Iteration 3935, the loss is 10.93884470844013, parameters k is 14.120237285433495 and b is -76.5230929973392\n",
      "Iteration 3936, the loss is 10.908333990100138, parameters k is 14.12568129136235 and b is -76.5220929973392\n",
      "Iteration 3937, the loss is 10.877823271760182, parameters k is 14.131125297291204 and b is -76.5210929973392\n",
      "Iteration 3938, the loss is 10.847421963291778, parameters k is 14.136569303220059 and b is -76.52009299733919\n",
      "Iteration 3939, the loss is 10.817181117930335, parameters k is 14.141988830888042 and b is -76.51909299733919\n",
      "Iteration 3940, the loss is 10.786940272568904, parameters k is 14.147408358556026 and b is -76.51809299733918\n",
      "Iteration 3941, the loss is 10.756720201092211, parameters k is 14.15282788622401 and b is -76.51709299733918\n",
      "Iteration 3942, the loss is 10.726733485345491, parameters k is 14.158224283457212 and b is -76.51609299733917\n",
      "Iteration 3943, the loss is 10.69674676959875, parameters k is 14.163620680690414 and b is -76.51509299733917\n",
      "Iteration 3944, the loss is 10.666760053851998, parameters k is 14.169017077923616 and b is -76.51409299733916\n",
      "Iteration 3945, the loss is 10.636804873239873, parameters k is 14.174413475156818 and b is -76.51309299733916\n",
      "Iteration 3946, the loss is 10.607116945071379, parameters k is 14.179784239978952 and b is -76.51209299733915\n",
      "Iteration 3947, the loss is 10.577766997913592, parameters k is 14.185122052231916 and b is -76.51109299733915\n",
      "Iteration 3948, the loss is 10.548417050755829, parameters k is 14.19045986448488 and b is -76.51009299733914\n",
      "Iteration 3949, the loss is 10.519166393414777, parameters k is 14.195797676737845 and b is -76.50909299733914\n",
      "Iteration 3950, the loss is 10.490158645943284, parameters k is 14.201103710334683 and b is -76.50809299733913\n",
      "Iteration 3951, the loss is 10.461150898471788, parameters k is 14.206409743931522 and b is -76.50709299733913\n",
      "Iteration 3952, the loss is 10.432223145267331, parameters k is 14.21171577752836 and b is -76.50609299733912\n",
      "Iteration 3953, the loss is 10.403479142396758, parameters k is 14.21699727357579 and b is -76.50509299733912\n",
      "Iteration 3954, the loss is 10.374773124332483, parameters k is 14.222278769623221 and b is -76.50409299733911\n",
      "Iteration 3955, the loss is 10.346305457076927, parameters k is 14.22753441586828 and b is -76.50309299733911\n",
      "Iteration 3956, the loss is 10.317837789821324, parameters k is 14.23279006211334 and b is -76.5020929973391\n",
      "Iteration 3957, the loss is 10.289370122565739, parameters k is 14.238045708358399 and b is -76.5010929973391\n",
      "Iteration 3958, the loss is 10.26090245531016, parameters k is 14.243301354603458 and b is -76.5000929973391\n",
      "Iteration 3959, the loss is 10.232434788054594, parameters k is 14.248557000848518 and b is -76.49909299733909\n",
      "Iteration 3960, the loss is 10.203976962141471, parameters k is 14.253812647093577 and b is -76.49809299733909\n",
      "Iteration 3961, the loss is 10.175772344857062, parameters k is 14.259043585828755 and b is -76.49709299733908\n",
      "Iteration 3962, the loss is 10.14756772757269, parameters k is 14.264274524563932 and b is -76.49609299733908\n",
      "Iteration 3963, the loss is 10.11936311028831, parameters k is 14.26950546329911 and b is -76.49509299733907\n",
      "Iteration 3964, the loss is 10.091158493003912, parameters k is 14.274736402034288 and b is -76.49409299733907\n",
      "Iteration 3965, the loss is 10.063080213566677, parameters k is 14.279967340769465 and b is -76.49309299733906\n",
      "Iteration 3966, the loss is 10.035357521111573, parameters k is 14.285166386224011 and b is -76.49209299733906\n",
      "Iteration 3967, the loss is 10.00806583063723, parameters k is 14.290310475156817 and b is -76.49109299733905\n",
      "Iteration 3968, the loss is 9.98077414016294, parameters k is 14.295454564089622 and b is -76.49009299733905\n",
      "Iteration 3969, the loss is 9.953482449688627, parameters k is 14.300598653022428 and b is -76.48909299733904\n",
      "Iteration 3970, the loss is 9.926255937776224, parameters k is 14.305742741955234 and b is -76.48809299733904\n",
      "Iteration 3971, the loss is 9.899208994770065, parameters k is 14.310863372390017 and b is -76.48709299733903\n",
      "Iteration 3972, the loss is 9.872162051763926, parameters k is 14.3159840028248 and b is -76.48609299733903\n",
      "Iteration 3973, the loss is 9.845216797702392, parameters k is 14.321104633259583 and b is -76.48509299733902\n",
      "Iteration 3974, the loss is 9.818414388019272, parameters k is 14.32620171823982 and b is -76.48409299733902\n",
      "Iteration 3975, the loss is 9.791611978336157, parameters k is 14.331298803220058 and b is -76.48309299733901\n",
      "Iteration 3976, the loss is 9.764909758775413, parameters k is 14.336395888200295 and b is -76.48209299733901\n",
      "Iteration 3977, the loss is 9.738451310718476, parameters k is 14.341467882271441 and b is -76.481092997339\n",
      "Iteration 3978, the loss is 9.712169543309573, parameters k is 14.346517413891995 and b is -76.480092997339\n",
      "Iteration 3979, the loss is 9.68611541400166, parameters k is 14.351541739978952 and b is -76.479092997339\n",
      "Iteration 3980, the loss is 9.660061284693725, parameters k is 14.35656606606591 and b is -76.47809299733899\n",
      "Iteration 3981, the loss is 9.634007155385802, parameters k is 14.361590392152866 and b is -76.47709299733899\n",
      "Iteration 3982, the loss is 9.607953026077896, parameters k is 14.366614718239823 and b is -76.47609299733898\n",
      "Iteration 3983, the loss is 9.581952908077206, parameters k is 14.37163904432678 and b is -76.47509299733898\n",
      "Iteration 3984, the loss is 9.556441797850654, parameters k is 14.37660983286433 and b is -76.47409299733897\n",
      "Iteration 3985, the loss is 9.531012530890715, parameters k is 14.38158062140188 and b is -76.47309299733897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3986, the loss is 9.505736512110802, parameters k is 14.386528105591603 and b is -76.47209299733896\n",
      "Iteration 3987, the loss is 9.480554725413812, parameters k is 14.391475589781326 and b is -76.47109299733896\n",
      "Iteration 3988, the loss is 9.455554734101563, parameters k is 14.39639550084852 and b is -76.47009299733895\n",
      "Iteration 3989, the loss is 9.430554742789294, parameters k is 14.401315411915714 and b is -76.46909299733895\n",
      "Iteration 3990, the loss is 9.40555475147704, parameters k is 14.406235322982909 and b is -76.46809299733894\n",
      "Iteration 3991, the loss is 9.380707415197204, parameters k is 14.411155234050103 and b is -76.46709299733894\n",
      "Iteration 3992, the loss is 9.356209285608973, parameters k is 14.416024686619274 and b is -76.46609299733893\n",
      "Iteration 3993, the loss is 9.33171115602075, parameters k is 14.420894139188444 and b is -76.46509299733893\n",
      "Iteration 3994, the loss is 9.307213026432528, parameters k is 14.425763591757615 and b is -76.46409299733892\n",
      "Iteration 3995, the loss is 9.282714896844297, parameters k is 14.430633044326786 and b is -76.46309299733892\n",
      "Iteration 3996, the loss is 9.25821676725608, parameters k is 14.435502496895957 and b is -76.46209299733891\n",
      "Iteration 3997, the loss is 9.233726301435803, parameters k is 14.440371949465128 and b is -76.46109299733891\n",
      "Iteration 3998, the loss is 9.209548978205389, parameters k is 14.445208757765522 and b is -76.4600929973389\n",
      "Iteration 3999, the loss is 9.18537165497497, parameters k is 14.450045566065917 and b is -76.4590929973389\n",
      "Iteration 4000, the loss is 9.161194331744534, parameters k is 14.454882374366312 and b is -76.4580929973389\n",
      "Iteration 4001, the loss is 9.1370170085141, parameters k is 14.459719182666706 and b is -76.45709299733889\n",
      "Iteration 4002, the loss is 9.112839685283685, parameters k is 14.464555990967101 and b is -76.45609299733889\n",
      "Iteration 4003, the loss is 9.088662362053258, parameters k is 14.469392799267496 and b is -76.45509299733888\n",
      "Iteration 4004, the loss is 9.064485038822822, parameters k is 14.47422960756789 and b is -76.45409299733888\n",
      "Iteration 4005, the loss is 9.040307715592412, parameters k is 14.479066415868285 and b is -76.45309299733887\n",
      "Iteration 4006, the loss is 9.01613039236198, parameters k is 14.48390322416868 and b is -76.45209299733887\n",
      "Iteration 4007, the loss is 8.991953069131544, parameters k is 14.488740032469074 and b is -76.45109299733886\n",
      "Iteration 4008, the loss is 8.967877062095681, parameters k is 14.49357684076947 and b is -76.45009299733886\n",
      "Iteration 4009, the loss is 8.944409108945539, parameters k is 14.498352309148915 and b is -76.44909299733885\n",
      "Iteration 4010, the loss is 8.921316181274715, parameters k is 14.503077362508598 and b is -76.44809299733885\n",
      "Iteration 4011, the loss is 8.898223253603872, parameters k is 14.507802415868282 and b is -76.44709299733884\n",
      "Iteration 4012, the loss is 8.87513032593303, parameters k is 14.512527469227965 and b is -76.44609299733884\n",
      "Iteration 4013, the loss is 8.852065446301273, parameters k is 14.517252522587649 and b is -76.44509299733883\n",
      "Iteration 4014, the loss is 8.829262822861493, parameters k is 14.521947176737847 and b is -76.44409299733883\n",
      "Iteration 4015, the loss is 8.806460199421727, parameters k is 14.526641830888044 and b is -76.44309299733882\n",
      "Iteration 4016, the loss is 8.78388273399252, parameters k is 14.531336485038242 and b is -76.44209299733882\n",
      "Iteration 4017, the loss is 8.76164539268025, parameters k is 14.535971396105436 and b is -76.44109299733881\n",
      "Iteration 4018, the loss is 8.739408051367988, parameters k is 14.54060630717263 and b is -76.44009299733881\n",
      "Iteration 4019, the loss is 8.717170710055722, parameters k is 14.545241218239825 and b is -76.4390929973388\n",
      "Iteration 4020, the loss is 8.694933368743467, parameters k is 14.54987612930702 and b is -76.4380929973388\n",
      "Iteration 4021, the loss is 8.672696027431202, parameters k is 14.554511040374214 and b is -76.4370929973388\n",
      "Iteration 4022, the loss is 8.650458686118938, parameters k is 14.559145951441408 and b is -76.43609299733879\n",
      "Iteration 4023, the loss is 8.628248715073235, parameters k is 14.563780862508603 and b is -76.43509299733878\n",
      "Iteration 4024, the loss is 8.60624050642491, parameters k is 14.568391417844571 and b is -76.43409299733878\n",
      "Iteration 4025, the loss is 8.584301500237334, parameters k is 14.57300197318054 and b is -76.43309299733878\n",
      "Iteration 4026, the loss is 8.562522361725456, parameters k is 14.577588050255638 and b is -76.43209299733877\n",
      "Iteration 4027, the loss is 8.540743223213582, parameters k is 14.582174127330736 and b is -76.43109299733877\n",
      "Iteration 4028, the loss is 8.518964084701711, parameters k is 14.586760204405834 and b is -76.43009299733876\n",
      "Iteration 4029, the loss is 8.497271766905257, parameters k is 14.591346281480932 and b is -76.42909299733876\n",
      "Iteration 4030, the loss is 8.475764434169381, parameters k is 14.595903062113344 and b is -76.42809299733875\n",
      "Iteration 4031, the loss is 8.45434691340873, parameters k is 14.600459842745755 and b is -76.42709299733875\n",
      "Iteration 4032, the loss is 8.433550582308573, parameters k is 14.604939251836663 and b is -76.42609299733874\n",
      "Iteration 4033, the loss is 8.41275425120841, parameters k is 14.609418660927572 and b is -76.42509299733874\n",
      "Iteration 4034, the loss is 8.391957920108245, parameters k is 14.61389807001848 and b is -76.42409299733873\n",
      "Iteration 4035, the loss is 8.371161589008073, parameters k is 14.61837747910939 and b is -76.42309299733873\n",
      "Iteration 4036, the loss is 8.350365257907919, parameters k is 14.622856888200298 and b is -76.42209299733872\n",
      "Iteration 4037, the loss is 8.329568926807756, parameters k is 14.627336297291206 and b is -76.42109299733872\n",
      "Iteration 4038, the loss is 8.308772595707598, parameters k is 14.631815706382115 and b is -76.42009299733871\n",
      "Iteration 4039, the loss is 8.288001530583177, parameters k is 14.636295115473024 and b is -76.41909299733871\n",
      "Iteration 4040, the loss is 8.267427567419697, parameters k is 14.640750077923617 and b is -76.4180929973387\n",
      "Iteration 4041, the loss is 8.246863101971377, parameters k is 14.64520504037421 and b is -76.4170929973387\n",
      "Iteration 4042, the loss is 8.22659375888634, parameters k is 14.649635599662748 and b is -76.4160929973387\n",
      "Iteration 4043, the loss is 8.206455163459099, parameters k is 14.65404232495919 and b is -76.41509299733869\n",
      "Iteration 4044, the loss is 8.186316568031854, parameters k is 14.658449050255633 and b is -76.41409299733868\n",
      "Iteration 4045, the loss is 8.166263550747416, parameters k is 14.662855775552076 and b is -76.41309299733868\n",
      "Iteration 4046, the loss is 8.14652825492187, parameters k is 14.66723354037421 and b is -76.41209299733868\n",
      "Iteration 4047, the loss is 8.127192803743894, parameters k is 14.671549550255634 and b is -76.41109299733867\n",
      "Iteration 4048, the loss is 8.10785735256594, parameters k is 14.675865560137057 and b is -76.41009299733867\n",
      "Iteration 4049, the loss is 8.088521901387976, parameters k is 14.68018157001848 and b is -76.40909299733866\n",
      "Iteration 4050, the loss is 8.06929677012699, parameters k is 14.684497579899903 and b is -76.40809299733866\n",
      "Iteration 4051, the loss is 8.050184042465553, parameters k is 14.688788170808994 and b is -76.40709299733865\n",
      "Iteration 4052, the loss is 8.031135441148782, parameters k is 14.693078761718086 and b is -76.40609299733865\n",
      "Iteration 4053, the loss is 8.01223962642732, parameters k is 14.697344463299114 and b is -76.40509299733864\n",
      "Iteration 4054, the loss is 7.993343811705846, parameters k is 14.701610164880142 and b is -76.40409299733864\n",
      "Iteration 4055, the loss is 7.974447996984381, parameters k is 14.70587586646117 and b is -76.40309299733863\n",
      "Iteration 4056, the loss is 7.955552182262908, parameters k is 14.710141568042198 and b is -76.40209299733863\n",
      "Iteration 4057, the loss is 7.936689768863376, parameters k is 14.714407269623226 and b is -76.40109299733862\n",
      "Iteration 4058, the loss is 7.918312972526216, parameters k is 14.718624402034294 and b is -76.40009299733862\n",
      "Iteration 4059, the loss is 7.900044788564262, parameters k is 14.72281730519635 and b is -76.39909299733861\n",
      "Iteration 4060, the loss is 7.881776604602315, parameters k is 14.727010208358404 and b is -76.39809299733861\n",
      "Iteration 4061, the loss is 7.863591438750714, parameters k is 14.73120311152046 and b is -76.3970929973386\n",
      "Iteration 4062, the loss is 7.845554212385315, parameters k is 14.735368856579749 and b is -76.3960929973386\n",
      "Iteration 4063, the loss is 7.827516986019928, parameters k is 14.739534601639038 and b is -76.3950929973386\n",
      "Iteration 4064, the loss is 7.809479759654521, parameters k is 14.743700346698327 and b is -76.39409299733859\n",
      "Iteration 4065, the loss is 7.791481658577734, parameters k is 14.747866091757617 and b is -76.39309299733858\n",
      "Iteration 4066, the loss is 7.7736485503209725, parameters k is 14.752007741955245 and b is -76.39209299733858\n",
      "Iteration 4067, the loss is 7.755815442064226, parameters k is 14.756149392152873 and b is -76.39109299733857\n",
      "Iteration 4068, the loss is 7.738067403723229, parameters k is 14.7602910423505 and b is -76.39009299733857\n",
      "Iteration 4069, the loss is 7.720446365182058, parameters k is 14.764407490967102 and b is -76.38909299733857\n",
      "Iteration 4070, the loss is 7.702825326640876, parameters k is 14.768523939583703 and b is -76.38809299733856\n",
      "Iteration 4071, the loss is 7.685293056965602, parameters k is 14.772640388200305 and b is -76.38709299733856\n",
      "Iteration 4072, the loss is 7.66808302445455, parameters k is 14.77670757989991 and b is -76.38609299733855\n",
      "Iteration 4073, the loss is 7.650988140990287, parameters k is 14.780774771599514 and b is -76.38509299733855\n",
      "Iteration 4074, the loss is 7.634019638944132, parameters k is 14.784812651046154 and b is -76.38409299733854\n",
      "Iteration 4075, the loss is 7.617051136897976, parameters k is 14.788850530492795 and b is -76.38309299733854\n",
      "Iteration 4076, the loss is 7.600082634851823, parameters k is 14.792888409939435 and b is -76.38209299733853\n",
      "Iteration 4077, the loss is 7.583161959168929, parameters k is 14.796926289386075 and b is -76.38109299733853\n",
      "Iteration 4078, the loss is 7.566450566692374, parameters k is 14.800934840769475 and b is -76.38009299733852\n",
      "Iteration 4079, the loss is 7.5499299465494145, parameters k is 14.804917866461174 and b is -76.37909299733852\n",
      "Iteration 4080, the loss is 7.533409326406465, parameters k is 14.808900892152874 and b is -76.37809299733851\n",
      "Iteration 4081, the loss is 7.516888706263521, parameters k is 14.812883917844573 and b is -76.37709299733851\n",
      "Iteration 4082, the loss is 7.500368086120556, parameters k is 14.816866943536272 and b is -76.3760929973385\n",
      "Iteration 4083, the loss is 7.483847465977607, parameters k is 14.820849969227972 and b is -76.3750929973385\n",
      "Iteration 4084, the loss is 7.467326845834644, parameters k is 14.82483299491967 and b is -76.3740929973385\n",
      "Iteration 4085, the loss is 7.450948050447823, parameters k is 14.82881602061137 and b is -76.37309299733849\n",
      "Iteration 4086, the loss is 7.435295369239014, parameters k is 14.832693832864335 and b is -76.37209299733848\n",
      "Iteration 4087, the loss is 7.419799976602813, parameters k is 14.836548573971054 and b is -76.37109299733848\n",
      "Iteration 4088, the loss is 7.404334092290667, parameters k is 14.840403315077774 and b is -76.37009299733847\n",
      "Iteration 4089, the loss is 7.389105582695982, parameters k is 14.844230629307022 and b is -76.36909299733847\n",
      "Iteration 4090, the loss is 7.374042185414472, parameters k is 14.848029963299117 and b is -76.36809299733847\n",
      "Iteration 4091, the loss is 7.358978788132955, parameters k is 14.851829297291212 and b is -76.36709299733846\n",
      "Iteration 4092, the loss is 7.343951939316212, parameters k is 14.855628631283308 and b is -76.36609299733846\n",
      "Iteration 4093, the loss is 7.329086281614864, parameters k is 14.859402376342596 and b is -76.36509299733845\n",
      "Iteration 4094, the loss is 7.314220623913503, parameters k is 14.863176121401883 and b is -76.36409299733845\n",
      "Iteration 4095, the loss is 7.2993549662121495, parameters k is 14.866949866461171 and b is -76.36309299733844\n",
      "Iteration 4096, the loss is 7.284489308510789, parameters k is 14.870723611520459 and b is -76.36209299733844\n",
      "Iteration 4097, the loss is 7.269623650809425, parameters k is 14.874497356579747 and b is -76.36109299733843\n",
      "Iteration 4098, the loss is 7.2547579931080675, parameters k is 14.878271101639035 and b is -76.36009299733843\n",
      "Iteration 4099, the loss is 7.239892335406706, parameters k is 14.882044846698323 and b is -76.35909299733842\n",
      "Iteration 4100, the loss is 7.225026677705351, parameters k is 14.88581859175761 and b is -76.35809299733842\n",
      "Iteration 4101, the loss is 7.210187030052954, parameters k is 14.889592336816898 and b is -76.35709299733841\n",
      "Iteration 4102, the loss is 7.195499425929902, parameters k is 14.893342943536267 and b is -76.35609299733841\n",
      "Iteration 4103, the loss is 7.180811821806841, parameters k is 14.897093550255635 and b is -76.3550929973384\n",
      "Iteration 4104, the loss is 7.166124217683788, parameters k is 14.900844156975003 and b is -76.3540929973384\n",
      "Iteration 4105, the loss is 7.151564910551516, parameters k is 14.904594763694371 and b is -76.3530929973384\n",
      "Iteration 4106, the loss is 7.137365927412586, parameters k is 14.90828855618449 and b is -76.35209299733839\n",
      "Iteration 4107, the loss is 7.123355764485445, parameters k is 14.911958071994766 and b is -76.35109299733838\n",
      "Iteration 4108, the loss is 7.109468814013542, parameters k is 14.91560254827935 and b is -76.35009299733838\n",
      "Iteration 4109, the loss is 7.095603843887914, parameters k is 14.919247024563935 and b is -76.34909299733837\n",
      "Iteration 4110, the loss is 7.0818774828543045, parameters k is 14.922869947488836 and b is -76.34809299733837\n",
      "Iteration 4111, the loss is 7.068224224661361, parameters k is 14.926492870413737 and b is -76.34709299733836\n",
      "Iteration 4112, the loss is 7.054757735627473, parameters k is 14.930089745907809 and b is -76.34609299733836\n",
      "Iteration 4113, the loss is 7.041392235952864, parameters k is 14.93366362535445 and b is -76.34509299733836\n",
      "Iteration 4114, the loss is 7.0280267362782505, parameters k is 14.937237504801091 and b is -76.34409299733835\n",
      "Iteration 4115, the loss is 7.014661236603629, parameters k is 14.940811384247732 and b is -76.34309299733835\n",
      "Iteration 4116, the loss is 7.001350690396498, parameters k is 14.944385263694373 and b is -76.34209299733834\n",
      "Iteration 4117, the loss is 6.9882493871197315, parameters k is 14.947932917844572 and b is -76.34109299733834\n",
      "Iteration 4118, the loss is 6.975250496610259, parameters k is 14.951456255789235 and b is -76.34009299733833\n",
      "Iteration 4119, the loss is 6.962251606100794, parameters k is 14.9549795937339 and b is -76.33909299733833\n",
      "Iteration 4120, the loss is 6.9493107482677985, parameters k is 14.958502931678563 and b is -76.33809299733832\n",
      "Iteration 4121, the loss is 6.936619925489047, parameters k is 14.961995577923622 and b is -76.33709299733832\n",
      "Iteration 4122, the loss is 6.924207586799147, parameters k is 14.965436394129155 and b is -76.33609299733831\n",
      "Iteration 4123, the loss is 6.911795248109228, parameters k is 14.968877210334687 and b is -76.33509299733831\n",
      "Iteration 4124, the loss is 6.8994641288200125, parameters k is 14.97231802654022 and b is -76.3340929973383\n",
      "Iteration 4125, the loss is 6.887244725906691, parameters k is 14.975732376342592 and b is -76.3330929973383\n",
      "Iteration 4126, the loss is 6.875198995909248, parameters k is 14.979120666856426 and b is -76.3320929973383\n",
      "Iteration 4127, the loss is 6.8631532659118015, parameters k is 14.98250895737026 and b is -76.33109299733829\n",
      "Iteration 4128, the loss is 6.851125497150936, parameters k is 14.985897247884095 and b is -76.33009299733828\n",
      "Iteration 4129, the loss is 6.8392641249048385, parameters k is 14.989258811125202 and b is -76.32909299733828\n",
      "Iteration 4130, the loss is 6.8274027526587435, parameters k is 14.99262037436631 and b is -76.32809299733827\n",
      "Iteration 4131, the loss is 6.81554138041264, parameters k is 14.995981937607416 and b is -76.32709299733827\n",
      "Iteration 4132, the loss is 6.803680008166543, parameters k is 14.999343500848523 and b is -76.32609299733826\n",
      "Iteration 4133, the loss is 6.791818635920443, parameters k is 15.00270506408963 and b is -76.32509299733826\n",
      "Iteration 4134, the loss is 6.780052214358547, parameters k is 15.006066627330737 and b is -76.32409299733825\n",
      "Iteration 4135, the loss is 6.7683828643172586, parameters k is 15.009400099662754 and b is -76.32309299733825\n",
      "Iteration 4136, the loss is 6.756713514275972, parameters k is 15.01273357199477 and b is -76.32209299733825\n",
      "Iteration 4137, the loss is 6.745044164234689, parameters k is 15.016067044326787 and b is -76.32109299733824\n",
      "Iteration 4138, the loss is 6.733374814193403, parameters k is 15.019400516658804 and b is -76.32009299733824\n",
      "Iteration 4139, the loss is 6.721705464152113, parameters k is 15.02273398899082 and b is -76.31909299733823\n",
      "Iteration 4140, the loss is 6.710036114110838, parameters k is 15.026067461322837 and b is -76.31809299733823\n",
      "Iteration 4141, the loss is 6.698381834380691, parameters k is 15.029400933654854 and b is -76.31709299733822\n",
      "Iteration 4142, the loss is 6.68687353905331, parameters k is 15.032710757765527 and b is -76.31609299733822\n",
      "Iteration 4143, the loss is 6.675365243725919, parameters k is 15.0360205818762 and b is -76.31509299733821\n",
      "Iteration 4144, the loss is 6.663856948398531, parameters k is 15.039330405986872 and b is -76.31409299733821\n",
      "Iteration 4145, the loss is 6.6523590339382705, parameters k is 15.042640230097545 and b is -76.3130929973382\n",
      "Iteration 4146, the loss is 6.641088548669379, parameters k is 15.045921251836676 and b is -76.3120929973382\n",
      "Iteration 4147, the loss is 6.629931762122915, parameters k is 15.049178755789246 and b is -76.31109299733819\n",
      "Iteration 4148, the loss is 6.618774975576456, parameters k is 15.052436259741816 and b is -76.31009299733819\n",
      "Iteration 4149, the loss is 6.60765449553422, parameters k is 15.055693763694386 and b is -76.30909299733818\n",
      "Iteration 4150, the loss is 6.596687305552253, parameters k is 15.058922647093596 and b is -76.30809299733818\n",
      "Iteration 4151, the loss is 6.585720115570264, parameters k is 15.062151530492805 and b is -76.30709299733817\n",
      "Iteration 4152, the loss is 6.574781490439556, parameters k is 15.065380413892015 and b is -76.30609299733817\n",
      "Iteration 4153, the loss is 6.564058056987607, parameters k is 15.06858098503826 and b is -76.30509299733816\n",
      "Iteration 4154, the loss is 6.553588379732912, parameters k is 15.071757654998734 and b is -76.30409299733816\n",
      "Iteration 4155, the loss is 6.543302015468512, parameters k is 15.074881862508615 and b is -76.30309299733815\n",
      "Iteration 4156, the loss is 6.533028359113998, parameters k is 15.078006070018496 and b is -76.30209299733815\n",
      "Iteration 4157, the loss is 6.522920883950809, parameters k is 15.081104166856441 and b is -76.30109299733815\n",
      "Iteration 4158, the loss is 6.513008908733376, parameters k is 15.084169160927587 and b is -76.30009299733814\n",
      "Iteration 4159, the loss is 6.50309693351596, parameters k is 15.087234154998733 and b is -76.29909299733814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4160, the loss is 6.493216874698185, parameters k is 15.090299149069878 and b is -76.29809299733813\n",
      "Iteration 4161, the loss is 6.483474785450412, parameters k is 15.093336953417705 and b is -76.29709299733813\n",
      "Iteration 4162, the loss is 6.473732696202647, parameters k is 15.096374757765531 and b is -76.29609299733812\n",
      "Iteration 4163, the loss is 6.463990606954881, parameters k is 15.099412562113358 and b is -76.29509299733812\n",
      "Iteration 4164, the loss is 6.4542485177071045, parameters k is 15.102450366461184 and b is -76.29409299733811\n",
      "Iteration 4165, the loss is 6.444506428459334, parameters k is 15.10548817080901 and b is -76.2930929973381\n",
      "Iteration 4166, the loss is 6.434795646404372, parameters k is 15.108525975156837 and b is -76.2920929973381\n",
      "Iteration 4167, the loss is 6.4252544928039965, parameters k is 15.111531182666718 and b is -76.2910929973381\n",
      "Iteration 4168, the loss is 6.415713339203627, parameters k is 15.1145363901766 and b is -76.29009299733809\n",
      "Iteration 4169, the loss is 6.406203309667446, parameters k is 15.11754159768648 and b is -76.28909299733809\n",
      "Iteration 4170, the loss is 6.396805422193336, parameters k is 15.12052353642166 and b is -76.28809299733808\n",
      "Iteration 4171, the loss is 6.387407534719218, parameters k is 15.123505475156838 and b is -76.28709299733808\n",
      "Iteration 4172, the loss is 6.378028367764965, parameters k is 15.126487413892017 and b is -76.28609299733807\n",
      "Iteration 4173, the loss is 6.368773809553931, parameters k is 15.129445890176601 and b is -76.28509299733807\n",
      "Iteration 4174, the loss is 6.359519251342895, parameters k is 15.132404366461186 and b is -76.28409299733806\n",
      "Iteration 4175, the loss is 6.350264693131858, parameters k is 15.13536284274577 and b is -76.28309299733806\n",
      "Iteration 4176, the loss is 6.341083082799567, parameters k is 15.138321319030355 and b is -76.28209299733805\n",
      "Iteration 4177, the loss is 6.331986592345101, parameters k is 15.141253633259604 and b is -76.28109299733805\n",
      "Iteration 4178, the loss is 6.3228901018906205, parameters k is 15.144185947488852 and b is -76.28009299733804\n",
      "Iteration 4179, the loss is 6.313887552054371, parameters k is 15.1471182617181 and b is -76.27909299733804\n",
      "Iteration 4180, the loss is 6.305099128511871, parameters k is 15.149998939583712 and b is -76.27809299733804\n",
      "Iteration 4181, the loss is 6.29631070496936, parameters k is 15.152879617449324 and b is -76.27709299733803\n",
      "Iteration 4182, the loss is 6.287554028025913, parameters k is 15.155760295314936 and b is -76.27609299733803\n",
      "Iteration 4183, the loss is 6.279044949020426, parameters k is 15.15861625381296 and b is -76.27509299733802\n",
      "Iteration 4184, the loss is 6.270705789120911, parameters k is 15.161420405986874 and b is -76.27409299733802\n",
      "Iteration 4185, the loss is 6.262507618257091, parameters k is 15.16419958978134 and b is -76.27309299733801\n",
      "Iteration 4186, the loss is 6.254309447393272, parameters k is 15.166978773575806 and b is -76.272092997338\n",
      "Iteration 4187, the loss is 6.246111276529446, parameters k is 15.169757957370273 and b is -76.271092997338\n",
      "Iteration 4188, the loss is 6.237913105665623, parameters k is 15.172537141164739 and b is -76.270092997338\n",
      "Iteration 4189, the loss is 6.229714934801804, parameters k is 15.175316324959205 and b is -76.26909299733799\n",
      "Iteration 4190, the loss is 6.221516763937977, parameters k is 15.178095508753671 and b is -76.26809299733799\n",
      "Iteration 4191, the loss is 6.213318593074157, parameters k is 15.180874692548137 and b is -76.26709299733798\n",
      "Iteration 4192, the loss is 6.205120422210334, parameters k is 15.183653876342603 and b is -76.26609299733798\n",
      "Iteration 4193, the loss is 6.196922251346516, parameters k is 15.18643306013707 and b is -76.26509299733797\n",
      "Iteration 4194, the loss is 6.1887886268903936, parameters k is 15.189212243931536 and b is -76.26409299733797\n",
      "Iteration 4195, the loss is 6.1807394906673245, parameters k is 15.191965202429559 and b is -76.26309299733796\n",
      "Iteration 4196, the loss is 6.172714658602926, parameters k is 15.194718160927582 and b is -76.26209299733796\n",
      "Iteration 4197, the loss is 6.164883556132957, parameters k is 15.197444360532325 and b is -76.26109299733795\n",
      "Iteration 4198, the loss is 6.157138605981373, parameters k is 15.200142971204261 and b is -76.26009299733795\n",
      "Iteration 4199, the loss is 6.149393655829792, parameters k is 15.202841581876198 and b is -76.25909299733794\n",
      "Iteration 4200, the loss is 6.141648705678211, parameters k is 15.205540192548135 and b is -76.25809299733794\n",
      "Iteration 4201, the loss is 6.13390375552664, parameters k is 15.208238803220071 and b is -76.25709299733794\n",
      "Iteration 4202, the loss is 6.126158805375054, parameters k is 15.210937413892008 and b is -76.25609299733793\n",
      "Iteration 4203, the loss is 6.1184138552234835, parameters k is 15.213636024563945 and b is -76.25509299733793\n",
      "Iteration 4204, the loss is 6.1107193755937255, parameters k is 15.216334635235881 and b is -76.25409299733792\n",
      "Iteration 4205, the loss is 6.1033331127255925, parameters k is 15.21898152258766 and b is -76.25309299733792\n",
      "Iteration 4206, the loss is 6.096092556548136, parameters k is 15.221595615473035 and b is -76.25209299733791\n",
      "Iteration 4207, the loss is 6.088940344570727, parameters k is 15.224185127330742 and b is -76.2510929973379\n",
      "Iteration 4208, the loss is 6.081820874685581, parameters k is 15.226774639188449 and b is -76.2500929973379\n",
      "Iteration 4209, the loss is 6.0748040605353495, parameters k is 15.229338645117302 and b is -76.2490929973379\n",
      "Iteration 4210, the loss is 6.067787246385123, parameters k is 15.231902651046155 and b is -76.24809299733789\n",
      "Iteration 4211, the loss is 6.060770432234889, parameters k is 15.234466656975009 and b is -76.24709299733789\n",
      "Iteration 4212, the loss is 6.053814832969832, parameters k is 15.237030662903862 and b is -76.24609299733788\n",
      "Iteration 4213, the loss is 6.046996488059969, parameters k is 15.239568712310977 and b is -76.24509299733788\n",
      "Iteration 4214, the loss is 6.0403958045593376, parameters k is 15.24205263128331 and b is -76.24409299733787\n",
      "Iteration 4215, the loss is 6.033795121058689, parameters k is 15.244536550255642 and b is -76.24309299733787\n",
      "Iteration 4216, the loss is 6.027253993059293, parameters k is 15.247020469227975 and b is -76.24209299733786\n",
      "Iteration 4217, the loss is 6.02193092587081, parameters k is 15.249424921797145 and b is -76.24309299733787\n",
      "Iteration 4218, the loss is 6.016930972612484, parameters k is 15.251750232073825 and b is -76.24409299733787\n",
      "Iteration 4219, the loss is 6.011976355305884, parameters k is 15.254075542350504 and b is -76.24509299733788\n",
      "Iteration 4220, the loss is 6.0070927077891225, parameters k is 15.256374848674614 and b is -76.24609299733788\n",
      "Iteration 4221, the loss is 6.0022090602723726, parameters k is 15.258674154998724 and b is -76.24709299733789\n",
      "Iteration 4222, the loss is 5.997325412755616, parameters k is 15.260973461322834 and b is -76.24809299733789\n",
      "Iteration 4223, the loss is 5.992441765238857, parameters k is 15.263272767646944 and b is -76.2490929973379\n",
      "Iteration 4224, the loss is 5.987558117722111, parameters k is 15.265572073971054 and b is -76.2500929973379\n",
      "Iteration 4225, the loss is 5.982681476303633, parameters k is 15.267871380295164 and b is -76.2510929973379\n",
      "Iteration 4226, the loss is 5.97791784863202, parameters k is 15.270143568042199 and b is -76.25209299733791\n",
      "Iteration 4227, the loss is 5.973154220960415, parameters k is 15.272415755789234 and b is -76.25309299733792\n",
      "Iteration 4228, the loss is 5.9683905932888, parameters k is 15.27468794353627 and b is -76.25409299733792\n",
      "Iteration 4229, the loss is 5.963626965617196, parameters k is 15.276960131283305 and b is -76.25509299733793\n",
      "Iteration 4230, the loss is 5.95888840573139, parameters k is 15.27923231903034 and b is -76.25609299733793\n",
      "Iteration 4231, the loss is 5.954359896770604, parameters k is 15.281450384247732 and b is -76.25709299733794\n",
      "Iteration 4232, the loss is 5.949831387809841, parameters k is 15.283668449465123 and b is -76.25809299733794\n",
      "Iteration 4233, the loss is 5.9453092839143675, parameters k is 15.285886514682515 and b is -76.25909299733794\n",
      "Iteration 4234, the loss is 5.940892404146516, parameters k is 15.288078370413741 and b is -76.26009299733795\n",
      "Iteration 4235, the loss is 5.9364755243786655, parameters k is 15.290270226144967 and b is -76.26109299733795\n",
      "Iteration 4236, the loss is 5.932089074193797, parameters k is 15.292462081876193 and b is -76.26209299733796\n",
      "Iteration 4237, the loss is 5.927889051477593, parameters k is 15.294606475156826 and b is -76.26309299733796\n",
      "Iteration 4238, the loss is 5.923775816644022, parameters k is 15.296725137212162 and b is -76.26409299733797\n",
      "Iteration 4239, the loss is 5.919662581810452, parameters k is 15.298843799267498 and b is -76.26509299733797\n",
      "Iteration 4240, the loss is 5.915574146044866, parameters k is 15.300962461322834 and b is -76.26609299733798\n",
      "Iteration 4241, the loss is 5.911579402126745, parameters k is 15.303052921797143 and b is -76.26709299733798\n",
      "Iteration 4242, the loss is 5.907693313067356, parameters k is 15.305115366461175 and b is -76.26809299733799\n",
      "Iteration 4243, the loss is 5.9038072240079735, parameters k is 15.307177811125207 and b is -76.26909299733799\n",
      "Iteration 4244, the loss is 5.899921134948584, parameters k is 15.30924025578924 and b is -76.270092997338\n",
      "Iteration 4245, the loss is 5.896061487411279, parameters k is 15.311302700453272 and b is -76.271092997338\n",
      "Iteration 4246, the loss is 5.89229016227434, parameters k is 15.31333616092758 and b is -76.272092997338\n",
      "Iteration 4247, the loss is 5.888518837137403, parameters k is 15.315369621401889 and b is -76.27309299733801\n",
      "Iteration 4248, the loss is 5.884747512000462, parameters k is 15.317403081876197 and b is -76.27409299733802\n",
      "Iteration 4249, the loss is 5.8809761868635375, parameters k is 15.319436542350505 and b is -76.27509299733802\n",
      "Iteration 4250, the loss is 5.877223469120773, parameters k is 15.321470002824814 and b is -76.27609299733803\n",
      "Iteration 4251, the loss is 5.8735503507628835, parameters k is 15.32347818661928 and b is -76.27709299733803\n",
      "Iteration 4252, the loss is 5.8698772324050035, parameters k is 15.325486370413746 and b is -76.27809299733804\n",
      "Iteration 4253, the loss is 5.866204114047107, parameters k is 15.327494554208211 and b is -76.27909299733804\n",
      "Iteration 4254, the loss is 5.862560191920659, parameters k is 15.329502738002677 and b is -76.28009299733804\n",
      "Iteration 4255, the loss is 5.858970447524412, parameters k is 15.331489060137065 and b is -76.28109299733805\n",
      "Iteration 4256, the loss is 5.855380703128144, parameters k is 15.333475382271452 and b is -76.28209299733805\n",
      "Iteration 4257, the loss is 5.851823650607879, parameters k is 15.335461704405839 and b is -76.28309299733806\n",
      "Iteration 4258, the loss is 5.848327931508069, parameters k is 15.337423208358409 and b is -76.28409299733806\n",
      "Iteration 4259, the loss is 5.844832212408247, parameters k is 15.339384712310979 and b is -76.28509299733807\n",
      "Iteration 4260, the loss is 5.841336493308426, parameters k is 15.341346216263549 and b is -76.28609299733807\n",
      "Iteration 4261, the loss is 5.8378407742086, parameters k is 15.343307720216119 and b is -76.28709299733808\n",
      "Iteration 4262, the loss is 5.83434505510879, parameters k is 15.345269224168689 and b is -76.28809299733808\n",
      "Iteration 4263, the loss is 5.830888544768966, parameters k is 15.347230728121259 and b is -76.28909299733809\n",
      "Iteration 4264, the loss is 5.827487547864154, parameters k is 15.349166915868295 and b is -76.29009299733809\n",
      "Iteration 4265, the loss is 5.824086550959339, parameters k is 15.351103103615332 and b is -76.2910929973381\n",
      "Iteration 4266, the loss is 5.820685554054522, parameters k is 15.353039291362368 and b is -76.2920929973381\n",
      "Iteration 4267, the loss is 5.817284557149709, parameters k is 15.354975479109404 and b is -76.2930929973381\n",
      "Iteration 4268, the loss is 5.813883560244901, parameters k is 15.35691166685644 and b is -76.29409299733811\n",
      "Iteration 4269, the loss is 5.810526425892103, parameters k is 15.358847854603477 and b is -76.29509299733812\n",
      "Iteration 4270, the loss is 5.807240212652398, parameters k is 15.360753133259603 and b is -76.29609299733812\n",
      "Iteration 4271, the loss is 5.8039539994126965, parameters k is 15.36265841191573 and b is -76.29709299733813\n",
      "Iteration 4272, the loss is 5.800698514359686, parameters k is 15.364563690571856 and b is -76.29809299733813\n",
      "Iteration 4273, the loss is 5.797501560408801, parameters k is 15.366444348674623 and b is -76.29909299733814\n",
      "Iteration 4274, the loss is 5.794304606457924, parameters k is 15.36832500677739 and b is -76.30009299733814\n",
      "Iteration 4275, the loss is 5.791107652507036, parameters k is 15.370205664880157 and b is -76.30109299733815\n",
      "Iteration 4276, the loss is 5.787910698556149, parameters k is 15.372086322982923 and b is -76.30209299733815\n",
      "Iteration 4277, the loss is 5.7847399843416785, parameters k is 15.37396698108569 and b is -76.30309299733815\n",
      "Iteration 4278, the loss is 5.781632265684738, parameters k is 15.375822698476995 and b is -76.30409299733816\n",
      "Iteration 4279, the loss is 5.778524547027801, parameters k is 15.3776784158683 and b is -76.30509299733816\n",
      "Iteration 4280, the loss is 5.775416828370856, parameters k is 15.379534133259604 and b is -76.30609299733817\n",
      "Iteration 4281, the loss is 5.772309109713913, parameters k is 15.381389850650908 and b is -76.30709299733817\n",
      "Iteration 4282, the loss is 5.769201391056975, parameters k is 15.383245568042213 and b is -76.30809299733818\n",
      "Iteration 4283, the loss is 5.766093672400024, parameters k is 15.385101285433517 and b is -76.30909299733818\n",
      "Iteration 4284, the loss is 5.762985953743084, parameters k is 15.386957002824822 and b is -76.31009299733819\n",
      "Iteration 4285, the loss is 5.759937411516936, parameters k is 15.388812720216126 and b is -76.31109299733819\n",
      "Iteration 4286, the loss is 5.757002974961726, parameters k is 15.390618959346561 and b is -76.3120929973382\n",
      "Iteration 4287, the loss is 5.754088130969144, parameters k is 15.392425198476996 and b is -76.3130929973382\n",
      "Iteration 4288, the loss is 5.751238386726043, parameters k is 15.39420673009755 and b is -76.31409299733821\n",
      "Iteration 4289, the loss is 5.748388642482965, parameters k is 15.395988261718102 and b is -76.31509299733821\n",
      "Iteration 4290, the loss is 5.74553889823986, parameters k is 15.397769793338655 and b is -76.31609299733822\n",
      "Iteration 4291, the loss is 5.742715684454599, parameters k is 15.399551324959209 and b is -76.31709299733822\n",
      "Iteration 4292, the loss is 5.739949106059339, parameters k is 15.401308236026402 and b is -76.31809299733823\n",
      "Iteration 4293, the loss is 5.737220007401521, parameters k is 15.403065147093596 and b is -76.31909299733823\n",
      "Iteration 4294, the loss is 5.734628465631184, parameters k is 15.404770647093596 and b is -76.32009299733824\n",
      "Iteration 4295, the loss is 5.7321385410574655, parameters k is 15.40645084274577 and b is -76.32109299733824\n",
      "Iteration 4296, the loss is 5.729706002537066, parameters k is 15.40810519650071 and b is -76.32209299733825\n",
      "Iteration 4297, the loss is 5.72727346401667, parameters k is 15.40975955025565 and b is -76.32309299733825\n",
      "Iteration 4298, the loss is 5.724867537527282, parameters k is 15.41141390401059 and b is -76.32409299733825\n",
      "Iteration 4299, the loss is 5.722525409354343, parameters k is 15.413044423773437 and b is -76.32509299733826\n",
      "Iteration 4300, the loss is 5.720255872269616, parameters k is 15.41464629136237 and b is -76.32609299733826\n",
      "Iteration 4301, the loss is 5.7179863351849, parameters k is 15.416248158951303 and b is -76.32709299733827\n",
      "Iteration 4302, the loss is 5.715749409258157, parameters k is 15.417850026540236 and b is -76.32809299733827\n",
      "Iteration 4303, the loss is 5.713556534664266, parameters k is 15.419426530492805 and b is -76.32909299733828\n",
      "Iteration 4304, the loss is 5.711363660070378, parameters k is 15.421003034445373 and b is -76.33009299733828\n",
      "Iteration 4305, the loss is 5.709170785476498, parameters k is 15.422579538397942 and b is -76.33109299733829\n",
      "Iteration 4306, the loss is 5.706977910882603, parameters k is 15.42415604235051 and b is -76.3320929973383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4307, the loss is 5.704785036288717, parameters k is 15.42573254630308 and b is -76.3330929973383\n",
      "Iteration 4308, the loss is 5.7025921616948345, parameters k is 15.427309050255648 and b is -76.3340929973383\n",
      "Iteration 4309, the loss is 5.700399287100951, parameters k is 15.428885554208216 and b is -76.33509299733831\n",
      "Iteration 4310, the loss is 5.698206412507057, parameters k is 15.430462058160785 and b is -76.33609299733831\n",
      "Iteration 4311, the loss is 5.696013537913172, parameters k is 15.432038562113354 and b is -76.33709299733832\n",
      "Iteration 4312, the loss is 5.693820663319289, parameters k is 15.433615066065922 and b is -76.33809299733832\n",
      "Iteration 4313, the loss is 5.691627788725401, parameters k is 15.43519157001849 and b is -76.33909299733833\n",
      "Iteration 4314, the loss is 5.689469090915439, parameters k is 15.43676807397106 and b is -76.34009299733833\n",
      "Iteration 4315, the loss is 5.687430190225596, parameters k is 15.438292372390032 and b is -76.34109299733834\n",
      "Iteration 4316, the loss is 5.68539128953575, parameters k is 15.439816670809005 and b is -76.34209299733834\n",
      "Iteration 4317, the loss is 5.6833523888459085, parameters k is 15.441340969227978 and b is -76.34309299733835\n",
      "Iteration 4318, the loss is 5.681313488156059, parameters k is 15.442865267646951 and b is -76.34409299733835\n",
      "Iteration 4319, the loss is 5.6792745874662165, parameters k is 15.444389566065924 and b is -76.34509299733836\n",
      "Iteration 4320, the loss is 5.6772356867763705, parameters k is 15.445913864484897 and b is -76.34609299733836\n",
      "Iteration 4321, the loss is 5.675196786086523, parameters k is 15.44743816290387 and b is -76.34709299733836\n",
      "Iteration 4322, the loss is 5.673157885396684, parameters k is 15.448962461322843 and b is -76.34809299733837\n",
      "Iteration 4323, the loss is 5.671118984706839, parameters k is 15.450486759741816 and b is -76.34909299733837\n",
      "Iteration 4324, the loss is 5.669080084016993, parameters k is 15.452011058160789 and b is -76.35009299733838\n",
      "Iteration 4325, the loss is 5.667041183327151, parameters k is 15.453535356579762 and b is -76.35109299733838\n",
      "Iteration 4326, the loss is 5.665003245265828, parameters k is 15.455059654998735 and b is -76.35209299733839\n",
      "Iteration 4327, the loss is 5.6630590356602815, parameters k is 15.456559004801106 and b is -76.3530929973384\n",
      "Iteration 4328, the loss is 5.661237582157619, parameters k is 15.458006133259603 and b is -76.3540929973384\n",
      "Iteration 4329, the loss is 5.6594161286549465, parameters k is 15.459453261718101 and b is -76.3550929973384\n",
      "Iteration 4330, the loss is 5.657594675152283, parameters k is 15.4609003901766 and b is -76.35609299733841\n",
      "Iteration 4331, the loss is 5.655773221649619, parameters k is 15.462347518635097 and b is -76.35709299733841\n",
      "Iteration 4332, the loss is 5.653951768146952, parameters k is 15.463794647093595 and b is -76.35809299733842\n",
      "Iteration 4333, the loss is 5.6521303146442845, parameters k is 15.465241775552093 and b is -76.35909299733842\n",
      "Iteration 4334, the loss is 5.650308861141621, parameters k is 15.46668890401059 and b is -76.36009299733843\n",
      "Iteration 4335, the loss is 5.648516256032892, parameters k is 15.468136032469088 and b is -76.36109299733843\n",
      "Iteration 4336, the loss is 5.646763840305689, parameters k is 15.46955771823984 and b is -76.36209299733844\n",
      "Iteration 4337, the loss is 5.645011424578494, parameters k is 15.47097940401059 and b is -76.36309299733844\n",
      "Iteration 4338, the loss is 5.643259008851298, parameters k is 15.472401089781341 and b is -76.36409299733845\n",
      "Iteration 4339, the loss is 5.641506593124096, parameters k is 15.473822775552092 and b is -76.36509299733845\n",
      "Iteration 4340, the loss is 5.639754177396901, parameters k is 15.475244461322843 and b is -76.36609299733846\n",
      "Iteration 4341, the loss is 5.63800176166971, parameters k is 15.476666147093594 and b is -76.36709299733846\n",
      "Iteration 4342, the loss is 5.636249345942504, parameters k is 15.478087832864345 and b is -76.36809299733847\n",
      "Iteration 4343, the loss is 5.634496930215313, parameters k is 15.479509518635096 and b is -76.36909299733847\n",
      "Iteration 4344, the loss is 5.632744514488108, parameters k is 15.480931204405847 and b is -76.37009299733847\n",
      "Iteration 4345, the loss is 5.630992098760913, parameters k is 15.482352890176598 and b is -76.37109299733848\n",
      "Iteration 4346, the loss is 5.629255912767963, parameters k is 15.483774575947349 and b is -76.37209299733848\n",
      "Iteration 4347, the loss is 5.627566038029722, parameters k is 15.485172680690432 and b is -76.37309299733849\n",
      "Iteration 4348, the loss is 5.625904791733818, parameters k is 15.486570785433516 and b is -76.3740929973385\n",
      "Iteration 4349, the loss is 5.62430208508226, parameters k is 15.48794426567067 and b is -76.3750929973385\n",
      "Iteration 4350, the loss is 5.622749759107316, parameters k is 15.489289346698339 and b is -76.3760929973385\n",
      "Iteration 4351, the loss is 5.6211974331323775, parameters k is 15.490634427726008 and b is -76.37709299733851\n",
      "Iteration 4352, the loss is 5.619645107157425, parameters k is 15.491979508753676 and b is -76.37809299733851\n",
      "Iteration 4353, the loss is 5.618112993390234, parameters k is 15.493324589781345 and b is -76.37909299733852\n",
      "Iteration 4354, the loss is 5.616628922377256, parameters k is 15.494642556184507 and b is -76.38009299733852\n",
      "Iteration 4355, the loss is 5.615144851364261, parameters k is 15.49596052258767 and b is -76.38109299733853\n",
      "Iteration 4356, the loss is 5.613660780351279, parameters k is 15.497278488990831 and b is -76.38209299733853\n",
      "Iteration 4357, the loss is 5.612176709338294, parameters k is 15.498596455393994 and b is -76.38309299733854\n",
      "Iteration 4358, the loss is 5.61069263832531, parameters k is 15.499914421797156 and b is -76.38409299733854\n",
      "Iteration 4359, the loss is 5.609208567312326, parameters k is 15.501232388200318 and b is -76.38509299733855\n",
      "Iteration 4360, the loss is 5.607724496299335, parameters k is 15.50255035460348 and b is -76.38609299733855\n",
      "Iteration 4361, the loss is 5.606240425286354, parameters k is 15.503868321006642 and b is -76.38709299733856\n",
      "Iteration 4362, the loss is 5.60475635427336, parameters k is 15.505186287409805 and b is -76.38809299733856\n",
      "Iteration 4363, the loss is 5.603277267641426, parameters k is 15.506504253812967 and b is -76.38909299733857\n",
      "Iteration 4364, the loss is 5.601854854658002, parameters k is 15.507797089781347 and b is -76.39009299733857\n",
      "Iteration 4365, the loss is 5.600432441674564, parameters k is 15.509089925749727 and b is -76.39109299733857\n",
      "Iteration 4366, the loss is 5.599010028691142, parameters k is 15.510382761718107 and b is -76.39209299733858\n",
      "Iteration 4367, the loss is 5.597587615707718, parameters k is 15.511675597686487 and b is -76.39309299733858\n",
      "Iteration 4368, the loss is 5.596165202724292, parameters k is 15.512968433654867 and b is -76.39409299733859\n",
      "Iteration 4369, the loss is 5.5947427897408595, parameters k is 15.514261269623248 and b is -76.3950929973386\n",
      "Iteration 4370, the loss is 5.5933203767574335, parameters k is 15.515554105591628 and b is -76.3960929973386\n",
      "Iteration 4371, the loss is 5.5918979637740085, parameters k is 15.516846941560008 and b is -76.3970929973386\n",
      "Iteration 4372, the loss is 5.590477476033557, parameters k is 15.518139777528388 and b is -76.39809299733861\n",
      "Iteration 4373, the loss is 5.58911283132622, parameters k is 15.519408518635107 and b is -76.39909299733861\n",
      "Iteration 4374, the loss is 5.587777842464507, parameters k is 15.520677259741825 and b is -76.40009299733862\n",
      "Iteration 4375, the loss is 5.586476007160719, parameters k is 15.52191941191574 and b is -76.40109299733862\n",
      "Iteration 4376, the loss is 5.58518264465005, parameters k is 15.523161564089653 and b is -76.40209299733863\n",
      "Iteration 4377, the loss is 5.58393760804206, parameters k is 15.524379016658823 and b is -76.40309299733863\n",
      "Iteration 4378, the loss is 5.582692571434082, parameters k is 15.525596469227994 and b is -76.40409299733864\n",
      "Iteration 4379, the loss is 5.581447534826105, parameters k is 15.526813921797164 and b is -76.40509299733864\n",
      "Iteration 4380, the loss is 5.580202498218124, parameters k is 15.528031374366334 and b is -76.40609299733865\n",
      "Iteration 4381, the loss is 5.578957461610144, parameters k is 15.529248826935504 and b is -76.40709299733865\n",
      "Iteration 4382, the loss is 5.577712425002169, parameters k is 15.530466279504674 and b is -76.40809299733866\n",
      "Iteration 4383, the loss is 5.576469765593659, parameters k is 15.531683732073844 and b is -76.40909299733866\n",
      "Iteration 4384, the loss is 5.575277241505292, parameters k is 15.532877769623251 and b is -76.41009299733867\n",
      "Iteration 4385, the loss is 5.574084717416928, parameters k is 15.534071807172658 and b is -76.41109299733867\n",
      "Iteration 4386, the loss is 5.572892193328548, parameters k is 15.535265844722066 and b is -76.41209299733868\n",
      "Iteration 4387, the loss is 5.571699669240198, parameters k is 15.536459882271473 and b is -76.41309299733868\n",
      "Iteration 4388, the loss is 5.5705093289110215, parameters k is 15.53765391982088 and b is -76.41409299733868\n",
      "Iteration 4389, the loss is 5.569374746305726, parameters k is 15.53882175183669 and b is -76.41509299733869\n",
      "Iteration 4390, the loss is 5.568240163700431, parameters k is 15.539989583852499 and b is -76.4160929973387\n",
      "Iteration 4391, the loss is 5.567105581095142, parameters k is 15.541157415868309 and b is -76.4170929973387\n",
      "Iteration 4392, the loss is 5.565990646259354, parameters k is 15.542325247884119 and b is -76.4180929973387\n",
      "Iteration 4393, the loss is 5.564911340823393, parameters k is 15.543467439583724 and b is -76.41909299733871\n",
      "Iteration 4394, the loss is 5.563832035387437, parameters k is 15.544609631283329 and b is -76.42009299733871\n",
      "Iteration 4395, the loss is 5.562752729951482, parameters k is 15.545751822982934 and b is -76.42109299733872\n",
      "Iteration 4396, the loss is 5.5616734245155275, parameters k is 15.54689401468254 and b is -76.42209299733872\n",
      "Iteration 4397, the loss is 5.56059411907956, parameters k is 15.548036206382145 and b is -76.42309299733873\n",
      "Iteration 4398, the loss is 5.559514813643608, parameters k is 15.54917839808175 and b is -76.42409299733873\n",
      "Iteration 4399, the loss is 5.558435508207657, parameters k is 15.550320589781355 and b is -76.42509299733874\n",
      "Iteration 4400, the loss is 5.557373165971127, parameters k is 15.55146278148096 and b is -76.42609299733874\n",
      "Iteration 4401, the loss is 5.556354425131842, parameters k is 15.552576372390051 and b is -76.42709299733875\n",
      "Iteration 4402, the loss is 5.555335684292547, parameters k is 15.553689963299142 and b is -76.42809299733875\n",
      "Iteration 4403, the loss is 5.554316943453261, parameters k is 15.554803554208233 and b is -76.42909299733876\n",
      "Iteration 4404, the loss is 5.553298202613966, parameters k is 15.555917145117323 and b is -76.43009299733876\n",
      "Iteration 4405, the loss is 5.55227946177467, parameters k is 15.557030736026414 and b is -76.43109299733877\n",
      "Iteration 4406, the loss is 5.5512607209353835, parameters k is 15.558144326935505 and b is -76.43209299733877\n",
      "Iteration 4407, the loss is 5.550241980096094, parameters k is 15.559257917844596 and b is -76.43309299733878\n",
      "Iteration 4408, the loss is 5.549223239256799, parameters k is 15.560371508753686 and b is -76.43409299733878\n",
      "Iteration 4409, the loss is 5.548204498417518, parameters k is 15.561485099662777 and b is -76.43509299733878\n",
      "Iteration 4410, the loss is 5.547185757578217, parameters k is 15.562598690571868 and b is -76.43609299733879\n",
      "Iteration 4411, the loss is 5.5461670167389325, parameters k is 15.563712281480958 and b is -76.4370929973388\n",
      "Iteration 4412, the loss is 5.545157771696107, parameters k is 15.564825872390049 and b is -76.4380929973388\n",
      "Iteration 4413, the loss is 5.54418979719633, parameters k is 15.565914617449337 and b is -76.4390929973388\n",
      "Iteration 4414, the loss is 5.543221822696552, parameters k is 15.567003362508625 and b is -76.44009299733881\n",
      "Iteration 4415, the loss is 5.542253848196773, parameters k is 15.568092107567914 and b is -76.44109299733881\n",
      "Iteration 4416, the loss is 5.541285873697001, parameters k is 15.569180852627202 and b is -76.44209299733882\n",
      "Iteration 4417, the loss is 5.540317899197227, parameters k is 15.57026959768649 and b is -76.44309299733882\n",
      "Iteration 4418, the loss is 5.539362509853955, parameters k is 15.571358342745778 and b is -76.44409299733883\n",
      "Iteration 4419, the loss is 5.538449181379742, parameters k is 15.572422479109415 and b is -76.44509299733883\n",
      "Iteration 4420, the loss is 5.537583105892847, parameters k is 15.57345957199479 and b is -76.44609299733884\n",
      "Iteration 4421, the loss is 5.5367170304059625, parameters k is 15.574496664880167 and b is -76.44709299733884\n",
      "Iteration 4422, the loss is 5.535850954919075, parameters k is 15.575533757765543 and b is -76.44809299733885\n",
      "Iteration 4423, the loss is 5.534984879432189, parameters k is 15.576570850650919 and b is -76.44909299733885\n",
      "Iteration 4424, the loss is 5.534118803945296, parameters k is 15.577607943536295 and b is -76.45009299733886\n",
      "Iteration 4425, the loss is 5.533252728458409, parameters k is 15.57864503642167 and b is -76.45109299733886\n",
      "Iteration 4426, the loss is 5.532386652971525, parameters k is 15.579682129307047 and b is -76.45209299733887\n",
      "Iteration 4427, the loss is 5.531520577484634, parameters k is 15.580719222192423 and b is -76.45309299733887\n",
      "Iteration 4428, the loss is 5.530654501997745, parameters k is 15.581756315077799 and b is -76.45409299733888\n",
      "Iteration 4429, the loss is 5.529815408071499, parameters k is 15.582793407963175 and b is -76.45509299733888\n",
      "Iteration 4430, the loss is 5.529055709609382, parameters k is 15.583773856579775 and b is -76.45609299733889\n",
      "Iteration 4431, the loss is 5.528296011147249, parameters k is 15.584754305196375 and b is -76.45709299733889\n",
      "Iteration 4432, the loss is 5.527536312685122, parameters k is 15.585734753812975 and b is -76.4580929973389\n",
      "Iteration 4433, the loss is 5.526776614223003, parameters k is 15.586715202429575 and b is -76.4590929973389\n",
      "Iteration 4434, the loss is 5.52601691576088, parameters k is 15.587695651046175 and b is -76.4600929973389\n",
      "Iteration 4435, the loss is 5.5252572172987495, parameters k is 15.588676099662775 and b is -76.46109299733891\n",
      "Iteration 4436, the loss is 5.524497518836628, parameters k is 15.589656548279375 and b is -76.46209299733891\n",
      "Iteration 4437, the loss is 5.5237378203745005, parameters k is 15.590636996895975 and b is -76.46309299733892\n",
      "Iteration 4438, the loss is 5.522978121912382, parameters k is 15.591617445512576 and b is -76.46409299733892\n",
      "Iteration 4439, the loss is 5.5222184234502505, parameters k is 15.592597894129176 and b is -76.46509299733893\n",
      "Iteration 4440, the loss is 5.521458724988128, parameters k is 15.593578342745776 and b is -76.46609299733893\n",
      "Iteration 4441, the loss is 5.520699026525999, parameters k is 15.594558791362376 and b is -76.46709299733894\n",
      "Iteration 4442, the loss is 5.519939328063875, parameters k is 15.595539239978976 and b is -76.46809299733894\n",
      "Iteration 4443, the loss is 5.5191796296017595, parameters k is 15.596519688595576 and b is -76.46909299733895\n",
      "Iteration 4444, the loss is 5.518433638187116, parameters k is 15.597500137212176 and b is -76.47009299733895\n",
      "Iteration 4445, the loss is 5.517723440995618, parameters k is 15.598455226144983 and b is -76.47109299733896\n",
      "Iteration 4446, the loss is 5.517052198505401, parameters k is 15.599385236026405 and b is -76.47209299733896\n",
      "Iteration 4447, the loss is 5.516380956015184, parameters k is 15.600315245907828 and b is -76.47309299733897\n",
      "Iteration 4448, the loss is 5.515709713524973, parameters k is 15.60124525578925 and b is -76.47409299733897\n",
      "Iteration 4449, the loss is 5.5150384710347575, parameters k is 15.602175265670672 and b is -76.47509299733898\n",
      "Iteration 4450, the loss is 5.514378789300413, parameters k is 15.603105275552094 and b is -76.47609299733898\n",
      "Iteration 4451, the loss is 5.513749877475347, parameters k is 15.604010060137075 and b is -76.47709299733899\n",
      "Iteration 4452, the loss is 5.513120965650291, parameters k is 15.604914844722055 and b is -76.47809299733899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4453, the loss is 5.51250748442044, parameters k is 15.605819629307035 and b is -76.479092997339\n",
      "Iteration 4454, the loss is 5.511919936532795, parameters k is 15.60669901468253 and b is -76.480092997339\n",
      "Iteration 4455, the loss is 5.5113427271582625, parameters k is 15.607578400058024 and b is -76.481092997339\n",
      "Iteration 4456, the loss is 5.510793300659546, parameters k is 15.608433528516523 and b is -76.48209299733901\n",
      "Iteration 4457, the loss is 5.5102580784384685, parameters k is 15.609288656975021 and b is -76.48309299733901\n",
      "Iteration 4458, the loss is 5.509755237526937, parameters k is 15.610113706382135 and b is -76.48409299733902\n",
      "Iteration 4459, the loss is 5.50926670415608, parameters k is 15.610938755789249 and b is -76.48509299733902\n",
      "Iteration 4460, the loss is 5.508832502521126, parameters k is 15.611716034445376 and b is -76.48609299733903\n",
      "Iteration 4461, the loss is 5.5083983008861575, parameters k is 15.612493313101503 and b is -76.48709299733903\n",
      "Iteration 4462, the loss is 5.5079640992512005, parameters k is 15.61327059175763 and b is -76.48809299733904\n",
      "Iteration 4463, the loss is 5.507544206046819, parameters k is 15.614047870413756 and b is -76.48909299733904\n",
      "Iteration 4464, the loss is 5.507144570243727, parameters k is 15.614799963299133 and b is -76.49009299733905\n",
      "Iteration 4465, the loss is 5.506744934440632, parameters k is 15.615552056184509 and b is -76.49109299733905\n",
      "Iteration 4466, the loss is 5.506345298637538, parameters k is 15.616304149069885 and b is -76.49209299733906\n",
      "Iteration 4467, the loss is 5.505945662834443, parameters k is 15.617056241955261 and b is -76.49309299733906\n",
      "Iteration 4468, the loss is 5.505546027031349, parameters k is 15.617808334840637 and b is -76.49409299733907\n",
      "Iteration 4469, the loss is 5.505146391228257, parameters k is 15.618560427726013 and b is -76.49509299733907\n",
      "Iteration 4470, the loss is 5.504746755425167, parameters k is 15.61931252061139 and b is -76.49609299733908\n",
      "Iteration 4471, the loss is 5.50434711962207, parameters k is 15.620064613496766 and b is -76.49709299733908\n",
      "Iteration 4472, the loss is 5.503948409995078, parameters k is 15.620816706382142 and b is -76.49809299733909\n",
      "Iteration 4473, the loss is 5.503582094362712, parameters k is 15.62154359768649 and b is -76.49909299733909\n",
      "Iteration 4474, the loss is 5.503215778730338, parameters k is 15.622270488990837 and b is -76.5000929973391\n",
      "Iteration 4475, the loss is 5.502849463097973, parameters k is 15.622997380295185 and b is -76.5010929973391\n",
      "Iteration 4476, the loss is 5.502483147465607, parameters k is 15.623724271599533 and b is -76.5020929973391\n",
      "Iteration 4477, the loss is 5.50211683183324, parameters k is 15.624451162903881 and b is -76.50309299733911\n",
      "Iteration 4478, the loss is 5.501750516200874, parameters k is 15.625178054208229 and b is -76.50409299733911\n",
      "Iteration 4479, the loss is 5.50138420056851, parameters k is 15.625904945512577 and b is -76.50509299733912\n",
      "Iteration 4480, the loss is 5.501017884936138, parameters k is 15.626631836816925 and b is -76.50609299733912\n",
      "Iteration 4481, the loss is 5.500651569303768, parameters k is 15.627358728121273 and b is -76.50709299733913\n",
      "Iteration 4482, the loss is 5.500285253671397, parameters k is 15.62808561942562 and b is -76.50809299733913\n",
      "Iteration 4483, the loss is 5.499935221195003, parameters k is 15.628812510729968 and b is -76.50909299733914\n",
      "Iteration 4484, the loss is 5.499629893717302, parameters k is 15.629490358556055 and b is -76.51009299733914\n",
      "Iteration 4485, the loss is 5.499324566239599, parameters k is 15.630168206382141 and b is -76.51109299733915\n",
      "Iteration 4486, the loss is 5.499019238761896, parameters k is 15.630846054208227 and b is -76.51209299733915\n",
      "Iteration 4487, the loss is 5.498713911284194, parameters k is 15.631523902034314 and b is -76.51309299733916\n",
      "Iteration 4488, the loss is 5.498408583806498, parameters k is 15.6322017498604 and b is -76.51409299733916\n",
      "Iteration 4489, the loss is 5.498107386380755, parameters k is 15.632879597686486 and b is -76.51509299733917\n",
      "Iteration 4490, the loss is 5.497829767189048, parameters k is 15.633533674761585 and b is -76.51609299733917\n",
      "Iteration 4491, the loss is 5.497552147997335, parameters k is 15.634187751836684 and b is -76.51709299733918\n",
      "Iteration 4492, the loss is 5.497282341301913, parameters k is 15.634841828911783 and b is -76.51809299733918\n",
      "Iteration 4493, the loss is 5.497032062280054, parameters k is 15.635471530492811 and b is -76.51909299733919\n",
      "Iteration 4494, the loss is 5.496781783258193, parameters k is 15.63610123207384 and b is -76.52009299733919\n",
      "Iteration 4495, the loss is 5.496531504236329, parameters k is 15.636730933654867 and b is -76.5210929973392\n",
      "Iteration 4496, the loss is 5.496281225214473, parameters k is 15.637360635235895 and b is -76.5220929973392\n",
      "Iteration 4497, the loss is 5.496030946192616, parameters k is 15.637990336816923 and b is -76.5230929973392\n",
      "Iteration 4498, the loss is 5.49578066717075, parameters k is 15.638620038397951 and b is -76.52409299733921\n",
      "Iteration 4499, the loss is 5.495530388148893, parameters k is 15.639249739978979 and b is -76.52509299733921\n",
      "Iteration 4500, the loss is 5.495280109127032, parameters k is 15.639879441560007 and b is -76.52609299733922\n",
      "Iteration 4501, the loss is 5.495029830105176, parameters k is 15.640509143141035 and b is -76.52709299733922\n",
      "Iteration 4502, the loss is 5.494786783886831, parameters k is 15.641138844722063 and b is -76.52809299733923\n",
      "Iteration 4503, the loss is 5.494562403046646, parameters k is 15.641744380295185 and b is -76.52909299733923\n",
      "Iteration 4504, the loss is 5.494338022206438, parameters k is 15.642349915868307 and b is -76.53009299733924\n",
      "Iteration 4505, the loss is 5.494113641366245, parameters k is 15.642955451441429 and b is -76.53109299733924\n",
      "Iteration 4506, the loss is 5.493889260526045, parameters k is 15.643560987014551 and b is -76.53209299733925\n",
      "Iteration 4507, the loss is 5.493664879685849, parameters k is 15.644166522587673 and b is -76.53309299733925\n",
      "Iteration 4508, the loss is 5.493440498845656, parameters k is 15.644772058160795 and b is -76.53409299733926\n",
      "Iteration 4509, the loss is 5.493216118005456, parameters k is 15.645377593733917 and b is -76.53509299733926\n",
      "Iteration 4510, the loss is 5.492991737165259, parameters k is 15.645983129307039 and b is -76.53609299733927\n",
      "Iteration 4511, the loss is 5.492767356325058, parameters k is 15.646588664880161 and b is -76.53709299733927\n",
      "Iteration 4512, the loss is 5.492542975484864, parameters k is 15.647194200453283 and b is -76.53809299733928\n",
      "Iteration 4513, the loss is 5.492318594644666, parameters k is 15.647799736026405 and b is -76.53909299733928\n",
      "Iteration 4514, the loss is 5.492094213804472, parameters k is 15.648405271599527 and b is -76.54009299733929\n",
      "Iteration 4515, the loss is 5.491869832964269, parameters k is 15.64901080717265 and b is -76.54109299733929\n",
      "Iteration 4516, the loss is 5.4916454521240725, parameters k is 15.649616342745771 and b is -76.5420929973393\n",
      "Iteration 4517, the loss is 5.49142107128388, parameters k is 15.650221878318893 and b is -76.5430929973393\n",
      "Iteration 4518, the loss is 5.491196690443681, parameters k is 15.650827413892015 and b is -76.5440929973393\n",
      "Iteration 4519, the loss is 5.490972309603483, parameters k is 15.651432949465137 and b is -76.54509299733931\n",
      "Iteration 4520, the loss is 5.490747928763287, parameters k is 15.65203848503826 and b is -76.54609299733931\n",
      "Iteration 4521, the loss is 5.490523547923081, parameters k is 15.652644020611381 and b is -76.54709299733932\n",
      "Iteration 4522, the loss is 5.490307775580784, parameters k is 15.653249556184504 and b is -76.54809299733932\n",
      "Iteration 4523, the loss is 5.490109048056366, parameters k is 15.653830131283318 and b is -76.54909299733933\n",
      "Iteration 4524, the loss is 5.4899103205319575, parameters k is 15.654410706382132 and b is -76.55009299733933\n",
      "Iteration 4525, the loss is 5.489711593007537, parameters k is 15.654991281480946 and b is -76.55109299733934\n",
      "Iteration 4526, the loss is 5.489512865483125, parameters k is 15.65557185657976 and b is -76.55209299733934\n",
      "Iteration 4527, the loss is 5.489314137958713, parameters k is 15.656152431678574 and b is -76.55309299733935\n",
      "Iteration 4528, the loss is 5.489115410434296, parameters k is 15.656733006777388 and b is -76.55409299733935\n",
      "Iteration 4529, the loss is 5.488927251750521, parameters k is 15.657313581876203 and b is -76.55509299733936\n",
      "Iteration 4530, the loss is 5.4887530105460645, parameters k is 15.657869125354463 and b is -76.55609299733936\n",
      "Iteration 4531, the loss is 5.488578769341611, parameters k is 15.658424668832723 and b is -76.55709299733937\n",
      "Iteration 4532, the loss is 5.488404528137153, parameters k is 15.658980212310983 and b is -76.55809299733937\n",
      "Iteration 4533, the loss is 5.488230286932699, parameters k is 15.659535755789243 and b is -76.55909299733938\n",
      "Iteration 4534, the loss is 5.488056045728237, parameters k is 15.660091299267503 and b is -76.56009299733938\n",
      "Iteration 4535, the loss is 5.48788180452378, parameters k is 15.660646842745763 and b is -76.56109299733939\n",
      "Iteration 4536, the loss is 5.4877075633193195, parameters k is 15.661202386224023 and b is -76.56209299733939\n",
      "Iteration 4537, the loss is 5.487533322114861, parameters k is 15.661757929702283 and b is -76.5630929973394\n",
      "Iteration 4538, the loss is 5.4873590809104025, parameters k is 15.662313473180543 and b is -76.5640929973394\n",
      "Iteration 4539, the loss is 5.48718483970594, parameters k is 15.662869016658803 and b is -76.5650929973394\n",
      "Iteration 4540, the loss is 5.487010598501483, parameters k is 15.663424560137063 and b is -76.56609299733941\n",
      "Iteration 4541, the loss is 5.486836357297028, parameters k is 15.663980103615323 and b is -76.56709299733942\n",
      "Iteration 4542, the loss is 5.486662116092564, parameters k is 15.664535647093583 and b is -76.56809299733942\n",
      "Iteration 4543, the loss is 5.486487874888106, parameters k is 15.665091190571843 and b is -76.56909299733942\n",
      "Iteration 4544, the loss is 5.486313633683655, parameters k is 15.665646734050103 and b is -76.57009299733943\n",
      "Iteration 4545, the loss is 5.486139392479193, parameters k is 15.666202277528363 and b is -76.57109299733943\n",
      "Iteration 4546, the loss is 5.485965151274738, parameters k is 15.666757821006623 and b is -76.57209299733944\n",
      "Iteration 4547, the loss is 5.485794861020518, parameters k is 15.667313364484883 and b is -76.57309299733944\n",
      "Iteration 4548, the loss is 5.4856441565666305, parameters k is 15.66784593167856 and b is -76.57409299733945\n",
      "Iteration 4549, the loss is 5.485512777538644, parameters k is 15.668353732073816 and b is -76.57509299733945\n",
      "Iteration 4550, the loss is 5.485381398510661, parameters k is 15.668861532469073 and b is -76.57609299733946\n",
      "Iteration 4551, the loss is 5.485250019482678, parameters k is 15.66936933286433 and b is -76.57709299733946\n",
      "Iteration 4552, the loss is 5.485118640454696, parameters k is 15.669877133259586 and b is -76.57809299733947\n",
      "Iteration 4553, the loss is 5.484987261426707, parameters k is 15.670384933654843 and b is -76.57909299733947\n",
      "Iteration 4554, the loss is 5.484855882398729, parameters k is 15.6708927340501 and b is -76.58009299733948\n",
      "Iteration 4555, the loss is 5.484724503370741, parameters k is 15.671400534445356 and b is -76.58109299733948\n",
      "Iteration 4556, the loss is 5.4845931243427595, parameters k is 15.671908334840612 and b is -76.58209299733949\n",
      "Iteration 4557, the loss is 5.484461745314774, parameters k is 15.672416135235869 and b is -76.58309299733949\n",
      "Iteration 4558, the loss is 5.484330366286793, parameters k is 15.672923935631125 and b is -76.5840929973395\n",
      "Iteration 4559, the loss is 5.484198987258804, parameters k is 15.673431736026382 and b is -76.5850929973395\n",
      "Iteration 4560, the loss is 5.484067608230826, parameters k is 15.673939536421639 and b is -76.5860929973395\n",
      "Iteration 4561, the loss is 5.483936229202845, parameters k is 15.674447336816895 and b is -76.58709299733951\n",
      "Iteration 4562, the loss is 5.483804850174854, parameters k is 15.674955137212152 and b is -76.58809299733952\n",
      "Iteration 4563, the loss is 5.483673471146884, parameters k is 15.675462937607408 and b is -76.58909299733952\n",
      "Iteration 4564, the loss is 5.4835420921188955, parameters k is 15.675970738002665 and b is -76.59009299733953\n",
      "Iteration 4565, the loss is 5.483410713090907, parameters k is 15.676478538397921 and b is -76.59109299733953\n",
      "Iteration 4566, the loss is 5.483279334062925, parameters k is 15.676986338793178 and b is -76.59209299733953\n",
      "Iteration 4567, the loss is 5.483147955034942, parameters k is 15.677494139188434 and b is -76.59309299733954\n",
      "Iteration 4568, the loss is 5.483016576006957, parameters k is 15.678001939583691 and b is -76.59409299733954\n",
      "Iteration 4569, the loss is 5.482885196978973, parameters k is 15.678509739978947 and b is -76.59509299733955\n",
      "Iteration 4570, the loss is 5.482753817950989, parameters k is 15.679017540374204 and b is -76.59609299733955\n",
      "Iteration 4571, the loss is 5.482622438923012, parameters k is 15.67952534076946 and b is -76.59709299733956\n",
      "Iteration 4572, the loss is 5.482493713587604, parameters k is 15.680033141164717 and b is -76.59809299733956\n",
      "Iteration 4573, the loss is 5.482382543596783, parameters k is 15.680516566065902 and b is -76.59909299733957\n",
      "Iteration 4574, the loss is 5.4822713736059665, parameters k is 15.680999990967088 and b is -76.60009299733957\n",
      "Iteration 4575, the loss is 5.4821602036151535, parameters k is 15.681483415868273 and b is -76.60109299733958\n",
      "Iteration 4576, the loss is 5.48204903362434, parameters k is 15.681966840769459 and b is -76.60209299733958\n",
      "Iteration 4577, the loss is 5.4819378636335205, parameters k is 15.682450265670644 and b is -76.60309299733959\n",
      "Iteration 4578, the loss is 5.481828247759896, parameters k is 15.68293369057183 and b is -76.60409299733959\n",
      "Iteration 4579, the loss is 5.481738656264077, parameters k is 15.683389945512541 and b is -76.6050929973396\n",
      "Iteration 4580, the loss is 5.481649064768247, parameters k is 15.683846200453253 and b is -76.6060929973396\n",
      "Iteration 4581, the loss is 5.481559473272422, parameters k is 15.684302455393965 and b is -76.6070929973396\n",
      "Iteration 4582, the loss is 5.481469881776608, parameters k is 15.684758710334677 and b is -76.60809299733961\n",
      "Iteration 4583, the loss is 5.481380290280777, parameters k is 15.685214965275389 and b is -76.60909299733962\n",
      "Iteration 4584, the loss is 5.481290698784954, parameters k is 15.6856712202161 and b is -76.61009299733962\n",
      "Iteration 4585, the loss is 5.481201107289128, parameters k is 15.686127475156812 and b is -76.61109299733963\n",
      "Iteration 4586, the loss is 5.481111515793301, parameters k is 15.686583730097524 and b is -76.61209299733963\n",
      "Iteration 4587, the loss is 5.481021924297478, parameters k is 15.687039985038236 and b is -76.61309299733963\n",
      "Iteration 4588, the loss is 5.480932332801652, parameters k is 15.687496239978948 and b is -76.61409299733964\n",
      "Iteration 4589, the loss is 5.480842741305839, parameters k is 15.68795249491966 and b is -76.61509299733964\n",
      "Iteration 4590, the loss is 5.480753149810007, parameters k is 15.688408749860372 and b is -76.61609299733965\n",
      "Iteration 4591, the loss is 5.4806635583141805, parameters k is 15.688865004801084 and b is -76.61709299733965\n",
      "Iteration 4592, the loss is 5.480573966818357, parameters k is 15.689321259741796 and b is -76.61809299733966\n",
      "Iteration 4593, the loss is 5.4804843753225345, parameters k is 15.689777514682508 and b is -76.61909299733966\n",
      "Iteration 4594, the loss is 5.48039478382671, parameters k is 15.69023376962322 and b is -76.62009299733967\n",
      "Iteration 4595, the loss is 5.480305192330888, parameters k is 15.690690024563931 and b is -76.62109299733967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4596, the loss is 5.48021560083506, parameters k is 15.691146279504643 and b is -76.62209299733968\n",
      "Iteration 4597, the loss is 5.480126009339237, parameters k is 15.691602534445355 and b is -76.62309299733968\n",
      "Iteration 4598, the loss is 5.480036417843407, parameters k is 15.692058789386067 and b is -76.62409299733969\n",
      "Iteration 4599, the loss is 5.479946826347585, parameters k is 15.692515044326779 and b is -76.62509299733969\n",
      "Iteration 4600, the loss is 5.4798572348517665, parameters k is 15.69297129926749 and b is -76.6260929973397\n",
      "Iteration 4601, the loss is 5.4797715538567875, parameters k is 15.693427554208203 and b is -76.6270929973397\n",
      "Iteration 4602, the loss is 5.479700429287424, parameters k is 15.69385854037421 and b is -76.6280929973397\n",
      "Iteration 4603, the loss is 5.479629304718066, parameters k is 15.694289526540217 and b is -76.62909299733971\n",
      "Iteration 4604, the loss is 5.479558180148701, parameters k is 15.694720512706224 and b is -76.63009299733972\n",
      "Iteration 4605, the loss is 5.479487055579339, parameters k is 15.695151498872232 and b is -76.63109299733972\n",
      "Iteration 4606, the loss is 5.479422119906172, parameters k is 15.695582485038239 and b is -76.63209299733973\n",
      "Iteration 4607, the loss is 5.479367385666918, parameters k is 15.695989186619267 and b is -76.63309299733973\n",
      "Iteration 4608, the loss is 5.479312651427665, parameters k is 15.696395888200295 and b is -76.63409299733974\n",
      "Iteration 4609, the loss is 5.479257917188417, parameters k is 15.696802589781322 and b is -76.63509299733974\n",
      "Iteration 4610, the loss is 5.479203182949159, parameters k is 15.69720929136235 and b is -76.63609299733974\n",
      "Iteration 4611, the loss is 5.47914844870991, parameters k is 15.697615992943378 and b is -76.63709299733975\n",
      "Iteration 4612, the loss is 5.479093714470662, parameters k is 15.698022694524406 and b is -76.63809299733975\n",
      "Iteration 4613, the loss is 5.479038980231409, parameters k is 15.698429396105434 and b is -76.63909299733976\n",
      "Iteration 4614, the loss is 5.47898424599216, parameters k is 15.698836097686462 and b is -76.64009299733976\n",
      "Iteration 4615, the loss is 5.478929511752908, parameters k is 15.69924279926749 and b is -76.64109299733977\n",
      "Iteration 4616, the loss is 5.478874777513655, parameters k is 15.699649500848517 and b is -76.64209299733977\n",
      "Iteration 4617, the loss is 5.478820043274403, parameters k is 15.700056202429545 and b is -76.64309299733978\n",
      "Iteration 4618, the loss is 5.478770019787941, parameters k is 15.700462904010573 and b is -76.64409299733978\n",
      "Iteration 4619, the loss is 5.478730762304895, parameters k is 15.700844973180534 and b is -76.64509299733979\n",
      "Iteration 4620, the loss is 5.478691504821847, parameters k is 15.701227042350494 and b is -76.64609299733979\n",
      "Iteration 4621, the loss is 5.478652247338805, parameters k is 15.701609111520455 and b is -76.6470929973398\n",
      "Iteration 4622, the loss is 5.478614790056221, parameters k is 15.701991180690415 and b is -76.6480929973398\n",
      "Iteration 4623, the loss is 5.47859253311881, parameters k is 15.702344767646936 and b is -76.6490929973398\n",
      "Iteration 4624, the loss is 5.478570276181413, parameters k is 15.702698354603458 and b is -76.65009299733981\n",
      "Iteration 4625, the loss is 5.478548019244001, parameters k is 15.703051941559979 and b is -76.65109299733982\n",
      "Iteration 4626, the loss is 5.478525762306605, parameters k is 15.7034055285165 and b is -76.65209299733982\n",
      "Iteration 4627, the loss is 5.478503505369197, parameters k is 15.703759115473021 and b is -76.65309299733983\n",
      "Iteration 4628, the loss is 5.4784812484317955, parameters k is 15.704112702429542 and b is -76.65409299733983\n",
      "Iteration 4629, the loss is 5.478458991494392, parameters k is 15.704466289386064 and b is -76.65509299733984\n",
      "Iteration 4630, the loss is 5.478436734556991, parameters k is 15.704819876342585 and b is -76.65609299733984\n",
      "Iteration 4631, the loss is 5.478414477619587, parameters k is 15.705173463299106 and b is -76.65709299733984\n",
      "Iteration 4632, the loss is 5.478392220682189, parameters k is 15.705527050255627 and b is -76.65809299733985\n",
      "Iteration 4633, the loss is 5.478369963744786, parameters k is 15.705880637212148 and b is -76.65909299733985\n",
      "Iteration 4634, the loss is 5.47834770680739, parameters k is 15.70623422416867 and b is -76.66009299733986\n",
      "Iteration 4635, the loss is 5.478325449869975, parameters k is 15.70658781112519 and b is -76.66109299733986\n",
      "Iteration 4636, the loss is 5.478303192932577, parameters k is 15.706941398081712 and b is -76.66209299733987\n",
      "Iteration 4637, the loss is 5.478280935995176, parameters k is 15.707294985038233 and b is -76.66309299733987\n",
      "Iteration 4638, the loss is 5.478258679057773, parameters k is 15.707648571994755 and b is -76.66409299733988\n",
      "Iteration 4639, the loss is 5.478236422120364, parameters k is 15.708002158951276 and b is -76.66509299733988\n",
      "Iteration 4640, the loss is 5.478214165182969, parameters k is 15.708355745907797 and b is -76.66609299733989\n",
      "Iteration 4641, the loss is 5.478191908245561, parameters k is 15.708709332864318 and b is -76.66709299733989\n",
      "Iteration 4642, the loss is 5.4781696513081615, parameters k is 15.70906291982084 and b is -76.6680929973399\n",
      "Iteration 4643, the loss is 5.47814739437076, parameters k is 15.70941650677736 and b is -76.6690929973399\n",
      "Iteration 4644, the loss is 5.478125137433357, parameters k is 15.709770093733882 and b is -76.6700929973399\n",
      "Iteration 4645, the loss is 5.478102880495956, parameters k is 15.710123680690403 and b is -76.67109299733991\n",
      "Iteration 4646, the loss is 5.47808062355855, parameters k is 15.710477267646924 and b is -76.67209299733992\n",
      "Iteration 4647, the loss is 5.47805836662115, parameters k is 15.710830854603445 and b is -76.67309299733992\n",
      "Iteration 4648, the loss is 5.478036109683747, parameters k is 15.711184441559967 and b is -76.67409299733993\n",
      "Iteration 4649, the loss is 5.478016666115755, parameters k is 15.711538028516488 and b is -76.67509299733993\n",
      "Iteration 4650, the loss is 5.478008550052512, parameters k is 15.711865030492772 and b is -76.67609299733994\n",
      "Iteration 4651, the loss is 5.478000433989268, parameters k is 15.712192032469057 and b is -76.67709299733994\n",
      "Iteration 4652, the loss is 5.477992317926019, parameters k is 15.712519034445341 and b is -76.67809299733995\n",
      "Iteration 4653, the loss is 5.477984201862783, parameters k is 15.712846036421626 and b is -76.67909299733995\n",
      "Iteration 4654, the loss is 5.4779760857995345, parameters k is 15.71317303839791 and b is -76.68009299733995\n",
      "Iteration 4655, the loss is 5.47796796973629, parameters k is 15.713500040374194 and b is -76.68109299733996\n",
      "Iteration 4656, the loss is 5.477959853673039, parameters k is 15.713827042350479 and b is -76.68209299733996\n",
      "Iteration 4657, the loss is 5.477951737609798, parameters k is 15.714154044326763 and b is -76.68309299733997\n",
      "Iteration 4658, the loss is 5.477943621546557, parameters k is 15.714481046303048 and b is -76.68409299733997\n",
      "Iteration 4659, the loss is 5.477935505483309, parameters k is 15.714808048279332 and b is -76.68509299733998\n",
      "Iteration 4660, the loss is 5.47792738942007, parameters k is 15.715135050255617 and b is -76.68609299733998\n",
      "Iteration 4661, the loss is 5.477919273356825, parameters k is 15.715462052231901 and b is -76.68709299733999\n",
      "Iteration 4662, the loss is 5.47791115729358, parameters k is 15.715789054208186 and b is -76.68809299734\n",
      "Iteration 4663, the loss is 5.477903041230333, parameters k is 15.71611605618447 and b is -76.68909299734\n",
      "Iteration 4664, the loss is 5.477894925167087, parameters k is 15.716443058160754 and b is -76.69009299734\n",
      "Iteration 4665, the loss is 5.4778868091038495, parameters k is 15.716770060137039 and b is -76.69109299734001\n",
      "Iteration 4666, the loss is 5.4778786930406, parameters k is 15.717097062113323 and b is -76.69209299734001\n",
      "Iteration 4667, the loss is 5.477870576977359, parameters k is 15.717424064089608 and b is -76.69309299734002\n",
      "Iteration 4668, the loss is 5.477862460914115, parameters k is 15.717751066065892 and b is -76.69409299734002\n",
      "Iteration 4669, the loss is 5.477854344850867, parameters k is 15.718078068042177 and b is -76.69509299734003\n",
      "Iteration 4670, the loss is 5.47784622878762, parameters k is 15.718405070018461 and b is -76.69609299734003\n",
      "Iteration 4671, the loss is 5.477838112724377, parameters k is 15.718732071994745 and b is -76.69709299734004\n",
      "Iteration 4672, the loss is 5.477829996661135, parameters k is 15.71905907397103 and b is -76.69809299734004\n",
      "Iteration 4673, the loss is 5.477821880597888, parameters k is 15.719386075947314 and b is -76.69909299734005\n",
      "Iteration 4674, the loss is 5.4778137645346465, parameters k is 15.719713077923599 and b is -76.70009299734005\n",
      "Iteration 4675, the loss is 5.477805648471402, parameters k is 15.720040079899883 and b is -76.70109299734006\n",
      "Iteration 4676, the loss is 5.477797532408149, parameters k is 15.720367081876168 and b is -76.70209299734006\n",
      "Iteration 4677, the loss is 5.477789416344913, parameters k is 15.720694083852452 and b is -76.70309299734006\n",
      "Iteration 4678, the loss is 5.477781300281668, parameters k is 15.721021085828736 and b is -76.70409299734007\n",
      "Iteration 4679, the loss is 5.47777318421842, parameters k is 15.721348087805021 and b is -76.70509299734007\n",
      "Iteration 4680, the loss is 5.477765068155181, parameters k is 15.721675089781305 and b is -76.70609299734008\n",
      "Iteration 4681, the loss is 5.4777569520919345, parameters k is 15.72200209175759 and b is -76.70709299734008\n",
      "Iteration 4682, the loss is 5.477748836028681, parameters k is 15.722329093733874 and b is -76.70809299734009\n",
      "Iteration 4683, the loss is 5.4777407199654435, parameters k is 15.722656095710159 and b is -76.7090929973401\n",
      "Iteration 4684, the loss is 5.477732603902201, parameters k is 15.722983097686443 and b is -76.7100929973401\n",
      "Iteration 4685, the loss is 5.477724487838952, parameters k is 15.723310099662728 and b is -76.7110929973401\n",
      "Iteration 4686, the loss is 5.47771637177571, parameters k is 15.723637101639012 and b is -76.71209299734011\n",
      "Iteration 4687, the loss is 5.477708255712466, parameters k is 15.723964103615296 and b is -76.71309299734011\n",
      "Iteration 4688, the loss is 5.477700139649218, parameters k is 15.72429110559158 and b is -76.71409299734012\n",
      "Iteration 4689, the loss is 5.47769202358598, parameters k is 15.724618107567865 and b is -76.71509299734012\n",
      "Iteration 4690, the loss is 5.4776839075227315, parameters k is 15.72494510954415 and b is -76.71609299734013\n",
      "Iteration 4691, the loss is 5.477675791459489, parameters k is 15.725272111520434 and b is -76.71709299734013\n",
      "Iteration 4692, the loss is 5.477667675396241, parameters k is 15.725599113496719 and b is -76.71809299734014\n",
      "Iteration 4693, the loss is 5.477659559333, parameters k is 15.725926115473003 and b is -76.71909299734014\n",
      "Iteration 4694, the loss is 5.477651443269751, parameters k is 15.726253117449287 and b is -76.72009299734015\n",
      "Iteration 4695, the loss is 5.477643327206511, parameters k is 15.726580119425572 and b is -76.72109299734015\n",
      "Iteration 4696, the loss is 5.477635211143269, parameters k is 15.726907121401856 and b is -76.72209299734016\n",
      "Iteration 4697, the loss is 5.477627095080019, parameters k is 15.72723412337814 and b is -76.72309299734016\n",
      "Iteration 4698, the loss is 5.477618979016772, parameters k is 15.727561125354425 and b is -76.72409299734016\n",
      "Iteration 4699, the loss is 5.477613887126425, parameters k is 15.72788812733071 and b is -76.72509299734017\n",
      "Iteration 4700, the loss is 5.477617763098391, parameters k is 15.728189765670631 and b is -76.72609299734017\n",
      "Iteration 4701, the loss is 5.477621639070363, parameters k is 15.728491404010553 and b is -76.72709299734018\n",
      "Iteration 4702, the loss is 5.477625515042334, parameters k is 15.728793042350475 and b is -76.72809299734018\n",
      "Iteration 4703, the loss is 5.477629391014298, parameters k is 15.729094680690396 and b is -76.72909299734019\n",
      "Iteration 4704, the loss is 5.477633266986267, parameters k is 15.729396319030318 and b is -76.7300929973402\n",
      "Iteration 4705, the loss is 5.477637142958238, parameters k is 15.72969795737024 and b is -76.7310929973402\n",
      "Iteration 4706, the loss is 5.477641018930203, parameters k is 15.729999595710161 and b is -76.7320929973402\n",
      "Iteration 4707, the loss is 5.477644894902176, parameters k is 15.730301234050083 and b is -76.73309299734021\n",
      "Iteration 4708, the loss is 5.47764877087414, parameters k is 15.730602872390005 and b is -76.73409299734021\n",
      "Iteration 4709, the loss is 5.477652646846112, parameters k is 15.730904510729927 and b is -76.73509299734022\n",
      "Iteration 4710, the loss is 5.4776565228180765, parameters k is 15.731206149069848 and b is -76.73609299734022\n",
      "Iteration 4711, the loss is 5.477661562325048, parameters k is 15.73150778740977 and b is -76.73709299734023\n",
      "Iteration 4712, the loss is 5.477677372671157, parameters k is 15.731781828911746 and b is -76.73809299734023\n",
      "Iteration 4713, the loss is 5.477693183017257, parameters k is 15.732055870413722 and b is -76.73909299734024\n",
      "Iteration 4714, the loss is 5.477708993363357, parameters k is 15.732329911915699 and b is -76.74009299734024\n",
      "Iteration 4715, the loss is 5.477724803709466, parameters k is 15.732603953417675 and b is -76.74109299734025\n",
      "Iteration 4716, the loss is 5.477740614055568, parameters k is 15.73287799491965 and b is -76.74209299734025\n",
      "Iteration 4717, the loss is 5.477756424401676, parameters k is 15.733152036421627 and b is -76.74309299734026\n",
      "Iteration 4718, the loss is 5.477772234747778, parameters k is 15.733426077923603 and b is -76.74409299734026\n",
      "Iteration 4719, the loss is 5.477788045093878, parameters k is 15.73370011942558 and b is -76.74509299734027\n",
      "Iteration 4720, the loss is 5.477805484794199, parameters k is 15.733974160927556 and b is -76.74609299734027\n",
      "Iteration 4721, the loss is 5.477829758375944, parameters k is 15.734224526540205 and b is -76.74709299734027\n",
      "Iteration 4722, the loss is 5.477854031957687, parameters k is 15.734474892152853 and b is -76.74809299734028\n",
      "Iteration 4723, the loss is 5.477878305539424, parameters k is 15.734725257765502 and b is -76.74909299734028\n",
      "Iteration 4724, the loss is 5.477902579121171, parameters k is 15.734975623378151 and b is -76.75009299734029\n",
      "Iteration 4725, the loss is 5.477926852702911, parameters k is 15.7352259889908 and b is -76.7510929973403\n",
      "Iteration 4726, the loss is 5.477951126284654, parameters k is 15.735476354603449 and b is -76.7520929973403\n",
      "Iteration 4727, the loss is 5.4779753998664, parameters k is 15.735726720216098 and b is -76.7530929973403\n",
      "Iteration 4728, the loss is 5.477999673448136, parameters k is 15.735977085828747 and b is -76.75409299734031\n",
      "Iteration 4729, the loss is 5.478023947029883, parameters k is 15.736227451441396 and b is -76.75509299734031\n",
      "Iteration 4730, the loss is 5.478048220611626, parameters k is 15.736477817054045 and b is -76.75609299734032\n",
      "Iteration 4731, the loss is 5.47807249419337, parameters k is 15.736728182666694 and b is -76.75709299734032\n",
      "Iteration 4732, the loss is 5.478096767775108, parameters k is 15.736978548279343 and b is -76.75809299734033\n",
      "Iteration 4733, the loss is 5.478121041356856, parameters k is 15.737228913891991 and b is -76.75909299734033\n",
      "Iteration 4734, the loss is 5.478145314938592, parameters k is 15.73747927950464 and b is -76.76009299734034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4735, the loss is 5.478169588520332, parameters k is 15.73772964511729 and b is -76.76109299734034\n",
      "Iteration 4736, the loss is 5.478193862102085, parameters k is 15.737980010729938 and b is -76.76209299734035\n",
      "Iteration 4737, the loss is 5.478218135683826, parameters k is 15.738230376342587 and b is -76.76309299734035\n",
      "Iteration 4738, the loss is 5.478242409265565, parameters k is 15.738480741955236 and b is -76.76409299734036\n",
      "Iteration 4739, the loss is 5.4782666828473054, parameters k is 15.738731107567885 and b is -76.76509299734036\n",
      "Iteration 4740, the loss is 5.478290956429053, parameters k is 15.738981473180534 and b is -76.76609299734037\n",
      "Iteration 4741, the loss is 5.478315230010798, parameters k is 15.739231838793183 and b is -76.76709299734037\n",
      "Iteration 4742, the loss is 5.478339503592535, parameters k is 15.739482204405832 and b is -76.76809299734037\n",
      "Iteration 4743, the loss is 5.4783637771742795, parameters k is 15.73973257001848 and b is -76.76909299734038\n",
      "Iteration 4744, the loss is 5.478388050756018, parameters k is 15.73998293563113 and b is -76.77009299734038\n",
      "Iteration 4745, the loss is 5.478412324337772, parameters k is 15.740233301243778 and b is -76.77109299734039\n",
      "Iteration 4746, the loss is 5.478436597919515, parameters k is 15.740483666856427 and b is -76.7720929973404\n",
      "Iteration 4747, the loss is 5.478460871501248, parameters k is 15.740734032469076 and b is -76.7730929973404\n",
      "Iteration 4748, the loss is 5.478485145082989, parameters k is 15.740984398081725 and b is -76.7740929973404\n",
      "Iteration 4749, the loss is 5.478509418664736, parameters k is 15.741234763694374 and b is -76.77509299734041\n",
      "Iteration 4750, the loss is 5.478533692246478, parameters k is 15.741485129307023 and b is -76.77609299734041\n",
      "Iteration 4751, the loss is 5.478557965828221, parameters k is 15.741735494919672 and b is -76.77709299734042\n",
      "Iteration 4752, the loss is 5.47858223940996, parameters k is 15.74198586053232 and b is -76.77809299734042\n",
      "Iteration 4753, the loss is 5.478606512991703, parameters k is 15.74223622614497 and b is -76.77909299734043\n",
      "Iteration 4754, the loss is 5.478630786573451, parameters k is 15.742486591757618 and b is -76.78009299734043\n",
      "Iteration 4755, the loss is 5.478655060155191, parameters k is 15.742736957370267 and b is -76.78109299734044\n",
      "Iteration 4756, the loss is 5.4786793337369355, parameters k is 15.742987322982916 and b is -76.78209299734044\n",
      "Iteration 4757, the loss is 5.478703607318675, parameters k is 15.743237688595565 and b is -76.78309299734045\n",
      "Iteration 4758, the loss is 5.478727880900424, parameters k is 15.743488054208214 and b is -76.78409299734045\n",
      "Iteration 4759, the loss is 5.478752154482162, parameters k is 15.743738419820863 and b is -76.78509299734046\n",
      "Iteration 4760, the loss is 5.478776428063904, parameters k is 15.743988785433512 and b is -76.78609299734046\n",
      "Iteration 4761, the loss is 5.47880070164565, parameters k is 15.74423915104616 and b is -76.78709299734047\n",
      "Iteration 4762, the loss is 5.47882497522738, parameters k is 15.74448951665881 and b is -76.78809299734047\n",
      "Iteration 4763, the loss is 5.478849248809129, parameters k is 15.744739882271459 and b is -76.78909299734048\n",
      "Iteration 4764, the loss is 5.47887352239087, parameters k is 15.744990247884108 and b is -76.79009299734048\n",
      "Iteration 4765, the loss is 5.478897795972621, parameters k is 15.745240613496756 and b is -76.79109299734048\n",
      "Iteration 4766, the loss is 5.478922069554366, parameters k is 15.745490979109405 and b is -76.79209299734049\n",
      "Iteration 4767, the loss is 5.478946343136102, parameters k is 15.745741344722054 and b is -76.7930929973405\n",
      "Iteration 4768, the loss is 5.478970616717847, parameters k is 15.745991710334703 and b is -76.7940929973405\n",
      "Iteration 4769, the loss is 5.478996796533696, parameters k is 15.746242075947352 and b is -76.7950929973405\n",
      "Iteration 4770, the loss is 5.479029203051685, parameters k is 15.74646701468253 and b is -76.79609299734051\n",
      "Iteration 4771, the loss is 5.47906160956967, parameters k is 15.746691953417708 and b is -76.79709299734051\n",
      "Iteration 4772, the loss is 5.479094016087656, parameters k is 15.746916892152885 and b is -76.79809299734052\n",
      "Iteration 4773, the loss is 5.479126422605636, parameters k is 15.747141830888063 and b is -76.79909299734052\n",
      "Iteration 4774, the loss is 5.479158829123631, parameters k is 15.747366769623241 and b is -76.80009299734053\n",
      "Iteration 4775, the loss is 5.479193424486478, parameters k is 15.747591708358419 and b is -76.80109299734053\n",
      "Iteration 4776, the loss is 5.479233557001717, parameters k is 15.747788987014545 and b is -76.80209299734054\n",
      "Iteration 4777, the loss is 5.479273689516956, parameters k is 15.74798626567067 and b is -76.80309299734054\n",
      "Iteration 4778, the loss is 5.479313822032193, parameters k is 15.748183544326796 and b is -76.80409299734055\n",
      "Iteration 4779, the loss is 5.479353954547431, parameters k is 15.748380822982922 and b is -76.80509299734055\n",
      "Iteration 4780, the loss is 5.479394087062659, parameters k is 15.748578101639048 and b is -76.80609299734056\n",
      "Iteration 4781, the loss is 5.479434219577895, parameters k is 15.748775380295173 and b is -76.80709299734056\n",
      "Iteration 4782, the loss is 5.479474352093136, parameters k is 15.748972658951299 and b is -76.80809299734057\n",
      "Iteration 4783, the loss is 5.479514484608375, parameters k is 15.749169937607425 and b is -76.80909299734057\n",
      "Iteration 4784, the loss is 5.479554617123608, parameters k is 15.74936721626355 and b is -76.81009299734058\n",
      "Iteration 4785, the loss is 5.479594749638847, parameters k is 15.749564494919676 and b is -76.81109299734058\n",
      "Iteration 4786, the loss is 5.479634882154082, parameters k is 15.749761773575802 and b is -76.81209299734059\n",
      "Iteration 4787, the loss is 5.479675014669319, parameters k is 15.749959052231928 and b is -76.81309299734059\n",
      "Iteration 4788, the loss is 5.479715147184555, parameters k is 15.750156330888053 and b is -76.8140929973406\n",
      "Iteration 4789, the loss is 5.479755279699797, parameters k is 15.75035360954418 and b is -76.8150929973406\n",
      "Iteration 4790, the loss is 5.479795412215033, parameters k is 15.750550888200305 and b is -76.8160929973406\n",
      "Iteration 4791, the loss is 5.479835544730267, parameters k is 15.75074816685643 and b is -76.81709299734061\n",
      "Iteration 4792, the loss is 5.479875677245503, parameters k is 15.750945445512556 and b is -76.81809299734061\n",
      "Iteration 4793, the loss is 5.479915809760743, parameters k is 15.751142724168682 and b is -76.81909299734062\n",
      "Iteration 4794, the loss is 5.479955942275977, parameters k is 15.751340002824808 and b is -76.82009299734062\n",
      "Iteration 4795, the loss is 5.47999607479121, parameters k is 15.751537281480934 and b is -76.82109299734063\n",
      "Iteration 4796, the loss is 5.480036207306446, parameters k is 15.75173456013706 and b is -76.82209299734063\n",
      "Iteration 4797, the loss is 5.480076339821686, parameters k is 15.751931838793185 and b is -76.82309299734064\n",
      "Iteration 4798, the loss is 5.48011647233692, parameters k is 15.75212911744931 and b is -76.82409299734064\n",
      "Iteration 4799, the loss is 5.480156604852158, parameters k is 15.752326396105437 and b is -76.82509299734065\n",
      "Iteration 4800, the loss is 5.480196737367396, parameters k is 15.752523674761562 and b is -76.82609299734065\n",
      "Iteration 4801, the loss is 5.480236869882638, parameters k is 15.752720953417688 and b is -76.82709299734066\n",
      "Iteration 4802, the loss is 5.480277002397876, parameters k is 15.752918232073814 and b is -76.82809299734066\n",
      "Iteration 4803, the loss is 5.480317134913114, parameters k is 15.75311551072994 and b is -76.82909299734067\n",
      "Iteration 4804, the loss is 5.480357267428337, parameters k is 15.753312789386065 and b is -76.83009299734067\n",
      "Iteration 4805, the loss is 5.480397399943579, parameters k is 15.753510068042191 and b is -76.83109299734068\n",
      "Iteration 4806, the loss is 5.48043753245882, parameters k is 15.753707346698317 and b is -76.83209299734068\n",
      "Iteration 4807, the loss is 5.480477664974052, parameters k is 15.753904625354442 and b is -76.83309299734069\n",
      "Iteration 4808, the loss is 5.480517797489289, parameters k is 15.754101904010568 and b is -76.83409299734069\n",
      "Iteration 4809, the loss is 5.480557930004524, parameters k is 15.754299182666694 and b is -76.8350929973407\n",
      "Iteration 4810, the loss is 5.480598062519762, parameters k is 15.75449646132282 and b is -76.8360929973407\n",
      "Iteration 4811, the loss is 5.4806381950350005, parameters k is 15.754693739978945 and b is -76.8370929973407\n",
      "Iteration 4812, the loss is 5.480678327550237, parameters k is 15.754891018635071 and b is -76.83809299734071\n",
      "Iteration 4813, the loss is 5.480718460065478, parameters k is 15.755088297291197 and b is -76.83909299734071\n",
      "Iteration 4814, the loss is 5.480758592580711, parameters k is 15.755285575947322 and b is -76.84009299734072\n",
      "Iteration 4815, the loss is 5.480798725095943, parameters k is 15.755482854603448 and b is -76.84109299734072\n",
      "Iteration 4816, the loss is 5.480838857611188, parameters k is 15.755680133259574 and b is -76.84209299734073\n",
      "Iteration 4817, the loss is 5.480878990126419, parameters k is 15.7558774119157 and b is -76.84309299734073\n",
      "Iteration 4818, the loss is 5.480919122641658, parameters k is 15.756074690571825 and b is -76.84409299734074\n",
      "Iteration 4819, the loss is 5.480959255156891, parameters k is 15.756271969227951 and b is -76.84509299734074\n",
      "Iteration 4820, the loss is 5.480999387672135, parameters k is 15.756469247884077 and b is -76.84609299734075\n",
      "Iteration 4821, the loss is 5.481039520187368, parameters k is 15.756666526540203 and b is -76.84709299734075\n",
      "Iteration 4822, the loss is 5.481079652702603, parameters k is 15.756863805196328 and b is -76.84809299734076\n",
      "Iteration 4823, the loss is 5.481119785217842, parameters k is 15.757061083852454 and b is -76.84909299734076\n",
      "Iteration 4824, the loss is 5.481159917733077, parameters k is 15.75725836250858 and b is -76.85009299734077\n",
      "Iteration 4825, the loss is 5.481200050248312, parameters k is 15.757455641164706 and b is -76.85109299734077\n",
      "Iteration 4826, the loss is 5.48124018276355, parameters k is 15.757652919820831 and b is -76.85209299734078\n",
      "Iteration 4827, the loss is 5.481280315278789, parameters k is 15.757850198476957 and b is -76.85309299734078\n",
      "Iteration 4828, the loss is 5.481320447794022, parameters k is 15.758047477133083 and b is -76.85409299734079\n",
      "Iteration 4829, the loss is 5.481360580309264, parameters k is 15.758244755789208 and b is -76.85509299734079\n",
      "Iteration 4830, the loss is 5.481400712824495, parameters k is 15.758442034445334 and b is -76.8560929973408\n",
      "Iteration 4831, the loss is 5.481440845339738, parameters k is 15.75863931310146 and b is -76.8570929973408\n",
      "Iteration 4832, the loss is 5.481480977854966, parameters k is 15.758836591757586 and b is -76.8580929973408\n",
      "Iteration 4833, the loss is 5.481521110370205, parameters k is 15.759033870413711 and b is -76.85909299734081\n",
      "Iteration 4834, the loss is 5.481561242885441, parameters k is 15.759231149069837 and b is -76.86009299734081\n",
      "Iteration 4835, the loss is 5.4816013754006825, parameters k is 15.759428427725963 and b is -76.86109299734082\n",
      "Iteration 4836, the loss is 5.481641507915919, parameters k is 15.759625706382089 and b is -76.86209299734082\n",
      "Iteration 4837, the loss is 5.481681640431157, parameters k is 15.759822985038214 and b is -76.86309299734083\n",
      "Iteration 4838, the loss is 5.481721772946392, parameters k is 15.76002026369434 and b is -76.86409299734083\n",
      "Iteration 4839, the loss is 5.481761905461623, parameters k is 15.760217542350466 and b is -76.86509299734084\n",
      "Iteration 4840, the loss is 5.481802037976865, parameters k is 15.760414821006592 and b is -76.86609299734084\n",
      "Iteration 4841, the loss is 5.481842170492097, parameters k is 15.760612099662717 and b is -76.86709299734085\n",
      "Iteration 4842, the loss is 5.481882303007336, parameters k is 15.760809378318843 and b is -76.86809299734085\n",
      "Iteration 4843, the loss is 5.481922435522569, parameters k is 15.761006656974969 and b is -76.86909299734086\n",
      "Iteration 4844, the loss is 5.481962568037811, parameters k is 15.761203935631094 and b is -76.87009299734086\n",
      "Iteration 4845, the loss is 5.482002700553048, parameters k is 15.76140121428722 and b is -76.87109299734087\n",
      "Iteration 4846, the loss is 5.482042833068285, parameters k is 15.761598492943346 and b is -76.87209299734087\n",
      "Iteration 4847, the loss is 5.482082965583521, parameters k is 15.761795771599472 and b is -76.87309299734088\n",
      "Iteration 4848, the loss is 5.482123098098756, parameters k is 15.761993050255597 and b is -76.87409299734088\n",
      "Iteration 4849, the loss is 5.482163230613998, parameters k is 15.762190328911723 and b is -76.87509299734089\n",
      "Iteration 4850, the loss is 5.482203363129229, parameters k is 15.762387607567849 and b is -76.87609299734089\n",
      "Iteration 4851, the loss is 5.482243495644465, parameters k is 15.762584886223975 and b is -76.8770929973409\n",
      "Iteration 4852, the loss is 5.482283628159704, parameters k is 15.7627821648801 and b is -76.8780929973409\n",
      "Iteration 4853, the loss is 5.482323760674941, parameters k is 15.762979443536226 and b is -76.8790929973409\n",
      "Iteration 4854, the loss is 5.482363893190175, parameters k is 15.763176722192352 and b is -76.88009299734091\n",
      "Iteration 4855, the loss is 5.482404025705416, parameters k is 15.763374000848478 and b is -76.88109299734091\n",
      "Iteration 4856, the loss is 5.482444158220652, parameters k is 15.763571279504603 and b is -76.88209299734092\n",
      "Iteration 4857, the loss is 5.482484290735887, parameters k is 15.763768558160729 and b is -76.88309299734092\n",
      "Iteration 4858, the loss is 5.4825244232511245, parameters k is 15.763965836816855 and b is -76.88409299734093\n",
      "Iteration 4859, the loss is 5.482564555766367, parameters k is 15.76416311547298 and b is -76.88509299734093\n",
      "Iteration 4860, the loss is 5.482604688281598, parameters k is 15.764360394129106 and b is -76.88609299734094\n",
      "Iteration 4861, the loss is 5.4826448207968355, parameters k is 15.764557672785232 and b is -76.88709299734094\n",
      "Iteration 4862, the loss is 5.482684953312077, parameters k is 15.764754951441358 and b is -76.88809299734095\n",
      "Iteration 4863, the loss is 5.48272508582731, parameters k is 15.764952230097483 and b is -76.88909299734095\n",
      "Iteration 4864, the loss is 5.482765218342542, parameters k is 15.765149508753609 and b is -76.89009299734096\n",
      "Iteration 4865, the loss is 5.482805350857782, parameters k is 15.765346787409735 and b is -76.89109299734096\n",
      "Iteration 4866, the loss is 5.482845483373015, parameters k is 15.76554406606586 and b is -76.89209299734097\n",
      "Iteration 4867, the loss is 5.482885615888248, parameters k is 15.765741344721986 and b is -76.89309299734097\n",
      "Iteration 4868, the loss is 5.4829257484034875, parameters k is 15.765938623378112 and b is -76.89409299734098\n",
      "Iteration 4869, the loss is 5.4829658809187265, parameters k is 15.766135902034238 and b is -76.89509299734098\n",
      "Iteration 4870, the loss is 5.483006013433963, parameters k is 15.766333180690363 and b is -76.89609299734099\n",
      "Iteration 4871, the loss is 5.483046145949194, parameters k is 15.76653045934649 and b is -76.89709299734099\n",
      "Iteration 4872, the loss is 5.483086278464441, parameters k is 15.766727738002615 and b is -76.898092997341\n",
      "Iteration 4873, the loss is 5.483126410979677, parameters k is 15.76692501665874 and b is -76.899092997341\n",
      "Iteration 4874, the loss is 5.48316654349491, parameters k is 15.767122295314866 and b is -76.900092997341\n",
      "Iteration 4875, the loss is 5.483206676010144, parameters k is 15.767319573970992 and b is -76.90109299734101\n",
      "Iteration 4876, the loss is 5.483246808525379, parameters k is 15.767516852627118 and b is -76.90209299734101\n",
      "Iteration 4877, the loss is 5.48328694104062, parameters k is 15.767714131283244 and b is -76.90309299734102\n",
      "Iteration 4878, the loss is 5.4833270735558655, parameters k is 15.76791140993937 and b is -76.90409299734102\n",
      "Iteration 4879, the loss is 5.483367206071091, parameters k is 15.768108688595495 and b is -76.90509299734103\n",
      "Iteration 4880, the loss is 5.483407338586324, parameters k is 15.76830596725162 and b is -76.90609299734103\n",
      "Iteration 4881, the loss is 5.483447471101566, parameters k is 15.768503245907747 and b is -76.90709299734104\n",
      "Iteration 4882, the loss is 5.483487603616799, parameters k is 15.768700524563872 and b is -76.90809299734104\n",
      "Iteration 4883, the loss is 5.483527736132033, parameters k is 15.768897803219998 and b is -76.90909299734105\n",
      "Iteration 4884, the loss is 5.4835678686472775, parameters k is 15.769095081876124 and b is -76.91009299734105\n",
      "Iteration 4885, the loss is 5.4836080011625095, parameters k is 15.76929236053225 and b is -76.91109299734106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4886, the loss is 5.483648133677751, parameters k is 15.769489639188375 and b is -76.91209299734106\n",
      "Iteration 4887, the loss is 5.48368826619299, parameters k is 15.769686917844501 and b is -76.91309299734107\n",
      "Iteration 4888, the loss is 5.483728398708226, parameters k is 15.769884196500627 and b is -76.91409299734107\n",
      "Iteration 4889, the loss is 5.483768531223468, parameters k is 15.770081475156752 and b is -76.91509299734108\n",
      "Iteration 4890, the loss is 5.4838086637386985, parameters k is 15.770278753812878 and b is -76.91609299734108\n",
      "Iteration 4891, the loss is 5.483848796253933, parameters k is 15.770476032469004 and b is -76.91709299734109\n",
      "Iteration 4892, the loss is 5.483888928769166, parameters k is 15.77067331112513 and b is -76.91809299734109\n",
      "Iteration 4893, the loss is 5.483929061284406, parameters k is 15.770870589781255 and b is -76.9190929973411\n",
      "Iteration 4894, the loss is 5.48396919379964, parameters k is 15.771067868437381 and b is -76.9200929973411\n",
      "Iteration 4895, the loss is 5.484009326314876, parameters k is 15.771265147093507 and b is -76.9210929973411\n",
      "Iteration 4896, the loss is 5.484049458830118, parameters k is 15.771462425749633 and b is -76.92209299734111\n",
      "Iteration 4897, the loss is 5.484089591345356, parameters k is 15.771659704405758 and b is -76.92309299734112\n",
      "Iteration 4898, the loss is 5.484129723860591, parameters k is 15.771856983061884 and b is -76.92409299734112\n",
      "Iteration 4899, the loss is 5.484169856375825, parameters k is 15.77205426171801 and b is -76.92509299734112\n",
      "Iteration 4900, the loss is 5.484209988891056, parameters k is 15.772251540374135 and b is -76.92609299734113\n",
      "Iteration 4901, the loss is 5.484250121406293, parameters k is 15.772448819030261 and b is -76.92709299734113\n",
      "Iteration 4902, the loss is 5.4842902539215395, parameters k is 15.772646097686387 and b is -76.92809299734114\n",
      "Iteration 4903, the loss is 5.484330386436768, parameters k is 15.772843376342513 and b is -76.92909299734114\n",
      "Iteration 4904, the loss is 5.484370518952009, parameters k is 15.773040654998638 and b is -76.93009299734115\n",
      "Iteration 4905, the loss is 5.484410651467243, parameters k is 15.773237933654764 and b is -76.93109299734115\n",
      "Iteration 4906, the loss is 5.48445078398249, parameters k is 15.77343521231089 and b is -76.93209299734116\n",
      "Iteration 4907, the loss is 5.484490916497721, parameters k is 15.773632490967016 and b is -76.93309299734116\n",
      "Iteration 4908, the loss is 5.48453104901296, parameters k is 15.773829769623141 and b is -76.93409299734117\n",
      "Iteration 4909, the loss is 5.484571181528193, parameters k is 15.774027048279267 and b is -76.93509299734117\n",
      "Iteration 4910, the loss is 5.484611314043432, parameters k is 15.774224326935393 and b is -76.93609299734118\n",
      "Iteration 4911, the loss is 5.4846514465586695, parameters k is 15.774421605591519 and b is -76.93709299734118\n",
      "Iteration 4912, the loss is 5.4846915790739015, parameters k is 15.774618884247644 and b is -76.93809299734119\n",
      "Iteration 4913, the loss is 5.484731711589145, parameters k is 15.77481616290377 and b is -76.93909299734119\n",
      "Iteration 4914, the loss is 5.484771844104377, parameters k is 15.775013441559896 and b is -76.9400929973412\n",
      "Iteration 4915, the loss is 5.4848119766196195, parameters k is 15.775210720216021 and b is -76.9410929973412\n",
      "Iteration 4916, the loss is 5.48485210913485, parameters k is 15.775407998872147 and b is -76.9420929973412\n",
      "Iteration 4917, the loss is 5.484892241650087, parameters k is 15.775605277528273 and b is -76.94309299734121\n",
      "Iteration 4918, the loss is 5.484932374165322, parameters k is 15.775802556184399 and b is -76.94409299734122\n",
      "Iteration 4919, the loss is 5.484972506680561, parameters k is 15.775999834840524 and b is -76.94509299734122\n",
      "Iteration 4920, the loss is 5.485012639195796, parameters k is 15.77619711349665 and b is -76.94609299734122\n",
      "Iteration 4921, the loss is 5.485052771711035, parameters k is 15.776394392152776 and b is -76.94709299734123\n",
      "Iteration 4922, the loss is 5.485092904226273, parameters k is 15.776591670808902 and b is -76.94809299734123\n",
      "Iteration 4923, the loss is 5.485133036741505, parameters k is 15.776788949465027 and b is -76.94909299734124\n",
      "Iteration 4924, the loss is 5.485173169256743, parameters k is 15.776986228121153 and b is -76.95009299734124\n",
      "Iteration 4925, the loss is 5.485213301771982, parameters k is 15.777183506777279 and b is -76.95109299734125\n",
      "Iteration 4926, the loss is 5.485253434287215, parameters k is 15.777380785433404 and b is -76.95209299734125\n",
      "Iteration 4927, the loss is 5.485293566802454, parameters k is 15.77757806408953 and b is -76.95309299734126\n",
      "Iteration 4928, the loss is 5.485333699317697, parameters k is 15.777775342745656 and b is -76.95409299734126\n",
      "Iteration 4929, the loss is 5.485373831832923, parameters k is 15.777972621401782 and b is -76.95509299734127\n",
      "Iteration 4930, the loss is 5.485413964348166, parameters k is 15.778169900057907 and b is -76.95609299734127\n",
      "Iteration 4931, the loss is 5.485454096863406, parameters k is 15.778367178714033 and b is -76.95709299734128\n",
      "Iteration 4932, the loss is 5.485494229378633, parameters k is 15.778564457370159 and b is -76.95809299734128\n",
      "Iteration 4933, the loss is 5.4855343618938655, parameters k is 15.778761736026285 and b is -76.95909299734129\n",
      "Iteration 4934, the loss is 5.485574494409105, parameters k is 15.77895901468241 and b is -76.96009299734129\n",
      "Iteration 4935, the loss is 5.485614626924348, parameters k is 15.779156293338536 and b is -76.9610929973413\n",
      "Iteration 4936, the loss is 5.4856547594395835, parameters k is 15.779353571994662 and b is -76.9620929973413\n",
      "Iteration 4937, the loss is 5.4856948919548225, parameters k is 15.779550850650788 and b is -76.9630929973413\n",
      "Iteration 4938, the loss is 5.485735024470055, parameters k is 15.779748129306913 and b is -76.96409299734131\n",
      "Iteration 4939, the loss is 5.485775156985293, parameters k is 15.779945407963039 and b is -76.96509299734132\n",
      "Iteration 4940, the loss is 5.485815289500529, parameters k is 15.780142686619165 and b is -76.96609299734132\n",
      "Iteration 4941, the loss is 5.485855422015767, parameters k is 15.78033996527529 and b is -76.96709299734133\n",
      "Iteration 4942, the loss is 5.485895554531004, parameters k is 15.780537243931416 and b is -76.96809299734133\n",
      "Iteration 4943, the loss is 5.485935687046242, parameters k is 15.780734522587542 and b is -76.96909299734133\n",
      "Iteration 4944, the loss is 5.485975819561479, parameters k is 15.780931801243668 and b is -76.97009299734134\n",
      "Iteration 4945, the loss is 5.486015952076715, parameters k is 15.781129079899793 and b is -76.97109299734134\n",
      "Iteration 4946, the loss is 5.48605608459195, parameters k is 15.78132635855592 and b is -76.97209299734135\n",
      "Iteration 4947, the loss is 5.486096217107186, parameters k is 15.781523637212045 and b is -76.97309299734135\n",
      "Iteration 4948, the loss is 5.486136349622428, parameters k is 15.78172091586817 and b is -76.97409299734136\n",
      "Iteration 4949, the loss is 5.48617648213766, parameters k is 15.781918194524296 and b is -76.97509299734136\n",
      "Iteration 4950, the loss is 5.4862166146528955, parameters k is 15.782115473180422 and b is -76.97609299734137\n",
      "Iteration 4951, the loss is 5.486256747168131, parameters k is 15.782312751836548 and b is -76.97709299734137\n",
      "Iteration 4952, the loss is 5.486296879683368, parameters k is 15.782510030492674 and b is -76.97809299734138\n",
      "Iteration 4953, the loss is 5.48633701219861, parameters k is 15.7827073091488 and b is -76.97909299734138\n",
      "Iteration 4954, the loss is 5.486377144713846, parameters k is 15.782904587804925 and b is -76.98009299734139\n",
      "Iteration 4955, the loss is 5.486417277229077, parameters k is 15.78310186646105 and b is -76.98109299734139\n",
      "Iteration 4956, the loss is 5.486457409744314, parameters k is 15.783299145117176 and b is -76.9820929973414\n",
      "Iteration 4957, the loss is 5.48649754225955, parameters k is 15.783496423773302 and b is -76.9830929973414\n",
      "Iteration 4958, the loss is 5.486537674774793, parameters k is 15.783693702429428 and b is -76.9840929973414\n",
      "Iteration 4959, the loss is 5.486577807290031, parameters k is 15.783890981085554 and b is -76.98509299734141\n",
      "Iteration 4960, the loss is 5.486617939805271, parameters k is 15.78408825974168 and b is -76.98609299734142\n",
      "Iteration 4961, the loss is 5.486658072320501, parameters k is 15.784285538397805 and b is -76.98709299734142\n",
      "Iteration 4962, the loss is 5.48669820483573, parameters k is 15.78448281705393 and b is -76.98809299734143\n",
      "Iteration 4963, the loss is 5.486738337350968, parameters k is 15.784680095710057 and b is -76.98909299734143\n",
      "Iteration 4964, the loss is 5.486778469866208, parameters k is 15.784877374366182 and b is -76.99009299734143\n",
      "Iteration 4965, the loss is 5.486818602381445, parameters k is 15.785074653022308 and b is -76.99109299734144\n",
      "Iteration 4966, the loss is 5.486858734896682, parameters k is 15.785271931678434 and b is -76.99209299734144\n",
      "Iteration 4967, the loss is 5.486898867411916, parameters k is 15.78546921033456 and b is -76.99309299734145\n",
      "Iteration 4968, the loss is 5.486938999927153, parameters k is 15.785666488990685 and b is -76.99409299734145\n",
      "Iteration 4969, the loss is 5.4869791324423955, parameters k is 15.785863767646811 and b is -76.99509299734146\n",
      "Iteration 4970, the loss is 5.487019264957629, parameters k is 15.786061046302937 and b is -76.99609299734146\n",
      "Iteration 4971, the loss is 5.48705939747286, parameters k is 15.786258324959062 and b is -76.99709299734147\n",
      "Iteration 4972, the loss is 5.487099529988102, parameters k is 15.786455603615188 and b is -76.99809299734147\n",
      "Iteration 4973, the loss is 5.4871396625033375, parameters k is 15.786652882271314 and b is -76.99909299734148\n",
      "Iteration 4974, the loss is 5.487179795018576, parameters k is 15.78685016092744 and b is -77.00009299734148\n",
      "Iteration 4975, the loss is 5.487219927533812, parameters k is 15.787047439583565 and b is -77.00109299734149\n",
      "Iteration 4976, the loss is 5.487260060049052, parameters k is 15.787244718239691 and b is -77.00209299734149\n",
      "Iteration 4977, the loss is 5.487300192564287, parameters k is 15.787441996895817 and b is -77.0030929973415\n",
      "Iteration 4978, the loss is 5.487340325079521, parameters k is 15.787639275551943 and b is -77.0040929973415\n",
      "Iteration 4979, the loss is 5.48738045759476, parameters k is 15.787836554208068 and b is -77.0050929973415\n",
      "Iteration 4980, the loss is 5.4874205901099975, parameters k is 15.788033832864194 and b is -77.00609299734151\n",
      "Iteration 4981, the loss is 5.487460722625235, parameters k is 15.78823111152032 and b is -77.00709299734152\n",
      "Iteration 4982, the loss is 5.487500855140468, parameters k is 15.788428390176446 and b is -77.00809299734152\n",
      "Iteration 4983, the loss is 5.487540987655708, parameters k is 15.788625668832571 and b is -77.00909299734153\n",
      "Iteration 4984, the loss is 5.48758112017094, parameters k is 15.788822947488697 and b is -77.01009299734153\n",
      "Iteration 4985, the loss is 5.487621252686179, parameters k is 15.789020226144823 and b is -77.01109299734154\n",
      "Iteration 4986, the loss is 5.487661385201413, parameters k is 15.789217504800948 and b is -77.01209299734154\n",
      "Iteration 4987, the loss is 5.487701517716656, parameters k is 15.789414783457074 and b is -77.01309299734154\n",
      "Iteration 4988, the loss is 5.4877416502318805, parameters k is 15.7896120621132 and b is -77.01409299734155\n",
      "Iteration 4989, the loss is 5.487781782747128, parameters k is 15.789809340769326 and b is -77.01509299734155\n",
      "Iteration 4990, the loss is 5.487821915262365, parameters k is 15.790006619425451 and b is -77.01609299734156\n",
      "Iteration 4991, the loss is 5.487862047777602, parameters k is 15.790203898081577 and b is -77.01709299734156\n",
      "Iteration 4992, the loss is 5.487902180292834, parameters k is 15.790401176737703 and b is -77.01809299734157\n",
      "Iteration 4993, the loss is 5.487942312808075, parameters k is 15.790598455393829 and b is -77.01909299734157\n",
      "Iteration 4994, the loss is 5.487982445323316, parameters k is 15.790795734049954 and b is -77.02009299734158\n",
      "Iteration 4995, the loss is 5.488022577838551, parameters k is 15.79099301270608 and b is -77.02109299734158\n",
      "Iteration 4996, the loss is 5.488062710353788, parameters k is 15.791190291362206 and b is -77.02209299734159\n",
      "Iteration 4997, the loss is 5.488102842869014, parameters k is 15.791387570018331 and b is -77.02309299734159\n",
      "Iteration 4998, the loss is 5.488142975384259, parameters k is 15.791584848674457 and b is -77.0240929973416\n",
      "Iteration 4999, the loss is 5.488183107899494, parameters k is 15.791782127330583 and b is -77.0250929973416\n",
      "Iteration 5000, the loss is 5.4882232404147295, parameters k is 15.791979405986709 and b is -77.0260929973416\n",
      "Iteration 5001, the loss is 5.488263372929963, parameters k is 15.792176684642834 and b is -77.02709299734161\n",
      "Iteration 5002, the loss is 5.4883035054452, parameters k is 15.79237396329896 and b is -77.02809299734162\n",
      "Iteration 5003, the loss is 5.488343637960439, parameters k is 15.792571241955086 and b is -77.02909299734162\n",
      "Iteration 5004, the loss is 5.488383770475678, parameters k is 15.792768520611212 and b is -77.03009299734163\n",
      "Iteration 5005, the loss is 5.48842390299091, parameters k is 15.792965799267337 and b is -77.03109299734163\n",
      "Iteration 5006, the loss is 5.488464035506151, parameters k is 15.793163077923463 and b is -77.03209299734164\n",
      "Iteration 5007, the loss is 5.488504168021382, parameters k is 15.793360356579589 and b is -77.03309299734164\n",
      "Iteration 5008, the loss is 5.488544300536625, parameters k is 15.793557635235715 and b is -77.03409299734165\n",
      "Iteration 5009, the loss is 5.4885844330518605, parameters k is 15.79375491389184 and b is -77.03509299734165\n",
      "Iteration 5010, the loss is 5.4886245655670995, parameters k is 15.793952192547966 and b is -77.03609299734165\n",
      "Iteration 5011, the loss is 5.488664698082334, parameters k is 15.794149471204092 and b is -77.03709299734166\n",
      "Iteration 5012, the loss is 5.488704830597569, parameters k is 15.794346749860217 and b is -77.03809299734166\n",
      "Iteration 5013, the loss is 5.488744963112806, parameters k is 15.794544028516343 and b is -77.03909299734167\n",
      "Iteration 5014, the loss is 5.48878509562804, parameters k is 15.794741307172469 and b is -77.04009299734167\n",
      "Iteration 5015, the loss is 5.488825228143284, parameters k is 15.794938585828595 and b is -77.04109299734168\n",
      "Iteration 5016, the loss is 5.488865360658508, parameters k is 15.79513586448472 and b is -77.04209299734168\n",
      "Iteration 5017, the loss is 5.48890549317375, parameters k is 15.795333143140846 and b is -77.04309299734169\n",
      "Iteration 5018, the loss is 5.488945625688989, parameters k is 15.795530421796972 and b is -77.04409299734169\n",
      "Iteration 5019, the loss is 5.488985758204226, parameters k is 15.795727700453098 and b is -77.0450929973417\n",
      "Iteration 5020, the loss is 5.4890258907194625, parameters k is 15.795924979109223 and b is -77.0460929973417\n",
      "Iteration 5021, the loss is 5.489066023234694, parameters k is 15.796122257765349 and b is -77.04709299734171\n",
      "Iteration 5022, the loss is 5.489106155749936, parameters k is 15.796319536421475 and b is -77.04809299734171\n",
      "Iteration 5023, the loss is 5.48914628826517, parameters k is 15.7965168150776 and b is -77.04909299734172\n",
      "Iteration 5024, the loss is 5.489186420780411, parameters k is 15.796714093733726 and b is -77.05009299734172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5025, the loss is 5.489226553295646, parameters k is 15.796911372389852 and b is -77.05109299734173\n",
      "Iteration 5026, the loss is 5.489266685810886, parameters k is 15.797108651045978 and b is -77.05209299734173\n",
      "Iteration 5027, the loss is 5.489306818326122, parameters k is 15.797305929702103 and b is -77.05309299734174\n",
      "Iteration 5028, the loss is 5.489346950841358, parameters k is 15.79750320835823 and b is -77.05409299734174\n",
      "Iteration 5029, the loss is 5.489387083356592, parameters k is 15.797700487014355 and b is -77.05509299734175\n",
      "Iteration 5030, the loss is 5.489427215871826, parameters k is 15.79789776567048 and b is -77.05609299734175\n",
      "Iteration 5031, the loss is 5.489467348387066, parameters k is 15.798095044326606 and b is -77.05709299734175\n",
      "Iteration 5032, the loss is 5.489507480902302, parameters k is 15.798292322982732 and b is -77.05809299734176\n",
      "Iteration 5033, the loss is 5.489547613417542, parameters k is 15.798489601638858 and b is -77.05909299734176\n",
      "Iteration 5034, the loss is 5.489587745932774, parameters k is 15.798686880294984 and b is -77.06009299734177\n",
      "Iteration 5035, the loss is 5.48962787844801, parameters k is 15.79888415895111 and b is -77.06109299734177\n",
      "Iteration 5036, the loss is 5.489668010963245, parameters k is 15.799081437607235 and b is -77.06209299734178\n",
      "Iteration 5037, the loss is 5.489708143478484, parameters k is 15.79927871626336 and b is -77.06309299734178\n",
      "Iteration 5038, the loss is 5.489748275993723, parameters k is 15.799475994919487 and b is -77.06409299734179\n",
      "Iteration 5039, the loss is 5.489788408508961, parameters k is 15.799673273575612 and b is -77.0650929973418\n",
      "Iteration 5040, the loss is 5.4898285410242025, parameters k is 15.799870552231738 and b is -77.0660929973418\n",
      "Iteration 5041, the loss is 5.4898686735394335, parameters k is 15.800067830887864 and b is -77.0670929973418\n",
      "Iteration 5042, the loss is 5.489908806054672, parameters k is 15.80026510954399 and b is -77.06809299734181\n",
      "Iteration 5043, the loss is 5.489948938569906, parameters k is 15.800462388200115 and b is -77.06909299734181\n",
      "Iteration 5044, the loss is 5.4899890710851444, parameters k is 15.800659666856241 and b is -77.07009299734182\n",
      "Iteration 5045, the loss is 5.490029203600379, parameters k is 15.800856945512367 and b is -77.07109299734182\n",
      "Iteration 5046, the loss is 5.490069336115616, parameters k is 15.801054224168492 and b is -77.07209299734183\n",
      "Iteration 5047, the loss is 5.490109468630851, parameters k is 15.801251502824618 and b is -77.07309299734183\n",
      "Iteration 5048, the loss is 5.490149601146089, parameters k is 15.801448781480744 and b is -77.07409299734184\n",
      "Iteration 5049, the loss is 5.490189733661329, parameters k is 15.80164606013687 and b is -77.07509299734184\n",
      "Iteration 5050, the loss is 5.49022986617656, parameters k is 15.801843338792995 and b is -77.07609299734185\n",
      "Iteration 5051, the loss is 5.490269998691797, parameters k is 15.802040617449121 and b is -77.07709299734185\n",
      "Iteration 5052, the loss is 5.490310131207034, parameters k is 15.802237896105247 and b is -77.07809299734186\n",
      "Iteration 5053, the loss is 5.490350263722272, parameters k is 15.802435174761372 and b is -77.07909299734186\n",
      "Iteration 5054, the loss is 5.490390396237509, parameters k is 15.802632453417498 and b is -77.08009299734186\n",
      "Iteration 5055, the loss is 5.490430528752747, parameters k is 15.802829732073624 and b is -77.08109299734187\n",
      "Iteration 5056, the loss is 5.490470661267983, parameters k is 15.80302701072975 and b is -77.08209299734187\n",
      "Iteration 5057, the loss is 5.49051079378322, parameters k is 15.803224289385875 and b is -77.08309299734188\n",
      "Iteration 5058, the loss is 5.490550926298456, parameters k is 15.803421568042001 and b is -77.08409299734188\n",
      "Iteration 5059, the loss is 5.490591058813692, parameters k is 15.803618846698127 and b is -77.08509299734189\n",
      "Iteration 5060, the loss is 5.49063119132893, parameters k is 15.803816125354253 and b is -77.0860929973419\n",
      "Iteration 5061, the loss is 5.490671323844169, parameters k is 15.804013404010378 and b is -77.0870929973419\n",
      "Iteration 5062, the loss is 5.490711456359401, parameters k is 15.804210682666504 and b is -77.0880929973419\n",
      "Iteration 5063, the loss is 5.490751588874639, parameters k is 15.80440796132263 and b is -77.08909299734191\n",
      "Iteration 5064, the loss is 5.490791721389877, parameters k is 15.804605239978756 and b is -77.09009299734191\n",
      "Iteration 5065, the loss is 5.490831853905109, parameters k is 15.804802518634881 and b is -77.09109299734192\n",
      "Iteration 5066, the loss is 5.490871986420347, parameters k is 15.804999797291007 and b is -77.09209299734192\n",
      "Iteration 5067, the loss is 5.490912118935583, parameters k is 15.805197075947133 and b is -77.09309299734193\n",
      "Iteration 5068, the loss is 5.490952251450824, parameters k is 15.805394354603258 and b is -77.09409299734193\n",
      "Iteration 5069, the loss is 5.490992383966059, parameters k is 15.805591633259384 and b is -77.09509299734194\n",
      "Iteration 5070, the loss is 5.4910325164813, parameters k is 15.80578891191551 and b is -77.09609299734194\n",
      "Iteration 5071, the loss is 5.491072648996529, parameters k is 15.805986190571636 and b is -77.09709299734195\n",
      "Iteration 5072, the loss is 5.491112781511772, parameters k is 15.806183469227761 and b is -77.09809299734195\n",
      "Iteration 5073, the loss is 5.491152914027002, parameters k is 15.806380747883887 and b is -77.09909299734196\n",
      "Iteration 5074, the loss is 5.491193046542243, parameters k is 15.806578026540013 and b is -77.10009299734196\n",
      "Iteration 5075, the loss is 5.491233179057479, parameters k is 15.806775305196139 and b is -77.10109299734196\n",
      "Iteration 5076, the loss is 5.4912733115727175, parameters k is 15.806972583852264 and b is -77.10209299734197\n",
      "Iteration 5077, the loss is 5.491313444087955, parameters k is 15.80716986250839 and b is -77.10309299734197\n",
      "Iteration 5078, the loss is 5.491353576603191, parameters k is 15.807367141164516 and b is -77.10409299734198\n",
      "Iteration 5079, the loss is 5.491393709118428, parameters k is 15.807564419820642 and b is -77.10509299734198\n",
      "Iteration 5080, the loss is 5.491433841633661, parameters k is 15.807761698476767 and b is -77.10609299734199\n",
      "Iteration 5081, the loss is 5.491473974148899, parameters k is 15.807958977132893 and b is -77.107092997342\n",
      "Iteration 5082, the loss is 5.491514106664133, parameters k is 15.808156255789019 and b is -77.108092997342\n",
      "Iteration 5083, the loss is 5.491554239179373, parameters k is 15.808353534445144 and b is -77.109092997342\n",
      "Iteration 5084, the loss is 5.491594371694613, parameters k is 15.80855081310127 and b is -77.11009299734201\n",
      "Iteration 5085, the loss is 5.491634504209846, parameters k is 15.808748091757396 and b is -77.11109299734201\n",
      "Iteration 5086, the loss is 5.491674636725087, parameters k is 15.808945370413522 and b is -77.11209299734202\n",
      "Iteration 5087, the loss is 5.4917147692403185, parameters k is 15.809142649069647 and b is -77.11309299734202\n",
      "Iteration 5088, the loss is 5.4917549017555505, parameters k is 15.809339927725773 and b is -77.11409299734203\n",
      "Iteration 5089, the loss is 5.491795034270794, parameters k is 15.809537206381899 and b is -77.11509299734203\n",
      "Iteration 5090, the loss is 5.491835166786039, parameters k is 15.809734485038025 and b is -77.11609299734204\n",
      "Iteration 5091, the loss is 5.491875299301264, parameters k is 15.80993176369415 and b is -77.11709299734204\n",
      "Iteration 5092, the loss is 5.491915431816498, parameters k is 15.810129042350276 and b is -77.11809299734205\n",
      "Iteration 5093, the loss is 5.491955564331741, parameters k is 15.810326321006402 and b is -77.11909299734205\n",
      "Iteration 5094, the loss is 5.491995696846974, parameters k is 15.810523599662528 and b is -77.12009299734206\n",
      "Iteration 5095, the loss is 5.492035829362206, parameters k is 15.810720878318653 and b is -77.12109299734206\n",
      "Iteration 5096, the loss is 5.492075961877455, parameters k is 15.810918156974779 and b is -77.12209299734207\n",
      "Iteration 5097, the loss is 5.492116094392686, parameters k is 15.811115435630905 and b is -77.12309299734207\n",
      "Iteration 5098, the loss is 5.492156226907927, parameters k is 15.81131271428703 and b is -77.12409299734207\n",
      "Iteration 5099, the loss is 5.492196359423167, parameters k is 15.811509992943156 and b is -77.12509299734208\n",
      "Iteration 5100, the loss is 5.492236491938397, parameters k is 15.811707271599282 and b is -77.12609299734208\n",
      "Iteration 5101, the loss is 5.492276624453632, parameters k is 15.811904550255408 and b is -77.12709299734209\n",
      "Iteration 5102, the loss is 5.492316756968872, parameters k is 15.812101828911533 and b is -77.1280929973421\n",
      "Iteration 5103, the loss is 5.492356889484106, parameters k is 15.812299107567659 and b is -77.1290929973421\n",
      "Iteration 5104, the loss is 5.492397021999341, parameters k is 15.812496386223785 and b is -77.1300929973421\n",
      "Iteration 5105, the loss is 5.492437154514577, parameters k is 15.81269366487991 and b is -77.13109299734211\n",
      "Iteration 5106, the loss is 5.492477287029818, parameters k is 15.812890943536036 and b is -77.13209299734211\n",
      "Iteration 5107, the loss is 5.4925174195450515, parameters k is 15.813088222192162 and b is -77.13309299734212\n",
      "Iteration 5108, the loss is 5.492557552060291, parameters k is 15.813285500848288 and b is -77.13409299734212\n",
      "Iteration 5109, the loss is 5.492597684575525, parameters k is 15.813482779504414 and b is -77.13509299734213\n",
      "Iteration 5110, the loss is 5.49263781709077, parameters k is 15.81368005816054 and b is -77.13609299734213\n",
      "Iteration 5111, the loss is 5.492677949606003, parameters k is 15.813877336816665 and b is -77.13709299734214\n",
      "Iteration 5112, the loss is 5.4927180821212405, parameters k is 15.81407461547279 and b is -77.13809299734214\n",
      "Iteration 5113, the loss is 5.4927582146364715, parameters k is 15.814271894128916 and b is -77.13909299734215\n",
      "Iteration 5114, the loss is 5.492798347151708, parameters k is 15.814469172785042 and b is -77.14009299734215\n",
      "Iteration 5115, the loss is 5.49283847966695, parameters k is 15.814666451441168 and b is -77.14109299734216\n",
      "Iteration 5116, the loss is 5.492878612182181, parameters k is 15.814863730097294 and b is -77.14209299734216\n",
      "Iteration 5117, the loss is 5.492918744697419, parameters k is 15.81506100875342 and b is -77.14309299734217\n",
      "Iteration 5118, the loss is 5.492958877212658, parameters k is 15.815258287409545 and b is -77.14409299734217\n",
      "Iteration 5119, the loss is 5.492999009727897, parameters k is 15.81545556606567 and b is -77.14509299734218\n",
      "Iteration 5120, the loss is 5.49303958899248, parameters k is 15.815652844721797 and b is -77.14609299734218\n",
      "Iteration 5121, the loss is 5.493085094968104, parameters k is 15.815824870413497 and b is -77.14709299734218\n",
      "Iteration 5122, the loss is 5.493130600943736, parameters k is 15.815996896105197 and b is -77.14809299734219\n",
      "Iteration 5123, the loss is 5.493176106919359, parameters k is 15.816168921796898 and b is -77.1490929973422\n",
      "Iteration 5124, the loss is 5.49322161289498, parameters k is 15.816340947488598 and b is -77.1500929973422\n",
      "Iteration 5125, the loss is 5.493267118870604, parameters k is 15.816512973180298 and b is -77.1510929973422\n",
      "Iteration 5126, the loss is 5.493312624846221, parameters k is 15.816684998871999 and b is -77.15209299734221\n",
      "Iteration 5127, the loss is 5.4933581308218535, parameters k is 15.8168570245637 and b is -77.15309299734221\n",
      "Iteration 5128, the loss is 5.4934036367974795, parameters k is 15.8170290502554 and b is -77.15409299734222\n",
      "Iteration 5129, the loss is 5.4934491427731, parameters k is 15.8172010759471 and b is -77.15509299734222\n",
      "Iteration 5130, the loss is 5.493494648748724, parameters k is 15.8173731016388 and b is -77.15609299734223\n",
      "Iteration 5131, the loss is 5.493540154724348, parameters k is 15.8175451273305 and b is -77.15709299734223\n",
      "Iteration 5132, the loss is 5.49358566069997, parameters k is 15.817717153022201 and b is -77.15809299734224\n",
      "Iteration 5133, the loss is 5.493631166675596, parameters k is 15.817889178713902 and b is -77.15909299734224\n",
      "Iteration 5134, the loss is 5.493676672651217, parameters k is 15.818061204405602 and b is -77.16009299734225\n",
      "Iteration 5135, the loss is 5.493722178626846, parameters k is 15.818233230097302 and b is -77.16109299734225\n",
      "Iteration 5136, the loss is 5.493767684602474, parameters k is 15.818405255789003 and b is -77.16209299734226\n",
      "Iteration 5137, the loss is 5.493813190578098, parameters k is 15.818577281480703 and b is -77.16309299734226\n",
      "Iteration 5138, the loss is 5.493858696553723, parameters k is 15.818749307172403 and b is -77.16409299734227\n",
      "Iteration 5139, the loss is 5.493904202529348, parameters k is 15.818921332864104 and b is -77.16509299734227\n",
      "Iteration 5140, the loss is 5.4939497085049736, parameters k is 15.819093358555804 and b is -77.16609299734228\n",
      "Iteration 5141, the loss is 5.493995214480597, parameters k is 15.819265384247505 and b is -77.16709299734228\n",
      "Iteration 5142, the loss is 5.494040720456219, parameters k is 15.819437409939205 and b is -77.16809299734228\n",
      "Iteration 5143, the loss is 5.49408622643184, parameters k is 15.819609435630905 and b is -77.16909299734229\n",
      "Iteration 5144, the loss is 5.494131732407469, parameters k is 15.819781461322606 and b is -77.1700929973423\n",
      "Iteration 5145, the loss is 5.494177238383098, parameters k is 15.819953487014306 and b is -77.1710929973423\n",
      "Iteration 5146, the loss is 5.49422274435872, parameters k is 15.820125512706007 and b is -77.1720929973423\n",
      "Iteration 5147, the loss is 5.494268250334345, parameters k is 15.820297538397707 and b is -77.17309299734231\n",
      "Iteration 5148, the loss is 5.494313756309975, parameters k is 15.820469564089407 and b is -77.17409299734231\n",
      "Iteration 5149, the loss is 5.494359262285595, parameters k is 15.820641589781108 and b is -77.17509299734232\n",
      "Iteration 5150, the loss is 5.494404768261217, parameters k is 15.820813615472808 and b is -77.17609299734232\n",
      "Iteration 5151, the loss is 5.494450274236841, parameters k is 15.820985641164508 and b is -77.17709299734233\n",
      "Iteration 5152, the loss is 5.494495780212471, parameters k is 15.821157666856209 and b is -77.17809299734233\n",
      "Iteration 5153, the loss is 5.494541286188098, parameters k is 15.82132969254791 and b is -77.17909299734234\n",
      "Iteration 5154, the loss is 5.494586792163721, parameters k is 15.82150171823961 and b is -77.18009299734234\n",
      "Iteration 5155, the loss is 5.494632298139341, parameters k is 15.82167374393131 and b is -77.18109299734235\n",
      "Iteration 5156, the loss is 5.494677804114969, parameters k is 15.82184576962301 and b is -77.18209299734235\n",
      "Iteration 5157, the loss is 5.494723310090597, parameters k is 15.82201779531471 and b is -77.18309299734236\n",
      "Iteration 5158, the loss is 5.49476881606622, parameters k is 15.822189821006411 and b is -77.18409299734236\n",
      "Iteration 5159, the loss is 5.494814322041844, parameters k is 15.822361846698112 and b is -77.18509299734237\n",
      "Iteration 5160, the loss is 5.4948598280174705, parameters k is 15.822533872389812 and b is -77.18609299734237\n",
      "Iteration 5161, the loss is 5.494905333993096, parameters k is 15.822705898081512 and b is -77.18709299734238\n",
      "Iteration 5162, the loss is 5.4949508399687215, parameters k is 15.822877923773213 and b is -77.18809299734238\n",
      "Iteration 5163, the loss is 5.494996345944347, parameters k is 15.823049949464913 and b is -77.18909299734239\n",
      "Iteration 5164, the loss is 5.495041851919958, parameters k is 15.823221975156613 and b is -77.19009299734239\n",
      "Iteration 5165, the loss is 5.4950873578955965, parameters k is 15.823394000848314 and b is -77.1910929973424\n",
      "Iteration 5166, the loss is 5.495132863871219, parameters k is 15.823566026540014 and b is -77.1920929973424\n",
      "Iteration 5167, the loss is 5.495178369846845, parameters k is 15.823738052231715 and b is -77.1930929973424\n",
      "Iteration 5168, the loss is 5.495223875822464, parameters k is 15.823910077923415 and b is -77.19409299734241\n",
      "Iteration 5169, the loss is 5.495269381798097, parameters k is 15.824082103615115 and b is -77.19509299734241\n",
      "Iteration 5170, the loss is 5.495314887773718, parameters k is 15.824254129306816 and b is -77.19609299734242\n",
      "Iteration 5171, the loss is 5.495360393749346, parameters k is 15.824426154998516 and b is -77.19709299734242\n",
      "Iteration 5172, the loss is 5.495405899724967, parameters k is 15.824598180690217 and b is -77.19809299734243\n",
      "Iteration 5173, the loss is 5.49545140570059, parameters k is 15.824770206381917 and b is -77.19909299734243\n",
      "Iteration 5174, the loss is 5.495496911676215, parameters k is 15.824942232073617 and b is -77.20009299734244\n",
      "Iteration 5175, the loss is 5.495542417651838, parameters k is 15.825114257765318 and b is -77.20109299734244\n",
      "Iteration 5176, the loss is 5.4955879236274665, parameters k is 15.825286283457018 and b is -77.20209299734245\n",
      "Iteration 5177, the loss is 5.495633429603087, parameters k is 15.825458309148718 and b is -77.20309299734245\n",
      "Iteration 5178, the loss is 5.495678935578715, parameters k is 15.825630334840419 and b is -77.20409299734246\n",
      "Iteration 5179, the loss is 5.4957244415543345, parameters k is 15.82580236053212 and b is -77.20509299734246\n",
      "Iteration 5180, the loss is 5.495769947529964, parameters k is 15.82597438622382 and b is -77.20609299734247\n",
      "Iteration 5181, the loss is 5.49581545350559, parameters k is 15.82614641191552 and b is -77.20709299734247\n",
      "Iteration 5182, the loss is 5.495860959481218, parameters k is 15.82631843760722 and b is -77.20809299734248\n",
      "Iteration 5183, the loss is 5.495906465456841, parameters k is 15.82649046329892 and b is -77.20909299734248\n",
      "Iteration 5184, the loss is 5.495951971432461, parameters k is 15.826662488990621 and b is -77.21009299734249\n",
      "Iteration 5185, the loss is 5.495997477408089, parameters k is 15.826834514682321 and b is -77.21109299734249\n",
      "Iteration 5186, the loss is 5.496042983383712, parameters k is 15.827006540374022 and b is -77.2120929973425\n",
      "Iteration 5187, the loss is 5.496088489359341, parameters k is 15.827178566065722 and b is -77.2130929973425\n",
      "Iteration 5188, the loss is 5.496133995334964, parameters k is 15.827350591757423 and b is -77.2140929973425\n",
      "Iteration 5189, the loss is 5.496179501310589, parameters k is 15.827522617449123 and b is -77.21509299734251\n",
      "Iteration 5190, the loss is 5.49622500728621, parameters k is 15.827694643140823 and b is -77.21609299734251\n",
      "Iteration 5191, the loss is 5.496270513261839, parameters k is 15.827866668832524 and b is -77.21709299734252\n",
      "Iteration 5192, the loss is 5.4963160192374625, parameters k is 15.828038694524224 and b is -77.21809299734252\n",
      "Iteration 5193, the loss is 5.496361525213087, parameters k is 15.828210720215925 and b is -77.21909299734253\n",
      "Iteration 5194, the loss is 5.49640703118871, parameters k is 15.828382745907625 and b is -77.22009299734253\n",
      "Iteration 5195, the loss is 5.496452537164341, parameters k is 15.828554771599325 and b is -77.22109299734254\n",
      "Iteration 5196, the loss is 5.49649804313995, parameters k is 15.828726797291026 and b is -77.22209299734254\n",
      "Iteration 5197, the loss is 5.4965435491155885, parameters k is 15.828898822982726 and b is -77.22309299734255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5198, the loss is 5.496589055091208, parameters k is 15.829070848674426 and b is -77.22409299734255\n",
      "Iteration 5199, the loss is 5.496634561066833, parameters k is 15.829242874366127 and b is -77.22509299734256\n",
      "Iteration 5200, the loss is 5.496680067042459, parameters k is 15.829414900057827 and b is -77.22609299734256\n",
      "Iteration 5201, the loss is 5.496725573018086, parameters k is 15.829586925749528 and b is -77.22709299734257\n",
      "Iteration 5202, the loss is 5.496771078993711, parameters k is 15.829758951441228 and b is -77.22809299734257\n",
      "Iteration 5203, the loss is 5.496816584969331, parameters k is 15.829930977132928 and b is -77.22909299734258\n",
      "Iteration 5204, the loss is 5.496862090944951, parameters k is 15.830103002824629 and b is -77.23009299734258\n",
      "Iteration 5205, the loss is 5.496907596920576, parameters k is 15.83027502851633 and b is -77.23109299734259\n",
      "Iteration 5206, the loss is 5.496953102896204, parameters k is 15.83044705420803 and b is -77.23209299734259\n",
      "Iteration 5207, the loss is 5.496998608871832, parameters k is 15.83061907989973 and b is -77.2330929973426\n",
      "Iteration 5208, the loss is 5.49704411484746, parameters k is 15.83079110559143 and b is -77.2340929973426\n",
      "Iteration 5209, the loss is 5.497089620823081, parameters k is 15.83096313128313 and b is -77.2350929973426\n",
      "Iteration 5210, the loss is 5.497135126798703, parameters k is 15.831135156974831 and b is -77.23609299734261\n",
      "Iteration 5211, the loss is 5.497180751192666, parameters k is 15.831307182666531 and b is -77.23709299734261\n",
      "Iteration 5212, the loss is 5.497231260922852, parameters k is 15.83145083681673 and b is -77.23809299734262\n",
      "Iteration 5213, the loss is 5.497281770653044, parameters k is 15.831594490966928 and b is -77.23909299734262\n",
      "Iteration 5214, the loss is 5.497332280383232, parameters k is 15.831738145117127 and b is -77.24009299734263\n",
      "Iteration 5215, the loss is 5.497382790113429, parameters k is 15.831881799267325 and b is -77.24109299734263\n",
      "Iteration 5216, the loss is 5.49743329984361, parameters k is 15.832025453417524 and b is -77.24209299734264\n",
      "Iteration 5217, the loss is 5.4974838095738034, parameters k is 15.832169107567722 and b is -77.24309299734264\n",
      "Iteration 5218, the loss is 5.497534319303994, parameters k is 15.83231276171792 and b is -77.24409299734265\n",
      "Iteration 5219, the loss is 5.4975848290341895, parameters k is 15.83245641586812 and b is -77.24509299734265\n",
      "Iteration 5220, the loss is 5.497635338764377, parameters k is 15.832600070018318 and b is -77.24609299734266\n",
      "Iteration 5221, the loss is 5.497685848494565, parameters k is 15.832743724168516 and b is -77.24709299734266\n",
      "Iteration 5222, the loss is 5.497736358224756, parameters k is 15.832887378318715 and b is -77.24809299734267\n",
      "Iteration 5223, the loss is 5.497786867954945, parameters k is 15.833031032468913 and b is -77.24909299734267\n",
      "Iteration 5224, the loss is 5.497837377685136, parameters k is 15.833174686619111 and b is -77.25009299734268\n",
      "Iteration 5225, the loss is 5.49788788741533, parameters k is 15.83331834076931 and b is -77.25109299734268\n",
      "Iteration 5226, the loss is 5.497938397145517, parameters k is 15.833461994919508 and b is -77.25209299734269\n",
      "Iteration 5227, the loss is 5.497988906875708, parameters k is 15.833605649069707 and b is -77.25309299734269\n",
      "Iteration 5228, the loss is 5.498039416605902, parameters k is 15.833749303219905 and b is -77.2540929973427\n",
      "Iteration 5229, the loss is 5.498089926336089, parameters k is 15.833892957370104 and b is -77.2550929973427\n",
      "Iteration 5230, the loss is 5.498140436066284, parameters k is 15.834036611520302 and b is -77.2560929973427\n",
      "Iteration 5231, the loss is 5.498190945796474, parameters k is 15.8341802656705 and b is -77.25709299734271\n",
      "Iteration 5232, the loss is 5.498241455526659, parameters k is 15.834323919820699 and b is -77.25809299734271\n",
      "Iteration 5233, the loss is 5.4982919652568505, parameters k is 15.834467573970898 and b is -77.25909299734272\n",
      "Iteration 5234, the loss is 5.498342474987041, parameters k is 15.834611228121096 and b is -77.26009299734272\n",
      "Iteration 5235, the loss is 5.498392984717231, parameters k is 15.834754882271294 and b is -77.26109299734273\n",
      "Iteration 5236, the loss is 5.498443494447423, parameters k is 15.834898536421493 and b is -77.26209299734273\n",
      "Iteration 5237, the loss is 5.498494004177613, parameters k is 15.835042190571691 and b is -77.26309299734274\n",
      "Iteration 5238, the loss is 5.498544513907806, parameters k is 15.83518584472189 and b is -77.26409299734274\n",
      "Iteration 5239, the loss is 5.498595023638001, parameters k is 15.835329498872088 and b is -77.26509299734275\n",
      "Iteration 5240, the loss is 5.498645533368188, parameters k is 15.835473153022287 and b is -77.26609299734275\n",
      "Iteration 5241, the loss is 5.498696043098378, parameters k is 15.835616807172485 and b is -77.26709299734276\n",
      "Iteration 5242, the loss is 5.498746552828567, parameters k is 15.835760461322684 and b is -77.26809299734276\n",
      "Iteration 5243, the loss is 5.498797062558758, parameters k is 15.835904115472882 and b is -77.26909299734277\n",
      "Iteration 5244, the loss is 5.4988475722889465, parameters k is 15.83604776962308 and b is -77.27009299734277\n",
      "Iteration 5245, the loss is 5.498898082019142, parameters k is 15.836191423773279 and b is -77.27109299734278\n",
      "Iteration 5246, the loss is 5.498948591749329, parameters k is 15.836335077923477 and b is -77.27209299734278\n",
      "Iteration 5247, the loss is 5.498999101479517, parameters k is 15.836478732073676 and b is -77.27309299734279\n",
      "Iteration 5248, the loss is 5.499049611209718, parameters k is 15.836622386223874 and b is -77.27409299734279\n",
      "Iteration 5249, the loss is 5.499100120939905, parameters k is 15.836766040374073 and b is -77.2750929973428\n",
      "Iteration 5250, the loss is 5.499150630670092, parameters k is 15.836909694524271 and b is -77.2760929973428\n",
      "Iteration 5251, the loss is 5.499201140400284, parameters k is 15.83705334867447 and b is -77.2770929973428\n",
      "Iteration 5252, the loss is 5.499251650130475, parameters k is 15.837197002824668 and b is -77.27809299734281\n",
      "Iteration 5253, the loss is 5.4993021598606635, parameters k is 15.837340656974867 and b is -77.27909299734281\n",
      "Iteration 5254, the loss is 5.499352669590852, parameters k is 15.837484311125065 and b is -77.28009299734282\n",
      "Iteration 5255, the loss is 5.499403179321048, parameters k is 15.837627965275264 and b is -77.28109299734282\n",
      "Iteration 5256, the loss is 5.499453689051238, parameters k is 15.837771619425462 and b is -77.28209299734283\n",
      "Iteration 5257, the loss is 5.499504198781426, parameters k is 15.83791527357566 and b is -77.28309299734283\n",
      "Iteration 5258, the loss is 5.499554708511613, parameters k is 15.838058927725859 and b is -77.28409299734284\n",
      "Iteration 5259, the loss is 5.4996052182418085, parameters k is 15.838202581876057 and b is -77.28509299734284\n",
      "Iteration 5260, the loss is 5.4996557279719935, parameters k is 15.838346236026256 and b is -77.28609299734285\n",
      "Iteration 5261, the loss is 5.499706237702181, parameters k is 15.838489890176454 and b is -77.28709299734285\n",
      "Iteration 5262, the loss is 5.4997567474323805, parameters k is 15.838633544326653 and b is -77.28809299734286\n",
      "Iteration 5263, the loss is 5.499807257162573, parameters k is 15.838777198476851 and b is -77.28909299734286\n",
      "Iteration 5264, the loss is 5.499857766892759, parameters k is 15.83892085262705 and b is -77.29009299734287\n",
      "Iteration 5265, the loss is 5.499908276622951, parameters k is 15.839064506777248 and b is -77.29109299734287\n",
      "Iteration 5266, the loss is 5.499958786353135, parameters k is 15.839208160927447 and b is -77.29209299734288\n",
      "Iteration 5267, the loss is 5.500009296083323, parameters k is 15.839351815077645 and b is -77.29309299734288\n",
      "Iteration 5268, the loss is 5.500059805813524, parameters k is 15.839495469227844 and b is -77.29409299734289\n",
      "Iteration 5269, the loss is 5.500110315543717, parameters k is 15.839639123378042 and b is -77.29509299734289\n",
      "Iteration 5270, the loss is 5.500160825273904, parameters k is 15.83978277752824 and b is -77.2960929973429\n",
      "Iteration 5271, the loss is 5.50021133500409, parameters k is 15.839926431678439 and b is -77.2970929973429\n",
      "Iteration 5272, the loss is 5.500261844734275, parameters k is 15.840070085828637 and b is -77.2980929973429\n",
      "Iteration 5273, the loss is 5.500312354464469, parameters k is 15.840213739978836 and b is -77.29909299734291\n",
      "Iteration 5274, the loss is 5.500362864194665, parameters k is 15.840357394129034 and b is -77.30009299734292\n",
      "Iteration 5275, the loss is 5.500413373924853, parameters k is 15.840501048279233 and b is -77.30109299734292\n",
      "Iteration 5276, the loss is 5.500463883655045, parameters k is 15.840644702429431 and b is -77.30209299734292\n",
      "Iteration 5277, the loss is 5.500514393385234, parameters k is 15.84078835657963 and b is -77.30309299734293\n",
      "Iteration 5278, the loss is 5.500564903115426, parameters k is 15.840932010729828 and b is -77.30409299734293\n",
      "Iteration 5279, the loss is 5.500615412845619, parameters k is 15.841075664880027 and b is -77.30509299734294\n",
      "Iteration 5280, the loss is 5.500665922575804, parameters k is 15.841219319030225 and b is -77.30609299734294\n",
      "Iteration 5281, the loss is 5.500716432306, parameters k is 15.841362973180424 and b is -77.30709299734295\n",
      "Iteration 5282, the loss is 5.500766942036191, parameters k is 15.841506627330622 and b is -77.30809299734295\n",
      "Iteration 5283, the loss is 5.500817451766376, parameters k is 15.84165028148082 and b is -77.30909299734296\n",
      "Iteration 5284, the loss is 5.500867961496572, parameters k is 15.841793935631019 and b is -77.31009299734296\n",
      "Iteration 5285, the loss is 5.5009184712267585, parameters k is 15.841937589781217 and b is -77.31109299734297\n",
      "Iteration 5286, the loss is 5.500968980956946, parameters k is 15.842081243931416 and b is -77.31209299734297\n",
      "Iteration 5287, the loss is 5.5010194906871455, parameters k is 15.842224898081614 and b is -77.31309299734298\n",
      "Iteration 5288, the loss is 5.50107000041733, parameters k is 15.842368552231813 and b is -77.31409299734298\n",
      "Iteration 5289, the loss is 5.501120510147525, parameters k is 15.842512206382011 and b is -77.31509299734299\n",
      "Iteration 5290, the loss is 5.50117101987771, parameters k is 15.84265586053221 and b is -77.31609299734299\n",
      "Iteration 5291, the loss is 5.501221529607903, parameters k is 15.842799514682408 and b is -77.317092997343\n",
      "Iteration 5292, the loss is 5.501272039338088, parameters k is 15.842943168832607 and b is -77.318092997343\n",
      "Iteration 5293, the loss is 5.501322549068281, parameters k is 15.843086822982805 and b is -77.319092997343\n",
      "Iteration 5294, the loss is 5.501373058798478, parameters k is 15.843230477133003 and b is -77.32009299734301\n",
      "Iteration 5295, the loss is 5.501423568528666, parameters k is 15.843374131283202 and b is -77.32109299734302\n",
      "Iteration 5296, the loss is 5.50147407825886, parameters k is 15.8435177854334 and b is -77.32209299734302\n",
      "Iteration 5297, the loss is 5.5015245879890395, parameters k is 15.843661439583599 and b is -77.32309299734302\n",
      "Iteration 5298, the loss is 5.501575097719234, parameters k is 15.843805093733797 and b is -77.32409299734303\n",
      "Iteration 5299, the loss is 5.501625607449425, parameters k is 15.843948747883996 and b is -77.32509299734303\n",
      "Iteration 5300, the loss is 5.50167611717961, parameters k is 15.844092402034194 and b is -77.32609299734304\n",
      "Iteration 5301, the loss is 5.501726626909807, parameters k is 15.844236056184393 and b is -77.32709299734304\n",
      "Iteration 5302, the loss is 5.501777136640004, parameters k is 15.844379710334591 and b is -77.32809299734305\n",
      "Iteration 5303, the loss is 5.501827646370195, parameters k is 15.84452336448479 and b is -77.32909299734305\n",
      "Iteration 5304, the loss is 5.501878156100377, parameters k is 15.844667018634988 and b is -77.33009299734306\n",
      "Iteration 5305, the loss is 5.501928665830568, parameters k is 15.844810672785187 and b is -77.33109299734306\n",
      "Iteration 5306, the loss is 5.5019791755607566, parameters k is 15.844954326935385 and b is -77.33209299734307\n",
      "Iteration 5307, the loss is 5.502029685290951, parameters k is 15.845097981085583 and b is -77.33309299734307\n",
      "Iteration 5308, the loss is 5.502080195021136, parameters k is 15.845241635235782 and b is -77.33409299734308\n",
      "Iteration 5309, the loss is 5.502130704751331, parameters k is 15.84538528938598 and b is -77.33509299734308\n",
      "Iteration 5310, the loss is 5.502181214481526, parameters k is 15.845528943536179 and b is -77.33609299734309\n",
      "Iteration 5311, the loss is 5.502231724211714, parameters k is 15.845672597686377 and b is -77.33709299734309\n",
      "Iteration 5312, the loss is 5.502282233941906, parameters k is 15.845816251836576 and b is -77.3380929973431\n",
      "Iteration 5313, the loss is 5.502332743672094, parameters k is 15.845959905986774 and b is -77.3390929973431\n",
      "Iteration 5314, the loss is 5.502383253402281, parameters k is 15.846103560136973 and b is -77.3400929973431\n",
      "Iteration 5315, the loss is 5.50243376313247, parameters k is 15.846247214287171 and b is -77.34109299734311\n",
      "Iteration 5316, the loss is 5.502484272862663, parameters k is 15.84639086843737 and b is -77.34209299734312\n",
      "Iteration 5317, the loss is 5.502534782592854, parameters k is 15.846534522587568 and b is -77.34309299734312\n",
      "Iteration 5318, the loss is 5.502585292323045, parameters k is 15.846678176737766 and b is -77.34409299734313\n",
      "Iteration 5319, the loss is 5.502635802053234, parameters k is 15.846821830887965 and b is -77.34509299734313\n",
      "Iteration 5320, the loss is 5.502686311783426, parameters k is 15.846965485038163 and b is -77.34609299734313\n",
      "Iteration 5321, the loss is 5.502736821513615, parameters k is 15.847109139188362 and b is -77.34709299734314\n",
      "Iteration 5322, the loss is 5.502787331243802, parameters k is 15.84725279333856 and b is -77.34809299734314\n",
      "Iteration 5323, the loss is 5.502838145694699, parameters k is 15.847396447488759 and b is -77.34909299734315\n",
      "Iteration 5324, the loss is 5.502884723011047, parameters k is 15.847565354603383 and b is -77.35009299734315\n",
      "Iteration 5325, the loss is 5.502935549501778, parameters k is 15.847709008753581 and b is -77.35109299734316\n",
      "Iteration 5326, the loss is 5.502982118702635, parameters k is 15.847877915868205 and b is -77.35209299734316\n",
      "Iteration 5327, the loss is 5.503028996815329, parameters k is 15.848046822982829 and b is -77.35309299734317\n",
      "Iteration 5328, the loss is 5.503079522509708, parameters k is 15.848190477133027 and b is -77.35409299734317\n",
      "Iteration 5329, the loss is 5.503126388582563, parameters k is 15.848359384247651 and b is -77.35509299734318\n",
      "Iteration 5330, the loss is 5.503176926316782, parameters k is 15.84850303839785 and b is -77.35609299734318\n",
      "Iteration 5331, the loss is 5.5032237803498, parameters k is 15.848671945512473 and b is -77.35709299734319\n",
      "Iteration 5332, the loss is 5.503274330123851, parameters k is 15.848815599662672 and b is -77.35809299734319\n",
      "Iteration 5333, the loss is 5.503321172117037, parameters k is 15.848984506777295 and b is -77.3590929973432\n",
      "Iteration 5334, the loss is 5.503371733930929, parameters k is 15.849128160927494 and b is -77.3600929973432\n",
      "Iteration 5335, the loss is 5.503418563884273, parameters k is 15.849297068042118 and b is -77.3610929973432\n",
      "Iteration 5336, the loss is 5.503469137737999, parameters k is 15.849440722192316 and b is -77.36209299734321\n",
      "Iteration 5337, the loss is 5.503515955651513, parameters k is 15.84960962930694 and b is -77.36309299734322\n",
      "Iteration 5338, the loss is 5.5035665415450765, parameters k is 15.849753283457138 and b is -77.36409299734322\n",
      "Iteration 5339, the loss is 5.503613347418741, parameters k is 15.849922190571762 and b is -77.36509299734323\n",
      "Iteration 5340, the loss is 5.503663945352164, parameters k is 15.85006584472196 and b is -77.36609299734323\n",
      "Iteration 5341, the loss is 5.50371073918598, parameters k is 15.850234751836584 and b is -77.36709299734324\n",
      "Iteration 5342, the loss is 5.503761349159231, parameters k is 15.850378405986783 and b is -77.36809299734324\n",
      "Iteration 5343, the loss is 5.503808130953218, parameters k is 15.850547313101407 and b is -77.36909299734324\n",
      "Iteration 5344, the loss is 5.503858752966305, parameters k is 15.850690967251605 and b is -77.37009299734325\n",
      "Iteration 5345, the loss is 5.503905522720457, parameters k is 15.850859874366229 and b is -77.37109299734325\n",
      "Iteration 5346, the loss is 5.503956156773381, parameters k is 15.851003528516427 and b is -77.37209299734326\n",
      "Iteration 5347, the loss is 5.504002914487687, parameters k is 15.851172435631051 and b is -77.37309299734326\n",
      "Iteration 5348, the loss is 5.504053560580452, parameters k is 15.85131608978125 and b is -77.37409299734327\n",
      "Iteration 5349, the loss is 5.5041003062549265, parameters k is 15.851484996895874 and b is -77.37509299734327\n",
      "Iteration 5350, the loss is 5.504150964387531, parameters k is 15.851628651046072 and b is -77.37609299734328\n",
      "Iteration 5351, the loss is 5.504197698022162, parameters k is 15.851797558160696 and b is -77.37709299734328\n",
      "Iteration 5352, the loss is 5.5042483681946015, parameters k is 15.851941212310894 and b is -77.37809299734329\n",
      "Iteration 5353, the loss is 5.504295089789399, parameters k is 15.852110119425518 and b is -77.37909299734329\n",
      "Iteration 5354, the loss is 5.504345772001678, parameters k is 15.852253773575717 and b is -77.3800929973433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5355, the loss is 5.50439248155664, parameters k is 15.85242268069034 and b is -77.3810929973433\n",
      "Iteration 5356, the loss is 5.504443175808756, parameters k is 15.852566334840539 and b is -77.3820929973433\n",
      "Iteration 5357, the loss is 5.504489873323872, parameters k is 15.852735241955163 and b is -77.38309299734331\n",
      "Iteration 5358, the loss is 5.504540579615833, parameters k is 15.852878896105361 and b is -77.38409299734332\n",
      "Iteration 5359, the loss is 5.504587265091114, parameters k is 15.853047803219985 and b is -77.38509299734332\n",
      "Iteration 5360, the loss is 5.504637983422906, parameters k is 15.853191457370183 and b is -77.38609299734333\n",
      "Iteration 5361, the loss is 5.504684656858348, parameters k is 15.853360364484807 and b is -77.38709299734333\n",
      "Iteration 5362, the loss is 5.504735387229976, parameters k is 15.853504018635006 and b is -77.38809299734334\n",
      "Iteration 5363, the loss is 5.5047820486255885, parameters k is 15.85367292574963 and b is -77.38909299734334\n",
      "Iteration 5364, the loss is 5.5048327910370505, parameters k is 15.853816579899828 and b is -77.39009299734334\n",
      "Iteration 5365, the loss is 5.504879440392816, parameters k is 15.853985487014452 and b is -77.39109299734335\n",
      "Iteration 5366, the loss is 5.504930194844129, parameters k is 15.85412914116465 and b is -77.39209299734335\n",
      "Iteration 5367, the loss is 5.504976832160055, parameters k is 15.854298048279274 and b is -77.39309299734336\n",
      "Iteration 5368, the loss is 5.5050275986512, parameters k is 15.854441702429472 and b is -77.39409299734336\n",
      "Iteration 5369, the loss is 5.505074223927291, parameters k is 15.854610609544096 and b is -77.39509299734337\n",
      "Iteration 5370, the loss is 5.505125002458283, parameters k is 15.854754263694295 and b is -77.39609299734337\n",
      "Iteration 5371, the loss is 5.505171615694527, parameters k is 15.854923170808918 and b is -77.39709299734338\n",
      "Iteration 5372, the loss is 5.505222406265349, parameters k is 15.855066824959117 and b is -77.39809299734338\n",
      "Iteration 5373, the loss is 5.505269007461767, parameters k is 15.85523573207374 and b is -77.39909299734339\n",
      "Iteration 5374, the loss is 5.505319810072426, parameters k is 15.85537938622394 and b is -77.40009299734339\n",
      "Iteration 5375, the loss is 5.505366399229004, parameters k is 15.855548293338563 and b is -77.4010929973434\n",
      "Iteration 5376, the loss is 5.505417213879501, parameters k is 15.855691947488761 and b is -77.4020929973434\n",
      "Iteration 5377, the loss is 5.505463790996245, parameters k is 15.855860854603385 and b is -77.4030929973434\n",
      "Iteration 5378, the loss is 5.505514617686571, parameters k is 15.856004508753584 and b is -77.40409299734341\n",
      "Iteration 5379, the loss is 5.505561186887436, parameters k is 15.856173415868207 and b is -77.40509299734342\n",
      "Iteration 5380, the loss is 5.50560806480052, parameters k is 15.856342322982831 and b is -77.40609299734342\n",
      "Iteration 5381, the loss is 5.5056585906945115, parameters k is 15.85648597713303 and b is -77.40709299734343\n",
      "Iteration 5382, the loss is 5.505705456567758, parameters k is 15.856654884247654 and b is -77.40809299734343\n",
      "Iteration 5383, the loss is 5.505755994501589, parameters k is 15.856798538397852 and b is -77.40909299734344\n",
      "Iteration 5384, the loss is 5.505802848334997, parameters k is 15.856967445512476 and b is -77.41009299734344\n",
      "Iteration 5385, the loss is 5.50585339830866, parameters k is 15.857111099662674 and b is -77.41109299734345\n",
      "Iteration 5386, the loss is 5.505900240102234, parameters k is 15.857280006777298 and b is -77.41209299734345\n",
      "Iteration 5387, the loss is 5.505950802115733, parameters k is 15.857423660927497 and b is -77.41309299734345\n",
      "Iteration 5388, the loss is 5.505997631869471, parameters k is 15.85759256804212 and b is -77.41409299734346\n",
      "Iteration 5389, the loss is 5.506048205922807, parameters k is 15.857736222192319 and b is -77.41509299734346\n",
      "Iteration 5390, the loss is 5.506095023636699, parameters k is 15.857905129306943 and b is -77.41609299734347\n",
      "Iteration 5391, the loss is 5.506145609729883, parameters k is 15.858048783457141 and b is -77.41709299734347\n",
      "Iteration 5392, the loss is 5.506192415403939, parameters k is 15.858217690571765 and b is -77.41809299734348\n",
      "Iteration 5393, the loss is 5.506243013536957, parameters k is 15.858361344721963 and b is -77.41909299734348\n",
      "Iteration 5394, the loss is 5.50628980717118, parameters k is 15.858530251836587 and b is -77.42009299734349\n",
      "Iteration 5395, the loss is 5.506340417344035, parameters k is 15.858673905986786 and b is -77.4210929973435\n",
      "Iteration 5396, the loss is 5.506387198938412, parameters k is 15.85884281310141 and b is -77.4220929973435\n",
      "Iteration 5397, the loss is 5.50643782115111, parameters k is 15.858986467251608 and b is -77.4230929973435\n",
      "Iteration 5398, the loss is 5.506484590705648, parameters k is 15.859155374366232 and b is -77.42409299734351\n",
      "Iteration 5399, the loss is 5.50653522495818, parameters k is 15.85929902851643 and b is -77.42509299734351\n",
      "Iteration 5400, the loss is 5.506581982472885, parameters k is 15.859467935631054 and b is -77.42609299734352\n",
      "Iteration 5401, the loss is 5.506632628765256, parameters k is 15.859611589781252 and b is -77.42709299734352\n",
      "Iteration 5402, the loss is 5.506679374240124, parameters k is 15.859780496895876 and b is -77.42809299734353\n",
      "Iteration 5403, the loss is 5.506730032572331, parameters k is 15.859924151046075 and b is -77.42909299734353\n",
      "Iteration 5404, the loss is 5.506776766007352, parameters k is 15.860093058160698 and b is -77.43009299734354\n",
      "Iteration 5405, the loss is 5.506827436379409, parameters k is 15.860236712310897 and b is -77.43109299734354\n",
      "Iteration 5406, the loss is 5.5068741577745985, parameters k is 15.86040561942552 and b is -77.43209299734355\n",
      "Iteration 5407, the loss is 5.506924840186482, parameters k is 15.86054927357572 and b is -77.43309299734355\n",
      "Iteration 5408, the loss is 5.50697154954183, parameters k is 15.860718180690343 and b is -77.43409299734355\n",
      "Iteration 5409, the loss is 5.507022243993561, parameters k is 15.860861834840541 and b is -77.43509299734356\n",
      "Iteration 5410, the loss is 5.507068941309073, parameters k is 15.861030741955165 and b is -77.43609299734356\n",
      "Iteration 5411, the loss is 5.507119647800633, parameters k is 15.861174396105364 and b is -77.43709299734357\n",
      "Iteration 5412, the loss is 5.507166333076309, parameters k is 15.861343303219988 and b is -77.43809299734357\n",
      "Iteration 5413, the loss is 5.507217051607704, parameters k is 15.861486957370186 and b is -77.43909299734358\n",
      "Iteration 5414, the loss is 5.507263724843543, parameters k is 15.86165586448481 and b is -77.44009299734358\n",
      "Iteration 5415, the loss is 5.507314455414778, parameters k is 15.861799518635008 and b is -77.44109299734359\n",
      "Iteration 5416, the loss is 5.507361116610783, parameters k is 15.861968425749632 and b is -77.4420929973436\n",
      "Iteration 5417, the loss is 5.507411859221851, parameters k is 15.86211207989983 and b is -77.4430929973436\n",
      "Iteration 5418, the loss is 5.507458508378017, parameters k is 15.862280987014454 and b is -77.4440929973436\n",
      "Iteration 5419, the loss is 5.5075092630289335, parameters k is 15.862424641164653 and b is -77.44509299734361\n",
      "Iteration 5420, the loss is 5.507555900145258, parameters k is 15.862593548279277 and b is -77.44609299734361\n",
      "Iteration 5421, the loss is 5.5076066668360015, parameters k is 15.862737202429475 and b is -77.44709299734362\n",
      "Iteration 5422, the loss is 5.507653291912487, parameters k is 15.862906109544099 and b is -77.44809299734362\n",
      "Iteration 5423, the loss is 5.507704070643085, parameters k is 15.863049763694297 and b is -77.44909299734363\n",
      "Iteration 5424, the loss is 5.507750683679724, parameters k is 15.863218670808921 and b is -77.45009299734363\n",
      "Iteration 5425, the loss is 5.507801474450156, parameters k is 15.86336232495912 and b is -77.45109299734364\n",
      "Iteration 5426, the loss is 5.507848075446965, parameters k is 15.863531232073743 and b is -77.45209299734364\n",
      "Iteration 5427, the loss is 5.507898878257225, parameters k is 15.863674886223942 and b is -77.45309299734365\n",
      "Iteration 5428, the loss is 5.507945467214195, parameters k is 15.863843793338566 and b is -77.45409299734365\n",
      "Iteration 5429, the loss is 5.5079962820642985, parameters k is 15.863987447488764 and b is -77.45509299734366\n",
      "Iteration 5430, the loss is 5.508042858981438, parameters k is 15.864156354603388 and b is -77.45609299734366\n",
      "Iteration 5431, the loss is 5.508093685871376, parameters k is 15.864300008753586 and b is -77.45709299734366\n",
      "Iteration 5432, the loss is 5.508140255072231, parameters k is 15.86446891586821 and b is -77.45809299734367\n",
      "Iteration 5433, the loss is 5.508187132785715, parameters k is 15.864637822982834 and b is -77.45909299734367\n",
      "Iteration 5434, the loss is 5.508237658879312, parameters k is 15.864781477133032 and b is -77.46009299734368\n",
      "Iteration 5435, the loss is 5.5082845245529555, parameters k is 15.864950384247656 and b is -77.46109299734368\n",
      "Iteration 5436, the loss is 5.508335062686385, parameters k is 15.865094038397855 and b is -77.46209299734369\n",
      "Iteration 5437, the loss is 5.508381916320187, parameters k is 15.865262945512479 and b is -77.4630929973437\n",
      "Iteration 5438, the loss is 5.508432466493462, parameters k is 15.865406599662677 and b is -77.4640929973437\n",
      "Iteration 5439, the loss is 5.508479308087433, parameters k is 15.8655755067773 and b is -77.4650929973437\n",
      "Iteration 5440, the loss is 5.508529870300533, parameters k is 15.8657191609275 and b is -77.46609299734371\n",
      "Iteration 5441, the loss is 5.508576699854666, parameters k is 15.865888068042123 and b is -77.46709299734371\n",
      "Iteration 5442, the loss is 5.508627274107616, parameters k is 15.866031722192321 and b is -77.46809299734372\n",
      "Iteration 5443, the loss is 5.508674091621902, parameters k is 15.866200629306945 and b is -77.46909299734372\n",
      "Iteration 5444, the loss is 5.508725140270224, parameters k is 15.866344283457144 and b is -77.47009299734373\n",
      "Iteration 5445, the loss is 5.508777475796473, parameters k is 15.866481435631057 and b is -77.47109299734373\n",
      "Iteration 5446, the loss is 5.508829811322729, parameters k is 15.86661858780497 and b is -77.47209299734374\n",
      "Iteration 5447, the loss is 5.5088821468489675, parameters k is 15.866755739978883 and b is -77.47309299734374\n",
      "Iteration 5448, the loss is 5.508934482375225, parameters k is 15.866892892152796 and b is -77.47409299734375\n",
      "Iteration 5449, the loss is 5.50898681790147, parameters k is 15.86703004432671 and b is -77.47509299734375\n",
      "Iteration 5450, the loss is 5.509039153427718, parameters k is 15.867167196500622 and b is -77.47609299734376\n",
      "Iteration 5451, the loss is 5.5090914889539775, parameters k is 15.867304348674535 and b is -77.47709299734376\n",
      "Iteration 5452, the loss is 5.5091438244802236, parameters k is 15.867441500848448 and b is -77.47809299734377\n",
      "Iteration 5453, the loss is 5.509196160006476, parameters k is 15.867578653022361 and b is -77.47909299734377\n",
      "Iteration 5454, the loss is 5.50924849553273, parameters k is 15.867715805196275 and b is -77.48009299734377\n",
      "Iteration 5455, the loss is 5.509300831058977, parameters k is 15.867852957370188 and b is -77.48109299734378\n",
      "Iteration 5456, the loss is 5.509353166585233, parameters k is 15.8679901095441 and b is -77.48209299734378\n",
      "Iteration 5457, the loss is 5.509405502111481, parameters k is 15.868127261718014 and b is -77.48309299734379\n",
      "Iteration 5458, the loss is 5.509457837637728, parameters k is 15.868264413891927 and b is -77.4840929973438\n",
      "Iteration 5459, the loss is 5.509510173163981, parameters k is 15.86840156606584 and b is -77.4850929973438\n",
      "Iteration 5460, the loss is 5.509562508690234, parameters k is 15.868538718239753 and b is -77.4860929973438\n",
      "Iteration 5461, the loss is 5.509614844216477, parameters k is 15.868675870413666 and b is -77.48709299734381\n",
      "Iteration 5462, the loss is 5.509667179742734, parameters k is 15.86881302258758 and b is -77.48809299734381\n",
      "Iteration 5463, the loss is 5.509719515268983, parameters k is 15.868950174761492 and b is -77.48909299734382\n",
      "Iteration 5464, the loss is 5.509771850795234, parameters k is 15.869087326935405 and b is -77.49009299734382\n",
      "Iteration 5465, the loss is 5.509824186321479, parameters k is 15.869224479109318 and b is -77.49109299734383\n",
      "Iteration 5466, the loss is 5.5098765218477315, parameters k is 15.869361631283232 and b is -77.49209299734383\n",
      "Iteration 5467, the loss is 5.509928857373985, parameters k is 15.869498783457145 and b is -77.49309299734384\n",
      "Iteration 5468, the loss is 5.509981192900235, parameters k is 15.869635935631058 and b is -77.49409299734384\n",
      "Iteration 5469, the loss is 5.5100335284264865, parameters k is 15.86977308780497 and b is -77.49509299734385\n",
      "Iteration 5470, the loss is 5.510085863952739, parameters k is 15.869910239978884 and b is -77.49609299734385\n",
      "Iteration 5471, the loss is 5.5101381994789875, parameters k is 15.870047392152797 and b is -77.49709299734386\n",
      "Iteration 5472, the loss is 5.510190535005243, parameters k is 15.87018454432671 and b is -77.49809299734386\n",
      "Iteration 5473, the loss is 5.51024287053149, parameters k is 15.870321696500623 and b is -77.49909299734387\n",
      "Iteration 5474, the loss is 5.510295206057732, parameters k is 15.870458848674536 and b is -77.50009299734387\n",
      "Iteration 5475, the loss is 5.510347541583983, parameters k is 15.87059600084845 and b is -77.50109299734387\n",
      "Iteration 5476, the loss is 5.510399877110237, parameters k is 15.870733153022362 and b is -77.50209299734388\n",
      "Iteration 5477, the loss is 5.5104522126364905, parameters k is 15.870870305196275 and b is -77.50309299734388\n",
      "Iteration 5478, the loss is 5.510504548162739, parameters k is 15.871007457370188 and b is -77.50409299734389\n",
      "Iteration 5479, the loss is 5.510556883689, parameters k is 15.871144609544102 and b is -77.5050929973439\n",
      "Iteration 5480, the loss is 5.510609219215239, parameters k is 15.871281761718015 and b is -77.5060929973439\n",
      "Iteration 5481, the loss is 5.510661554741491, parameters k is 15.871418913891928 and b is -77.5070929973439\n",
      "Iteration 5482, the loss is 5.510713890267742, parameters k is 15.87155606606584 and b is -77.50809299734391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5483, the loss is 5.5107662257939936, parameters k is 15.871693218239754 and b is -77.50909299734391\n",
      "Iteration 5484, the loss is 5.510818561320243, parameters k is 15.871830370413667 and b is -77.51009299734392\n",
      "Iteration 5485, the loss is 5.510870896846492, parameters k is 15.87196752258758 and b is -77.51109299734392\n",
      "Iteration 5486, the loss is 5.510923232372746, parameters k is 15.872104674761493 and b is -77.51209299734393\n",
      "Iteration 5487, the loss is 5.510975567898998, parameters k is 15.872241826935406 and b is -77.51309299734393\n",
      "Iteration 5488, the loss is 5.511027903425246, parameters k is 15.87237897910932 and b is -77.51409299734394\n",
      "Iteration 5489, the loss is 5.511080238951494, parameters k is 15.872516131283232 and b is -77.51509299734394\n",
      "Iteration 5490, the loss is 5.511132574477743, parameters k is 15.872653283457145 and b is -77.51609299734395\n",
      "Iteration 5491, the loss is 5.511184910003998, parameters k is 15.872790435631059 and b is -77.51709299734395\n",
      "Iteration 5492, the loss is 5.511237245530247, parameters k is 15.872927587804972 and b is -77.51809299734396\n",
      "Iteration 5493, the loss is 5.5112895810565, parameters k is 15.873064739978885 and b is -77.51909299734396\n",
      "Iteration 5494, the loss is 5.511341916582749, parameters k is 15.873201892152798 and b is -77.52009299734397\n",
      "Iteration 5495, the loss is 5.511394252108995, parameters k is 15.87333904432671 and b is -77.52109299734397\n",
      "Iteration 5496, the loss is 5.511446587635249, parameters k is 15.873476196500624 and b is -77.52209299734398\n",
      "Iteration 5497, the loss is 5.511498923161502, parameters k is 15.873613348674537 and b is -77.52309299734398\n",
      "Iteration 5498, the loss is 5.5115512586877475, parameters k is 15.87375050084845 and b is -77.52409299734398\n",
      "Iteration 5499, the loss is 5.511603594213993, parameters k is 15.873887653022363 and b is -77.52509299734399\n",
      "Iteration 5500, the loss is 5.511655929740248, parameters k is 15.874024805196276 and b is -77.526092997344\n",
      "Iteration 5501, the loss is 5.511708265266498, parameters k is 15.87416195737019 and b is -77.527092997344\n",
      "Iteration 5502, the loss is 5.511760600792757, parameters k is 15.874299109544102 and b is -77.528092997344\n",
      "Iteration 5503, the loss is 5.511812936319005, parameters k is 15.874436261718015 and b is -77.52909299734401\n",
      "Iteration 5504, the loss is 5.511865271845253, parameters k is 15.874573413891929 and b is -77.53009299734401\n",
      "Iteration 5505, the loss is 5.511917607371504, parameters k is 15.874710566065842 and b is -77.53109299734402\n",
      "Iteration 5506, the loss is 5.51196994289776, parameters k is 15.874847718239755 and b is -77.53209299734402\n",
      "Iteration 5507, the loss is 5.512022278424009, parameters k is 15.874984870413668 and b is -77.53309299734403\n",
      "Iteration 5508, the loss is 5.512074613950258, parameters k is 15.87512202258758 and b is -77.53409299734403\n",
      "Iteration 5509, the loss is 5.512126949476506, parameters k is 15.875259174761494 and b is -77.53509299734404\n",
      "Iteration 5510, the loss is 5.512179285002753, parameters k is 15.875396326935407 and b is -77.53609299734404\n",
      "Iteration 5511, the loss is 5.512231620529008, parameters k is 15.87553347910932 and b is -77.53709299734405\n",
      "Iteration 5512, the loss is 5.512283956055261, parameters k is 15.875670631283233 and b is -77.53809299734405\n",
      "Iteration 5513, the loss is 5.512336291581509, parameters k is 15.875807783457146 and b is -77.53909299734406\n",
      "Iteration 5514, the loss is 5.512388627107758, parameters k is 15.87594493563106 and b is -77.54009299734406\n",
      "Iteration 5515, the loss is 5.512440962634014, parameters k is 15.876082087804972 and b is -77.54109299734407\n",
      "Iteration 5516, the loss is 5.512493298160261, parameters k is 15.876219239978886 and b is -77.54209299734407\n",
      "Iteration 5517, the loss is 5.512545633686512, parameters k is 15.876356392152799 and b is -77.54309299734408\n",
      "Iteration 5518, the loss is 5.512597969212772, parameters k is 15.876493544326712 and b is -77.54409299734408\n",
      "Iteration 5519, the loss is 5.512650304739013, parameters k is 15.876630696500625 and b is -77.54509299734409\n",
      "Iteration 5520, the loss is 5.512702640265264, parameters k is 15.876767848674538 and b is -77.54609299734409\n",
      "Iteration 5521, the loss is 5.512754975791511, parameters k is 15.876905000848451 and b is -77.5470929973441\n",
      "Iteration 5522, the loss is 5.512807311317763, parameters k is 15.877042153022364 and b is -77.5480929973441\n",
      "Iteration 5523, the loss is 5.512859646844011, parameters k is 15.877179305196277 and b is -77.5490929973441\n",
      "Iteration 5524, the loss is 5.5129119823702695, parameters k is 15.87731645737019 and b is -77.55009299734411\n",
      "Iteration 5525, the loss is 5.512964317896513, parameters k is 15.877453609544103 and b is -77.55109299734411\n",
      "Iteration 5526, the loss is 5.513016653422765, parameters k is 15.877590761718016 and b is -77.55209299734412\n",
      "Iteration 5527, the loss is 5.513068988949023, parameters k is 15.87772791389193 and b is -77.55309299734412\n",
      "Iteration 5528, the loss is 5.5131213244752635, parameters k is 15.877865066065842 and b is -77.55409299734413\n",
      "Iteration 5529, the loss is 5.5131736600015175, parameters k is 15.878002218239756 and b is -77.55509299734413\n",
      "Iteration 5530, the loss is 5.513225995527772, parameters k is 15.878139370413669 and b is -77.55609299734414\n",
      "Iteration 5531, the loss is 5.51327833105402, parameters k is 15.878276522587582 and b is -77.55709299734414\n",
      "Iteration 5532, the loss is 5.513330666580268, parameters k is 15.878413674761495 and b is -77.55809299734415\n",
      "Iteration 5533, the loss is 5.513383002106519, parameters k is 15.878550826935408 and b is -77.55909299734415\n",
      "Iteration 5534, the loss is 5.513435337632769, parameters k is 15.878687979109321 and b is -77.56009299734416\n",
      "Iteration 5535, the loss is 5.513487673159022, parameters k is 15.878825131283234 and b is -77.56109299734416\n",
      "Iteration 5536, the loss is 5.5135400086852755, parameters k is 15.878962283457147 and b is -77.56209299734417\n",
      "Iteration 5537, the loss is 5.513592344211523, parameters k is 15.87909943563106 and b is -77.56309299734417\n",
      "Iteration 5538, the loss is 5.513644679737777, parameters k is 15.879236587804973 and b is -77.56409299734418\n",
      "Iteration 5539, the loss is 5.513697015264018, parameters k is 15.879373739978886 and b is -77.56509299734418\n",
      "Iteration 5540, the loss is 5.513749350790275, parameters k is 15.8795108921528 and b is -77.56609299734419\n",
      "Iteration 5541, the loss is 5.513801686316519, parameters k is 15.879648044326713 and b is -77.56709299734419\n",
      "Iteration 5542, the loss is 5.513854021842778, parameters k is 15.879785196500626 and b is -77.5680929973442\n",
      "Iteration 5543, the loss is 5.513906357369023, parameters k is 15.879922348674539 and b is -77.5690929973442\n",
      "Iteration 5544, the loss is 5.513958692895276, parameters k is 15.880059500848452 and b is -77.5700929973442\n",
      "Iteration 5545, the loss is 5.514011028421526, parameters k is 15.880196653022365 and b is -77.57109299734421\n",
      "Iteration 5546, the loss is 5.514063363947779, parameters k is 15.880333805196278 and b is -77.57209299734421\n",
      "Iteration 5547, the loss is 5.514115699474026, parameters k is 15.880470957370191 and b is -77.57309299734422\n",
      "Iteration 5548, the loss is 5.514168035000274, parameters k is 15.880608109544104 and b is -77.57409299734422\n",
      "Iteration 5549, the loss is 5.51422037052653, parameters k is 15.880745261718017 and b is -77.57509299734423\n",
      "Iteration 5550, the loss is 5.514272706052776, parameters k is 15.88088241389193 and b is -77.57609299734423\n",
      "Iteration 5551, the loss is 5.514325041579029, parameters k is 15.881019566065843 and b is -77.57709299734424\n",
      "Iteration 5552, the loss is 5.51437737710528, parameters k is 15.881156718239756 and b is -77.57809299734424\n",
      "Iteration 5553, the loss is 5.514429712631533, parameters k is 15.88129387041367 and b is -77.57909299734425\n",
      "Iteration 5554, the loss is 5.514482048157779, parameters k is 15.881431022587583 and b is -77.58009299734425\n",
      "Iteration 5555, the loss is 5.514534383684031, parameters k is 15.881568174761496 and b is -77.58109299734426\n",
      "Iteration 5556, the loss is 5.514586719210286, parameters k is 15.881705326935409 and b is -77.58209299734426\n",
      "Iteration 5557, the loss is 5.514639054736538, parameters k is 15.881842479109322 and b is -77.58309299734427\n",
      "Iteration 5558, the loss is 5.5146913902627865, parameters k is 15.881979631283235 and b is -77.58409299734427\n",
      "Iteration 5559, the loss is 5.514743725789033, parameters k is 15.882116783457148 and b is -77.58509299734428\n",
      "Iteration 5560, the loss is 5.514796061315287, parameters k is 15.882253935631061 and b is -77.58609299734428\n",
      "Iteration 5561, the loss is 5.514848396841539, parameters k is 15.882391087804974 and b is -77.58709299734429\n",
      "Iteration 5562, the loss is 5.514900732367794, parameters k is 15.882528239978887 and b is -77.58809299734429\n",
      "Iteration 5563, the loss is 5.514953067894041, parameters k is 15.8826653921528 and b is -77.5890929973443\n",
      "Iteration 5564, the loss is 5.515005403420288, parameters k is 15.882802544326713 and b is -77.5900929973443\n",
      "Iteration 5565, the loss is 5.515057738946541, parameters k is 15.882939696500626 and b is -77.5910929973443\n",
      "Iteration 5566, the loss is 5.5151100744727914, parameters k is 15.88307684867454 and b is -77.59209299734431\n",
      "Iteration 5567, the loss is 5.515162409999035, parameters k is 15.883214000848453 and b is -77.59309299734431\n",
      "Iteration 5568, the loss is 5.515214745525294, parameters k is 15.883351153022366 and b is -77.59409299734432\n",
      "Iteration 5569, the loss is 5.51526708105154, parameters k is 15.883488305196279 and b is -77.59509299734432\n",
      "Iteration 5570, the loss is 5.515319416577783, parameters k is 15.883625457370192 and b is -77.59609299734433\n",
      "Iteration 5571, the loss is 5.515371752104039, parameters k is 15.883762609544105 and b is -77.59709299734433\n",
      "Iteration 5572, the loss is 5.515424087630288, parameters k is 15.883899761718018 and b is -77.59809299734434\n",
      "Iteration 5573, the loss is 5.515476423156537, parameters k is 15.884036913891931 and b is -77.59909299734434\n",
      "Iteration 5574, the loss is 5.515528758682791, parameters k is 15.884174066065844 and b is -77.60009299734435\n",
      "Iteration 5575, the loss is 5.515581094209043, parameters k is 15.884311218239757 and b is -77.60109299734435\n",
      "Iteration 5576, the loss is 5.5156334297352965, parameters k is 15.88444837041367 and b is -77.60209299734436\n",
      "Iteration 5577, the loss is 5.515685765261547, parameters k is 15.884585522587583 and b is -77.60309299734436\n",
      "Iteration 5578, the loss is 5.515738100787791, parameters k is 15.884722674761496 and b is -77.60409299734437\n",
      "Iteration 5579, the loss is 5.515790436314048, parameters k is 15.88485982693541 and b is -77.60509299734437\n",
      "Iteration 5580, the loss is 5.515842771840295, parameters k is 15.884996979109323 and b is -77.60609299734438\n",
      "Iteration 5581, the loss is 5.515895107366546, parameters k is 15.885134131283236 and b is -77.60709299734438\n",
      "Iteration 5582, the loss is 5.5159474428928, parameters k is 15.885271283457149 and b is -77.60809299734439\n",
      "Iteration 5583, the loss is 5.515999778419048, parameters k is 15.885408435631062 and b is -77.60909299734439\n",
      "Iteration 5584, the loss is 5.516052113945295, parameters k is 15.885545587804975 and b is -77.6100929973444\n",
      "Iteration 5585, the loss is 5.516104449471551, parameters k is 15.885682739978888 and b is -77.6110929973444\n",
      "Iteration 5586, the loss is 5.516156784997799, parameters k is 15.885819892152801 and b is -77.6120929973444\n",
      "Iteration 5587, the loss is 5.5162091205240475, parameters k is 15.885957044326714 and b is -77.61309299734441\n",
      "Iteration 5588, the loss is 5.516261456050297, parameters k is 15.886094196500627 and b is -77.61409299734441\n",
      "Iteration 5589, the loss is 5.51631379157655, parameters k is 15.88623134867454 and b is -77.61509299734442\n",
      "Iteration 5590, the loss is 5.516366127102796, parameters k is 15.886368500848453 and b is -77.61609299734442\n",
      "Iteration 5591, the loss is 5.516418462629053, parameters k is 15.886505653022367 and b is -77.61709299734443\n",
      "Iteration 5592, the loss is 5.5164707981553045, parameters k is 15.88664280519628 and b is -77.61809299734443\n",
      "Iteration 5593, the loss is 5.516523133681553, parameters k is 15.886779957370193 and b is -77.61909299734444\n",
      "Iteration 5594, the loss is 5.516575469207804, parameters k is 15.886917109544106 and b is -77.62009299734444\n",
      "Iteration 5595, the loss is 5.516627804734055, parameters k is 15.887054261718019 and b is -77.62109299734445\n",
      "Iteration 5596, the loss is 5.516680140260308, parameters k is 15.887191413891932 and b is -77.62209299734445\n",
      "Iteration 5597, the loss is 5.516732475786559, parameters k is 15.887328566065845 and b is -77.62309299734446\n",
      "Iteration 5598, the loss is 5.5167848113127995, parameters k is 15.887465718239758 and b is -77.62409299734446\n",
      "Iteration 5599, the loss is 5.516837146839054, parameters k is 15.887602870413671 and b is -77.62509299734447\n",
      "Iteration 5600, the loss is 5.516889482365305, parameters k is 15.887740022587584 and b is -77.62609299734447\n",
      "Iteration 5601, the loss is 5.516941817891555, parameters k is 15.887877174761497 and b is -77.62709299734448\n",
      "Iteration 5602, the loss is 5.516994153417802, parameters k is 15.88801432693541 and b is -77.62809299734448\n",
      "Iteration 5603, the loss is 5.517046488944061, parameters k is 15.888151479109323 and b is -77.62909299734449\n",
      "Iteration 5604, the loss is 5.517098824470306, parameters k is 15.888288631283237 and b is -77.63009299734449\n",
      "Iteration 5605, the loss is 5.517151159996556, parameters k is 15.88842578345715 and b is -77.6310929973445\n",
      "Iteration 5606, the loss is 5.517203495522814, parameters k is 15.888562935631063 and b is -77.6320929973445\n",
      "Iteration 5607, the loss is 5.517255831049068, parameters k is 15.888700087804976 and b is -77.6330929973445\n",
      "Iteration 5608, the loss is 5.517308166575315, parameters k is 15.888837239978889 and b is -77.63409299734451\n",
      "Iteration 5609, the loss is 5.517360502101568, parameters k is 15.888974392152802 and b is -77.63509299734451\n",
      "Iteration 5610, the loss is 5.517412837627814, parameters k is 15.889111544326715 and b is -77.63609299734452\n",
      "Iteration 5611, the loss is 5.517465173154063, parameters k is 15.889248696500628 and b is -77.63709299734452\n",
      "Iteration 5612, the loss is 5.517517508680319, parameters k is 15.889385848674541 and b is -77.63809299734453\n",
      "Iteration 5613, the loss is 5.517569844206567, parameters k is 15.889523000848454 and b is -77.63909299734453\n",
      "Iteration 5614, the loss is 5.517622179732819, parameters k is 15.889660153022367 and b is -77.64009299734454\n",
      "Iteration 5615, the loss is 5.5176745152590625, parameters k is 15.88979730519628 and b is -77.64109299734454\n",
      "Iteration 5616, the loss is 5.517726850785312, parameters k is 15.889934457370193 and b is -77.64209299734455\n",
      "Iteration 5617, the loss is 5.517779186311566, parameters k is 15.890071609544107 and b is -77.64309299734455\n",
      "Iteration 5618, the loss is 5.517831521837809, parameters k is 15.89020876171802 and b is -77.64409299734456\n",
      "Iteration 5619, the loss is 5.517883857364074, parameters k is 15.890345913891933 and b is -77.64509299734456\n",
      "Iteration 5620, the loss is 5.517936192890321, parameters k is 15.890483066065846 and b is -77.64609299734457\n",
      "Iteration 5621, the loss is 5.517988528416566, parameters k is 15.890620218239759 and b is -77.64709299734457\n",
      "Iteration 5622, the loss is 5.5180408639428205, parameters k is 15.890757370413672 and b is -77.64809299734458\n",
      "Iteration 5623, the loss is 5.518093199469065, parameters k is 15.890894522587585 and b is -77.64909299734458\n",
      "Iteration 5624, the loss is 5.518145534995321, parameters k is 15.891031674761498 and b is -77.65009299734459\n",
      "Iteration 5625, the loss is 5.518197870521567, parameters k is 15.891168826935411 and b is -77.65109299734459\n",
      "Iteration 5626, the loss is 5.518250206047822, parameters k is 15.891305979109324 and b is -77.6520929973446\n",
      "Iteration 5627, the loss is 5.518302541574075, parameters k is 15.891443131283237 and b is -77.6530929973446\n",
      "Iteration 5628, the loss is 5.518354877100325, parameters k is 15.89158028345715 and b is -77.6540929973446\n",
      "Iteration 5629, the loss is 5.5184072126265695, parameters k is 15.891717435631064 and b is -77.65509299734461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5630, the loss is 5.518459548152824, parameters k is 15.891854587804977 and b is -77.65609299734462\n",
      "Iteration 5631, the loss is 5.518511883679078, parameters k is 15.89199173997889 and b is -77.65709299734462\n",
      "Iteration 5632, the loss is 5.518564219205327, parameters k is 15.892128892152803 and b is -77.65809299734462\n",
      "Iteration 5633, the loss is 5.518616554731571, parameters k is 15.892266044326716 and b is -77.65909299734463\n",
      "Iteration 5634, the loss is 5.518668890257823, parameters k is 15.892403196500629 and b is -77.66009299734463\n",
      "Iteration 5635, the loss is 5.518721225784072, parameters k is 15.892540348674542 and b is -77.66109299734464\n",
      "Iteration 5636, the loss is 5.518773561310326, parameters k is 15.892677500848455 and b is -77.66209299734464\n",
      "Iteration 5637, the loss is 5.518825896836576, parameters k is 15.892814653022368 and b is -77.66309299734465\n",
      "Iteration 5638, the loss is 5.518878232362831, parameters k is 15.892951805196281 and b is -77.66409299734465\n",
      "Iteration 5639, the loss is 5.518930567889074, parameters k is 15.893088957370194 and b is -77.66509299734466\n",
      "Iteration 5640, the loss is 5.518982903415328, parameters k is 15.893226109544107 and b is -77.66609299734466\n",
      "Iteration 5641, the loss is 5.519035238941576, parameters k is 15.89336326171802 and b is -77.66709299734467\n",
      "Iteration 5642, the loss is 5.519087574467831, parameters k is 15.893500413891934 and b is -77.66809299734467\n",
      "Iteration 5643, the loss is 5.519139909994077, parameters k is 15.893637566065847 and b is -77.66909299734468\n",
      "Iteration 5644, the loss is 5.519192245520328, parameters k is 15.89377471823976 and b is -77.67009299734468\n",
      "Iteration 5645, the loss is 5.519244581046585, parameters k is 15.893911870413673 and b is -77.67109299734469\n",
      "Iteration 5646, the loss is 5.519296916572834, parameters k is 15.894049022587586 and b is -77.67209299734469\n",
      "Iteration 5647, the loss is 5.519349252099086, parameters k is 15.894186174761499 and b is -77.6730929973447\n",
      "Iteration 5648, the loss is 5.519401587625332, parameters k is 15.894323326935412 and b is -77.6740929973447\n",
      "Iteration 5649, the loss is 5.519453923151587, parameters k is 15.894460479109325 and b is -77.6750929973447\n",
      "Iteration 5650, the loss is 5.519506258677833, parameters k is 15.894597631283238 and b is -77.67609299734471\n",
      "Iteration 5651, the loss is 5.519558594204079, parameters k is 15.894734783457151 and b is -77.67709299734472\n",
      "Iteration 5652, the loss is 5.519610929730334, parameters k is 15.894871935631064 and b is -77.67809299734472\n",
      "Iteration 5653, the loss is 5.519663265256587, parameters k is 15.895009087804977 and b is -77.67909299734472\n",
      "Iteration 5654, the loss is 5.519715600782838, parameters k is 15.89514623997889 and b is -77.68009299734473\n",
      "Iteration 5655, the loss is 5.519767936309092, parameters k is 15.895283392152804 and b is -77.68109299734473\n",
      "Iteration 5656, the loss is 5.519820271835341, parameters k is 15.895420544326717 and b is -77.68209299734474\n",
      "Iteration 5657, the loss is 5.519872607361592, parameters k is 15.89555769650063 and b is -77.68309299734474\n",
      "Iteration 5658, the loss is 5.519924942887843, parameters k is 15.895694848674543 and b is -77.68409299734475\n",
      "Iteration 5659, the loss is 5.519977278414093, parameters k is 15.895832000848456 and b is -77.68509299734475\n",
      "Iteration 5660, the loss is 5.520029613940341, parameters k is 15.895969153022369 and b is -77.68609299734476\n",
      "Iteration 5661, the loss is 5.52008194946659, parameters k is 15.896106305196282 and b is -77.68709299734476\n",
      "Iteration 5662, the loss is 5.520134284992844, parameters k is 15.896243457370195 and b is -77.68809299734477\n",
      "Iteration 5663, the loss is 5.520186620519093, parameters k is 15.896380609544108 and b is -77.68909299734477\n",
      "Iteration 5664, the loss is 5.5202389560453415, parameters k is 15.896517761718021 and b is -77.69009299734478\n",
      "Iteration 5665, the loss is 5.520291291571593, parameters k is 15.896654913891934 and b is -77.69109299734478\n",
      "Iteration 5666, the loss is 5.520343627097842, parameters k is 15.896792066065847 and b is -77.69209299734479\n",
      "Iteration 5667, the loss is 5.520395962624096, parameters k is 15.89692921823976 and b is -77.69309299734479\n",
      "Iteration 5668, the loss is 5.520448298150344, parameters k is 15.897066370413674 and b is -77.6940929973448\n",
      "Iteration 5669, the loss is 5.520500633676596, parameters k is 15.897203522587587 and b is -77.6950929973448\n",
      "Iteration 5670, the loss is 5.520552969202848, parameters k is 15.8973406747615 and b is -77.6960929973448\n",
      "Iteration 5671, the loss is 5.520605304729098, parameters k is 15.897477826935413 and b is -77.69709299734481\n",
      "Iteration 5672, the loss is 5.520657640255341, parameters k is 15.897614979109326 and b is -77.69809299734482\n",
      "Iteration 5673, the loss is 5.520709975781598, parameters k is 15.897752131283239 and b is -77.69909299734482\n",
      "Iteration 5674, the loss is 5.520762311307848, parameters k is 15.897889283457152 and b is -77.70009299734483\n",
      "Iteration 5675, the loss is 5.520814646834103, parameters k is 15.898026435631065 and b is -77.70109299734483\n",
      "Iteration 5676, the loss is 5.5208669823603485, parameters k is 15.898163587804978 and b is -77.70209299734483\n",
      "Iteration 5677, the loss is 5.5209193178866025, parameters k is 15.898300739978891 and b is -77.70309299734484\n",
      "Iteration 5678, the loss is 5.520971653412849, parameters k is 15.898437892152804 and b is -77.70409299734484\n",
      "Iteration 5679, the loss is 5.521023988939099, parameters k is 15.898575044326718 and b is -77.70509299734485\n",
      "Iteration 5680, the loss is 5.521076324465344, parameters k is 15.89871219650063 and b is -77.70609299734485\n",
      "Iteration 5681, the loss is 5.521128659991606, parameters k is 15.898849348674544 and b is -77.70709299734486\n",
      "Iteration 5682, the loss is 5.5211809955178515, parameters k is 15.898986500848457 and b is -77.70809299734486\n",
      "Iteration 5683, the loss is 5.521233331044103, parameters k is 15.89912365302237 and b is -77.70909299734487\n",
      "Iteration 5684, the loss is 5.521285666570354, parameters k is 15.899260805196283 and b is -77.71009299734487\n",
      "Iteration 5685, the loss is 5.5213380020966, parameters k is 15.899397957370196 and b is -77.71109299734488\n",
      "Iteration 5686, the loss is 5.521390337622854, parameters k is 15.899535109544109 and b is -77.71209299734488\n",
      "Iteration 5687, the loss is 5.521442673149107, parameters k is 15.899672261718022 and b is -77.71309299734489\n",
      "Iteration 5688, the loss is 5.521495008675355, parameters k is 15.899809413891935 and b is -77.71409299734489\n",
      "Iteration 5689, the loss is 5.521547344201608, parameters k is 15.899946566065848 and b is -77.7150929973449\n",
      "Iteration 5690, the loss is 5.5215996797278555, parameters k is 15.900083718239761 and b is -77.7160929973449\n",
      "Iteration 5691, the loss is 5.521652015254103, parameters k is 15.900220870413674 and b is -77.7170929973449\n",
      "Iteration 5692, the loss is 5.5217043507803565, parameters k is 15.900358022587588 and b is -77.71809299734491\n",
      "Iteration 5693, the loss is 5.52175668630661, parameters k is 15.9004951747615 and b is -77.71909299734492\n",
      "Iteration 5694, the loss is 5.521809021832857, parameters k is 15.900632326935414 and b is -77.72009299734492\n",
      "Iteration 5695, the loss is 5.521861357359111, parameters k is 15.900769479109327 and b is -77.72109299734493\n",
      "Iteration 5696, the loss is 5.521913692885359, parameters k is 15.90090663128324 and b is -77.72209299734493\n",
      "Iteration 5697, the loss is 5.521966028411608, parameters k is 15.901043783457153 and b is -77.72309299734493\n",
      "Iteration 5698, the loss is 5.522018363937853, parameters k is 15.901180935631066 and b is -77.72409299734494\n",
      "Iteration 5699, the loss is 5.522070699464114, parameters k is 15.90131808780498 and b is -77.72509299734494\n",
      "Iteration 5700, the loss is 5.522123034990367, parameters k is 15.901455239978892 and b is -77.72609299734495\n",
      "Iteration 5701, the loss is 5.52217537051661, parameters k is 15.901592392152805 and b is -77.72709299734495\n",
      "Iteration 5702, the loss is 5.522227706042868, parameters k is 15.901729544326718 and b is -77.72809299734496\n",
      "Iteration 5703, the loss is 5.522280041569114, parameters k is 15.901866696500631 and b is -77.72909299734496\n",
      "Iteration 5704, the loss is 5.522332377095364, parameters k is 15.902003848674545 and b is -77.73009299734497\n",
      "Iteration 5705, the loss is 5.5223847126216175, parameters k is 15.902141000848458 and b is -77.73109299734497\n",
      "Iteration 5706, the loss is 5.5224370481478715, parameters k is 15.90227815302237 and b is -77.73209299734498\n",
      "Iteration 5707, the loss is 5.5224893836741105, parameters k is 15.902415305196284 and b is -77.73309299734498\n",
      "Iteration 5708, the loss is 5.522541719200366, parameters k is 15.902552457370197 and b is -77.73409299734499\n",
      "Iteration 5709, the loss is 5.5225940547266195, parameters k is 15.90268960954411 and b is -77.73509299734499\n",
      "Iteration 5710, the loss is 5.522646390252867, parameters k is 15.902826761718023 and b is -77.736092997345\n",
      "Iteration 5711, the loss is 5.522698725779115, parameters k is 15.902963913891936 and b is -77.737092997345\n",
      "Iteration 5712, the loss is 5.522751061305363, parameters k is 15.90310106606585 and b is -77.738092997345\n",
      "Iteration 5713, the loss is 5.522803396831619, parameters k is 15.903238218239762 and b is -77.73909299734501\n",
      "Iteration 5714, the loss is 5.522855732357867, parameters k is 15.903375370413675 and b is -77.74009299734502\n",
      "Iteration 5715, the loss is 5.522908067884118, parameters k is 15.903512522587588 and b is -77.74109299734502\n",
      "Iteration 5716, the loss is 5.522960403410369, parameters k is 15.903649674761501 and b is -77.74209299734503\n",
      "Iteration 5717, the loss is 5.523012738936622, parameters k is 15.903786826935415 and b is -77.74309299734503\n",
      "Iteration 5718, the loss is 5.523065074462868, parameters k is 15.903923979109328 and b is -77.74409299734504\n",
      "Iteration 5719, the loss is 5.523117409989126, parameters k is 15.90406113128324 and b is -77.74509299734504\n",
      "Iteration 5720, the loss is 5.523169745515382, parameters k is 15.904198283457154 and b is -77.74609299734504\n",
      "Iteration 5721, the loss is 5.523222081041623, parameters k is 15.904335435631067 and b is -77.74709299734505\n",
      "Iteration 5722, the loss is 5.5232744165678715, parameters k is 15.90447258780498 and b is -77.74809299734505\n",
      "Iteration 5723, the loss is 5.5233267520941265, parameters k is 15.904609739978893 and b is -77.74909299734506\n",
      "Iteration 5724, the loss is 5.5233790876203805, parameters k is 15.904746892152806 and b is -77.75009299734506\n",
      "Iteration 5725, the loss is 5.523431423146628, parameters k is 15.90488404432672 and b is -77.75109299734507\n",
      "Iteration 5726, the loss is 5.523483758672878, parameters k is 15.905021196500632 and b is -77.75209299734507\n",
      "Iteration 5727, the loss is 5.523536094199126, parameters k is 15.905158348674545 and b is -77.75309299734508\n",
      "Iteration 5728, the loss is 5.5235884297253754, parameters k is 15.905295500848458 and b is -77.75409299734508\n",
      "Iteration 5729, the loss is 5.523640765251629, parameters k is 15.905432653022372 and b is -77.75509299734509\n",
      "Iteration 5730, the loss is 5.52369310077787, parameters k is 15.905569805196285 and b is -77.75609299734509\n",
      "Iteration 5731, the loss is 5.523745436304128, parameters k is 15.905706957370198 and b is -77.7570929973451\n",
      "Iteration 5732, the loss is 5.523797771830381, parameters k is 15.90584410954411 and b is -77.7580929973451\n",
      "Iteration 5733, the loss is 5.523850107356627, parameters k is 15.905981261718024 and b is -77.7590929973451\n",
      "Iteration 5734, the loss is 5.523902442882884, parameters k is 15.906118413891937 and b is -77.76009299734511\n",
      "Iteration 5735, the loss is 5.523954778409134, parameters k is 15.90625556606585 and b is -77.76109299734512\n",
      "Iteration 5736, the loss is 5.524007113935384, parameters k is 15.906392718239763 and b is -77.76209299734512\n",
      "Iteration 5737, the loss is 5.52405944946163, parameters k is 15.906529870413676 and b is -77.76309299734513\n",
      "Iteration 5738, the loss is 5.524111784987884, parameters k is 15.90666702258759 and b is -77.76409299734513\n",
      "Iteration 5739, the loss is 5.524164120514133, parameters k is 15.906804174761502 and b is -77.76509299734514\n",
      "Iteration 5740, the loss is 5.524216456040382, parameters k is 15.906941326935415 and b is -77.76609299734514\n",
      "Iteration 5741, the loss is 5.524268791566629, parameters k is 15.907078479109328 and b is -77.76709299734515\n",
      "Iteration 5742, the loss is 5.5243211270928825, parameters k is 15.907215631283242 and b is -77.76809299734515\n",
      "Iteration 5743, the loss is 5.524373462619134, parameters k is 15.907352783457155 and b is -77.76909299734515\n",
      "Iteration 5744, the loss is 5.5244257981453835, parameters k is 15.907489935631068 and b is -77.77009299734516\n",
      "Iteration 5745, the loss is 5.524478133671638, parameters k is 15.90762708780498 and b is -77.77109299734516\n",
      "Iteration 5746, the loss is 5.524530469197882, parameters k is 15.907764239978894 and b is -77.77209299734517\n",
      "Iteration 5747, the loss is 5.524582804724138, parameters k is 15.907901392152807 and b is -77.77309299734517\n",
      "Iteration 5748, the loss is 5.524635140250384, parameters k is 15.90803854432672 and b is -77.77409299734518\n",
      "Iteration 5749, the loss is 5.524687475776637, parameters k is 15.908175696500633 and b is -77.77509299734518\n",
      "Iteration 5750, the loss is 5.524739811302894, parameters k is 15.908312848674546 and b is -77.77609299734519\n",
      "Iteration 5751, the loss is 5.524792146829147, parameters k is 15.90845000084846 and b is -77.77709299734519\n",
      "Iteration 5752, the loss is 5.524844482355388, parameters k is 15.908587153022372 and b is -77.7780929973452\n",
      "Iteration 5753, the loss is 5.524896817881643, parameters k is 15.908724305196285 and b is -77.7790929973452\n",
      "Iteration 5754, the loss is 5.524949153407893, parameters k is 15.908861457370199 and b is -77.7800929973452\n",
      "Iteration 5755, the loss is 5.525001488934147, parameters k is 15.908998609544112 and b is -77.78109299734521\n",
      "Iteration 5756, the loss is 5.525053824460396, parameters k is 15.909135761718025 and b is -77.78209299734522\n",
      "Iteration 5757, the loss is 5.52510615998664, parameters k is 15.909272913891938 and b is -77.78309299734522\n",
      "Iteration 5758, the loss is 5.525158495512891, parameters k is 15.90941006606585 and b is -77.78409299734523\n",
      "Iteration 5759, the loss is 5.525210831039142, parameters k is 15.909547218239764 and b is -77.78509299734523\n",
      "Iteration 5760, the loss is 5.525263166565398, parameters k is 15.909684370413677 and b is -77.78609299734524\n",
      "Iteration 5761, the loss is 5.525315502091643, parameters k is 15.90982152258759 and b is -77.78709299734524\n",
      "Iteration 5762, the loss is 5.525367837617893, parameters k is 15.909958674761503 and b is -77.78809299734525\n",
      "Iteration 5763, the loss is 5.525420173144146, parameters k is 15.910095826935416 and b is -77.78909299734525\n",
      "Iteration 5764, the loss is 5.525472508670401, parameters k is 15.91023297910933 and b is -77.79009299734525\n",
      "Iteration 5765, the loss is 5.525524844196652, parameters k is 15.910370131283242 and b is -77.79109299734526\n",
      "Iteration 5766, the loss is 5.525577179722903, parameters k is 15.910507283457155 and b is -77.79209299734526\n",
      "Iteration 5767, the loss is 5.52562951524915, parameters k is 15.910644435631069 and b is -77.79309299734527\n",
      "Iteration 5768, the loss is 5.525681850775396, parameters k is 15.910781587804982 and b is -77.79409299734527\n",
      "Iteration 5769, the loss is 5.525734186301649, parameters k is 15.910918739978895 and b is -77.79509299734528\n",
      "Iteration 5770, the loss is 5.5257865218279, parameters k is 15.911055892152808 and b is -77.79609299734528\n",
      "Iteration 5771, the loss is 5.525838857354159, parameters k is 15.91119304432672 and b is -77.79709299734529\n",
      "Iteration 5772, the loss is 5.525891192880397, parameters k is 15.911330196500634 and b is -77.7980929973453\n",
      "Iteration 5773, the loss is 5.5259435284066525, parameters k is 15.911467348674547 and b is -77.7990929973453\n",
      "Iteration 5774, the loss is 5.525995863932902, parameters k is 15.91160450084846 and b is -77.8000929973453\n",
      "Iteration 5775, the loss is 5.5260481994591535, parameters k is 15.911741653022373 and b is -77.80109299734531\n",
      "Iteration 5776, the loss is 5.526100534985405, parameters k is 15.911878805196286 and b is -77.80209299734531\n",
      "Iteration 5777, the loss is 5.526152870511659, parameters k is 15.9120159573702 and b is -77.80309299734532\n",
      "Iteration 5778, the loss is 5.526205206037909, parameters k is 15.912153109544112 and b is -77.80409299734532\n",
      "Iteration 5779, the loss is 5.526257541564159, parameters k is 15.912290261718026 and b is -77.80509299734533\n",
      "Iteration 5780, the loss is 5.526309877090412, parameters k is 15.912427413891939 and b is -77.80609299734533\n",
      "Iteration 5781, the loss is 5.526362212616658, parameters k is 15.912564566065852 and b is -77.80709299734534\n",
      "Iteration 5782, the loss is 5.526414548142911, parameters k is 15.912701718239765 and b is -77.80809299734534\n",
      "Iteration 5783, the loss is 5.526466883669158, parameters k is 15.912838870413678 and b is -77.80909299734535\n",
      "Iteration 5784, the loss is 5.526519219195405, parameters k is 15.912976022587591 and b is -77.81009299734535\n",
      "Iteration 5785, the loss is 5.526571554721664, parameters k is 15.913113174761504 and b is -77.81109299734536\n",
      "Iteration 5786, the loss is 5.5266238902479055, parameters k is 15.913250326935417 and b is -77.81209299734536\n",
      "Iteration 5787, the loss is 5.526676225774156, parameters k is 15.91338747910933 and b is -77.81309299734536\n",
      "Iteration 5788, the loss is 5.526728561300406, parameters k is 15.913524631283243 and b is -77.81409299734537\n",
      "Iteration 5789, the loss is 5.526780896826664, parameters k is 15.913661783457156 and b is -77.81509299734537\n",
      "Iteration 5790, the loss is 5.526833232352909, parameters k is 15.91379893563107 and b is -77.81609299734538\n",
      "Iteration 5791, the loss is 5.526885567879161, parameters k is 15.913936087804982 and b is -77.81709299734538\n",
      "Iteration 5792, the loss is 5.526937903405411, parameters k is 15.914073239978896 and b is -77.81809299734539\n",
      "Iteration 5793, the loss is 5.526990238931661, parameters k is 15.914210392152809 and b is -77.8190929973454\n",
      "Iteration 5794, the loss is 5.527042574457916, parameters k is 15.914347544326722 and b is -77.8200929973454\n",
      "Iteration 5795, the loss is 5.52709490998416, parameters k is 15.914484696500635 and b is -77.8210929973454\n",
      "Iteration 5796, the loss is 5.527147245510412, parameters k is 15.914621848674548 and b is -77.82209299734541\n",
      "Iteration 5797, the loss is 5.527199581036664, parameters k is 15.914759000848461 and b is -77.82309299734541\n",
      "Iteration 5798, the loss is 5.527251916562916, parameters k is 15.914896153022374 and b is -77.82409299734542\n",
      "Iteration 5799, the loss is 5.527304252089163, parameters k is 15.915033305196287 and b is -77.82509299734542\n",
      "Iteration 5800, the loss is 5.527356587615413, parameters k is 15.9151704573702 and b is -77.82609299734543\n",
      "Iteration 5801, the loss is 5.527408923141669, parameters k is 15.915307609544113 and b is -77.82709299734543\n",
      "Iteration 5802, the loss is 5.527461258667921, parameters k is 15.915444761718026 and b is -77.82809299734544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5803, the loss is 5.5275135941941675, parameters k is 15.91558191389194 and b is -77.82909299734544\n",
      "Iteration 5804, the loss is 5.52756592972042, parameters k is 15.915719066065853 and b is -77.83009299734545\n",
      "Iteration 5805, the loss is 5.527618265246671, parameters k is 15.915856218239766 and b is -77.83109299734545\n",
      "Iteration 5806, the loss is 5.527670600772924, parameters k is 15.915993370413679 and b is -77.83209299734546\n",
      "Iteration 5807, the loss is 5.527722936299172, parameters k is 15.916130522587592 and b is -77.83309299734546\n",
      "Iteration 5808, the loss is 5.527775271825421, parameters k is 15.916267674761505 and b is -77.83409299734546\n",
      "Iteration 5809, the loss is 5.527827607351673, parameters k is 15.916404826935418 and b is -77.83509299734547\n",
      "Iteration 5810, the loss is 5.527879942877924, parameters k is 15.916541979109331 and b is -77.83609299734547\n",
      "Iteration 5811, the loss is 5.527932278404174, parameters k is 15.916679131283244 and b is -77.83709299734548\n",
      "Iteration 5812, the loss is 5.527984613930422, parameters k is 15.916816283457157 and b is -77.83809299734548\n",
      "Iteration 5813, the loss is 5.528036949456674, parameters k is 15.91695343563107 and b is -77.83909299734549\n",
      "Iteration 5814, the loss is 5.52808928498293, parameters k is 15.917090587804983 and b is -77.8400929973455\n",
      "Iteration 5815, the loss is 5.528141620509179, parameters k is 15.917227739978896 and b is -77.8410929973455\n",
      "Iteration 5816, the loss is 5.528193956035424, parameters k is 15.91736489215281 and b is -77.8420929973455\n",
      "Iteration 5817, the loss is 5.528246291561674, parameters k is 15.917502044326723 and b is -77.84309299734551\n",
      "Iteration 5818, the loss is 5.528298627087921, parameters k is 15.917639196500636 and b is -77.84409299734551\n",
      "Iteration 5819, the loss is 5.528350962614174, parameters k is 15.917776348674549 and b is -77.84509299734552\n",
      "Iteration 5820, the loss is 5.528403298140424, parameters k is 15.917913500848462 and b is -77.84609299734552\n",
      "Iteration 5821, the loss is 5.528455633666682, parameters k is 15.918050653022375 and b is -77.84709299734553\n",
      "Iteration 5822, the loss is 5.52850796919293, parameters k is 15.918187805196288 and b is -77.84809299734553\n",
      "Iteration 5823, the loss is 5.52856030471918, parameters k is 15.918324957370201 and b is -77.84909299734554\n",
      "Iteration 5824, the loss is 5.528612640245437, parameters k is 15.918462109544114 and b is -77.85009299734554\n",
      "Iteration 5825, the loss is 5.528664975771679, parameters k is 15.918599261718027 and b is -77.85109299734555\n",
      "Iteration 5826, the loss is 5.528717311297931, parameters k is 15.91873641389194 and b is -77.85209299734555\n",
      "Iteration 5827, the loss is 5.528769646824181, parameters k is 15.918873566065853 and b is -77.85309299734556\n",
      "Iteration 5828, the loss is 5.528821982350437, parameters k is 15.919010718239766 and b is -77.85409299734556\n",
      "Iteration 5829, the loss is 5.528874317876681, parameters k is 15.91914787041368 and b is -77.85509299734557\n",
      "Iteration 5830, the loss is 5.52892665340293, parameters k is 15.919285022587593 and b is -77.85609299734557\n",
      "Iteration 5831, the loss is 5.528978988929191, parameters k is 15.919422174761506 and b is -77.85709299734557\n",
      "Iteration 5832, the loss is 5.52903132445543, parameters k is 15.919559326935419 and b is -77.85809299734558\n",
      "Iteration 5833, the loss is 5.529084099062633, parameters k is 15.919696479109332 and b is -77.85909299734558\n",
      "Iteration 5834, the loss is 5.52913333221094, parameters k is 15.919857307172572 and b is -77.86009299734559\n",
      "Iteration 5835, the loss is 5.5291825653592435, parameters k is 15.920018135235813 and b is -77.8610929973456\n",
      "Iteration 5836, the loss is 5.52923179850755, parameters k is 15.920178963299053 and b is -77.8620929973456\n",
      "Iteration 5837, the loss is 5.529281031655853, parameters k is 15.920339791362293 and b is -77.8630929973456\n",
      "Iteration 5838, the loss is 5.5293302648041545, parameters k is 15.920500619425534 and b is -77.86409299734561\n",
      "Iteration 5839, the loss is 5.529379497952456, parameters k is 15.920661447488774 and b is -77.86509299734561\n",
      "Iteration 5840, the loss is 5.529428731100763, parameters k is 15.920822275552014 and b is -77.86609299734562\n",
      "Iteration 5841, the loss is 5.529477964249068, parameters k is 15.920983103615255 and b is -77.86709299734562\n",
      "Iteration 5842, the loss is 5.529527197397368, parameters k is 15.921143931678495 and b is -77.86809299734563\n",
      "Iteration 5843, the loss is 5.529576430545677, parameters k is 15.921304759741735 and b is -77.86909299734563\n",
      "Iteration 5844, the loss is 5.529625663693976, parameters k is 15.921465587804976 and b is -77.87009299734564\n",
      "Iteration 5845, the loss is 5.529674896842283, parameters k is 15.921626415868216 and b is -77.87109299734564\n",
      "Iteration 5846, the loss is 5.529724129990588, parameters k is 15.921787243931457 and b is -77.87209299734565\n",
      "Iteration 5847, the loss is 5.529773363138889, parameters k is 15.921948071994697 and b is -77.87309299734565\n",
      "Iteration 5848, the loss is 5.529822596287199, parameters k is 15.922108900057937 and b is -77.87409299734566\n",
      "Iteration 5849, the loss is 5.529871829435498, parameters k is 15.922269728121178 and b is -77.87509299734566\n",
      "Iteration 5850, the loss is 5.529921062583798, parameters k is 15.922430556184418 and b is -77.87609299734567\n",
      "Iteration 5851, the loss is 5.529970295732106, parameters k is 15.922591384247658 and b is -77.87709299734567\n",
      "Iteration 5852, the loss is 5.530019528880413, parameters k is 15.922752212310899 and b is -77.87809299734568\n",
      "Iteration 5853, the loss is 5.530068762028713, parameters k is 15.922913040374139 and b is -77.87909299734568\n",
      "Iteration 5854, the loss is 5.530117995177016, parameters k is 15.92307386843738 and b is -77.88009299734568\n",
      "Iteration 5855, the loss is 5.530167228325319, parameters k is 15.92323469650062 and b is -77.88109299734569\n",
      "Iteration 5856, the loss is 5.530216461473623, parameters k is 15.92339552456386 and b is -77.8820929973457\n",
      "Iteration 5857, the loss is 5.530265694621927, parameters k is 15.9235563526271 and b is -77.8830929973457\n",
      "Iteration 5858, the loss is 5.530314927770237, parameters k is 15.92371718069034 and b is -77.8840929973457\n",
      "Iteration 5859, the loss is 5.530364160918536, parameters k is 15.923878008753581 and b is -77.88509299734571\n",
      "Iteration 5860, the loss is 5.53041339406684, parameters k is 15.924038836816822 and b is -77.88609299734571\n",
      "Iteration 5861, the loss is 5.530462627215147, parameters k is 15.924199664880062 and b is -77.88709299734572\n",
      "Iteration 5862, the loss is 5.530511860363447, parameters k is 15.924360492943302 and b is -77.88809299734572\n",
      "Iteration 5863, the loss is 5.530561093511751, parameters k is 15.924521321006543 and b is -77.88909299734573\n",
      "Iteration 5864, the loss is 5.530610326660055, parameters k is 15.924682149069783 and b is -77.89009299734573\n",
      "Iteration 5865, the loss is 5.53065955980836, parameters k is 15.924842977133023 and b is -77.89109299734574\n",
      "Iteration 5866, the loss is 5.530708792956666, parameters k is 15.925003805196264 and b is -77.89209299734574\n",
      "Iteration 5867, the loss is 5.530758026104968, parameters k is 15.925164633259504 and b is -77.89309299734575\n",
      "Iteration 5868, the loss is 5.53080725925327, parameters k is 15.925325461322744 and b is -77.89409299734575\n",
      "Iteration 5869, the loss is 5.530856492401573, parameters k is 15.925486289385985 and b is -77.89509299734576\n",
      "Iteration 5870, the loss is 5.530905725549882, parameters k is 15.925647117449225 and b is -77.89609299734576\n",
      "Iteration 5871, the loss is 5.530954958698186, parameters k is 15.925807945512465 and b is -77.89709299734577\n",
      "Iteration 5872, the loss is 5.531004191846481, parameters k is 15.925968773575706 and b is -77.89809299734577\n",
      "Iteration 5873, the loss is 5.531053424994787, parameters k is 15.926129601638946 and b is -77.89909299734578\n",
      "Iteration 5874, the loss is 5.5311026581430935, parameters k is 15.926290429702187 and b is -77.90009299734578\n",
      "Iteration 5875, the loss is 5.531151891291392, parameters k is 15.926451257765427 and b is -77.90109299734578\n",
      "Iteration 5876, the loss is 5.531201124439702, parameters k is 15.926612085828667 and b is -77.90209299734579\n",
      "Iteration 5877, the loss is 5.531250357588007, parameters k is 15.926772913891908 and b is -77.9030929973458\n",
      "Iteration 5878, the loss is 5.531299590736308, parameters k is 15.926933741955148 and b is -77.9040929973458\n",
      "Iteration 5879, the loss is 5.531348823884617, parameters k is 15.927094570018388 and b is -77.9050929973458\n",
      "Iteration 5880, the loss is 5.531398057032915, parameters k is 15.927255398081629 and b is -77.90609299734581\n",
      "Iteration 5881, the loss is 5.531447290181221, parameters k is 15.927416226144869 and b is -77.90709299734581\n",
      "Iteration 5882, the loss is 5.531496523329528, parameters k is 15.92757705420811 and b is -77.90809299734582\n",
      "Iteration 5883, the loss is 5.531545756477826, parameters k is 15.92773788227135 and b is -77.90909299734582\n",
      "Iteration 5884, the loss is 5.531594989626134, parameters k is 15.92789871033459 and b is -77.91009299734583\n",
      "Iteration 5885, the loss is 5.53164422277443, parameters k is 15.92805953839783 and b is -77.91109299734583\n",
      "Iteration 5886, the loss is 5.531693455922745, parameters k is 15.92822036646107 and b is -77.91209299734584\n",
      "Iteration 5887, the loss is 5.531742689071045, parameters k is 15.928381194524311 and b is -77.91309299734584\n",
      "Iteration 5888, the loss is 5.531791922219348, parameters k is 15.928542022587552 and b is -77.91409299734585\n",
      "Iteration 5889, the loss is 5.531841155367651, parameters k is 15.928702850650792 and b is -77.91509299734585\n",
      "Iteration 5890, the loss is 5.531890388515956, parameters k is 15.928863678714032 and b is -77.91609299734586\n",
      "Iteration 5891, the loss is 5.531939621664259, parameters k is 15.929024506777273 and b is -77.91709299734586\n",
      "Iteration 5892, the loss is 5.531988854812561, parameters k is 15.929185334840513 and b is -77.91809299734587\n",
      "Iteration 5893, the loss is 5.532038087960865, parameters k is 15.929346162903753 and b is -77.91909299734587\n",
      "Iteration 5894, the loss is 5.5320873211091675, parameters k is 15.929506990966994 and b is -77.92009299734588\n",
      "Iteration 5895, the loss is 5.532136554257473, parameters k is 15.929667819030234 and b is -77.92109299734588\n",
      "Iteration 5896, the loss is 5.5321857874057745, parameters k is 15.929828647093474 and b is -77.92209299734589\n",
      "Iteration 5897, the loss is 5.532235020554086, parameters k is 15.929989475156715 and b is -77.92309299734589\n",
      "Iteration 5898, the loss is 5.53228425370239, parameters k is 15.930150303219955 and b is -77.9240929973459\n",
      "Iteration 5899, the loss is 5.532333486850691, parameters k is 15.930311131283196 and b is -77.9250929973459\n",
      "Iteration 5900, the loss is 5.532382719998997, parameters k is 15.930471959346436 and b is -77.9260929973459\n",
      "Iteration 5901, the loss is 5.532431953147295, parameters k is 15.930632787409676 and b is -77.92709299734591\n",
      "Iteration 5902, the loss is 5.532481186295608, parameters k is 15.930793615472917 and b is -77.92809299734591\n",
      "Iteration 5903, the loss is 5.532530419443905, parameters k is 15.930954443536157 and b is -77.92909299734592\n",
      "Iteration 5904, the loss is 5.5325796525922035, parameters k is 15.931115271599397 and b is -77.93009299734592\n",
      "Iteration 5905, the loss is 5.532628885740521, parameters k is 15.931276099662638 and b is -77.93109299734593\n",
      "Iteration 5906, the loss is 5.532678118888817, parameters k is 15.931436927725878 and b is -77.93209299734593\n",
      "Iteration 5907, the loss is 5.532727352037115, parameters k is 15.931597755789118 and b is -77.93309299734594\n",
      "Iteration 5908, the loss is 5.53277658518542, parameters k is 15.931758583852359 and b is -77.93409299734594\n",
      "Iteration 5909, the loss is 5.532825818333723, parameters k is 15.9319194119156 and b is -77.93509299734595\n",
      "Iteration 5910, the loss is 5.532875051482035, parameters k is 15.93208023997884 and b is -77.93609299734595\n",
      "Iteration 5911, the loss is 5.532924284630334, parameters k is 15.93224106804208 and b is -77.93709299734596\n",
      "Iteration 5912, the loss is 5.532973517778638, parameters k is 15.93240189610532 and b is -77.93809299734596\n",
      "Iteration 5913, the loss is 5.533022750926944, parameters k is 15.93256272416856 and b is -77.93909299734597\n",
      "Iteration 5914, the loss is 5.533071984075248, parameters k is 15.932723552231801 and b is -77.94009299734597\n",
      "Iteration 5915, the loss is 5.533121217223551, parameters k is 15.932884380295041 and b is -77.94109299734598\n",
      "Iteration 5916, the loss is 5.533170450371855, parameters k is 15.933045208358282 and b is -77.94209299734598\n",
      "Iteration 5917, the loss is 5.533219683520158, parameters k is 15.933206036421522 and b is -77.94309299734599\n",
      "Iteration 5918, the loss is 5.5332689166684625, parameters k is 15.933366864484762 and b is -77.94409299734599\n",
      "Iteration 5919, the loss is 5.53331814981677, parameters k is 15.933527692548003 and b is -77.945092997346\n",
      "Iteration 5920, the loss is 5.53336738296507, parameters k is 15.933688520611243 and b is -77.946092997346\n",
      "Iteration 5921, the loss is 5.533416616113375, parameters k is 15.933849348674483 and b is -77.947092997346\n",
      "Iteration 5922, the loss is 5.533465849261677, parameters k is 15.934010176737724 and b is -77.94809299734601\n",
      "Iteration 5923, the loss is 5.53351508240998, parameters k is 15.934171004800964 and b is -77.94909299734601\n",
      "Iteration 5924, the loss is 5.533564315558285, parameters k is 15.934331832864205 and b is -77.95009299734602\n",
      "Iteration 5925, the loss is 5.533613548706584, parameters k is 15.934492660927445 and b is -77.95109299734602\n",
      "Iteration 5926, the loss is 5.5336627818549005, parameters k is 15.934653488990685 and b is -77.95209299734603\n",
      "Iteration 5927, the loss is 5.533712015003198, parameters k is 15.934814317053926 and b is -77.95309299734603\n",
      "Iteration 5928, the loss is 5.533761248151496, parameters k is 15.934975145117166 and b is -77.95409299734604\n",
      "Iteration 5929, the loss is 5.533810481299809, parameters k is 15.935135973180406 and b is -77.95509299734604\n",
      "Iteration 5930, the loss is 5.533859714448108, parameters k is 15.935296801243647 and b is -77.95609299734605\n",
      "Iteration 5931, the loss is 5.533908947596416, parameters k is 15.935457629306887 and b is -77.95709299734605\n",
      "Iteration 5932, the loss is 5.533958180744714, parameters k is 15.935618457370127 and b is -77.95809299734606\n",
      "Iteration 5933, the loss is 5.534007413893021, parameters k is 15.935779285433368 and b is -77.95909299734606\n",
      "Iteration 5934, the loss is 5.53405664704132, parameters k is 15.935940113496608 and b is -77.96009299734607\n",
      "Iteration 5935, the loss is 5.534105880189636, parameters k is 15.936100941559848 and b is -77.96109299734607\n",
      "Iteration 5936, the loss is 5.534155113337932, parameters k is 15.936261769623089 and b is -77.96209299734608\n",
      "Iteration 5937, the loss is 5.534204346486235, parameters k is 15.93642259768633 and b is -77.96309299734608\n",
      "Iteration 5938, the loss is 5.534253579634547, parameters k is 15.93658342574957 and b is -77.96409299734609\n",
      "Iteration 5939, the loss is 5.534302812782838, parameters k is 15.93674425381281 and b is -77.96509299734609\n",
      "Iteration 5940, the loss is 5.534352045931156, parameters k is 15.93690508187605 and b is -77.9660929973461\n",
      "Iteration 5941, the loss is 5.534401279079449, parameters k is 15.93706590993929 and b is -77.9670929973461\n",
      "Iteration 5942, the loss is 5.534450512227756, parameters k is 15.937226738002531 and b is -77.9680929973461\n",
      "Iteration 5943, the loss is 5.534499745376059, parameters k is 15.937387566065771 and b is -77.96909299734611\n",
      "Iteration 5944, the loss is 5.534548978524363, parameters k is 15.937548394129012 and b is -77.97009299734611\n",
      "Iteration 5945, the loss is 5.534598211672666, parameters k is 15.937709222192252 and b is -77.97109299734612\n",
      "Iteration 5946, the loss is 5.5346474448209735, parameters k is 15.937870050255492 and b is -77.97209299734612\n",
      "Iteration 5947, the loss is 5.5346966779692774, parameters k is 15.938030878318733 and b is -77.97309299734613\n",
      "Iteration 5948, the loss is 5.534745911117574, parameters k is 15.938191706381973 and b is -77.97409299734613\n",
      "Iteration 5949, the loss is 5.53479514426588, parameters k is 15.938352534445213 and b is -77.97509299734614\n",
      "Iteration 5950, the loss is 5.534844377414182, parameters k is 15.938513362508454 and b is -77.97609299734614\n",
      "Iteration 5951, the loss is 5.534893610562493, parameters k is 15.938674190571694 and b is -77.97709299734615\n",
      "Iteration 5952, the loss is 5.534942843710796, parameters k is 15.938835018634935 and b is -77.97809299734615\n",
      "Iteration 5953, the loss is 5.534992076859092, parameters k is 15.938995846698175 and b is -77.97909299734616\n",
      "Iteration 5954, the loss is 5.535041310007401, parameters k is 15.939156674761415 and b is -77.98009299734616\n",
      "Iteration 5955, the loss is 5.535090543155708, parameters k is 15.939317502824656 and b is -77.98109299734617\n",
      "Iteration 5956, the loss is 5.5351397763040175, parameters k is 15.939478330887896 and b is -77.98209299734617\n",
      "Iteration 5957, the loss is 5.53518900945231, parameters k is 15.939639158951136 and b is -77.98309299734618\n",
      "Iteration 5958, the loss is 5.535238242600617, parameters k is 15.939799987014377 and b is -77.98409299734618\n",
      "Iteration 5959, the loss is 5.535287475748925, parameters k is 15.939960815077617 and b is -77.98509299734619\n",
      "Iteration 5960, the loss is 5.535336708897224, parameters k is 15.940121643140857 and b is -77.98609299734619\n",
      "Iteration 5961, the loss is 5.535385942045529, parameters k is 15.940282471204098 and b is -77.9870929973462\n",
      "Iteration 5962, the loss is 5.535435175193828, parameters k is 15.940443299267338 and b is -77.9880929973462\n",
      "Iteration 5963, the loss is 5.535484408342133, parameters k is 15.940604127330579 and b is -77.9890929973462\n",
      "Iteration 5964, the loss is 5.53553364149043, parameters k is 15.940764955393819 and b is -77.99009299734621\n",
      "Iteration 5965, the loss is 5.535582874638747, parameters k is 15.94092578345706 and b is -77.99109299734621\n",
      "Iteration 5966, the loss is 5.535632107787047, parameters k is 15.9410866115203 and b is -77.99209299734622\n",
      "Iteration 5967, the loss is 5.535681340935351, parameters k is 15.94124743958354 and b is -77.99309299734622\n",
      "Iteration 5968, the loss is 5.535730574083652, parameters k is 15.94140826764678 and b is -77.99409299734623\n",
      "Iteration 5969, the loss is 5.535779807231956, parameters k is 15.94156909571002 and b is -77.99509299734623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5970, the loss is 5.535829040380266, parameters k is 15.941729923773261 and b is -77.99609299734624\n",
      "Iteration 5971, the loss is 5.5358782735285645, parameters k is 15.941890751836501 and b is -77.99709299734624\n",
      "Iteration 5972, the loss is 5.535927506676877, parameters k is 15.942051579899742 and b is -77.99809299734625\n",
      "Iteration 5973, the loss is 5.535976739825176, parameters k is 15.942212407962982 and b is -77.99909299734625\n",
      "Iteration 5974, the loss is 5.5360259729734755, parameters k is 15.942373236026222 and b is -78.00009299734626\n",
      "Iteration 5975, the loss is 5.5360752061217795, parameters k is 15.942534064089463 and b is -78.00109299734626\n",
      "Iteration 5976, the loss is 5.536124439270086, parameters k is 15.942694892152703 and b is -78.00209299734627\n",
      "Iteration 5977, the loss is 5.53617367241839, parameters k is 15.942855720215944 and b is -78.00309299734627\n",
      "Iteration 5978, the loss is 5.536222905566696, parameters k is 15.943016548279184 and b is -78.00409299734628\n",
      "Iteration 5979, the loss is 5.536272138714997, parameters k is 15.943177376342424 and b is -78.00509299734628\n",
      "Iteration 5980, the loss is 5.5363213718633, parameters k is 15.943338204405665 and b is -78.00609299734629\n",
      "Iteration 5981, the loss is 5.5363706050116, parameters k is 15.943499032468905 and b is -78.00709299734629\n",
      "Iteration 5982, the loss is 5.536419838159908, parameters k is 15.943659860532145 and b is -78.0080929973463\n",
      "Iteration 5983, the loss is 5.536469071308222, parameters k is 15.943820688595386 and b is -78.0090929973463\n",
      "Iteration 5984, the loss is 5.536518304456517, parameters k is 15.943981516658626 and b is -78.0100929973463\n",
      "Iteration 5985, the loss is 5.536567537604819, parameters k is 15.944142344721866 and b is -78.01109299734631\n",
      "Iteration 5986, the loss is 5.536616770753121, parameters k is 15.944303172785107 and b is -78.01209299734631\n",
      "Iteration 5987, the loss is 5.536666003901424, parameters k is 15.944464000848347 and b is -78.01309299734632\n",
      "Iteration 5988, the loss is 5.536715237049729, parameters k is 15.944624828911587 and b is -78.01409299734632\n",
      "Iteration 5989, the loss is 5.536764470198038, parameters k is 15.944785656974828 and b is -78.01509299734633\n",
      "Iteration 5990, the loss is 5.5368137033463425, parameters k is 15.944946485038068 and b is -78.01609299734633\n",
      "Iteration 5991, the loss is 5.536862936494647, parameters k is 15.945107313101309 and b is -78.01709299734634\n",
      "Iteration 5992, the loss is 5.536912169642945, parameters k is 15.945268141164549 and b is -78.01809299734634\n",
      "Iteration 5993, the loss is 5.53696140279125, parameters k is 15.94542896922779 and b is -78.01909299734635\n",
      "Iteration 5994, the loss is 5.537010635939556, parameters k is 15.94558979729103 and b is -78.02009299734635\n",
      "Iteration 5995, the loss is 5.537059869087854, parameters k is 15.94575062535427 and b is -78.02109299734636\n",
      "Iteration 5996, the loss is 5.5371091022361645, parameters k is 15.94591145341751 and b is -78.02209299734636\n",
      "Iteration 5997, the loss is 5.537158335384466, parameters k is 15.94607228148075 and b is -78.02309299734637\n",
      "Iteration 5998, the loss is 5.537207568532768, parameters k is 15.946233109543991 and b is -78.02409299734637\n",
      "Iteration 5999, the loss is 5.537256801681075, parameters k is 15.946393937607231 and b is -78.02509299734638\n"
     ]
    }
   ],
   "source": [
    "#initialized parameters\n",
    "\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "iteration_num = 6000 \n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    \n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    \n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    \n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    \n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x218d1f0b7b8>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_num)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x218d1f20f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y)\n",
    "plt.scatter(X_rm,price_use_current_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平方loss 是按指数级下降； 绝对值loss是线性下降  \n",
    "平方loss收敛更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
